[{"title":"082-天文摄影软件(PPIP,AS3,RS6)汉化教程","date":"2023-08-04T19:35:21.000Z","path":"2023/08/04/localization/","text":"这是坚持技术写作计划（含翻译）的第 82 篇，定个小目标 999。 本文有点偏，最近入坑摄影，拍月亮接触了一些天文摄影软件，但是英文的，就想着汉化下，看着顺眼（当然网上有别人汉化好的） 对于 PPIP 和 AS3,RS6 不熟悉的，可以参考 富人靠装备，穷人靠后期: 如何用 400 块的镜头给月亮拍大头贴 本文不讨论三个软件的用法，仅仅讲解如何自己汉化这三个软件（网上一堆别人汉化过的，如果不介意，可以直接百度自行下载） PS sequator（需科学上网） 用此方法汉化失败（可能是加壳了） Radialix 3 或者 Sisulizer 4因为 PPIP，AS，RS 本身都没有做防护，汉化起来比较简单，这俩软件都可以，看自己喜好了 下载 Radialix 3 参考 汉化入门教程（绝对适合新手） 下载 Sisulizer 4 授权码 LAENT628901447012574111 参考 【新手向】三分钟学会软件汉化，谁都看得懂 汉化 PPIP下载 ppip-2.5.9（需科学上网）并安装。 下载 .NET 反编译调试软件 dnSpy 用法参考 神器如 dnSpy，无需源码也能修改 .NET 程序 Ctrl+O 打开 PPIP.exe 文件 Ctrl+Shift+K 搜索关键字 （注意改成数字/字符串选项，勾选区分大小写），比如 About 双击搜索结果，Ctrl+Shift+E 编辑方法 把 this.aboutToolStripMenuItem.Text = &quot;About&quot;; 改成 this.aboutToolStripMenuItem.Text = &quot;关于&quot;; 点击右下角 编译 剩下的就是体力活了 汉化 AutoStakkert3(AKA AS3)下载 AutoStakkert_3.1.4_x64.zip 并解压 运行 Radialix 3 或者 Sisulizer 4 ，本文以 Sisulizer 4 为例 基本上一路下一步就行，创建后，记得保存工程 注意第一步是右键选中，选择属性，第四步，原来默认是 &lt;sl&gt;/&lt;file&gt; 也就是在根目录创建 zh/AutoStakkert.exe 这样会找不到 dll 文件，改成 &lt;sl&gt;&lt;file&gt; 也就是 zh/AutoStakkert.exe 剩下的就是体力活了+1 汉化 RegiStax 6 (AKA RS6)下载并安装 RegiStax 6 依然以 Sisulizer 4 为例 忽略创建工程步骤，基本上还是一路下一步 注意跟汉化 AS3 一样 ，设置属性，改成 &lt;sl&gt;&lt;file&gt; 剩下的就是体力活了+2 招聘小广告山东济南的小伙伴欢迎投简历啊 加入我们 , 一起搞事情。长期招聘，Java 程序员，大数据工程师，运维工程师，前端工程师。 参考资料 我的博客 我的掘金","tags":[{"name":"汉化","slug":"汉化","permalink":"https://anjia0532.github.io/tags/汉化/"}]},{"title":"081-hutool httputil 集成 sentinel 和 seata","date":"2023-07-18T12:35:21.000Z","path":"2023/07/18/hutool-sentinel-seata/","text":"这是坚持技术写作计划（含翻译）的第 81 篇，定个小目标 999 篇。 首先声明，不建议在生产中使用 hutool httputil 因为他没有线程池，性能较差，扩展性差。如果你已经用了 spring boot/ spring cloud 那可以用开箱即用的声明式 http 库，比如 forest 或者 feign , 重度使用的话，可以用老牌的 httpclient 或者 okhttp 等。 但是如果前期团队内部对此没有硬性要求，导致已经已经有历史包袱的情况下，又得上 sentinel 或者 seata 等框架。就得对其进行非侵入式改造了。 Hutool 拦截器Hutool 5.8.0.M2+ 以后增加了 GlobalInterceptor.addRequestInterceptor、GlobalInterceptor.addResponseInterceptor 和 HttpRequest.addInterceptor 参见 使用 hutool 的 http 工具后，如何统一处理 Request 和 Response #2217 记录 httputil 请求日志@Value(\"$&#123;hutool.http.print-log:false&#125;\")private boolean hutoolHttpPrintLogEnabled;// 打印 hutool http 请求和响应数据if (hutoolHttpPrintLogEnabled) &#123; GlobalInterceptor.INSTANCE.addRequestInterceptor((req) -&gt; &#123; log.info(\"hutool http 请求 url: &#123;&#125;, method: &#123;&#125;, headers: &#123;&#125;, form: &#123;&#125;, body: &#123;&#125;\", req.getUrl(), req.getMethod().name(), req.headers(), req.form(), StrUtil.str(req.bodyBytes(), req.charset())); &#125;); GlobalInterceptor.INSTANCE.addResponseInterceptor((resp) -&gt; &#123; log.info(\"hutool http 响应 headers: &#123;&#125;, body: &#123;&#125;\", resp.headers(), StrUtil.str(resp.bodyBytes(), resp.charset())); &#125;);&#125; 集成 seata@Value(\"$&#123;seata.enabled:false&#125;\")private boolean seataEnabled;// seataif (seataEnabled) &#123; GlobalInterceptor.INSTANCE.addRequestInterceptor((req) -&gt; &#123; req.header(RootContext.KEY_XID, RootContext.getXID()); &#125;);&#125; 集成 sentinel@Value(\"$&#123;spring.cloud.sentinel.enabled:false&#125;\")private boolean sentinelEnabled;// sentinelif (sentinelEnabled) &#123; GlobalInterceptor.INSTANCE.addRequestInterceptor((req) -&gt; &#123; try &#123; // 抹去参数，只保留 url Entry entry = SphU.entry(req.getMethod().name().toUpperCase() + \":\" + StringUtils.substringBefore(req.getUrl(), \"?\")); ContextUtil.getContext().setCurEntry(entry); &#125; catch (BlockException e) &#123; log.error(\"Sentinel 触发流控快速失败\", e); throw new ApiException(\"触发流控快速失败\"); &#125; &#125;); GlobalInterceptor.INSTANCE.addResponseInterceptor((resp) -&gt; &#123; ContextUtil.getContext().getCurEntry().exit(); &#125;);&#125; 然后自己写个 configuration 类，把代码塞进去就行了。 招聘小广告山东济南的小伙伴欢迎投简历啊 加入我们 , 一起搞事情。长期招聘，Java 程序员，大数据工程师，运维工程师，前端工程师。 参考资料 我的博客 我的掘金","tags":[{"name":"hutool","slug":"hutool","permalink":"https://anjia0532.github.io/tags/hutool/"},{"name":"sentinel","slug":"sentinel","permalink":"https://anjia0532.github.io/tags/sentinel/"},{"name":"seata","slug":"seata","permalink":"https://anjia0532.github.io/tags/seata/"}]},{"title":"080-RKE2自动更新K8S证书","date":"2023-01-09T19:35:21.000Z","path":"2023/01/09/rke2-renew-certs/","text":"这是坚持技术写作计划（含翻译）的第 80 篇，定个小目标 999，每周最少 2 篇。 本文主要讲解 Rancher RKE2 自动更新 K8S 证书。 背景介绍RKE2 和 RKE ,K3S 一样，是 Rancher 系列的 K8S 发行版之一。 根据官方文档 高级选项和配置#证书轮转 介绍，RKE2 证书默认是 12 个月有效期，过期之前 90 天内，重启 service(rke2-server 或者 rke2-agent) 将自动轮转证书。 在 v1.21.8+rke2r1 及以上版本，支持手动显示轮转证书。 不重启 service 或者早于过期之前 90 天重启，都不会触发证书轮转。 新手很容易忽略这个问题，等遇到时，往往已经发生故障了。记忆深刻那种。 如何操作# 查询单个节点k8s证书有效期date --date=\"$(openssl s_client -showcerts -connect localhost:6443 &lt; /dev/null | openssl x509 -enddate -noout|cut -d= -f 2)\" --iso-8601# 查询单个节点k8s证书还有多少天过期echo $(( ($(date --date=\"$(openssl s_client -showcerts -connect localhost:6443 &lt; /dev/null | openssl x509 -enddate -noout|cut -d= -f 2)\" +%s) - $(date +%s) )/(60*60*24) ))# 查看 rke2-server 节点证书啥时候过期for pem in /var/lib/rancher/rke2/server/tls/*.crt; do printf '%s: %s\\n' \\ \"$(date --date=\"$(openssl x509 -enddate -noout -in \"$pem\"|cut -d= -f 2)\" --iso-8601)\" \\ \"$pem\"done | sort# 查看 rke2-agent 节点证书啥时候过期for pem in /var/lib/rancher/rke2/agent/*.crt; do printf '%s: %s\\n' \\ \"$(date --date=\"$(openssl x509 -enddate -noout -in \"$pem\"|cut -d= -f 2)\" --iso-8601)\" \\ \"$pem\"done | sort 为了简化操作，编写了 bash 脚本（注意目前仅在 Ubuntu 20.04 LTS 测试通过，其他发行版请自行测试） #!/usr/bin/env bash# author anjia0532@gmail.com# blog https://anjia0532.github.io/# github https://github.com/anjia0532RED='\\033[0;31m'NC='\\033[0m' # No Colorusage () &#123; echo -e \"$&#123;RED&#125; Renew certs of k8s cluster Usage : $0 &#123;OPTIONS&#125; -d &lt; days between 1 and 90 e.g. 70 &gt; $&#123;NC&#125;\";&#125;# parse argswhile getopts \"d:\" opts; do case $&#123;opts&#125; in d) DAYS=$&#123;OPTARG&#125; ;; *) usage; exit;; esacdone# those args must be not nullif [ ! \"$DAYS\" ]then usage exit 1fi# in batches to restart serviceRANDOM_DAYS=$((1 + $RANDOM % 10))echo -e \"Max days is $&#123;RED&#125;$&#123;DAYS&#125;$&#123;NC&#125;, will plus $&#123;RED&#125;$&#123;RANDOM_DAYS&#125; days$&#123;NC&#125;\"DAYS=$((DAYS+RANDOM_DAYS))echo -e \"Max days is $&#123;RED&#125;$&#123;DAYS&#125;$&#123;NC&#125;\"if [ \"$DAYS\" -gt 90 ]thenecho -e \"Max days &gt; 90, Must be set it to 90\"DAYS=90fi# days between 1 and 90if [ \"$DAYS\" -gt 90 ] || [ \"$DAYS\" -lt 1 ]then usage exit 1fiEXPIRE_DAYS=$(( ($(date --date=\"$(openssl s_client -showcerts -connect localhost:6443 &lt; /dev/null | openssl x509 -enddate -noout|cut -d= -f 2)\" +%s) - $(date +%s) )/(60*60*24) ))SERVICE_NAME=$(systemctl --type=service --state=running | grep rke2 | awk '&#123;print $1&#125;')if [ $EXPIRE_DAYS -gt $&#123;DAYS&#125; ]then echo -e \"K8S certs will expire after $&#123;RED&#125; $&#123;EXPIRE_DAYS&#125; days &gt; $&#123;DAYS&#125; days , skip renew $&#123;NC&#125;\"else echo -e \"K8S certs will expire after $&#123;RED&#125; $&#123;EXPIRE_DAYS&#125; days &lt;= $&#123;DAYS&#125; days , will be restart $&#123;SERVICE_NAME&#125; to renew certs $&#123;NC&#125;\"fi[[ $EXPIRE_DAYS -le $&#123;DAYS&#125; ]] &amp;&amp; ( echo -e \"\\n sudo systemctl restart $&#123;SERVICE_NAME&#125;\" &amp;&amp; sudo systemctl restart $&#123;SERVICE_NAME&#125;) 将上面脚本保存成 k8s_renew_certs.sh chmod +x k8s_renew_certs.sh./k8s_renew_certs.sh -h Renew certs of k8s cluster Usage : /etc/rancher/k8s_renew_certs.sh &#123;OPTIONS&#125; -d &lt; days between 1 and 90 e.g. 70 &gt; -d设置过期天数，大于 1 小于该值则会重启，比如如果 20 天内过期则重启，该值为 20， rke2 在 90 天内，重启 service 会自动轮转证书，所以该值需要 1 &lt; days &lt; 90，大于 90 的会强制改成 90 为了防止定时任务统一时间全部重启，可能导致服务不稳定，加了随机种子, -d+random[1,10],比如-d 90, 则强制为 90-d 88, 如果随机数是 1，则实际是 89，如果随机数大于等于 2，强制为 90-d 70, 则 70+[1,10] 最终范围为 [71,80]-d 0 ,报错退出 脚本会自动判断是 rke2-server 还是 rke2-agent rke2-canal 报错failed to setup network for sandbox &quot;xxxxx&quot;: error getting ClusterInformation: connection is unauthorized: Unauthorized kubectl rollout restart ds rke2-canal -n kube-system 参考 RKE2 ContainerNetwork interface ( Not able to create any running pods anymore) #3425 招聘小广告山东济南的小伙伴欢迎投简历啊 加入我们 , 一起搞事情。长期招聘，Java 程序员，大数据工程师，运维工程师，前端工程师。 参考资料 我的博客 我的掘金","tags":[{"name":"k8s","slug":"k8s","permalink":"https://anjia0532.github.io/tags/k8s/"},{"name":"容器","slug":"容器","permalink":"https://anjia0532.github.io/tags/容器/"},{"name":"kubernetes","slug":"kubernetes","permalink":"https://anjia0532.github.io/tags/kubernetes/"},{"name":"云原生","slug":"云原生","permalink":"https://anjia0532.github.io/tags/云原生/"}]},{"title":"079-自定义Rke2 Containerd Config.toml 支持 V2 规范","date":"2022-09-27T19:35:21.000Z","path":"2022/09/27/rke2-containerd-config-v2/","text":"这是坚持技术写作计划（含翻译）的第 79 篇，定个小目标 999，每周最少 2 篇。 之前 Rancher 集群比较老 v2.6.5，当时的 rke2 stable 版本是 v1.21.12+rke2r1，而这个版本的 Containerd 是v1.4.13-k3s1 而 Containerd 在 1.5.x 之前只支持单镜像库加速，在 1.5.x 后支持多镜像库加速（文档 Registry Configuration）。 因业务需要，给集群升级 Rancher 版本到 v2.6.8 ,Rke2 升级到 v1.24.4+rke2r1 。集群升级不是本文重点，不多描述。本文主要讲解升级后如何 自定义 rke2 的 /var/lib/rancher/rke2/agent/etc/containerd/config.toml 实现 v2 规范。比如 多镜像库通过一个 d7y 集群加速(通过 header 区分)。 根据 Rke2 文档 Advanced Options and Configuration &gt; Configuring containerd 可知，官方支持通过创建 /var/lib/rancher/rke2/agent/etc/containerd/config.toml.tmpl来自定义生成 /var/lib/rancher/rke2/agent/etc/containerd/config.toml /var/lib/rancher/rke2/agent/etc/containerd/config.toml.tmpl 如下 version = 2[plugins.\"io.containerd.internal.v1.opt\"] path = \"&#123;&#123; .NodeConfig.Containerd.Opt &#125;&#125;\"[plugins.\"io.containerd.grpc.v1.cri\"] stream_server_address = \"127.0.0.1\" stream_server_port = \"10010\" enable_selinux = &#123;&#123; .NodeConfig.SELinux &#125;&#125; enable_unprivileged_ports = &#123;&#123; .EnableUnprivileged &#125;&#125; enable_unprivileged_icmp = &#123;&#123; .EnableUnprivileged &#125;&#125;&#123;&#123;- if .DisableCgroup&#125;&#125; disable_cgroup = true&#123;&#123;end&#125;&#125;&#123;&#123;- if .IsRunningInUserNS &#125;&#125; disable_apparmor = true restrict_oom_score_adj = true&#123;&#123;end&#125;&#125;&#123;&#123;- if .NodeConfig.AgentConfig.PauseImage &#125;&#125; sandbox_image = \"&#123;&#123; .NodeConfig.AgentConfig.PauseImage &#125;&#125;\"&#123;&#123;end&#125;&#125;&#123;&#123;- if .NodeConfig.AgentConfig.Snapshotter &#125;&#125;[plugins.\"io.containerd.grpc.v1.cri\".containerd] snapshotter = \"&#123;&#123; .NodeConfig.AgentConfig.Snapshotter &#125;&#125;\" disable_snapshot_annotations = &#123;&#123; if eq .NodeConfig.AgentConfig.Snapshotter \"stargz\" &#125;&#125;false&#123;&#123;else&#125;&#125;true&#123;&#123;end&#125;&#125;&#123;&#123; if eq .NodeConfig.AgentConfig.Snapshotter \"stargz\" &#125;&#125;&#123;&#123; if .NodeConfig.AgentConfig.ImageServiceSocket &#125;&#125;[plugins.stargz]cri_keychain_image_service_path = \"&#123;&#123; .NodeConfig.AgentConfig.ImageServiceSocket &#125;&#125;\"[plugins.stargz.cri_keychain]enable_keychain = true&#123;&#123;end&#125;&#125;&#123;&#123; if .PrivateRegistryConfig &#125;&#125;&#123;&#123; if .PrivateRegistryConfig.Mirrors &#125;&#125;[plugins.stargz.registry.mirrors]&#123;&#123;end&#125;&#125;&#123;&#123;range $k, $v := .PrivateRegistryConfig.Mirrors &#125;&#125;[plugins.stargz.registry.mirrors.\"&#123;&#123;$k&#125;&#125;\"] endpoint = [&#123;&#123;range $i, $j := $v.Endpoints&#125;&#125;&#123;&#123;if $i&#125;&#125;, &#123;&#123;end&#125;&#125;&#123;&#123;printf \"%q\" .&#125;&#125;&#123;&#123;end&#125;&#125;]&#123;&#123;if $v.Rewrites&#125;&#125; [plugins.stargz.registry.mirrors.\"&#123;&#123;$k&#125;&#125;\".rewrite]&#123;&#123;range $pattern, $replace := $v.Rewrites&#125;&#125; \"&#123;&#123;$pattern&#125;&#125;\" = \"&#123;&#123;$replace&#125;&#125;\"&#123;&#123;end&#125;&#125;&#123;&#123;end&#125;&#125;&#123;&#123;end&#125;&#125;&#123;&#123;range $k, $v := .PrivateRegistryConfig.Configs &#125;&#125;&#123;&#123; if $v.Auth &#125;&#125;[plugins.stargz.registry.configs.\"&#123;&#123;$k&#125;&#125;\".auth] &#123;&#123; if $v.Auth.Username &#125;&#125;username = &#123;&#123; printf \"%q\" $v.Auth.Username &#125;&#125;&#123;&#123;end&#125;&#125; &#123;&#123; if $v.Auth.Password &#125;&#125;password = &#123;&#123; printf \"%q\" $v.Auth.Password &#125;&#125;&#123;&#123;end&#125;&#125; &#123;&#123; if $v.Auth.Auth &#125;&#125;auth = &#123;&#123; printf \"%q\" $v.Auth.Auth &#125;&#125;&#123;&#123;end&#125;&#125; &#123;&#123; if $v.Auth.IdentityToken &#125;&#125;identitytoken = &#123;&#123; printf \"%q\" $v.Auth.IdentityToken &#125;&#125;&#123;&#123;end&#125;&#125;&#123;&#123;end&#125;&#125;&#123;&#123; if $v.TLS &#125;&#125;[plugins.stargz.registry.configs.\"&#123;&#123;$k&#125;&#125;\".tls] &#123;&#123; if $v.TLS.CAFile &#125;&#125;ca_file = \"&#123;&#123; $v.TLS.CAFile &#125;&#125;\"&#123;&#123;end&#125;&#125; &#123;&#123; if $v.TLS.CertFile &#125;&#125;cert_file = \"&#123;&#123; $v.TLS.CertFile &#125;&#125;\"&#123;&#123;end&#125;&#125; &#123;&#123; if $v.TLS.KeyFile &#125;&#125;key_file = \"&#123;&#123; $v.TLS.KeyFile &#125;&#125;\"&#123;&#123;end&#125;&#125; &#123;&#123; if $v.TLS.InsecureSkipVerify &#125;&#125;insecure_skip_verify = true&#123;&#123;end&#125;&#125;&#123;&#123;end&#125;&#125;&#123;&#123;end&#125;&#125;&#123;&#123;end&#125;&#125;&#123;&#123;end&#125;&#125;&#123;&#123;end&#125;&#125;&#123;&#123;- if not .NodeConfig.NoFlannel &#125;&#125;[plugins.\"io.containerd.grpc.v1.cri\".cni] bin_dir = \"&#123;&#123; .NodeConfig.AgentConfig.CNIBinDir &#125;&#125;\" conf_dir = \"&#123;&#123; .NodeConfig.AgentConfig.CNIConfDir &#125;&#125;\"&#123;&#123;end&#125;&#125;[plugins.\"io.containerd.grpc.v1.cri\".containerd.runtimes.runc] runtime_type = \"io.containerd.runc.v2\"[plugins.\"io.containerd.grpc.v1.cri\".containerd.runtimes.runc.options] SystemdCgroup = &#123;&#123; .SystemdCgroup &#125;&#125;&#123;&#123; if .PrivateRegistryConfig &#125;&#125;[plugins.\"io.containerd.grpc.v1.cri\".registry] config_path = \"/var/lib/rancher/rke2/agent/etc/containerd/certs.d\"&#123;&#123;range $k, $v := .PrivateRegistryConfig.Configs &#125;&#125;&#123;&#123; if $v.Auth &#125;&#125;[plugins.\"io.containerd.grpc.v1.cri\".registry.configs.\"&#123;&#123;$k&#125;&#125;\".auth] &#123;&#123; if $v.Auth.Username &#125;&#125;username = &#123;&#123; printf \"%q\" $v.Auth.Username &#125;&#125;&#123;&#123;end&#125;&#125; &#123;&#123; if $v.Auth.Password &#125;&#125;password = &#123;&#123; printf \"%q\" $v.Auth.Password &#125;&#125;&#123;&#123;end&#125;&#125; &#123;&#123; if $v.Auth.Auth &#125;&#125;auth = &#123;&#123; printf \"%q\" $v.Auth.Auth &#125;&#125;&#123;&#123;end&#125;&#125; &#123;&#123; if $v.Auth.IdentityToken &#125;&#125;identitytoken = &#123;&#123; printf \"%q\" $v.Auth.IdentityToken &#125;&#125;&#123;&#123;end&#125;&#125;&#123;&#123;end&#125;&#125;&#123;&#123; if $v.TLS &#125;&#125;[plugins.\"io.containerd.grpc.v1.cri\".registry.configs.\"&#123;&#123;$k&#125;&#125;\".tls] &#123;&#123; if $v.TLS.CAFile &#125;&#125;ca_file = \"&#123;&#123; $v.TLS.CAFile &#125;&#125;\"&#123;&#123;end&#125;&#125; &#123;&#123; if $v.TLS.CertFile &#125;&#125;cert_file = \"&#123;&#123; $v.TLS.CertFile &#125;&#125;\"&#123;&#123;end&#125;&#125; &#123;&#123; if $v.TLS.KeyFile &#125;&#125;key_file = \"&#123;&#123; $v.TLS.KeyFile &#125;&#125;\"&#123;&#123;end&#125;&#125; &#123;&#123; if $v.TLS.InsecureSkipVerify &#125;&#125;insecure_skip_verify = true&#123;&#123;end&#125;&#125;&#123;&#123;end&#125;&#125;&#123;&#123;end&#125;&#125;&#123;&#123;end&#125;&#125;&#123;&#123;range $k, $v := .ExtraRuntimes&#125;&#125;[plugins.\"io.containerd.grpc.v1.cri\".containerd.runtimes.\"&#123;&#123;$k&#125;&#125;\"] runtime_type = \"&#123;&#123;$v.RuntimeType&#125;&#125;\"[plugins.\"io.containerd.grpc.v1.cri\".containerd.runtimes.\"&#123;&#123;$k&#125;&#125;\".options] BinaryName = \"&#123;&#123;$v.BinaryName&#125;&#125;\"&#123;&#123;end&#125;&#125; 如果要配置 RKE2 的镜像仓库，参考 Containerd Registry Configuration/etc/rancher/rke2/registries.yaml配置如下所示： mirrors: docker.io: endpoint: - \"http://127.0.0.1:65001\" registry.example.com: endpoint: - \"http://127.0.0.1:65001\" 创建 registry 目录 # 如果有镜像库配置，则创建 /var/lib/rancher/rke2/agent/etc/containerd/certs.d 目录sudo mkdir -p /var/lib/rancher/rke2/agent/etc/containerd/certs.d/# 或者也可以用下面这行 一次性创建 docker.io,ghcr.io,quay.io 等子目录sudo mkdir -p /var/lib/rancher/rke2/agent/etc/containerd/certs.d/&#123;docker.io,ghcr.io,quay.io&#125;# 根据 https://github.com/containerd/containerd/blob/main/docs/hosts.md 创建 hosts.toml 文件 如果用了 d7y ,也可以直接用他的脚本 wget https://github.com/dragonflyoss/Dragonfly2/blob/main/hack/gen-containerd-hosts.shchmod +x gen-containerd-hosts.shsudo CONTAINED_CONFIG_DIR=/var/lib/rancher/rke2/agent/etc/containerd/certs.d/ gen-containerd-hosts.sh docker.iosudo cat /var/lib/rancher/rke2/agent/etc/containerd/certs.d/docker.io/hosts.tomlserver = \"https://docker.io\"[host.\"http://127.0.0.1:65001\"] capabilities = [\"pull\", \"resolve\"] [host.\"http://127.0.0.1:65001\".header] X-Dragonfly-Registry = [\"https://docker.io\"] 最后别忘了 restart rke2-server 或者 rke2-agent。 校验下是否生效 # 查看 mirrors 和 configs.auth 是否生效sudo /var/lib/rancher/rke2/bin/crictl --config=/var/lib/rancher/rke2/agent/etc/crictl.yaml info# 拉取镜像sudo /var/lib/rancher/rke2/bin/crictl --config=/var/lib/rancher/rke2/agent/etc/crictl.yaml -D pull nginx:alpine# 查看日志，是否走镜像加速器sudo tail -f /var/lib/rancher/rke2/agent/containerd/containerd.log 招聘小广告山东济南的小伙伴欢迎投简历啊 加入我们 , 一起搞事情。长期招聘，Java 程序员，大数据工程师，运维工程师，前端工程师。 参考资料 我的博客 我的掘金","tags":[{"name":"k8s","slug":"k8s","permalink":"https://anjia0532.github.io/tags/k8s/"},{"name":"rancher","slug":"rancher","permalink":"https://anjia0532.github.io/tags/rancher/"},{"name":"rke","slug":"rke","permalink":"https://anjia0532.github.io/tags/rke/"},{"name":"containerd","slug":"containerd","permalink":"https://anjia0532.github.io/tags/containerd/"},{"name":"rke2","slug":"rke2","permalink":"https://anjia0532.github.io/tags/rke2/"}]},{"title":"078-Lua远程调试(以Apisix,Redis为例)","date":"2022-08-29T19:35:21.000Z","path":"2022/08/29/lua-debug/","text":"这是坚持技术写作计划（含翻译）的第 78 篇，定个小目标 999，每周最少 2 篇。 Lua 是一门轻量级类 C 高性能脚本语言，广泛用于 游戏领域，Redis 自定义脚本，Nginx 系(openresty,kong,apisix 等)，wireshark 的脚本，wrk 压测的脚本，路由器(比如 openwrt ), 物联网领域（比如 nodemcu,PlatformIO,OpenMQTTGateway,tasmota 等）,游戏领域没有涉猎。其他列出的方面都多多少少接触过，写过 lua 代码。 lua 的语法教程不是本文的重点，可以网上搜索，比如 LUA 简明教程 本文主要以 Apisix(Nginx 系) 和 Redis 两个为例，讲解如何进行断点调试，而不是 Print 大法来逮 bug。 安装 Redis如果是 Mac/Linux 那可以去 https://redis.io/download/#redis-stack-downloads 下载对应的系统，或者从源代码编译。 如果是 Windows ,并且是 Windows 10+，可以用 windows 子系统功能，安装 Linux 版本 Redis。或者在 Windows 上安装 Docker。 如果是 低版本 Windows。只能安装网上提供的低版本(好像是 redis 3 和 4) 的非官方版本的 Redis（最新 GA 是 6.x 预览版是 7.x） 本文一律采用 Docker 方式进行演示。对于 Docker 基础知识不做介绍，不了解可以去网上搜索相关内容。 # docker run --name redis-6-demo -p6379:6379 -d redis:6-alpine redis-server# docker psCONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES713c1863c29e redis:6-alpine \"docker-entrypoint.s…\" 53 seconds ago Up 52 seconds 0.0.0.0:6379-&gt;6379/tcp,&lt;/div&gt;6379-&gt;6379/tcp redis-6-demo 常用 Redis GUI 工具 https://redis.com/redis-enterprise/redis-insight/ https://github.com/uglide/RedisDesktopManager https://github.com/qishibo/AnotherRedisDesktopManager Redis 官方也有调试工具 LDB，参考 Debugging Lua scripts in Redis Redis 为啥要用 Lua 减少网络开销。可以将多个请求通过脚本的形式一次发送，减少网络时延。 原子操作。Redis 会将整个脚本作为一个整体执行，中间不会被其他请求插入。因此在脚本运行过程中无需担心会出现竞态条件，无需使用事务。 复用。客户端发送的脚本会永久存在 redis 中，这样其他客户端可以复用这一脚本，而不需要使用代码完成相同的逻辑。 Java 系的 Redis 库 redisson/redisson 大量用了 Lua ，可以参考，借鉴一下。 安装并配置 ZeroBrane Studio下载 ZeroBrane Studio 到本地并解压。 下载 ZeroBranePackage/master/redis.lua 并保存到 /path/to/zerobranestudio/packages/ 目录下。 启动 ZB Studio -&gt; Project -&gt; Lua Interpreter -&gt; Redis创建 demo.lua local key = KEYS[1]local val = ARGV[1]redis.call(\"set\", key, val)val = redis.call(\"get\", key)return val 使用 ZB Studio 调试 Redis Lua Scripts在 Project -&gt; Command Line Parameters... 添加参数，注意参数用英文,分隔，前后加空格,也就是 key空格,空格value 点击 Project-&gt; Start Debugging 或者直接按快进键 F5 启动调试。Step Into(F10) 没有函数时跟 Step Over(Shift + F10) 一样，都是执行下一步。区别是，遇到函数时，Step Into 会进入函数内部，Step Over 会将函数当成一步. 安装 Apisix为了简化步骤，本文以 docker-compose 安装为例。文件结构如下所示 .├── config.yaml├── docker-compose.yaml└── plugins └── usr └── local └── apisix └── apisix └── plugins ├── example.lua └── mobdebug.lua 下载 https://raw.githubusercontent.com/pkulchenko/MobDebug/master/src/mobdebug.lua 保存到 ./plugins/usr/local/apisix/apisix/plugins文件夹下 config.yaml apisix: node_listen: 9080 # APISIX listening port enable_ipv6: false allow_admin: # http://nginx.org/en/docs/http/ngx_http_access_module.html#allow - 0.0.0.0/0 # We need to restrict ip access rules for security. 0.0.0.0/0 is for test. admin_key: - name: \"admin\" key: edd1c9f034335f136f87ad84b625c8f1 role: admin # admin: manage all configuration data # viewer: only can view configuration data - name: \"viewer\" key: 4054f7cf07e344346cd3f287985e76a2 role: viewer enable_control: true control: ip: \"0.0.0.0\" port: 9092etcd: host: # it's possible to define multiple etcd hosts addresses of the same etcd cluster. - \"http://etcd:2379\" # multiple etcd address prefix: \"/apisix\" # apisix configurations prefix timeout: 30 # 30 secondsplugins: - example example.lua local plugin_name = \"example\"local core = require(\"apisix.core\")local mobdebug = require(\"apisix.plugins.mobdebug\")local schema = &#123; type = \"object\", properties = &#123;&#125;&#125;local _M = &#123; version = 0.1, priority = 0, name = plugin_name, schema = schema&#125;function _M.check_schema(conf) return core.schema.check(schema, conf)endfunction _M.access(conf, ctx) -- 把 192.168.xx.xxx 换成 idea 运行主机 ip mobdebug.start(\"192.168.xx.xxx\", 8172) core.log.warn(core.json.encode(conf))endreturn _M 注意更换 192.168.xx.xxx为实际 ip更多 Apisix 插件开发信息，详见 插件开发 docker-compose.yaml version: \"3\"services: apisix: image: apache/apisix:2.15.0-alpine restart: always volumes: - ./config.yaml:/usr/local/apisix/conf/config.yaml:ro - ./plugins/usr/local/apisix/apisix/plugins/example.lua:/usr/local/apisix/apisix/plugins/example.lua:ro - ./plugins/usr/local/apisix/apisix/plugins/mobdebug.lua:/usr/local/apisix/apisix/plugins/mobdebug.lua:ro depends_on: - etcd ports: - \"9080:9080/tcp\" - \"9091:9091/tcp\" - \"9443:9443/tcp\" - \"9092:9092/tcp\" networks: apisix: etcd: image: bitnami/etcd:3.4.9 restart: always environment: ETCD_ENABLE_V2: \"true\" ALLOW_NONE_AUTHENTICATION: \"yes\" ETCD_ADVERTISE_CLIENT_URLS: \"http://0.0.0.0:2379\" ETCD_LISTEN_CLIENT_URLS: \"http://0.0.0.0:2379\" ports: - \"2379:2379/tcp\" networks: apisix: web1: image: nginx:1.18.0-alpine restart: always ports: - \"9081:80/tcp\" environment: - NGINX_PORT=80 networks: apisix:networks: apisix: driver: bridge 运行 docker-compose up -d 查看 apisix 日志docker-compose logs -f apisix 重启 apisixdocker-compose restart apisix 只重新加载配置或者 lua 文件，不重启 apisix docker-compose exec apisix apisix reload # 新增路由curl --location --request PUT 'http://127.0.0.1:9080/apisix/admin/routes/1' \\--header 'X-API-KEY: edd1c9f034335f136f87ad84b625c8f1' \\--header 'Content-Type: application/json' \\--data-raw '&#123; \"methods\": [\"GET\"], \"uri\": \"/index.html\", \"id\": 1, \"plugins\": &#123; \"example\": &#123; &#125; &#125;, \"upstream\": &#123; \"type\": \"roundrobin\", \"nodes\": &#123; \"web1:80\": 1 &#125; &#125;&#125;'# 访问路由，测试断点是否生效curl --location --request GET 'http://127.0.0.1:9080/index.html' \\--header 'X-API-KEY: edd1c9f034335f136f87ad84b625c8f1' \\--header 'Content-Type: application/json' 通过 EmmyLua 调试 Apisix 插件右键 plugins 文件夹，将目录标记为 源代码根目录将要加的断点加上在他之前加上 mobdebug.start(&quot;192.168.xx.xxx&quot;, 8172)访问路由，正常情况下，就会进断点。注意: idea 里将某个文件夹设置成源代码根目录后，其子目录的 lua 文件要与被调试的环境下的 lua 文件的路径完全一致。比如 docker 里，apisix 插件目录的绝对路径是 /usr/local/apisix/apisix/plugins,那就要求 plugins 目录下对应创建这个层级关系才行。不然 mobdebug 不走断点。 调试时 mobdebug.start(ip,端口)其实是连接 emmylua 插件，或者 ZB Studio 的 DebugServer 开放的端口，此处要保持一致。可以在 apisix 所在主机用 telnet ip 端口 试试能否通信。 执行了 restart apisix 或者 apisix reload 后，client 端连接断开了，但是 idea 端还没释放，再次访问会报错，所以需要重新点击调试按钮。 不建议生产环境下用 mobdebug 进行调试。 其他此种方法也可以用 ZeroBrane Studio 作为 debug server 端,进行调试，而不用 emmylua 插件。 可以参考 lua 学习笔记（4）– 搭建 mobdebug 远程开发环境 如果是在本机调试(不是本机跑 docker)，也可以试试 EmmyLua 的 Attach Debug 附加调试。 如果是本机调试 Apisix 自身代码，可以参考 APISIX Runtime Debug/动态调试 写的挺详细了，不再赘述。 结合 077-加快云原生应用开发速度(Nocalhost 篇) 是可以调试通过 helm 安装到 k8s 的 apisix 的。具体原理上篇已经写的挺详细了，不再赘述。 招聘小广告山东济南的小伙伴欢迎投简历啊 加入我们 , 一起搞事情。长期招聘，Java 程序员，大数据工程师，运维工程师，前端工程师。 参考资料 我的博客 我的掘金 pkulchenko/MobDebug EmmyLua Remote Debug 远程调试 APISIX Runtime Debug/动态调试 关于 Lua 无法调试总结。 ZeroBrane Studio ZeroBrane Studio - ZeroBrane Studio Plugin for Redis Lua Scripts ZeroBrane Studio Plugin for Redis Lua Scripts EmmyLua MobDebug 浅析","tags":[{"name":"apisix","slug":"apisix","permalink":"https://anjia0532.github.io/tags/apisix/"},{"name":"openresty","slug":"openresty","permalink":"https://anjia0532.github.io/tags/openresty/"},{"name":"nginx","slug":"nginx","permalink":"https://anjia0532.github.io/tags/nginx/"},{"name":"kong","slug":"kong","permalink":"https://anjia0532.github.io/tags/kong/"},{"name":"redis","slug":"redis","permalink":"https://anjia0532.github.io/tags/redis/"},{"name":"lua","slug":"lua","permalink":"https://anjia0532.github.io/tags/lua/"}]},{"title":"077-加快云原生应用开发速度(Nocalhost篇)","date":"2022-08-19T19:35:21.000Z","path":"2022/08/19/k8s-nocalhost/","text":"这是坚持技术写作计划（含翻译）的第 77 篇，定个小目标 999，每周最少 2 篇。 本文主要以 Nocalhost 工具为例，讲解如何快速开发调试跑在 k8s 集群的微服务等云原生应用。 安装 NocalhostNocalhost 支持 VScode 和 Jetbrains (Jetbrains 插件目前不支持 2022.2.*,提了PR 没人合，感觉 idea plugin 已经没人维护了,我 Fork 了一个，使用 Github Action 构建了一个 2022.2.* 可用的版本 https://github.com/anjia0532/nocalhost-intellij-plugin/actions/runs/2831564805) 添加 K8S 集群可以直接复制 kubeconfig 文本粘贴，也可以下载 kubeconfig 文件到本地 详见 集群管理 创建实例应用官方是用 nocalhost-server 或者 istio 的 bookinfo 为例。 此处以 Java 系常用的 Spring Boot 为例。 基于 Spring Initializr 创建 demo 应用在 com.example.nocalhostspringdemo 包下创建 Controller.java 类 package com.example.nocalhostspringdemo;import org.springframework.web.bind.annotation.GetMapping;import org.springframework.web.bind.annotation.RestController;/** * @author AnJia * @since 2022-08-19 16:47 */@RestController(\"/\")public class Controller &#123; @GetMapping(\"/nocalhost-demo\") public String test() &#123; return \"hello nocalhost\"; &#125;&#125; 构建 jar 包 部署应用到 K8S 集群将下列 yaml 代码保存为 nocalhost-test.yaml ,执行 kubectl apply -f ./nocalhost-test.yaml apiVersion: v1kind: Namespacemetadata: name: nocalhost-test---apiVersion: apps/v1kind: Deploymentmetadata: name: spring-boot-demo namespace: nocalhost-test labels: app: spring-boot-demospec: replicas: 3 template: metadata: name: spring-boot-demo labels: app: spring-boot-demo spec: containers: - name: spring-boot-demo image: anjia0532/openjdk-8-alpine-lib:3.5.2 imagePullPolicy: IfNotPresent command: - tail - -f - /dev/null restartPolicy: Always selector: matchLabels: app: spring-boot-demo 也可以通过 helm 进行安装 使用 Nocalhost 部署调试服务在项目根目录创建个 .nocalhost 文件夹，并将下列代码保存为 config.yaml name: \"spring-boot-demo\"serviceType: \"deployment\"containers: - name: \"spring-boot-demo\" hub: null dev: gitUrl: \"\" image: \"anjia0532/openjdk-8-alpine-lib:3.5.2\" shell: \"sh\" workDir: \"\" storageClass: \"\" resources: null persistentVolumeDirs: [] command: debug: - java - -jar - -agentlib:jdwp=transport=dt_socket,server=y,suspend=n,address=5005 - /home/nocalhost-dev/target/nocalhost-spring-demo-0.0.1-SNAPSHOT.jar run: - java - -jar - /home/nocalhost-dev/target/nocalhost-spring-demo-0.0.1-SNAPSHOT.jar debug: language: \"java\" remoteDebugPort: 5005 hotReload: true sync: type: \"sendReceive\" mode: \"gitIgnore\" env: [] portForward: [] 在 Controller 类里加上断点，使用远程 debug 模式启动应用。然后把 8080 端口转到本地。 本地浏览器访问 http://localhost:8080/nocalhost-demo 命中断点，意味着可以进行断点调试。 参考 Nocalhost Jetbrains Debug 可以用于预发布环境下，进行调试，省去了 本地开发，提交代码，流水线构建推送镜像，发版，切换流量，看日志 的过程，生产不建议这么用，有些时候会发布失败。 另外 java 系可以结合 springboot 的热加载或者 jrebel 的热部署功能，实现修改后，不用重启，自动生效的效果。 其余 Lua，JS，Python，Golang 等也都可以使用本方法。 招聘小广告山东济南的小伙伴欢迎投简历啊 加入我们 , 一起搞事情。长期招聘，Java 程序员，大数据工程师，运维工程师，前端工程师。 参考资料 我的博客 我的掘金","tags":[{"name":"docker","slug":"docker","permalink":"https://anjia0532.github.io/tags/docker/"},{"name":"k8s","slug":"k8s","permalink":"https://anjia0532.github.io/tags/k8s/"},{"name":"微服务","slug":"微服务","permalink":"https://anjia0532.github.io/tags/微服务/"},{"name":"云原生","slug":"云原生","permalink":"https://anjia0532.github.io/tags/云原生/"},{"name":"nocalhost","slug":"nocalhost","permalink":"https://anjia0532.github.io/tags/nocalhost/"}]},{"title":"076-快速开发HelmCharts（工具篇）","date":"2022-08-18T19:35:21.000Z","path":"2022/08/18/build-helm-charts/","text":"这是坚持技术写作计划（含翻译）的第 76 篇，定个小目标 999，每周最少 2 篇。 本文不是用来讲解 helm 干嘛的，他的基础概念一类的。这种的网上一搜一大把。本文主要是讲解如何利用工具插件来提升开发 Helm Chart 效率，降低出错概率。 官方最佳实践不使用工具的情况下，最快上手的看到是官方文档 最佳实践 通过 helm create 应用名(比如 doris-charts)创建一个骨架装了 Kubernates 插件的话，也可以从 Idea 创建 快速跑通使用类似 Rancher kubesphere 等带 UI 的系统，快速验证服务可用。带 UI 的比一次次手动改 yaml 舒服多了。最好是单独起一个命名空间。 for n in $(kubectl get -n default -o=name pvc,configmap,serviceaccount,secret,ingress,service,deployment,statefulset,hpa,job,cronjob)domkdir -p $(dirname $n)kubectl get -o=yaml $n &gt; $n.yamldone 把该命名空间的配置文件导出。然后人工复制粘贴到 通过 helm create 生成的骨架模板里。 快速开发此处以 Idea+Kubernates插件(官方文档)为例 当然你也可以用命令 helm lint PATH [flags] 文档 Helm Lint 验证 这就省了你一趟趟的 helm uninstall &amp;&amp; helm install 或者 helm template 试错了。 会把一些 values 里的数据直接替换到 charts 模板文件里 写的时候比较方便。也可以把单个模板渲染出来（类似 helm template） 其他还有很多功能，比如查看应用日志，执行 Shell 命令，转发端口到本地，修改应用的 yaml 并 apply 快速部署以 Idea+Alibaba Cloud Toolkit 为例 cd /tmp/doris-charts &amp;&amp; sudo helm template doris --create-namespace -n doris-system /tmp/doris-charts -f /tmp/doris-charts/values.yaml | sudo kubectl apply -n doris-system -f - 这样每次只需要点击运行按钮就行（之所以用 helm template | kubectl apply 就是省了一趟趟 helm uninstall &amp;&amp; helm install）。如果本身用传统扔 Jar/War 的方式部署，或者依赖阿里云产品比较重的话，用这个工具还不错。比如一键发布(打包，传输到主机上，kill 原进程，启动新进程，并且 tail 前 N 条日志)，Shell 到远程主机终端（省了 Xshell 了）一键构建镜像，启动 DockerCompose发布到阿里云微服务相关产品 但是说实在的，这个插件平时我是禁用的，随用随开，他有这么几个问题 往往不支持最新版，每次升级后，大概率需要等一周左右才会发布新版 会让电脑变卡，集成了太多功能了，比如 Arthas，比如 PMD 静态分析，尤其是 PMD，特别卡 每次启动 Idea 这个插件都得加载一大会（虽然可以最小化，但是仍然很不爽） 会往杭州一个 OSS 传输一些日志，咱也不知道干嘛，反正关不掉，我直接改本地 HOST，变相禁掉了。 另外还有一个神器 nocalhost ,缺点是不支持最新的 2022.2.x ，可以自行编译。功能挺多，参考官网 https://nocalhost.dev/zh-CN/docs/quick-start/。 总结 Helm Charts 作为一个交付产物，比发给别人一堆 yaml 好管理多了(有版本，可以自定义值)。 Kubernates 插件跟 NocalHost 插件有不少功能是重合的，但是各自有各自的特点，建议按需使用。 Alibaba Cloud Toolkit 过于臃肿，但是某些场景下确实也能省不少事，见仁见智吧。 招聘小广告山东济南的小伙伴欢迎投简历啊 加入我们 , 一起搞事情。长期招聘，Java 程序员，大数据工程师，运维工程师，前端工程师。 参考资料 我的博客 我的掘金","tags":[{"name":"k8s","slug":"k8s","permalink":"https://anjia0532.github.io/tags/k8s/"},{"name":"helm","slug":"helm","permalink":"https://anjia0532.github.io/tags/helm/"}]},{"title":"075-Dlink+Flink+CDC on k8s 整库同步","date":"2022-08-02T19:35:21.000Z","path":"2022/08/02/dlink-flink-flink-cdc-on-k8s/","text":"这是坚持技术写作计划（含翻译）的第 75 篇，定个小目标 999，每周最少 2 篇。 本文 主要讲解如何在 K8S 集群跑 Dlink+Flink 通过 Flink CDC 进行整库同步。 安装 K8S如果是本地测试的话，可以起 minikube 如果是生产的话，可以使用 Rancher RKE2 配合 Rancher 使用，也可以用别的商用 K8S 方案(比如 阿里云 ACK，腾讯云 TKE 等） 安装 Flink Operator 及安装 Flink Session 到 K8S 集群安装 Flink Operator 到 K8S 集群本文假设你已经会一些最基本的 k8s 知识，比如 k8s 集群配置了加速器(flink,dlink,doris,hadoop 相关镜像没一个小的，不用加速器，得慢死) kubectl 的使用，~/.kube/config, 如何安装 helm, 如果不会，请自行搜索相关知识。 # 安装 cert-manager 必选kubectl create -f https://github.com/jetstack/cert-manager/releases/download/v1.8.2/cert-manager.yaml# 可以将 flink-kubernetes-operator-1.1.0 换成别的版本，具体以 https://downloads.apache.org/flink/ 列出为准helm repo add flink-operator-repo https://downloads.apache.org/flink/flink-kubernetes-operator-1.1.0/# 安装 flink-kubernetes-operator 到 k8s 集群 (--namespace 可以缩写 -n,不写默认装到 default 集群，如果命名空间不存在，可以加上 --create-namespace ，在安装时创建命名空间)helm install flink-kubernetes-operator --create-namespace --namespace flink flink-operator-repo/flink-kubernetes-operator --set image.repository=apache/flink-kubernetes-operator 参考 flink-kubernetes-operator quick-start 安装 Flink Session 集群到 K8S 集群apiVersion: flink.apache.org/v1beta1kind: FlinkDeploymentmetadata: name: flink-sessionspec: # 官方镜像少 jar ,我自己打的镜像，只用于演示本文，实际生产请自行构建镜像 # Flink CDC 目前只支持 flink 1.14.* ,暂不支持 1.15.* image: anjia0532/flink:1.14.5-scala_2.12-java8-5 # Flink 版本改成 1.14.* flinkVersion: v1_14 flinkConfiguration: taskmanager.numberOfTaskSlots: \"2\" serviceAccount: flink jobManager: resource: memory: \"2048m\" cpu: 1 taskManager: resource: memory: \"2048m\" cpu: 1 Flink CDC 目前只支持 flink 1.14. ,暂不支持 1.15. 参考 flink-cdc-connectors 支持的 Flink 版本 # 安装 到 flink 命名空间kubectl -n flink apply -f flink-session-only.yaml 会自动创建 Flink Session Deployment（部署） 和 对应的 Service (服务发现 ) 参考 flink-kubernetes-operator examples 安装 Dlink 到 K8S 集群---apiVersion: apps/v1kind: Deploymentmetadata: labels: app: flink-dlink name: dlinkspec: selector: matchLabels: app: flink-dlink template: metadata: labels: app: flink-dlink spec: containers: - image: anjia0532/dlink:v0.6.6-1 name: dlink volumeMounts: - mountPath: /opt/dlink/config/application.yml name: admin-config subPath: application.yml volumes: - configMap: name: dlink-config name: admin-config---apiVersion: v1kind: ConfigMapmetadata: name: dlink-configdata: application.yml: |- spring: datasource: url: jdbc:mysql://mysql-headless.mysql:3306/dlink?useUnicode=true&amp;characterEncoding=UTF-8&amp;autoReconnect=true&amp;useSSL=false&amp;zeroDateTimeBehavior=convertToNull&amp;serverTimezone=Asia/Shanghai&amp;allowPublicKeyRetrieval=true username: dlink password: dlink driver-class-name: com.mysql.cj.jdbc.Driver application: name: dlink # flyway: # enabled: false # clean-disabled: true ## baseline-on-migrate: true # table: dlink_schema_history # Redis配置 #sa-token如需依赖redis，请打开redis配置和pom.xml、dlink-admin/pom.xml中依赖 # redis: # host: localhost # port: 6379 # password: # database: 10 # jedis: # pool: # # 连接池最大连接数（使用负值表示没有限制） # max-active: 50 # # 连接池最大阻塞等待时间（使用负值表示没有限制） # max-wait: 3000 # # 连接池中的最大空闲连接数 # max-idle: 20 # # 连接池中的最小空闲连接数 # min-idle: 5 # # 连接超时时间（毫秒） # timeout: 5000 server: port: 8888 mybatis-plus: mapper-locations: classpath:/mapper/*Mapper.xml #实体扫描，多个package用逗号或者分号分隔 typeAliasesPackage: com.dlink.model global-config: db-config: id-type: auto configuration: ##### mybatis-plus打印完整sql(只适用于开发环境) # log-impl: org.apache.ibatis.logging.stdout.StdOutImpl log-impl: org.apache.ibatis.logging.nologging.NoLoggingImpl # Sa-Token 配置 sa-token: # token名称 (同时也是cookie名称) token-name: satoken # token有效期，单位s 默认10小时, -1代表永不过期 timeout: 36000 # token临时有效期 (指定时间内无操作就视为token过期) 单位: 秒 activity-timeout: -1 # 是否允许同一账号并发登录 (为true时允许一起登录, 为false时新登录挤掉旧登录) is-concurrent: false # 在多人登录同一账号时，是否共用一个token (为true时所有登录共用一个token, 为false时每次登录新建一个token) is-share: true # token风格 token-style: uuid # 是否输出操作日志 is-log: false---apiVersion: v1kind: Servicemetadata: name: flink-dlinkspec: ipFamilies: - IPv4 ipFamilyPolicy: SingleStack ports: - name: http port: 8888 protocol: TCP targetPort: 8888 selector: app: dlink type: ClusterIP 注意修改 ConfigMap 里的 dlink 链接的 MySQL 的地址，用户名，密码，以及执行https://github.com/DataLinkDC/dlink/tree/dev/dlink-doc/sql 里的 dlink.sql (第一次执行) 和 dlinkmysqlcatalog.sql（第一次执行），如果是已经存在了，只是要升级,执行 dlink_history.sql kubectl -n flink apply -f dlink.yaml 可以使用 Idea 里的 Kubernates, Nocalhost, 或者 VS Code 里的 Kubernates, Nocalhost 或者命令行程序 k9s 或者kubectl 把 dlink 和 flink job UI 的端口转出来。 整库同步需要确保 dlink 所在的 MySQL 的 my.conf 开了 binglog ,并且 格式为 ROW演示 整库同步 dlink 的所有表同步到 cdc-test 中。在 dlink 的 MySQL 数据库中创建一个名为 cdc-test 的库。 EXECUTE CDCSOURCE cdc_mysql1 WITH ( 'connector' = 'mysql-cdc', 'hostname' = 'mysql-headless.mysql', 'port' = '3306', 'username' = 'dlink', 'password' = 'dlink', 'checkpoint' = '3000', 'scan.startup.mode' = 'initial', 'parallelism' = '1', 'table-name' = 'dlink\\..*', 'sink.url' = 'jdbc:mysql://mysql-headless.mysql:3306/cdc-test?characterEncoding=utf-8&amp;useSSL=false', 'sink.username' = 'dlink', 'sink.password' = 'dlink', 'sink.connector' = 'jdbc', 'sink.sink.db' = 'cdc-test', 'sink.table.prefix' = '', 'sink.table.lower' = 'true', 'sink.table-name' = '$&#123;tableName&#125;', 'sink.driver' = 'com.mysql.jdbc.Driver', 'sink.sink.buffer-flush.interval' = '2s', 'sink.sink.buffer-flush.max-rows' = '100', 'sink.sink.max-retries' = '5') 打开 Dlink Web 添加 K8S Session 集群，添加 作业，复制 CDCSource SQL 保存，并执行、或者异步提交。打开 Flink UI 看看执行情况。 附录Dlink docker fileFROM flink:1.14.5-scala_2.12-java8 as builderFROM openjdk:8-jdkARG DLINK_VERSION=\"0.6.6\"WORKDIR /opt/dlinkADD https://github.com/DataLinkDC/dlink/releases/download/v$&#123;DLINK_VERSION&#125;/dlink-release-$&#123;DLINK_VERSION&#125;.tar.gz /tmp/dlink.tar.gz#COPY ./dlink-release-$&#123;DLINK_VERSION&#125;.tar.gz /tmp/dlink.tar.gzRUN tar zxf /tmp/dlink.tar.gz -C /opt/dlink --strip-components=1 &amp;&amp; mkdir -p /opt/dlink/plugins/ &amp;&amp; rm -rf /tmp/*ADD https://maven.aliyun.com/repository/central/ru/yandex/clickhouse/clickhouse-jdbc/0.2.6/clickhouse-jdbc-0.2.6.jar /opt/dlink/plugins/ADD https://maven.aliyun.com/repository/central/mysql/mysql-connector-java/8.0.22/mysql-connector-java-8.0.22.jar /opt/dlink/plugins/ADD https://maven.aliyun.com/repository/central/com/ververica/flink-sql-connector-mysql-cdc/2.2.1/flink-sql-connector-mysql-cdc-2.2.1.jar /opt/dlink/plugins/ADD https://maven.aliyun.com/repository/central/org/apache/flink/flink-connector-jdbc_2.12/1.14.5/flink-connector-jdbc_2.12-1.14.5.jar /opt/dlink/lib/#ADD ./flink-shaded-hadoop-3-uber-3.1.1.7.2.9.0-173-9.0.jar /opt/dlink/plugins/COPY --from=builder /opt/flink/lib/* /opt/dlink/plugins/RUN cp /opt/dlink/extends/dlink-client-1.14-0.6.6.jar /opt/dlink/lib/RUN cp /opt/dlink/extends/dlink-catalog-mysql-1.14-0.6.6.jar /opt/dlink/lib/RUN cp /opt/dlink/extends/dlink-connector-jdbc-1.14-0.6.6.jar /opt/dlink/lib/RUN rm -rf /opt/dlink/lib/dlink-client-1.13-0.6.6.jar &amp;&amp; rm -rf /opt/dlink/lib/dlink-catalog-mysql-1.13-0.6.6.jar &amp;&amp; rm -rf /opt/dlink/lib/dlink-connector-jdbc-1.13-0.6.6.jarCMD [ \"/bin/sh\", \"-c\", \"java -Dloader.path=./lib,./plugins -Ddruid.mysql.usePingMethod=false -jar -Xms512M -Xmx2048M ./dlink-admin-*.jar\" ] docker build . -f Dockerfile-dlink --build-arg DLINK_VERSION=\"0.6.6\" -t anjia0532/dlink:v0.6.6-1docker push anjia0532/dlink:v0.6.6-1 Flink Docker fileFROM anjia0532/dlink:v0.6.6-1 as builderFROM flink:1.14.5-scala_2.12-java8COPY --from=builder /opt/dlink/lib/dlink-client-1.14-0.6.6.jar /opt/flink/lib/COPY --from=builder /opt/dlink/jar/dlink-client-base-0.6.6.jar /opt/flink/lib/COPY --from=builder /opt/dlink/jar/dlink-common-0.6.6.jar /opt/flink/lib/COPY --from=builder /opt/dlink/lib/dlink-catalog-mysql-1.14-0.6.6.jar /opt/flink/lib/COPY --from=builder /opt/dlink/plugins/flink-sql-connector-mysql-cdc-2.2.1.jar /opt/flink/lib/ADD https://maven.aliyun.com/repository/central/org/apache/flink/flink-connector-jdbc_2.12/1.14.5/flink-connector-jdbc_2.12-1.14.5.jar /opt/flink/lib/RUN chown -R flink:flink /opt/flink/ENTRYPOINT [\"/docker-entrypoint.sh\"]EXPOSE 6123 8081CMD [\"help\"] docker build . -f Dockerfile-flink -t anjia0532/flink:1.14.5-scala_2.12-java8-1docker push anjia0532/flink:1.14.5-scala_2.12-java8-1 MySQL 表名查询 SQLSELECT GROUP_CONCAT(CONCAT(table_schema,\"\\\\.\",table_name))from `information_schema`.`TABLES` WHERE table_schema='dlink';## 结果为 dlink\\.dlink_alert_group,dlink\\.dlink_alert_history,dlink\\.dlink_alert_instance,dlink\\.dlink_catalogue,dlink\\.dlink_cluster,dlink\\.dlink_cluster_configuration,dlink\\.dlink_database,dlink\\.dlink_flink_document,dlink\\.dlink_history,dlink\\.dlink_jar,dlink\\.dlink_job_history,dlink\\.dlink_job_instance,dlink\\.dlink_savepoints,dlink\\.dlink_schema_history,dlink\\.dlink_sys_config,dlink\\.dlink_task,dlink\\.dlink_task_statement,dlink\\.dlink_task_version,dlink\\.dlink_user,dlink\\.metadata_column,dlink\\.metadata_database,dlink\\.metadata_database_property,dlink\\.metadata_function,dlink\\.metadata_table,dlink\\.metadata_table_propertySELECT GROUP_CONCAT( DISTINCT CONCAT(table_schema,\"\\\\..*\") ORDER BY table_schema )from `information_schema`.`TABLES`;## 结果为 canal_manager\\..*,cdc-test\\..*,datax_web\\..*,dlink\\..*,information_schema\\..*,mysql\\..*,performance_schema\\..*,sys\\..* 招聘小广告山东济南的小伙伴欢迎投简历啊 加入我们 , 一起搞事情。长期招聘，Java 程序员，大数据工程师，运维工程师，前端工程师。 参考资料 我的博客 我的掘金 FlinkCDC 整库实时入仓入湖_哔哩哔哩_bilibili Dinky 实践系列之 FlinkCDC 整库实时入仓入湖 CDCSOURCE 整库同步 Flink SQL 作业快速入门 基于 Flink CDC 同步 MySQL 分库分表构建实时数据湖","tags":[{"name":"大数据","slug":"大数据","permalink":"https://anjia0532.github.io/tags/大数据/"},{"name":"hadoop","slug":"hadoop","permalink":"https://anjia0532.github.io/tags/hadoop/"},{"name":"flink","slug":"flink","permalink":"https://anjia0532.github.io/tags/flink/"}]},{"title":"074-Elastic Curator 支持ES8.x","date":"2022-05-13T19:35:21.000Z","path":"2022/05/13/curator-es-8-x/","text":"这是坚持技术写作计划（含翻译）的第 74 篇，定个小目标 999，每周最少 2 篇。 ES 堪称版本帝, 截止到现在已经 ES 8.2.0 了. 但是悲催的是 Curator 目前只支持到 ES 7.x . Curator 是一个 ES 工具集, 用于减少 ES 的运维工作量, 比如创建索引,设置索引参数,关闭索引,归档索引,删除索引,定时备份索引等等 . 支持的操作有 https://www.elastic.co/guide/en/elasticsearch/client/curator/current/actions.html 其中 Curator 的部分功能,可以使用高版本的 ES 倡导的 ILM 功能 , 感兴趣,可以参考 干货 | Elasticsearch 索引生命周期管理 ILM 实战指南 本文主要讲解如何让 Curator 支持 ES 8.x . 详见我的 Gist https://gist.github.com/anjia0532/d8e779c97333d6fc0d045675e18e1224 将下面代码保存成 curator.patch Index: curator/_version.pyIDEA additional info:Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP&lt;+&gt;UTF-8===================================================================diff --git a/curator/_version.py b/curator/_version.py--- a/curator/_version.py (revision 191de8cd0c7c719de6d5fca1f9fbbc8adfb5c006)+++ b/curator/_version.py (revision caef1c9e29c67d534764ed25e4bf3f1ae70b6276)@@ -1,2 +1,2 @@ \"\"\"Curator Version\"\"\"-__version__ = '5.8.4'+__version__ = '5.8.5'Index: curator/defaults/settings.pyIDEA additional info:Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP&lt;+&gt;UTF-8===================================================================diff --git a/curator/defaults/settings.py b/curator/defaults/settings.py--- a/curator/defaults/settings.py (revision 191de8cd0c7c719de6d5fca1f9fbbc8adfb5c006)+++ b/curator/defaults/settings.py (revision caef1c9e29c67d534764ed25e4bf3f1ae70b6276)@@ -6,7 +6,7 @@ # Elasticsearch versions supported def version_max(): \"\"\"Return the maximum Elasticsearch version Curator supports\"\"\"- return (7, 99, 99)+ return (8, 99, 99) def version_min(): \"\"\"Return the minimum Elasticsearch version Curator supports\"\"\" return (5, 0, 0)Index: requirements.txtIDEA additional info:Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP&lt;+&gt;UTF-8===================================================================diff --git a/requirements.txt b/requirements.txt--- a/requirements.txt (revision 191de8cd0c7c719de6d5fca1f9fbbc8adfb5c006)+++ b/requirements.txt (revision caef1c9e29c67d534764ed25e4bf3f1ae70b6276)@@ -1,10 +1,10 @@ voluptuous&gt;=0.12.1-elasticsearch&gt;=7.14.0,&lt;8.0.0+elasticsearch&gt;=7.14.0,&lt;=9.0.0 urllib3&gt;=1.26.5,&lt;2 requests&gt;=2.26.0 boto3&gt;=1.18.18 requests_aws4auth&gt;=1.1.1-click&gt;=7.0,&lt;8.0+click&gt;=8.0.3,&lt;9.0 pyyaml&gt;=5.4.1 certifi&gt;=2021.5.30 six&gt;=1.16.0Index: setup.pyIDEA additional info:Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP&lt;+&gt;UTF-8===================================================================diff --git a/setup.py b/setup.py--- a/setup.py (revision 191de8cd0c7c719de6d5fca1f9fbbc8adfb5c006)+++ b/setup.py (revision caef1c9e29c67d534764ed25e4bf3f1ae70b6276)@@ -22,12 +22,13 @@ return VERSION def get_install_requires():- res = ['elasticsearch&gt;=7.14.0,&lt;8.0.0' ]+ res = ['elasticsearch&gt;=7.14.0,&lt;=9.0.0' ]+ res.append('voluptuous&gt;=0.12.1') res.append('urllib3&gt;=1.26.5,&lt;2') res.append('requests&gt;=2.26.0') res.append('boto3&gt;=1.18.18') res.append('requests_aws4auth&gt;=1.1.1')- res.append('click&gt;=7.0,&lt;8.0')+ res.append('click&gt;=8.0.3,&lt;9.0') res.append('pyyaml==5.4.1') res.append('voluptuous&gt;=0.12.1') res.append('certifi&gt;=2021.5.30') 将下面代码保存成 Dockerfile FROM python:3.9.4-alpine3.13# 国内加速器RUN sed -i 's/dl-cdn.alpinelinux.org/mirrors.ustc.edu.cn/g' /etc/apk/repositories &amp;&amp; \\ pip install -i https://mirrors.ustc.edu.cn/pypi/web/simple pip -U &amp;&amp; \\ pip config set global.index-url https://mirrors.ustc.edu.cn/pypi/web/simpleCOPY curator.patch /tmp/curator.patch# 如果下载 github 超时,可以换成 gitee 源 https://gitee.com/anjia/curator.gitRUN apk --no-cache add --virtual .build-deps git &amp;&amp; \\ git clone https://github.com/elastic/curator.git /tmp/curator &amp;&amp; \\ cd /tmp/curator &amp;&amp; \\ git checkout -b tags/v5.8.4 &amp;&amp; \\ git apply --check /tmp/curator.patch &amp;&amp; \\ git apply /tmp/curator.patch &amp;&amp; \\ apk del .build-depsRUN cd /tmp/curator &amp;&amp; python setup.py install# Thanks for @arslanbekovRUN rm -rf /tmp/curator docker build . -t curator:5.8.5# 或者也可以用我构建好的docker pull anjia0532/curator:5.8.5 招聘小广告山东济南的小伙伴欢迎投简历啊 加入我们 , 一起搞事情。长期招聘，Java 程序员，大数据工程师，运维工程师，前端工程师。 参考资料 我的博客 我的掘金 Curator not compatible with elasticsearch 8.0.0 #1639","tags":[{"name":"es","slug":"es","permalink":"https://anjia0532.github.io/tags/es/"},{"name":"elastic","slug":"elastic","permalink":"https://anjia0532.github.io/tags/elastic/"},{"name":"elk","slug":"elk","permalink":"https://anjia0532.github.io/tags/elk/"}]},{"title":"073-apisix的三种数据备份方案","date":"2022-04-19T19:35:21.000Z","path":"2022/04/19/apisix-data-backup/","text":"这是坚持技术写作计划（含翻译）的第 73 篇，定个小目标 999，每周最少 2 篇。 本文主要讲解 apisix 的数据备份方案。包括 Dashboard 导出，导出 stand-alone yaml，备份 etcd 数据 三种方式。 灵魂拷问你们团队有 ETCD 运维经验么？如果没有，你有打算短期内学习 ETCD 的打算么？如果没有，那你做好 ETCD 宕机数据丢失的心理准备了吗？ 比如我之前提的 issues request help: Etcd node high cpu and memory leak，建议看一下，里面有介绍自动压缩 etcd Dashboard 导出数据算是官方提供的备份方案，但是只能导出路由，其余的上游(Upstream)，插件，证书等，没有。意味着，如果导入到新集群的话，可能会失败(比如路由里有别的插件，消费者等配置)。 导出 stand-alone yaml根据官方文档 Stand-alone mode 写了个小工具 https://github.com/anjia0532/discovery-syncer/。吐槽下 apisix 的数据结构稍微有点乱，同一个 key，可能是 数组 []，可能是 对象 {}，虽然是历史债务吧，但是还是显得不严谨。参考我之前提的 issues Some Admin APIs’ data structure are not unified #6105 目前支持 Admin 暴露的所有资源。 可以作为数据备份用。 可以结合 Git/SVN 等版本控制工具，用于审计等操作。 同时这个工具也支持同步 nacos/eureka 数据到 apisix 并自动创建 upstream ，以及主持主动上下线 nacos/eureka 服务，可以参考我提的 issues usercase: golang toolkit-sync eureka/nacos instance info to apisix #5957 使用 etcdctl 备份还原数据# apisix etcd 地址export ENDPOINT=apisix-etcd:2379# ETCDCTL_API=3 etcdctl --endpoints $ENDPOINT endpoint status -w=table# 备份数据ETCDCTL_API=3 etcdctl --endpoints $ENDPOINT snapshot save snapshot.db# 使用 linux cronjob + docker run# 备份文件名为 北京时间 yyyyMMddHHmmss.db# 并且删除最后修改时间超过10天的老备份文件docker run anjia0532/etcd-development.etcd:v3.5.3 -rm -v$(pwd)/snapshot:/tmp /bin/sh -c \"/usr/local/bin/etcdctl --endpoints=$&#123;ENDPOINT&#125; snapshot save /tmp/$(TZ=Asia/Shanghai date +%Y%m%d%H%M%S).db &amp;&amp; find /tmp/ -mtime +10 -type f -delete\"# 更建议用 k8s cronjob 来备份，存储到共享存储里# 查看备份状态ETCDCTL_API=3 etcdctl --endpoints $ENDPOINT snapshot status snapshot.db -w=table# 还原快照# apisix-etcd-0ETCDCTL_API=3 etcdctl snapshot restore snapshot.db \\ --name apisix-etcd-0 \\ --initial-cluster apisix-etcd-0=http://apisix-etcd-0:2380,m2=http://apisix-etcd-1:2380,m3=http://apisix-etcd-2:2380 \\ --initial-advertise-peer-urls http://localhost:2380# apisix-etcd-1ETCDCTL_API=3 etcdctl snapshot restore snapshot.db \\ --name apisix-etcd-1 \\ --initial-cluster apisix-etcd-0=http://apisix-etcd-0:2380,m2=http://apisix-etcd-1:2380,m3=http://apisix-etcd-2:2380 \\ --initial-advertise-peer-urls http://localhost:2380# apisix-etcd-2ETCDCTL_API=3 etcdctl snapshot restore snapshot.db \\ --name apisix-etcd-2 \\ --initial-cluster apisix-etcd-0=http://apisix-etcd-0:2380,m2=http://apisix-etcd-1:2380,m3=http://apisix-etcd-2:2380 \\ --initial-advertise-peer-urls http://localhost:2380 其他方案关注 https://github.com/api7/etcd-adapter 项目，改用传统数据库 （比如 pgsql,mysql 等），或者 apisix 团队实现的 btree 招聘小广告山东济南的小伙伴欢迎投简历啊 加入我们 , 一起搞事情。长期招聘，Java 程序员，大数据工程师，运维工程师，前端工程师。 参考资料 我的博客 我的掘金","tags":[{"name":"apisix","slug":"apisix","permalink":"https://anjia0532.github.io/tags/apisix/"},{"name":"etcd","slug":"etcd","permalink":"https://anjia0532.github.io/tags/etcd/"}]},{"title":"072-解决 Jetbrains 启动失败报 BindException: Address already in use 错误","date":"2022-04-17T11:35:21.000Z","path":"2022/04/17/jetbrains-starting-failed-address-already-in-use/","text":"这是坚持技术写作计划（含翻译）的第 72 篇，定个小目标 999，每周最少 2 篇。 本文主要介绍遇到 Jetbrains 全家桶( Goland , Idea , Webstorm , Pycharm 等)启动时，报 BindException: Address already in use 的解决办法。 报错截图类似 方案 1对我有用 net stop winnatnet start winnat 方案 2对我没用 netsh winsock reset 方案 3对我没用 netsh int ipv4 set dynamicport tcp start=49152 num=16383netsh int ipv4 set dynamicport udp start=49152 num=16383 方案 4我没试过 关闭 Hyper-V 题外话TCPView 一个 Windows 小工具，用于查看本机的 TCP 连接及使用和监听的端口号，常用于排查端口占用问题火绒安全 安全工具-&gt;流量监控-&gt;查看所有连接 功能类似 TCPView ，如果已经装了火绒安全的话，就不用装 TCPView 了不想装软件，可以用 Win+R-&gt;cmd netstat -ano | findstr 8080 来排查端口使用 招聘小广告山东济南的小伙伴欢迎投简历啊 加入我们 , 一起搞事情。长期招聘，Java 程序员，大数据工程师，运维工程师，前端工程师。 参考资料 我的博客 我的掘金 IDEA Start Failed: Address already in use Revise IDE folders locking mechanism (don’t fail startup if all ports in range are taken, limited network due to firewall/VPN)","tags":[{"name":"ide","slug":"ide","permalink":"https://anjia0532.github.io/tags/ide/"},{"name":"idea","slug":"idea","permalink":"https://anjia0532.github.io/tags/idea/"}]},{"title":"071-基于flattened解决apisix写入es导致的字段爆炸问题","date":"2022-03-01T19:35:21.000Z","path":"2022/03/01/es-flattend/","text":"这是坚持技术写作计划（含翻译）的第 71 篇，定个小目标 999，每周最少 2 篇。 Apisix 支持日志输出到 kafka, tcp, udb, syslog 等多种方式 主流的不管是 ELK 还是 EFK, 都是用 Elasticsearch 是用于存储数据，Logstash/Fluentd/Filebeat 是用于摄取数据，Kibana 是用于展示数据(Grafana 也支持 ES 作为数据源) 其中： Logstash 支持大部分, 即所谓的 ELK，参见 Logstash Input Plugins , Fluentd, 即所谓的 EFK 可以参考 Fluentd Input Plugins Filebeat, 即所谓的 ELK 可以参考 Filebeat Input Types 还有一些逐渐流行的方案，用其他存储方案替代 ES ,一般来说，普遍比 ES 好运维，如果没有倒排索引的需求，及历史包袱的情况下，建议别用 ES 的方案 比如 Grafana Loki 作为存储源，配合自家的 Grafana 作为展示 使用 Clickhouse 作为存储源, 参考 快手、携程等公司转战到 ClickHouse，ES 难道不行了？，干货 | 携程 ClickHouse 日志分析实践 使用 TDengine, 参考 TDengine 官方文档-高效写入数据 … 本文主要介绍 Elasticsearch 默认 Mapping 如果不做特殊设置，默认为 dynamic，导致 Apisix 输入到 ES 的日志，不停动态添加字段,直到超过 index.mapping.total_fields.limit而报错(有新增字段的插入不了)，通俗来说就是字段爆炸, 主要是 request.headers,request.querystring两个对象。 问题描述查看当前索引字段上限如果没改过，则默认是 1000 ，参考文档 Mapping limit settings如果不确定，可以通过 API 查询，查看返回值有没有 index.mapping.total_fields.limit # 查询GET apisix-*/_settings# 修改 index.mapping.total_fields.limit 为 2000PUT apisix-*/_settings&#123; &quot;index.mapping.total_fields.limit&quot;: 2000&#125; 查看当前索引字段数打开 Kibana Stack Management &gt; 索引模式 &gt; apisix-* 查看字段数量，如果超过 300，最好是干预下，否则字段爆炸是早晚的事。而且需要注意的是，这个问题不是很明显，如果超过字段上限后不新增字段，日志能正常插入，只有新增字段才会报错，也就是说，会间歇性丢日志。 解决方案ES 7.3 之前的方案 通过 dynamic改为 false (缺点，新增字段不能被索引) 通过 dynamic 设置为 strict(缺点，新增字段直接报错) 参考文档 Dynamic field mapping ES 7.3 及之后的方案无脑使用 flattened 打开 kibana 的 DevTools 控制台执行下面脚本，假设你的 Apisix 的日志索引是 apisix-*，注意索引模板是要在索引生成之前设置才有效，如果是想修改当前索引，则使用 PUT apisix-*/_settings API PUT _index_template/apisix_template&#123; # 匹配索引 &quot;index_patterns&quot;: [&quot;apisix-*&quot;], # 模板 &quot;template&quot;: &#123; # 设置，此处可忽略，可以只改映射 mappings 部分 &quot;settings&quot;: &#123; # 每30秒刷新一次 &quot;refresh_interval&quot;: &quot;30s&quot;, # 3分片 &quot;number_of_shards&quot;: &quot;3&quot;, # 1副本 &quot;number_of_replicas&quot;: &quot;1&quot;, &#125;, # 映射 &quot;mappings&quot;: &#123; &quot;properties&quot;: &#123; # 将 request.headers,request.querystring,response.headers 设置为 flattened 类型 &quot;request.headers&quot;: &#123; &quot;type&quot;: &quot;flattened&quot; &#125;, &quot;request.querystring&quot;: &#123; &quot;type&quot;: &quot;flattened&quot; &#125;, &quot;response.headers&quot;: &#123; &quot;type&quot;: &quot;flattened&quot; &#125; &#125; &#125; &#125;&#125; 引用 Elasticsearch 字段膨胀不要怕，Flattened 类型解千愁！ 介绍的 flattened 缺点 每当面临 Flattened 扁平化对象的决定时，在选型 Elasticsearch 扁平化数据类型时，我们需要考虑以下几个关键限制：Flattened 类型支持的查询类型目前仅限于以下几种： term terms terms_set prefix range match and multi_match query_string and simple_query_string exists Flattened 不支持的查询类型如下： 无法执行涉及数字计算的查询，例如：range query。 无法支持高亮查询。 尽管支持诸如 term 聚合之类的聚合，但不支持处理诸如“histograms”或“date_histograms”之类的数值数据的聚合。 招聘小广告山东济南的小伙伴欢迎投简历啊 加入我们 , 一起搞事情。长期招聘，Java 程序员，大数据工程师，运维工程师，前端工程师。 参考资料 我的博客 我的掘金 Elasticsearch 字段膨胀不要怕，Flattened 类型解千愁！","tags":[{"name":"es","slug":"es","permalink":"https://anjia0532.github.io/tags/es/"},{"name":"elasticsearch","slug":"elasticsearch","permalink":"https://anjia0532.github.io/tags/elasticsearch/"},{"name":"apisix","slug":"apisix","permalink":"https://anjia0532.github.io/tags/apisix/"},{"name":"elk","slug":"elk","permalink":"https://anjia0532.github.io/tags/elk/"},{"name":"efk","slug":"efk","permalink":"https://anjia0532.github.io/tags/efk/"}]},{"title":"070-P2P加速Docker镜像分发(阿里Dragonfly2+google jib)","date":"2022-02-14T19:35:21.000Z","path":"2022/02/14/d7-jib/","text":"这是坚持技术写作计划（含翻译）的第 70 篇，定个小目标 999，每周最少 2 篇。 简单介绍下 google jib ：支持 gradle 和 maven，用于构建 java 应用镜像时，将基础镜像(jdk)，依赖(jar lib),资源文件(resources),class 文件等进行分层(layer),这样依赖，在拉取和推送镜像时，起到加速和节省带宽的目的。 Dragonfly2：是阿里开源的一款基于 P2P 协议的，镜像和文件分发加速工具，与 dragonfly1 相比，dragonfly2 用 golang 重构了，运行时占用资源更少。理论上可以基于 dragonfly 做一个局域网 CDN，及局域网镜像加速器，文件通过 dragonfly 下载后，缓存到局域网内，再次请求时，如果局域网节点内有，且未过期，则通过 p2p 协议从局域网内拉取，防止占用公网带宽及某个节点过载被打死的情况。 简单总结下，jib 解决的是 java 应用动不动 100M+甚至 1G+的情况（变成了 80M JDK(基本不变)+200M jar(基本不变)+300M resource(基本不变)+1M class（每次发版会变）），而 dragonfly2 解决的是节省公网带宽，减少内部 registry 节点过热的情况，加起来就是，容器 push&amp;pull 的过程更快了 其实三年前写过阿里 Dragonfly+google jib 的文章，但是时间比较久远，有些内容已经过时,所以准备重新整理下。之前文章如下： 加速和简化构建 Docker(基于 Google jib) 046-解决 google jib 多任务问题 012-P2P 加速 Docker 镜像分发(阿里 Dragonfly) 013-阿里 Dragonfly 体验之私有 registry 下载 Google Jibjib 支持 maven(jib-maven-plugin) 和gradle(jib-gradle-plugin) ,以及常见的多模块场景 翻了翻新版的 jib-maven-plugin 文档，主要部分跟我之前的 加速和简化构建 Docker(基于 Google jib) 差不多，不再CV了 但是加了不少新特性，比如 自定义 Entrypoint 支持镜像加速器等 jib 全局配置 支持自定义 CPU 架构（architecture）和操作系统（os） 支持更多选项的基础镜像的设置 特别的说一下，jib 的很多配置，除了改 pom.xml 外，还支持无侵入的通过命令行指定，并且，命令行传入优先级更高，比如 mvn compile com.google.cloud.tools:jib-maven-plugin:3.2.0:build -Dimage=&lt;MY IMAGE&gt;中的-Dimage= 对应的是 pom.xml 里的&lt;configuration&gt;&lt;to&gt;&lt;image&gt;&lt;/image&gt;&lt;/to&gt;&lt;/configuration&gt; K8S(kubernetes)以 rke2 为例安装 k8s 集群，如果只是简单测试一下，可以用k3s或者 本地分布式开发环境搭建（使用 Vagrant 和 Virtualbox），或者rke2(如果会用 ansible 也可以用 ansible playbook rke2) 如果想可视化看下 k8s 集群，可以用 kube-explorer, k9s 也可以用rancher2.6(注意如果用 rancher 的话，注意 rke2 安装的版本,以最新稳定版本 2.6.3为例，默认支持的是 k8s v1.21.7,也就是得用rke2 v1.21.7+rke2r2) Dragonfly2别看官网文档，已经年久失修了，直接看github 文档，更保险点是看 github 代码，切记，切记，切记。 helm 安装官方文档 https://github.com/dragonflyoss/helm-charts/blob/main/charts/dragonfly/README.md 考虑到国内特殊国情，可能会访问 github 失败，可以用 https://gitee.com/projects/import/url 中转(也可以用我的 https://gitee.com/anjia/dragonflyoss-helm-charts) git clone https://gitee.com/anjia/dragonflyoss-helm-charts.gitcd ./dragonflyoss-helm-charts/charts/dragonflyhelm dependency updatehelm install --create-namespace --namespace dragonfly-system dragonfly . -f values.yml 如果要自定义参数，通过 -f values.yml 来指定，如果默认则移除 -f values.yml,支持的配置有 https://github.com/dragonflyoss/helm-charts/tree/main/charts/dragonfly#values 注意点 dragonfly 的 helm 支持 docker 和 containerd 两种引擎，官方推荐使用 containerd(因为支持 fallback，docker 不支持)，如果是加速多镜像库官方推荐使用 containerd1.5.x+,因为 /etc/containerd/config.toml 是 version2 版本，支持多个注册中心的加速，否则只支持一个，当然也有办法解决，后边再说。 rke2 是通过 /etc/rancher/rke2/registries.yaml 来生成 /var/lib/rancher/rke2/agent/etc/containerd/config.toml的，而目前版本的 helm 不支持自定义/etc/containerd/config.toml就会导致 daemon 启动失败，提了个 pr 还没过 https://github.com/dragonflyoss/helm-charts/pull/51 ，可以先手动修改 通过 d7y 的 helm 修改的 config.toml 一重启 rke2-server/agent 就会被覆盖，所以，最终要修改 /etc/rancher/rke2/registries.yaml ，而这个改动需要重启 rke2-server/agent 才生效，所以注意测试是否对业务有影响，尽量一次改完 注意污点(taints)对于 d7y daemon 的影响，如果确定要不走 d7y 的，注意别改 /etc/rancher/rke2/registries.yaml,虽然 containerd 有 fallback，但是多少影响点时间不是么，如果有污点也有用 d7y 记得在 values 里加上对应的容忍(tolerations) 注意 d7y 的磁盘规划，以及缓存时间的设置 可以通过 多次运行 time sudo /var/lib/rancher/rke2/bin/crictl --config=/var/lib/rancher/rke2/agent/etc/crictl.yaml pull xxx:latest镜像来评估 d7y 对于镜像的加速作用(如果是在一台执行，记得执行 sudo /var/lib/rancher/rke2/bin/crictl --config=/var/lib/rancher/rke2/agent/etc/crictl.yaml rmi --prune来清理无用镜像) containerd1.4.x 支持多注册中心的办法：1. 等 d7y 官方支持，参见 PRchore: enable range feature gate in e2e，2，等 rancher 官方支持 containerd1.5.9 且你的集群升得动，3，改 hosts 劫持(但是不支持 fallback),4,只加速最常用的一个注册中心,5,将其他不常用的注册中心的镜像 pull&amp;push 到加速的注册中心里（注意别有镜像冲突）6,起两套 daemon 分别监听 65001 65002 d7y 支持预热功能，但是 consoleui 版本的，暂时没测通，api 版本可以，参见文档 https://github.com/dragonflyoss/Dragonfly2/blob/main/docs/zh-CN/preheat/api.md Harbor p2p 预热支持 d7y containerd 如果要配置私有镜像库加速，需要配置127.0.0.1:65001的 auth，详见 issues dragonflyoss/Dragonfly2/#1065 附赠：docker hub 转移镜像到阿里私服 bash 脚本注意将 xxxx 替换成实际值用法 /path/to/pull_push.sh nginx:alpine #!/usr/bin/env bashsudo service docker startsudo docker login -uxxxx -pxxxxx registry.cn-zhangjiakou.aliyuncs.comsudo docker pull $1sudo docker tag $1 registry.cn-zhangjiakou.aliyuncs.com/xxxx/$&#123;1##*/&#125;sudo docker push registry.cn-zhangjiakou.aliyuncs.com/xxxx/$&#123;1##*/&#125; 招聘小广告山东济南的小伙伴欢迎投简历啊 加入我们 , 一起搞事情。长期招聘，Java 程序员，大数据工程师，运维工程师，前端工程师。 参考资料 我的博客 我的掘金","tags":[{"name":"docker","slug":"docker","permalink":"https://anjia0532.github.io/tags/docker/"},{"name":"k8s","slug":"k8s","permalink":"https://anjia0532.github.io/tags/k8s/"},{"name":"容器","slug":"容器","permalink":"https://anjia0532.github.io/tags/容器/"},{"name":"kubernetes","slug":"kubernetes","permalink":"https://anjia0532.github.io/tags/kubernetes/"}]},{"title":"069-k8s 集群基于节点内存水位线通过打污点方式来干预Pod调度","date":"2022-01-28T18:47:21.000Z","path":"2022/01/28/k8s-node-flexible-memory-scheduling/","text":"这是坚持技术写作计划（含翻译）的第 69 篇，定个小目标 999，每周最少 2 篇。 本文主要介绍如何最小化改造的情况下，根据中小型 k8s 集群的 node 节点的内存，通过打污点(taints)的形式，柔性干预 Pod 调度 简单介绍其实关于 k8s 调度方面的资料很多 比如 k8s 的 Node Allocatable，对我来说，有点硬了，可能导致短暂的高峰把 pod 给驱逐了 比如大佬 智博老师 提到的 https://github.com/kubernetes-sigs/descheduler 和 https://github.com/kubernetes-sigs/scheduler-plugins/blob/master/pkg/trimaran/README.md 管用是管用，但是有点复杂了。 可用脚本花了几分钟，写了个 bash 脚本，脚本放到了我的 gist 上，防止过国内没法访问，下面也粘贴一份 #!/usr/bin/env bash# author anjia0532@gmail.com# blog https://anjia0532.github.io/# github https://github.com/anjia0532RED='\\033[0;31m'NC='\\033[0m' # No Colorusage () &#123; echo -e \"$&#123;RED&#125; Auto add/remove mem=poor:NoSchedule taint to your nodes of k8s cluster by threshold value(Low water level/High water level) Usage : $0 &#123;OPTIONS&#125; -k &lt; kubectl command e.g. -k sudo kubectl --kubeconfig /path/to/config.yaml&gt; -l &lt; Low water level range (0,100) e.g. -l 50 &gt; -h &lt; high water level range (0,100) e.g. -h 80&gt; -f &lt; Selector (label query) to filter on, supports '=', '==', and '!='. e.g. -f key1=value1,key2=value2 &gt; $&#123;NC&#125;\";&#125;# parse argswhile getopts \"k:l:h:f:\" opts; do case $&#123;opts&#125; in k) KUBECTL_CMD=$&#123;OPTARG&#125; ;; l) LOW=$&#123;OPTARG&#125; ;; h) HIGH=$&#123;OPTARG&#125; ;; f) FILTER=$&#123;OPTARG&#125; ;; *) usage; exit;; esacdone# those args must be not nullif [ ! \"$KUBECTL_CMD\" ] || [ ! \"$LOW\" ] || [ ! \"$HIGH\" ]then usage exit 1fi# low and hign must between 0 and 100if [ \"$LOW\" -ge 100 ] || [ \"$HIGH\" -ge 100 ] || [ \"$LOW\" -le 0 ] || [ \"$HIGH\" -le 0 ]then usage exit 1fiecho -e \"View top node(order by memory) by this command \\n$&#123;RED&#125; $&#123;KUBECTL_CMD&#125; top node --selector=\\\"$&#123;FILTER&#125;\\\" --use-protocol-buffers --sort-by='memory' \\n $&#123;NC&#125;\"nodes=()while IFS='' read -r line; do nodes+=(\"$line\"); done &lt; &lt;($&#123;KUBECTL_CMD&#125; top node --selector=\"$&#123;FILTER&#125;\" --no-headers --use-protocol-buffers --sort-by='memory' | awk '&#123;print $1\",\"$5&#125;'| sed \"s/%//g\")for node in \"$&#123;nodes[@]&#125;\" ; do IFS=\",\" read -r node_name mem_useage &lt;&lt;&lt; \"$&#123;node&#125;\" [[ $mem_useage -ge $&#123;HIGH&#125; ]] &amp;&amp; ( echo -e \"\\n$&#123;KUBECTL_CMD&#125; taint nodes $&#123;node_name&#125; mem=poor:NoSchedule --overwrite\" &amp;&amp; $&#123;KUBECTL_CMD&#125; taint nodes $&#123;node_name&#125; mem=poor:NoSchedule --overwrite) [[ $mem_useage -le $&#123;LOW&#125; ]] &amp;&amp; ( echo -e \"\\n$&#123;KUBECTL_CMD&#125; taint nodes $&#123;node_name&#125; mem=poor:NoSchedule-\" &amp;&amp; $&#123;KUBECTL_CMD&#125; taint nodes $&#123;node_name&#125; mem=poor:NoSchedule- )done 核心部分就最后五六行，用法也很简单 k8s_node_flexible_memory_scheduling.shAuto add/remove mem=poor:NoSchedule taint to your nodes of k8s cluster by threshold value(Low water level/High water level) Usage : ./a.sh &#123;OPTIONS&#125; -k &lt; kubectl command e.g. -k sudo kubectl --kubeconfig /path/to/config.yaml&gt; -l &lt; Low water level range (0,100) e.g. -l 50 &gt; -h &lt; high water level range (0,100) e.g. -h 80&gt; -f &lt; Selector (label query) to filter on, supports '=', '==', and '!='. e.g. -f key1=value1,key2=value2 &gt;k8s_node_flexible_memory_scheduling.sh -k \"kubectl\" -l 60 -h 80 -f \"biz=demo\"node/192.168.1.139 modifiednode/192.168.1.137 modifiednode/192.168.1.126 modifiednode/192.168.1.140 untaintednode/192.168.1.141 untaintednode/192.168.1.142 untaintederror: taint \"mem:NoSchedule\" not founderror: taint \"mem:NoSchedule\" not found 招聘小广告山东济南的小伙伴欢迎投简历啊 加入我们 , 一起搞事情。长期招聘，Java 程序员，大数据工程师，运维工程师，前端工程师。 参考资料 我的博客 我的掘金 Need simple kubectl command to see cluster resource usage #17512","tags":[{"name":"k8s","slug":"k8s","permalink":"https://anjia0532.github.io/tags/k8s/"},{"name":"kubernetes","slug":"kubernetes","permalink":"https://anjia0532.github.io/tags/kubernetes/"}]},{"title":"068-用go写个同步eureka/nacos实例到apisix/kong的工具","date":"2021-12-30T20:35:21.000Z","path":"2021/12/30/discovery-syncer/","text":"这是坚持技术写作计划（含翻译）的第 68 篇，定个小目标 999，每周最少 2 篇。 用业余时间，一边百度 golang 语法一边写了个从 eureka/nacos 这类注册中心同步实例信息到 apisix/kong 的 upstream 的工具。 项目介绍项目地址 anjia0532/discovery-syncer 支持从 nacos(已实现)，eureka(已实现)等注册中心同步到 apisix(已实现)和 kong(已实现)等网关，后续将支持自定义插件，支持用户自己用 golang 实现支持类似携程阿波罗注册中心，etcd 注册中心，consul 注册中心等插件，以及 spring gateway 等网关插件的高扩展性 快速开始通过二进制运行从 releases 下载最新的对应系统的二进制文件 discovery-syncer-windows-amd64.exe --helpusage: discovery-syncer-windows-amd64.exe [&lt;flags&gt;]Flags: -h, --help Show context-sensitive help (also try --help-long and --help-man). -p, --web.listen-address=\":8080\" The address to listen on for web interface. -c, --config.file=\"config.yml\" Path to configuration file. 通过 docker 运行docker run anjia0532/discovery-syncer:v1.0.4 特别的，-c 支持配置远端 http[s]的地址，比如读取静态资源的，比如读取 nacos 的 -c http://xxxxx/nacos/v1/cs/configs?tenant=public&amp;group=DEFAULT_GROUP&amp;dataId=discovery-syncer.yaml,便于管理 配置文件# 是否启用 pprof# 通过 http://ip:port/debug/pprof/ 访问enable-pprof: falselogger: level: debug # debug,info,error logger: console # console vs file log-file: syncer.log # The file name of the logger output, does not exist automatically date-slice: y # Cut the document by date, support \"y\" (year), \"m\" (month), \"d\" (day), \"h\" (hour), default \"y\".# 注册中心,map形式discovery-servers: # nacos1 是注册中心的名字，可以随便定义，但是不能重复 nacos1: # 类型，目前仅支持 nacos和eureka type: nacos # 默认，如果注册中心没有返回权重时，添加的默认权重 weight: 100 # 注册中心的url前缀 prefix: /nacos/v1/ # 注册中心的连接地址，注意最后不能带/ host: \"http://nacos-server:8858\" eureka1: type: eureka weight: 100 prefix: /eureka/ # 对于basic认证，可以这么写 host: \"http://admin:admin@eureka-server:8761\"# 网关,map形式gateway-servers: # 网关名字，可以随便写，但是不能重复 apisix1: # 网关类型，目前支持apisix和kong type: apisix # 管理端host,注意最后不能有/ admin-url: http://apisix-server:9080 # 管理端uri前缀 prefix: /apisix/admin/ # 特别的扩展参数，在config里用key:value形式添加 config: X-API-KEY: xxxxx kong1: type: kong admin-url: http://kong-server:8001 prefix: /upstreams/# 同步任务，列表形式targets: # 注意同一个注册中心，但是有多个租户（类似nacos的命名空间）时，不需要创建多个相同的注册中心 # 只需要创建多个targets，然后改config的扩展参数即可 # 第一个任务 # 注册中心，来源 - discovery: nacos1 # 网关，目标 gateway: apisix1 # 是否启用 enabled: false # 拉取间隔，具体支持表达式，详见 https://github.com/robfig/cron fetch-interval: \"@every 10s\" # 默认是把能拉倒的注册中心的服务都拉过来，有些不需要的，则进行排除,支持正则 exclude-service: [\"ex*\", \"test\"] # 同步到网关的upstream的名字的前缀，便于管理 upstream-prefix: nacos1 # 对于health检查时，超过限定秒数的，认为是失联状态，默认是10秒 maximum-interval-sec: 20 # 扩展参数 config: # nacos 的groupName groupName: DEFAULT_GROUP # nacos的 namespace namespaceId: test # 创建到apisix 的upstream的默认模板，具体支持的模板语法，自行搜索 golang text/template template: | &#123; \"id\": \"syncer-&#123;&#123;.Name&#125;&#125;\", \"timeout\": &#123; \"connect\": 30, \"send\": 30, \"read\": 30 &#125;, \"name\": \"&#123;&#123;.Name&#125;&#125;\", \"nodes\": &#123;&#123;.Nodes&#125;&#125;, \"type\":\"roundrobin\", \"desc\": \"auto sync by https://github.com/anjia0532/discovery-syncer\" &#125; - discovery: eureka1 gateway: kong1 enabled: false fetch-interval: \"@every 5s\" maximum-interval-sec: 10 config: template: | &#123; \"name\": \"&#123;&#123;.Name&#125;&#125;\", \"algorithm\": \"round-robin\", \"hash_on\": \"none\", \"hash_fallback\": \"none\", \"hash_on_cookie_path\": \"/\", \"slots\": 10000, \"healthchecks\": &#123; \"passive\": &#123; \"healthy\": &#123; \"http_statuses\": [200, 201, 202, 203, 204, 205, 206, 207, 208, 226, 300, 301, 302, 303, 304, 305, 306, 307, 308], \"successes\": 0 &#125;, \"type\": \"http\", \"unhealthy\": &#123; \"http_statuses\": [429, 500, 503], \"timeouts\": 0, \"http_failures\": 0, \"tcp_failures\": 0 &#125; &#125;, \"active\": &#123; \"timeout\": 1, \"https_sni\": \"example.com\", \"http_path\": \"/\", \"concurrency\": 10, \"https_verify_certificate\": true, \"type\": \"http\", \"healthy\": &#123; \"http_statuses\": [200, 302], \"successes\": 0, \"interval\": 0 &#125;, \"unhealthy\": &#123; \"http_statuses\": [429, 404, 500, 501, 502, 503, 504, 505], \"timeouts\": 0, \"http_failures\": 0, \"interval\": 0, \"tcp_failures\": 0 &#125; &#125;, \"threshold\": 0 &#125;, \"tags\": [\"discovery-syncer-auto\"] &#125; Api 接口 路径 返回值 用途 GET / OK 服务是否启动 GET /-/reload OK 重新加载配置文件，加载成功返回 OK，主要是 cicd 场景或者 k8s 的 configmap reload 场景使用 GET /health JSON 判断服务是否健康，可以配合 k8s 等容器服务的健康检查使用 PUT /discovery/{name} OK 主动下线上线注册中心的服务,配合 CICD 发版业务用 GET /health 的返回值 &#123; // 一共有几个enabled的同步任务(targets) \"total\": 2, // 正常在跑的有几个 \"running\": 2, // 有几个超过 配置文件定义的maximum-interval-sec的检测时间没有运行的，失联的。 \"lost\": 0, // 都在跑，状态是OK（http状态码是200），有在跑的，有失联的，状态是WARN（http状态码是200），全部失联，状态是DOWN(http状态码500) \"status\": \"OK\", // 哪些成功，哪些失败 \"details\": [\"syncer:a_task,is ok\", \"syncer:b-api,is ok\"], // 运行时长 \"uptime\": \"1m6s\"&#125; PUT /discovery/{name} 中的 name 是注册中的名字，如果不存在，则返回 Not Found body 入参 &#123; // 检索哪个服务下的实例 \"serviceName\": \"\", // 基于注册中心元数据还是基于实例ip来查找 \"type\": \"METADATA/IP\", // 匹配的查询条件，支持正则 \"regexpStr\": \"\", // 匹配的元数据key，如果是ip则不用填 \"metadataKey\": \"\", // 匹配到的将状态改成上线还是下线 \"status\": \"UP/DOWN\", // 其他没匹配的，状态是上线还是下线，ORIGIN保持不变 \"otherStatus\": \"UP/DOWN/ORIGIN\", // 扩展参数 \"extData\": &#123;&#125;&#125; 待优化点 目前的同步任务是串行的，如果待同步的量比较大，或者同步时间窗口设置的特别小的情况下，会导致挤压 不支持自定义同步插件，不利于自行扩展 同步机制目前是基于定时轮询，效率比较低，有待优化，比如增加缓存开关，上游注册中心与缓存比对没有差异的情况下，不去拉取/变更下游网关的 upstream 信息，或者看看注册中心支不支持变动主动通知机制等。 招聘小广告山东济南的小伙伴欢迎投简历啊 加入我们 , 一起搞事情。长期招聘，Java 程序员，大数据工程师，运维工程师，前端工程师。 参考资料 我的博客 我的掘金","tags":[{"name":"apisix","slug":"apisix","permalink":"https://anjia0532.github.io/tags/apisix/"},{"name":"nginx","slug":"nginx","permalink":"https://anjia0532.github.io/tags/nginx/"},{"name":"kong","slug":"kong","permalink":"https://anjia0532.github.io/tags/kong/"},{"name":"微服务","slug":"微服务","permalink":"https://anjia0532.github.io/tags/微服务/"},{"name":"golang","slug":"golang","permalink":"https://anjia0532.github.io/tags/golang/"},{"name":"eureka","slug":"eureka","permalink":"https://anjia0532.github.io/tags/eureka/"},{"name":"nacos","slug":"nacos","permalink":"https://anjia0532.github.io/tags/nacos/"}]},{"title":"067-Google Container Registry(gcr.io) 中国可用镜像(长期维护，王者归来)","date":"2021-12-30T19:35:21.000Z","path":"2021/12/30/gcr_io_mirror/","text":"这是坚持技术写作计划（含翻译）的第 67 篇，定个小目标 999，每周最少 2 篇。 17 年在 github 上搞了个项目，用来同步 gcr.io 的镜像 ,详见 https://anjia0532.github.io/2017/11/15/gcr-io-image-mirror/ ,后来因为被 travis 检测到流量异常，认为滥用结果 travis 账号被禁。 被禁后，考虑到当时中科大和*.azk8s.cn 都提供了加速业务，gcr.io_mirror 已经完成了历史使命，所以一边申请解封 travis 账号，一边将原项目归档，不再提供同步 gcr.io 的任务。 前两天接到小伙伴私信，说是中科大和*.azk8s.cn 都不再提供服务了，所以就花了点时间，重新搞了下 gcr.io_mirror 之前老版本是根据命名空间全量同步，但是实际上在用的过程中，大多是不会有 N 年前的老版本的，所以转换下思路，改成按需拉取，基于这个思路配合 github action 搞了一版新的。 镜像对应关系# 原镜像名称gcr.io/namespace/image_name:image_tag# 等同于anjia0532/namespace.image_name:image_tag# 特别的对于 k8s.gcr.iok8s.gcr.io/&#123;image&#125;:&#123;tag&#125; &lt;==&gt; gcr.io/google-containers/&#123;image&#125;:&#123;tag&#125; &lt;==&gt; anjia0532/google-containers.&#123;image&#125;:&#123;tag&#125; 如何拉取新镜像创建 issues ,将自动触发 github actions 进行拉取转推到 docker hub 注意： issues 标题必须为 [PORTER]镜像名:tag 的格式，例如 要拉取 k8s.gcr.io/federation-controller-manager-arm64:v1.3.1-beta.1 镜像,则 issues 的标题为[PORTER]gcr.io/google-containers/federation-controller-manager-arm64:v1.3.1-beta.1issues 的内容无所谓，可以为空可以参考 已搬运镜像集锦 注意:本项目目前仅支持 gcr.io 和 k8s.gcr.io 镜像 招聘小广告山东济南的小伙伴欢迎投简历啊 加入我们 , 一起搞事情。长期招聘，Java 程序员，大数据工程师，运维工程师，前端工程师。 参考资料 我的博客 我的掘金","tags":[{"name":"docker","slug":"docker","permalink":"https://anjia0532.github.io/tags/docker/"},{"name":"k8s","slug":"k8s","permalink":"https://anjia0532.github.io/tags/k8s/"},{"name":"kubernetes","slug":"kubernetes","permalink":"https://anjia0532.github.io/tags/kubernetes/"},{"name":"gcr.io","slug":"gcr-io","permalink":"https://anjia0532.github.io/tags/gcr-io/"},{"name":"k8s.gcr.io","slug":"k8s-gcr-io","permalink":"https://anjia0532.github.io/tags/k8s-gcr-io/"}]},{"title":"066-unidbg-boot-server零基础入门","date":"2021-11-01T19:35:21.000Z","path":"2021/11/01/unidbg-boot-server/","text":"这是坚持技术写作计划（含翻译）的第 66 篇，定个小目标 999，每周最少 2 篇。 本文主要讲解 anjia0532/unidbg-boot-server 如何使用，以及一些群友反馈的常见问题的处理。 啥是 unidbg简单来说 zhkl0228/unidbg 是凯神 的基于unicorn-engine/unicorn 开发的一个可编程的 Android 和 ios 的模拟器。当然做好心理准备，unidbg 并不是一个商业完备的模拟器，随着深入使用，几乎免不了的会遇到各种问题（比如内存管理，比如某些特性缺失啥的），但是，又不是不能用，要啥自行车 unidbg-boot-server 和 unidbg 的关系就像 zhkl0228/unidbg 之于unicorn-engine/unicorn，anjia0532/unidbg-boot-server 虽然最初定位是一个开箱机用的 unidbg 的高性能多线程的 http server，但是只是这点的话，那格局就小了，目前 unidbg-boot-server 的定位是 基于 unidbg 的开箱机用，新手友好，集成最佳实践的 unidbg 脚手架，Javaer 可以无门槛上手，pythoner 等无 java 基础的也可以低成本上手。 环境准备 Idea，以及一些简单的 jetbrains 家工具的使用经验(idea,goland,pycharm,webstorm 等) Java8 mac 或者 linux 也可以用 openjdk,但是别自以为是的用 java11+,除非你确定你能 hold 住。Windows 建议参考我的 jdk 绿色免安装 ，虽然麻烦点，但是可以避免一些坑。如果是 linux 或者 mac，想用 oracle 的 jdk，可以参考 044-wget 免登陆下载 jdk 8u291 Maven3.5以上 ，如果电脑没有安装 Maven，最简单办法是将下面的 mvn 命令替换成 mvnw(如果是 linux/mac 一类的，要替换成./mvnw,并且先执行chmod +x ./mvnw) ，会自动下载 maven git 建议最新版 idea Lombok 插件 【可选】配置 maven 加速器 阿里云加速器，博客园相关文章 aliyun 阿里云 Maven 仓库地址——加速你的 maven 构建 【可选】掌握科学上网或者加速访问 github 的方法，参考 提高国内访问 github 速度的 9 种方法！，稳定可靠的是使用 gitee 转一层，长期可用。简单省事的是使用反代服务器，比如 https://hub.fastgit.org/，一般是将github.com 替换成 hub.fastgit.org，但是随着用的人多，会被拦截，提示被滥用。 下载 unidbg-boot-server 并运行快速体验使用命令行 # 也可以试试hub.fastgit.org 加速器，不保证长期可用# git clone https://hub.fastgit.org/anjia0532/unidbg-boot-server.gitgit clone https://github.com/anjia0532/unidbg-boot-server.git# 体验jar版本,打成jar包，-T是10线程，加速构建，-DskipTests 是跳过单元测试mvn package -T10 -DskipTests# 没有maven就用 mvnw package -T10 -DskipTests (linux等需要用 chmod +x ./mvnw &amp;&amp; ./mvnw package -T10 -DskipTests)# 运行java -jar target\\unidbg-boot-server-0.0.1-SNAPSHOT.jar 使用 idea参考 在 IDEA 中配置及使用 Maven 的全过程 配置 maven 运行 . ____ _ __ _ _ /\\\\ / ___'_ __ _ _(_)_ __ __ _ \\ \\ \\ \\( ( )\\___ | '_ | '_| | '_ \\/ _` | \\ \\ \\ \\ \\\\/ ___)| |_)| | | | | || (_| | ) ) ) ) ' |____| .__|_| |_|_| |_\\__, | / / / / =========|_|==============|___/=/_/_/_/ :: Spring Boot :: (v2.5.5)2021-11-01 12:01:17.689 INFO 33648 --- [ main] c.a.u.UnidbgServerApplication : Starting UnidbgServerApplication using Java 1.8.0_221 on AnJia with PID 33648 (D:\\AnJia\\Work\\workspace\\idea\\unidbg-boot-server1\\target\\classes started by AnJia in D:\\AnJia\\Work\\workspace\\idea\\unidbg-boot-server1)2021-11-01 12:01:17.692 INFO 33648 --- [ main] c.a.u.UnidbgServerApplication : The following profiles are active: dev2021-11-01 12:01:19.224 INFO 33648 --- [ main] c.a.u.service.TTEncryptServiceWorker : 线程池为:82021-11-01 12:01:19.225 INFO 33648 --- [435772@424de326] c.a.u.service.TTEncryptServiceWorker : 是否启用动态引擎:true,是否打印详细信息:false2021-11-01 12:01:19.594 WARN 33648 --- [ main] ion$DefaultTemplateResolverConfiguration : Cannot find template location: classpath:/templates/ (please add some templates or check your Thymeleaf configuration)2021-11-01 12:01:19.699 INFO 33648 --- [ main] c.a.u.UnidbgServerApplication : Started UnidbgServerApplication in 2.755 seconds (JVM running for 4.456)2021-11-01 12:01:19.710 INFO 33648 --- [ main] c.a.u.UnidbgServerApplication :---------------------------------------------------------- 应用: unidbg-boot-server 已启动! 地址: http://127.0.0.1:9999/ 演示访问: curl http://127.0.0.1:9999/api/tt-encrypt/encrypt (linux) 演示访问: http://127.0.0.1:9999/api/tt-encrypt/encrypt (windows: 浏览器直接打开) 常见问题: https://github.com/anjia0532/unidbg-boot-server/blob/main/QA.md 配置文件: [application, application-dev]----------------------------------------------------------2021-11-01 12:01:19.710 INFO 33648 --- [ main] c.a.u.UnidbgServerApplication :----------------------------------------------------------2021-11-01 12:01:20.201 INFO 33648 --- [435772@424de326] c.a.u.service.TTEncryptServiceWorker : 是否启用动态引擎:true,是否打印详细信息:false2021-11-01 12:01:20.327 INFO 33648 --- [435772@424de326] c.a.u.service.TTEncryptServiceWorker : 是否启用动态引擎:true,是否打印详细信息:false2021-11-01 12:01:20.456 INFO 33648 --- [435772@424de326] c.a.u.service.TTEncryptServiceWorker : 是否启用动态引擎:true,是否打印详细信息:false2021-11-01 12:01:20.556 INFO 33648 --- [435772@424de326] c.a.u.service.TTEncryptServiceWorker : 是否启用动态引擎:true,是否打印详细信息:false2021-11-01 12:01:20.635 INFO 33648 --- [435772@424de326] c.a.u.service.TTEncryptServiceWorker : 是否启用动态引擎:true,是否打印详细信息:false2021-11-01 12:01:20.725 INFO 33648 --- [435772@424de326] c.a.u.service.TTEncryptServiceWorker : 是否启用动态引擎:true,是否打印详细信息:false2021-11-01 12:01:20.816 INFO 33648 --- [435772@424de326] c.a.u.service.TTEncryptServiceWorker : 是否启用动态引擎:true,是否打印详细信息:false 关键是这里,防止刚接触 spring boot 的，找不到访问地址，（主要是被问烦了），直接打印出来（就这样还 TM 有眼瞎看不到的，也是醉了） ---------------------------------------------------------- 应用: unidbg-boot-server 已启动! 地址: http://127.0.0.1:9999/ 演示访问: curl http://127.0.0.1:9999/api/tt-encrypt/encrypt (linux) 演示访问: http://127.0.0.1:9999/api/tt-encrypt/encrypt (windows: 浏览器直接打开) 常见问题: https://github.com/anjia0532/unidbg-boot-server/blob/main/QA.md 配置文件: [application, application-dev]---------------------------------------------------------- 如何使用自己魔改的 unidbg总有一些大佬发现标版 unidbg 满足不了（或者有 bug）自己，需要自行修改 unidbg。 # git clone https://hub.fastgit.org/zhkl0228/unidbg.gitgit clone https://github.com/zhkl0228/unidbg.git# 自己导入idea，各种修改后，改下pom.xml中的版本号# 安装到本地mvn clean install -Dgpg.skip=true -T10 如何自己写逻辑运行 src/test/java/com/anjia/unidbgserver/AutoGeneratorTest.java把自己的业务逻辑移植/实现到 src/main/java/com/anjia/unidbgserver/service/*Service.java里 修改参数入参，修改 src/main/java/com/anjia/unidbgserver/web/*Controller.java 关于这个类里的注解不会用的，自行百度，或者参考Spring MVC @RequestMapping Annotation Example with Controller, Methods, Headers, Params, @RequestParam, @PathVariable 主要 unidbg 模拟逻辑在 com.anjia.unidbgserver.service.*Service 里com.anjia.unidbgserver.web.*Controller 是暴露给外部 http 调用的com.anjia.unidbgserver.service.*ServiceWorker 是用多线程包装了一层业务逻辑com.anjia.unidbgserver.service.*ServiceTest 是单元测试 可不可以不要单元测试/单元测试如何写/如何用完全可以，但是不建议。个人认为单元测试是这个项目的灵魂。想象一下原来写 unidbg 时，是不是得创建一个个逻辑类，自己写 N 多个 main 来测试不同的情况，还得配合着横七竖八的注释，来屏蔽代码，让它不生效。 用单元测试多优雅啊，先用 src/test/java/com/anjia/unidbgserver/AutoGeneratorTest.java 生成框架，直接在 Service 里写逻辑，遇到新项目还是研究阶段的，写不同的单元测试方法就行了。不用改了重启访问 url。直接调用方法不香吗？ 其他一些常见问题都整理到这里了 常见问题汇总 ，先看，先看，先看，别上来就问就问就问。 关于是否开源基于 Jnitrace 日志补环境代码说明详见 关于是否开源基于 Jnitrace 日志补环境代码说明 招聘小广告山东济南的小伙伴欢迎投简历啊 加入我们 , 一起搞事情。长期招聘，Java 程序员，大数据工程师，运维工程师，前端工程师。 参考资料 我的博客 我的掘金 044-wget 免登陆下载 jdk 8u291 jdk 绿色免安装","tags":[{"name":"逆向","slug":"逆向","permalink":"https://anjia0532.github.io/tags/逆向/"},{"name":"unidbg","slug":"unidbg","permalink":"https://anjia0532.github.io/tags/unidbg/"}]},{"title":"065-使用Java将pdf转换并拼接成一张图片","date":"2021-09-09T19:35:21.000Z","path":"2021/09/09/convert-pdf-to-png/","text":"这是坚持技术写作计划（含翻译）的第 65 篇，定个小目标 999，每周最少 2 篇。 本文 主要讲解通过 java 将 pdf 转换成一张图片(基于apache pdfbox),需要注意本方法不适用于页数特别多的情况(容易 OOM),如果页码多的情况，还是建议生成多张图片 依赖库 参考 https://pdfbox.apache.org/3.0/migration.html#dependency-updates &lt;dependency&gt; &lt;groupId&gt;org.apache.pdfbox&lt;/groupId&gt; &lt;artifactId&gt;pdfbox&lt;/artifactId&gt; &lt;version&gt;3.0.0-RC1&lt;/version&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.apache.pdfbox&lt;/groupId&gt; &lt;artifactId&gt;pdfbox-tools&lt;/artifactId&gt; &lt;version&gt;3.0.0-RC1&lt;/version&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.apache.pdfbox&lt;/groupId&gt; &lt;artifactId&gt;fontbox&lt;/artifactId&gt; &lt;version&gt;3.0.0-RC1&lt;/version&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.apache.pdfbox&lt;/groupId&gt; &lt;artifactId&gt;jbig2-imageio&lt;/artifactId&gt; &lt;version&gt;3.0.3&lt;/version&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;com.github.jai-imageio&lt;/groupId&gt; &lt;artifactId&gt;jai-imageio-core&lt;/artifactId&gt; &lt;version&gt;1.4.0&lt;/version&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;com.github.jai-imageio&lt;/groupId&gt; &lt;artifactId&gt;jai-imageio-jpeg2000&lt;/artifactId&gt; &lt;version&gt;1.4.0&lt;/version&gt;&lt;/dependency&gt; import lombok.extern.slf4j.Slf4j;import org.apache.commons.io.FileUtils;import org.apache.pdfbox.Loader;import org.apache.pdfbox.pdmodel.PDDocument;import org.apache.pdfbox.rendering.ImageType;import org.apache.pdfbox.rendering.PDFRenderer;import org.apache.pdfbox.tools.imageio.ImageIOUtil;import org.junit.Test;import javax.imageio.ImageIO;import java.awt.image.BufferedImage;import java.io.File;import java.io.IOException;import java.net.URL;import java.util.ArrayList;import java.util.List;import java.util.Objects;/** * pdf 工具类 * * @author AnJia * @since 2021-09-09 16:05 */@Slf4jpublic class PdfUtils &#123; @Test public void convertPdf2ImageTest() throws IOException &#123; // pdf转换成单张图片 convertPdf2Image(\"https://file-examples-com.github.io/uploads/2017/10/file-sample_150kB.pdf\", System.getProperty(\"java.io.tmpdir\") + \"anjia\", \"sample.png\"); // pdf转换成多张 convertPdf2Images(\"https://file-examples-com.github.io/uploads/2017/10/file-sample_150kB.pdf\", System.getProperty(\"java.io.tmpdir\") + \"anjia\", \"sample.png\"); &#125; /** * 将pdf转成一张图片,如果要输出的文件已经存在，则不会进行转换 * * @param url pdf url * @param fileName 文件名带png后缀，例如 xxxx.png * @param dir 存放文件夹，如果不存在会自动创建 * @return 文件，如果报错，则会返回null * @throws IOException 文件下载失败 */ public File convertPdf2Image(String url, String dir, String fileName) throws IOException &#123; File pdfFile = new File(new File(dir).getAbsolutePath() + File.separator + fileName + \".pdf\"); pdfFile.getParentFile().mkdirs(); FileUtils.copyURLToFile(new URL(url), pdfFile); return convertPdf2Image(pdfFile, dir, fileName); &#125; /** * 将pdf转成一张图片,如果要输出的文件已经存在，则不会进行转换 * * @param pdfFile pdf 文件 * @param fileName 文件名带png后缀，例如 xxxx.png * @param dir 存放文件夹，如果不存在会自动创建 * @return 文件，如果报错，则会返回null */ public File convertPdf2Image(File pdfFile, String dir, String fileName) &#123; File pngFile = new File(new File(dir).getAbsolutePath() + File.separator + fileName); if (pngFile.exists()) &#123; return pngFile; &#125; try (final PDDocument document = Loader.loadPDF(pdfFile)) &#123; PDFRenderer pdfRenderer = new PDFRenderer(document); // 不知道图片的宽和高，所以先定义个null BufferedImage pdfImage = null; // pdf有多少页 int pageSize = document.getNumberOfPages(); int y = 0; for (int i = 0; i &lt; pageSize; ++i) &#123; // 每页pdf内容 BufferedImage bim = pdfRenderer.renderImageWithDPI(i, 300, ImageType.RGB); // 如果是第一页需要初始化 BufferedImage if (Objects.isNull(pdfImage)) &#123; // 假设每页一样宽，一样高，高度就是每页高度*总页数 pdfImage = new BufferedImage(bim.getWidth(), bim.getHeight() * pageSize, BufferedImage.TYPE_INT_ARGB); &#125; // 将每页pdf画到总的pdfImage上,x坐标=0，y坐标=之前所有页的高度和 pdfImage.getGraphics().drawImage(bim, 0, y, null); y += bim.getHeight(); &#125; assert pdfImage != null; ImageIO.write(pdfImage, \"png\", pngFile); return pngFile; &#125; catch (Exception ex) &#123; log.error(\"pdf转换png失败\", ex); &#125; return null; &#125; /** * 将pdf转换成多张图片(1页pdf转换成1张图片),如果要输出的图片已经存在，则不会进行转换 * * @param url pdf url * @param dir 存放目录 * @param baseFileName pdf文件名 * @return 如果转换成功会返回 图片文件list，如果失败会返回null * @throws IOException 下载文件失败 */ public List&lt;File&gt; convertPdf2Images(String url, String dir, String baseFileName) throws IOException &#123; File pdfFile = new File(dir + File.separator + baseFileName + \".pdf\"); pdfFile.getParentFile().mkdirs(); FileUtils.copyURLToFile(new URL(url), pdfFile); return convertPdf2Images(pdfFile, dir, baseFileName); &#125; /** * 将pdf转换成多张图片(1页pdf转换成1张图片),如果要输出的图片已经存在，则不会进行转换 * * @param pdfFile pdf 文件 * @param dir 存放目录 * @param baseFileName pdf文件名 * @return 如果转换成功会返回 图片文件list，如果失败会返回null */ public List&lt;File&gt; convertPdf2Images(File pdfFile, String dir, String baseFileName) &#123; List&lt;File&gt; images = null; File directory = new File(dir); directory.mkdirs(); try (final PDDocument document = Loader.loadPDF(pdfFile)) &#123; PDFRenderer pdfRenderer = new PDFRenderer(document); // pdf有多少页 int pageSize = document.getNumberOfPages(); images = new ArrayList&lt;&gt;(pageSize); File pageFile; for (int i = 0; i &lt; pageSize; ++i) &#123; pageFile = new File(String.format(\"%s%s%s-%s.png\", directory.getAbsolutePath(), File.separator, baseFileName, i)); if (pageFile.exists()) &#123; continue; &#125; BufferedImage bim = pdfRenderer.renderImageWithDPI(i, 300, ImageType.RGB); ImageIOUtil.writeImage(bim, pageFile.getAbsolutePath(), 300); images.add(pageFile); &#125; &#125; catch (Exception ex) &#123; log.error(\"pdf转换png失败\", ex); &#125; return images; &#125;&#125; 招聘小广告山东济南的小伙伴欢迎投简历啊 加入我们 , 一起搞事情。长期招聘，Java 程序员，大数据工程师，运维工程师，前端工程师。 参考资料 我的博客 我的掘金 Convert PDF Files to PNG, JPEG, BMP, and TIFF Images using Java pdfbox document &gt;&gt; Migration to PDFBox 2.0.0#pdf-rendering","tags":[{"name":"java","slug":"java","permalink":"https://anjia0532.github.io/tags/java/"},{"name":"pdf","slug":"pdf","permalink":"https://anjia0532.github.io/tags/pdf/"},{"name":"png","slug":"png","permalink":"https://anjia0532.github.io/tags/png/"},{"name":"tools","slug":"tools","permalink":"https://anjia0532.github.io/tags/tools/"},{"name":"utils","slug":"utils","permalink":"https://anjia0532.github.io/tags/utils/"}]},{"title":"064-真正解决scrapy自动将header请求头大写问题","date":"2021-08-05T19:35:21.000Z","path":"2021/08/05/scrapy-capitalizes-request-headers/","text":"这是坚持技术写作计划（含翻译）的第 64 篇，定个小目标 999，每周最少 2 篇。 本文主要讲解如何真正解决 scrapy 将 header 请求头自动大写(str.title())的问题 背景搞了个小爬虫，命名参数都正常，但是被模目标网站识别了，用 requests 又都正常，问题出在 scrapy 没跑了 分析过程用到的工具 fiddler , charles , wireshark 任选一个抓包工具就行 beyondcompare 等比对工具 分别用 request 和 scrapy 请求目标网站，url，参数，form 等都用一样的数据（排除类似随机数，时间戳，rsa 非对称加密等导致的数据不一致的问题） 以 fiddler 为例，点开抓包数据，选择 Raw 选项卡，复制到比对工具里,真实用的过程中，找到问题了，scrapy 自动将 header 转换成大写了,看了下 scrapy 的源码， 问题出在https://github.com/scrapy/scrapy/blob/4d1ecc31c9bdb42638e8a1f85f7e7f83130f41f3/scrapy/http/headers.py#L15 的 key.title() def normkey(self, key): \"\"\"Normalize key to bytes\"\"\" return self._tobytes(key.title()) 开始以为解决起来比较简单，用了网上的一些办法，还是不行。后来又研究了下源码，结合网上的方案，终于搞定了 新建Headers.py,复制自 https://github.com/scrapy/scrapy/blob/4d1ecc31c9bdb42638e8a1f85f7e7f83130f41f3/scrapy/http/headers.py ,只改第 15 行将 self._tobytes(key.title())改成self._tobytes(key) from w3lib.http import headers_dict_to_rawfrom scrapy.utils.datatypes import CaselessDictfrom scrapy.utils.python import to_unicodeclass Headers(CaselessDict): \"\"\"Case insensitive http headers dictionary\"\"\" def __init__(self, seq=None, encoding='utf-8'): self.encoding = encoding super().__init__(seq) def normkey(self, key): \"\"\"Normalize key to bytes\"\"\" return self._tobytes(key) def normvalue(self, value): \"\"\"Normalize values to bytes\"\"\" if value is None: value = [] elif isinstance(value, (str, bytes)): value = [value] elif not hasattr(value, '__iter__'): value = [value] return [self._tobytes(x) for x in value] def _tobytes(self, x): if isinstance(x, bytes): return x elif isinstance(x, str): return x.encode(self.encoding) elif isinstance(x, int): return str(x).encode(self.encoding) else: raise TypeError(f'Unsupported value type: &#123;type(x)&#125;') def __getitem__(self, key): try: return super().__getitem__(key)[-1] except IndexError: return None def get(self, key, def_val=None): try: return super().get(key, def_val)[-1] except IndexError: return None def getlist(self, key, def_val=None): try: return super().__getitem__(key) except KeyError: if def_val is not None: return self.normvalue(def_val) return [] def setlist(self, key, list_): self[key] = list_ def setlistdefault(self, key, default_list=()): return self.setdefault(key, default_list) def appendlist(self, key, value): lst = self.getlist(key) lst.extend(self.normvalue(value)) self[key] = lst def items(self): return ((k, self.getlist(k)) for k in self.keys()) def values(self): return [self[k] for k in self.keys()] def to_string(self): return headers_dict_to_raw(self) def to_unicode_dict(self): \"\"\" Return headers as a CaselessDict with unicode keys and unicode values. Multiple values are joined with ','. \"\"\" return CaselessDict( (to_unicode(key, encoding=self.encoding), to_unicode(b','.join(value), encoding=self.encoding)) for key, value in self.items()) def __copy__(self): return self.__class__(self) copy = __copy__ 修改 scrapy 的settings.py文件,参考 twisted 的源码 https://github.com/twisted/twisted/blob/022659ca88dca6361288cd26486942cba0ed77c4/src/twisted/web/http_headers.py#L261-L279 # 忽略其他from twisted.web.http_headers import Headers as TwistedHeadersTwistedHeaders._caseMappings.update(&#123; b\"aa\": b\"aa\", b\"aa-aa\": b\"aa-aa\", b\"aa-bb\": b\"AA-BB\", b\"aa-cc\": b\"AA-cc\",&#125;)# 清空默认headerDEFAULT_REQUEST_HEADERS = &#123;&#125; 修改使用代码 from your.package import Headersheaders = &#123; \"aa\": \"a\", \"aa-aa\": \"aa-aa\", \"aa-bb\": \"AA-BB\", \"aa-cc\": \"AA-cc\", # 千万别用 AA-BB或者AA-cc这样的，就是全部用小写，通过修改TwistedHeaders._caseMappings.update的映射来实现就行了&#125;yield scrapy.FormRequest(url=url + \"?\" + parse.urlencode(params, quote_via=parse.quote), formdata=body, dont_filter=True, errback=self.error,headers=Headers(headers), 招聘小广告山东济南的小伙伴欢迎投简历啊 加入我们 , 一起搞事情。长期招聘，Java 程序员，大数据工程师，运维工程师，前端工程师。 参考资料 我的博客 我的掘金 Scrapy capitalizes request headers How to prevent scrapy from forcing the key of the request headers into uppercase?","tags":[{"name":"python","slug":"python","permalink":"https://anjia0532.github.io/tags/python/"},{"name":"scrapy","slug":"scrapy","permalink":"https://anjia0532.github.io/tags/scrapy/"},{"name":"爬虫","slug":"爬虫","permalink":"https://anjia0532.github.io/tags/爬虫/"}]},{"title":"063-apisix基于acme.sh自动更新HTTPS证书","date":"2021-05-24T20:05:21.000Z","path":"2021/05/24/renew-hook-update-apisix/","text":"这是坚持技术写作计划（含翻译）的第 63 篇，定个小目标 999，每周最少 2 篇。 apisix 官方不支持自动更新 ssl 证书，但是开放了 api，本文主要讲解如何使用 acme.sh 的 renew-hook 特性来实现自动更新 apisix 的 https 证书。 创建/更新 apisix ssl 脚本NOTE:需要安装 openssl , jq , acme.sh 我的脚本，支持检索已有 ssl 列表是否存在该证书，如果存在则更新，不存在则创建，snis 使用 OpenSSL 读的 pem，有效起止时间也是用 OpenSSL 读的 pem 将我的 gist 保存成可执行脚本,并添加执行权限 $ curl --output /root/.acme.sh/renew-hook-update-apisix.sh --silent https://gist.githubusercontent.com/anjia0532/9ebf8011322f43e3f5037bc2af3aeaa6/raw/65b359a4eed0ae990f9188c2afa22bacd8471652/renew-hook-update-apisix.sh$ chmod +x /root/.acme.sh/renew-hook-update-apisix.sh$ /root/.acme.sh/renew-hook-update-apisix.shUsage : /root/.acme.sh/renew-hook-update-apisix.sh -h &lt;apisix admin host&gt; -p &lt;certificate pem file&gt; -k &lt;certificate private key file&gt; -a &lt;admin api key&gt; -t &lt;print debug info switch off/on,default off&gt; 考虑到国内网络环境，所以此处贴出 renew-hook-update-apisix.sh 的代码，但是注意，后续更新以gist为主 #!/usr/bin/env bash# author anjia0532@gmail.com# blog https://anjia0532.github.io/# github https://github.com/anjia0532# this script depend on jq,check it firstRED='\\033[0;31m'NC='\\033[0m' # No Colorif ! [ -x \"$(command -v jq)\" ]; then echo -e \"$&#123;RED&#125;Error: jq is not installed.$&#123;NC&#125;\" &gt;&amp;2 exit 1fiif ! [ -x \"$(command -v openssl)\" ]; then echo -e \"$&#123;RED&#125;Error: openssl is not installed.$&#123;NC&#125;\" &gt;&amp;2 exit 1fiif ! [ -x \"$(command -v ~/.acme.sh/acme.sh)\" ]; then echo -e \"$&#123;RED&#125;Error: acme.sh is not installed.(doc https://github.com/acmesh-official/acme.sh/wiki/How-to-install)$&#123;NC&#125;\" &gt;&amp;2 exit 1fiusage () &#123; echo \"Usage : $0 -h &lt;apisix admin host&gt; -p &lt;certificate pem file&gt; -k &lt;certificate private key file&gt; -a &lt;admin api key&gt; -t &lt;print debug info switch off/on,default off&gt;\"; &#125;# parse argswhile getopts \"h:p:k:a:t:\" opts; do case $&#123;opts&#125; in h) HOST=$&#123;OPTARG&#125; ;; p) PEM=$&#123;OPTARG&#125; ;; k) KEY=$&#123;OPTARG&#125; ;; a) API_KEY=$&#123;OPTARG&#125; ;; t) DEBUG=$&#123;OPTARG&#125; ;; *) usage; exit;; esacdone# those args must be not nullif [ ! \"$HOST\" ] || [ ! \"$PEM\" ] || [ ! \"$KEY\" ] || [ ! \"$API_KEY\" ]then usage exit 1fi# optional args,set default value[ -z \"$DEBUG\" ] &amp;&amp; DEBUG=off# print vars key and value when DEBUG eq on[[ \"on\" == \"$DEBUG\" ]] &amp;&amp; echo -e \"HOST:$&#123;HOST&#125; API_KEY:$&#123;API_KEY&#125; PEM FILE:$&#123;PEM&#125; KEY FILE:$&#123;KEY&#125; DEBUG:$&#123;DEBUG&#125;\"# get all ssl and filter this one by sni namecert_content=$(curl --silent --location --request GET \"$&#123;HOST&#125;/apisix/admin/ssl/\" \\--header \"X-API-KEY: $&#123;API_KEY&#125;\" \\--header 'Content-Type: application/json' | jq \"first(.node.nodes[]| select(.value.snis[] | contains(\\\"$(openssl x509 -in $PEM -noout -text|grep -oP '(?&lt;=DNS:|IP Address:)[^,]+'|sort|head -n1)\\\")))\")validity_start=$(date --date=\"$(openssl x509 -startdate -noout -in $PEM|cut -d= -f 2)\" +\"%s\")validity_end=$(date --date=\"$(openssl x509 -enddate -noout -in $PEM|cut -d= -f 2)\" +\"%s\")# create a new ssl when it not existif [ -z \"$cert_content\" ]then cert_content=\"&#123;\\\"snis\\\":[],\\\"status\\\": 1&#125;\" # read domains from pem file by openssl snis=$(openssl x509 -in $PEM -noout -text|grep -oP '(?&lt;=DNS:|IP Address:)[^,]+'|sort) for sni in $&#123;snis[@]&#125; ; do cert_content=$(echo $cert_content | jq \".snis += [\\\"$sni\\\"]\") done cert_content=$(echo $cert_content | jq \".|.cert = \\\"$(cat $PEM)\\\"|.key = \\\"$(cat $KEY)\\\"|.validity_start=$&#123;validity_start&#125;|.validity_end=$&#123;validity_end&#125;\") cert_update_result=$(curl --silent --location --request POST \"$&#123;HOST&#125;/apisix/admin/ssl/\" \\ --header \"X-API-KEY: $&#123;API_KEY&#125;\" \\ --header 'Content-Type: application/json' \\ --data \"$cert_content\" ) [[ \"on\" == \"$DEBUG\" ]] &amp;&amp; echo -e \"cert_content: \\n$&#123;cert_content&#125;\\n\\ncreate result json:\\n\\n$&#123;cert_update_result&#125;\"else # get exist ssl id URI=$(echo $cert_content | jq -r \".key\") ID=$(echo $&#123;URI##*/&#125;) # get exist ssl certificate json , modify cert and key value cert_content=$(echo $cert_content | jq \".value|.cert = \\\"$(cat $PEM)\\\"|.key = \\\"$(cat $KEY)\\\"|.id=\\\"$&#123;ID&#125;\\\"|.update_time=$(date +'%s')|.validity_start=$&#123;validity_start&#125;|.validity_end=$&#123;validity_end&#125;\") # update apisix ssl cert_update_result=$(curl --silent --location --request PUT \"$&#123;HOST&#125;/apisix/admin/ssl/$&#123;ID&#125;\" \\ --header \"X-API-KEY: $&#123;API_KEY&#125;\" \\ --header 'Content-Type: application/json' \\ --data \"$cert_content\" ) [[ \"on\" == \"$DEBUG\" ]] &amp;&amp; echo -e \"cert_content: \\n$&#123;cert_content&#125;\\n\\nupdate result json:\\n\\n$&#123;cert_update_result&#125;\"fiexit 0 acme.sh 相关 安装 acme.sh 参考官方文档 https://github.com/acmesh-official/acme.sh/wiki/How-to-install curl https://get.acme.sh | sh -s email=my@example.com 申请证书,并添加 renew-hook 参考官方文档 https://github.com/acmesh-official/acme.sh/wiki/How-to-issue-a-cert 和 renew-hook 的文档 https://github.com/acmesh-official/acme.sh/wiki/Using-pre-hook-post-hook-renew-hook-reloadcmd $ acme.sh --issue --staging -d demo.domain --renew-hook \"/root/.acme.sh/renew-hook-update-apisix.sh -h http://apisix-admin:port -p /root/.acme.sh/demo.domain/demo.domain.cer -k /root/.acme.sh/demo.domain/demo.domain.key -a xxxxxxxxxxxxx\"$ acme.sh --renew --domain demo.domain 题外话，如果用 ansible 的话，也可以用我的ansible galaxy ,文档参考 https://github.com/anjia0532/ansible-acme-sh/blob/master/README.md ansible-galaxy install anjia0532.acme_sh 招聘小广告山东济南的小伙伴欢迎投简历啊 加入我们 , 一起搞事情。长期招聘，Java 程序员，大数据工程师，运维工程师，前端工程师。 参考资料 我的博客 我的掘金 request help: How to auto upgrade SSL certificate, such as using let’s encrypt #3841","tags":[{"name":"apisix","slug":"apisix","permalink":"https://anjia0532.github.io/tags/apisix/"},{"name":"openresty","slug":"openresty","permalink":"https://anjia0532.github.io/tags/openresty/"},{"name":"nginx","slug":"nginx","permalink":"https://anjia0532.github.io/tags/nginx/"},{"name":"kong","slug":"kong","permalink":"https://anjia0532.github.io/tags/kong/"},{"name":"acme.sh","slug":"acme-sh","permalink":"https://anjia0532.github.io/tags/acme-sh/"}]},{"title":"062-ubuntu LVM不停机扩/缩容磁盘常见运维操作","date":"2021-04-27T20:12:21.000Z","path":"2021/04/27/ubuntu-lvm/","text":"这是坚持技术写作计划（含翻译）的第 62 篇，定个小目标 999，每周最少 2 篇。 本文主要基于 ubuntu 讲解如何配置 lvm 的物理卷，逻辑卷，逻辑卷组，以及常见的扩容缩容操作。 物理存储介质（The physical media） 这里指系统的存储设备：硬盘，如：/dev/hda、/dev/sda 等等，是存储系统最低层的存储单元。 物理卷（physicalvolume） 物理卷就是指硬盘分区或从逻辑上与磁盘分区具有同样功能的设备(如 RAID)，是 LVM 的基本存储逻辑块，但和基本的物理存储介质（如分区、磁盘等）比较，却包含有与 LVM 相关的管理参数。 卷组（Volume Group） LVM 卷组类似于非 LVM 系统中的物理硬盘，其由物理卷组成。可以在卷组上创建一个或多个“LVM 分区”（逻辑卷），LVM 卷组由一个或多个物理卷组成。 逻辑卷（logicalvolume） LVM 的逻辑卷类似于非 LVM 系统中的硬盘分区，在逻辑卷之上可以建立文件系统(比如/home 或者/usr 等)。 PE（physical extent） 每一个物理卷被划分为称为 PE(Physical Extents)的基本单元，具有唯一编号的 PE 是可以被 LVM 寻址的最小单元。PE 的大小是可配置的，默认为 4MB。 LE（logical extent） 逻辑卷也被划分为被称为 LE(Logical Extents) 的可被寻址的基本单位。在同一个卷组中，LE 的大小和 PE 是相同的，并且一一对应。 引自 Linx 卷管理详解 VG LV PV 操作步骤从 esxi/vmware 添加磁盘，新加磁盘默认用fdisk -l 看不到，要么重启，要么 echo &quot;scsi add-single-device 32 0 2 0&quot;&gt;/proc/scsi/scsi 后再fdisk -l 参考 虚拟机 VMware 新增硬盘无法识别问题 fdisk -lDisk /dev/sdb: 100 GiB, 107374182400 bytes, 209715200 sectorsUnits: sectors of 1 * 512 = 512 bytesSector size (logical/physical): 512 bytes / 512 bytesI/O size (minimum/optimal): 512 bytes / 512 bytesDisk /dev/sdc: 50 GiB, 53687091200 bytes, 104857600 sectorsUnits: sectors of 1 * 512 = 512 bytesSector size (logical/physical): 512 bytes / 512 bytesI/O size (minimum/optimal): 512 bytes / 512 bytes# ...省略无用 发现有两块待用磁盘，具体操作如下 创建物理卷，逻辑卷组，逻辑卷# 基于磁盘创建物理卷&gt; pvcreate /dev/sdc Physical volume \"/dev/sdc\" successfully created # 查看已有物理卷 &gt; pvdisplay --- Physical volume --- PV Name /dev/sda5 VG Name rancher-252-vg PV Size 49.28 GiB / not usable 2.00 MiB Allocatable yes PE Size 4.00 MiB Total PE 12616 Free PE 4 Allocated PE 12612 PV UUID 9FdgPm-P5Ao-zK2Q-FEiA-aYOi-QBcM-PRVjIn \"/dev/sdc\" is a new physical volume of \"50.00 GiB\" --- NEW Physical volume --- PV Name /dev/sdc VG Name PV Size 50.00 GiB Allocatable NO PE Size 0 Total PE 0 Free PE 0 Allocated PE 0 PV UUID FGkHWb-y0d8-iq4D-OeFd-JAh4-Dx2K-vp46W0# 创建逻辑卷组&gt; vgcreate vg_data /dev/sdc Volume group \"vg_data\" successfully created# 查看逻辑卷组&gt; vgdisplay --- Volume group --- VG Name vg_data System ID Format lvm2 Metadata Areas 1 Metadata Sequence No 1 VG Access read/write VG Status resizable MAX LV 0 Cur LV 0 Open LV 0 Max PV 0 Cur PV 1 Act PV 1 VG Size 50.00 GiB PE Size 4.00 MiB Total PE 12799 Alloc PE / Size 0 / 0 Free PE / Size 12799 / 50.00 GiB VG UUID 8VgOL0-H0FU-ATx1-e9cF-NO2D-xffH-iDUqoD --- Volume group --- VG Name rancher-252-vg System ID Format lvm2 Metadata Areas 1 Metadata Sequence No 3 VG Access read/write VG Status resizable MAX LV 0 Cur LV 2 Open LV 2 Max PV 0 Cur PV 1 Act PV 1 VG Size 49.28 GiB PE Size 4.00 MiB Total PE 12616 Alloc PE / Size 12612 / 49.27 GiB Free PE / Size 4 / 16.00 MiB VG UUID MWvlQB-lTEX-Svxu-wcTA-R6EC-wniE-RKpzGH# 创建逻辑卷并分配所有空间&gt; lvcreate -l 100%VG -n lv_data vg_data Logical volume \"lv_data\" created.# 格式化并挂载磁盘# 格式化mkfs.ext4 /dev/mapper/vg_data-lv_data# 创建文件夹mkdir -p /data# 备份cp /etc/fstab /etc/fstab.bak# 弄成开机自动挂载echo `blkid /dev/mapper/vg_data-lv_data | awk '&#123;print $2&#125;' | sed 's/\\\"//g'` /data ext4 defaults 0 0 &gt;&gt; /etc/fstab# 现在挂载mount /dev/mapper/vg_data-lv_data /data/df -hFilesystem Size Used Avail Use% Mounted onudev 7.9G 0 7.9G 0% /devtmpfs 1.6G 8.8M 1.6G 1% /run/dev/mapper/rancher--252--vg-root 48G 2.0G 44G 5% /tmpfs 7.9G 0 7.9G 0% /dev/shmtmpfs 5.0M 0 5.0M 0% /run/locktmpfs 7.9G 0 7.9G 0% /sys/fs/cgroup/dev/sda1 720M 58M 626M 9% /boottmpfs 1.6G 0 1.6G 0% /run/user/1000/dev/mapper/vg_data-lv_data 50G 52M 47G 1% /data# 发现已经挂载了一块50G的卷到了/data目录 卷扩容向 50G 的 /dev/mapper/vg_data-lv_data 逻辑卷上增加一块 100G 盘(/dev/sdb)扩成 150G 空间 # 卸载umount /data/# 创建物理卷pvcreate /dev/sdb Physical volume \"/dev/sdb\" successfully created# 将磁盘加到vg_data 逻辑组中vgextend vg_data /dev/sdb# 查询vg_data 显示为150Gvgdisplay vg_data --- Volume group --- VG Name vg_data System ID Format lvm2 Metadata Areas 2 Metadata Sequence No 3 VG Access read/write VG Status resizable MAX LV 0 Cur LV 1 Open LV 1 Max PV 0 Cur PV 2 Act PV 2 VG Size 149.99 GiB PE Size 4.00 MiB Total PE 38398 Alloc PE / Size 12799 / 50.00 GiB Free PE / Size 25599 / 100.00 GiB VG UUID 8VgOL0-H0FU-ATx1-e9cF-NO2D-xffH-iDUqoD# 扩容逻辑卷lvextend -l +100%FREE /dev/mapper/vg_data-lv_data Size of logical volume vg_data/lv_data changed from 50.00 GiB (12799 extents) to 149.99 GiB (38398 extents). Logical volume lv_data successfully resized.# 查看逻辑卷容量lvdisplay /dev/mapper/vg_data-lv_data --- Logical volume --- LV Path /dev/vg_data/lv_data LV Name lv_data VG Name vg_data LV UUID 02Xd3v-05hl-ZH2v-l3Qp-BkXE-ndbB-wbhdRu LV Write Access read/write LV Creation host, time rancher-252, 2021-04-27 15:15:49 +0800 LV Status available # open 1 LV Size 149.99 GiB Current LE 38398 Segments 2 Allocation inherit Read ahead sectors auto - currently set to 256 Block device 252:2# 重新计算逻辑卷大小resize2fs /dev/mapper/vg_data-lv_dataresize2fs 1.42.13 (17-May-2015)Filesystem at /dev/mapper/vg_data-lv_data is mounted on /data; on-line resizing requiredold_desc_blocks = 4, new_desc_blocks = 10The filesystem on /dev/mapper/vg_data-lv_data is now 39319552 (4k) blocks long.df -hFilesystem Size Used Avail Use% Mounted onudev 7.9G 0 7.9G 0% /devtmpfs 1.6G 8.8M 1.6G 1% /run/dev/mapper/rancher--252--vg-root 48G 2.0G 44G 5% /tmpfs 7.9G 0 7.9G 0% /dev/shmtmpfs 5.0M 0 5.0M 0% /run/locktmpfs 7.9G 0 7.9G 0% /sys/fs/cgroup/dev/sda1 720M 58M 626M 9% /boottmpfs 1.6G 0 1.6G 0% /run/user/1000/dev/mapper/vg_data-lv_data 148G 60M 141G 1% /data# 检查文件完整性e2fsck -f /dev/mapper/vg_data-lv_datae2fsck 1.42.13 (17-May-2015)第一步: 检查inode,块,和大小第二步: 检查目录结构第3步: 检查目录连接性Pass 4: Checking reference counts第5步: 检查簇概要信息/dev/mapper/vg_data-lv_data: 11/9830400 files (0.0% non-contiguous), 664949/39319552 blocks# 挂载mount /dev/mapper/vg_data-lv_data /data/ 卷缩容一般不会缩容，除非是，实在没剩余空间了，而另外一个文件夹更需要磁盘，将 A 缩容省出的空间给 B。 # 卸载umount /data/# 检查文件完整性e2fsck -f /dev/mapper/vg_data-lv_datae2fsck 1.42.13 (17-May-2015)第一步: 检查inode,块,和大小第二步: 检查目录结构第3步: 检查目录连接性Pass 4: Checking reference counts第5步: 检查簇概要信息/dev/mapper/vg_data-lv_data: 11/9830400 files (0.0% non-contiguous), 664949/39319552 blocks# 缩容到50Gresize2fs /dev/mapper/vg_data-lv_data 49Gresize2fs 1.42.13 (17-May-2015)Resizing the filesystem on /dev/mapper/vg_data-lv_data to 12845056 (4k) blocks.The filesystem on /dev/mapper/vg_data-lv_data is now 12845056 (4k) blocks long.# 逻辑卷缩容到49Glvreduce -L 50G /dev/mapper/vg_data-lv_data WARNING: Reducing active logical volume to 50.00 GiB THIS MAY DESTROY YOUR DATA (filesystem etc.)Do you really want to reduce lv_data? [y/n]: y Size of logical volume vg_data/lv_data changed from 149.99 GiB (38398 extents) to 49.00 GiB (12544 extents). Logical volume lv_data successfully resized.# 查看逻辑卷信息lvdisplay /dev/mapper/vg_data-lv_data --- Logical volume --- LV Path /dev/vg_data/lv_data LV Name lv_data VG Name vg_data LV UUID 02Xd3v-05hl-ZH2v-l3Qp-BkXE-ndbB-wbhdRu LV Write Access read/write LV Creation host, time rancher-252, 2021-04-27 15:15:49 +0800 LV Status available # open 0 LV Size 50.00 GiB Current LE 12544 Segments 1 Allocation inherit Read ahead sectors auto - currently set to 256 Block device 252:2# 将/dev/sdb硬盘从逻辑卷组中移除vgreduce vg_data /dev/sdb Removed \"/dev/sdb\" from volume group \"vg_data\"# 查看信息vgdisplay vg_data --- Volume group --- VG Name vg_data System ID Format lvm2 Metadata Areas 1 Metadata Sequence No 6 VG Access read/write VG Status resizable MAX LV 0 Cur LV 1 Open LV 0 Max PV 0 Cur PV 1 Act PV 1 VG Size 50.00 GiB PE Size 4.00 MiB Total PE 12799 Alloc PE / Size 12544 / 49.00 GiB Free PE / Size 255 / 1020.00 MiB VG UUID 8VgOL0-H0FU-ATx1-e9cF-NO2D-xffH-iDUqoD# 挂载mount /dev/mapper/vg_data-lv_data /data/df -hFilesystem Size Used Avail Use% Mounted onudev 7.9G 0 7.9G 0% /devtmpfs 1.6G 8.8M 1.6G 1% /run/dev/mapper/rancher--252--vg-root 48G 2.0G 44G 5% /tmpfs 7.9G 0 7.9G 0% /dev/shmtmpfs 5.0M 0 5.0M 0% /run/locktmpfs 7.9G 0 7.9G 0% /sys/fs/cgroup/dev/sda1 720M 58M 626M 9% /boottmpfs 1.6G 0 1.6G 0% /run/user/1000/dev/mapper/vg_data-lv_data 50G 52M 47G 1% /data 招聘小广告山东济南的小伙伴欢迎投简历啊 加入我们 , 一起搞事情。长期招聘，Java 程序员，大数据工程师，运维工程师，前端工程师。 参考资料 我的博客 我的掘金 Linx 卷管理详解 VG LV PV 虚拟机 VMware 新增硬盘无法识别问题","tags":[{"name":"运维","slug":"运维","permalink":"https://anjia0532.github.io/tags/运维/"},{"name":"linux","slug":"linux","permalink":"https://anjia0532.github.io/tags/linux/"},{"name":"ubuntu","slug":"ubuntu","permalink":"https://anjia0532.github.io/tags/ubuntu/"},{"name":"lvm","slug":"lvm","permalink":"https://anjia0532.github.io/tags/lvm/"}]},{"title":"061-基于swagger/yapi/openapi逆向生成sdk","date":"2021-04-09T19:35:21.000Z","path":"2021/04/09/codegen-by-openapi/","text":"这是坚持技术写作计划（含翻译）的第 61 篇，定个小目标 999，每周最少 2 篇。 本文主要讲解如何基于三方提供的类 openapi 文档来逆向生成 sdk（少掉挨个手敲的烦恼），生成的 pojo 支持 lombok 前置准备 Nodejs12 LTS+ Java8+ Git 研究了 swagger 自己的 https://github.com/swagger-api/swagger-codegen微软家的 https://github.com/Azure/autorest以及 openapi 的 https://github.com/OpenAPITools/openapi-generator最后选择了https://github.com/OpenAPITools/openapi-generator 安装openapi-generatornpm install @openapitools/openapi-generator-cli -ggit clone https://github.com/anjia0532/openapi-generator-templatesopenapi-generator-cli generate -t openapi-generator-templates\\generator-templates\\JavaSpring\\spring-boot-lombok-actuator -g spring -puseLombok=true -i swaggerApi.json --skip-validate-spec 参考资料 https://github.com/OpenAPITools/openapi-generator#17—npm参考资料 https://github.com/anjia0532/openapi-generator-templates/tree/master/generator-templates/JavaSpring/spring-boot-lombok-actuator 生成结果src└─ main ├─ java │ └─ org │ └─ openapitools │ ├─ api # 调用对方api的client │ │ ├─ xxx.java │ ├─ configuration # 配置相关 │ │ ├─ xxx.java │ ├─ model # pojo类 │ │ ├─ xxx.java │ ├─ OpenAPI2SpringBoot.java │ └─ RFC3339DateFormat.java ├─ resources │ └─ application.properties │ └─ RFC3339DateFormat.java └─ pom.xml 以实际用到的某个不重要的 model 类演示下生成的效果 package org.openapitools.model;import java.util.Objects;import com.fasterxml.jackson.annotation.JsonProperty;import com.fasterxml.jackson.annotation.JsonCreator;import io.swagger.annotations.ApiModel;import io.swagger.annotations.ApiModelProperty;import org.openapitools.jackson.nullable.JsonNullable;import javax.validation.Valid;import javax.validation.constraints.*;import lombok.*;/** * EmptyObject2 */@javax.annotation.Generated(value = \"org.openapitools.codegen.languages.SpringCodegen\", date = \"2021-04-09T19:10:24.687+08:00[Asia/Shanghai]\")@Getter@Setter@Builder(toBuilder = true)@NoArgsConstructor@AllArgsConstructor@ToStringpublic class EmptyObject2 &#123; /** * 获取渠道 */ @JsonProperty(\"getChannel\") private String getChannel; /** * 优惠券ID */ @JsonProperty(\"couponIds\") private String couponIds; /** * 会员ID */ @JsonProperty(\"memberId\") private String memberId;&#125; 招聘小广告山东济南的小伙伴欢迎投简历啊 加入我们 , 一起搞事情。长期招聘，Java 程序员，大数据工程师，运维工程师，前端工程师。 参考资料 我的博客 我的掘金","tags":[{"name":"java","slug":"java","permalink":"https://anjia0532.github.io/tags/java/"},{"name":"微服务","slug":"微服务","permalink":"https://anjia0532.github.io/tags/微服务/"},{"name":"swagger","slug":"swagger","permalink":"https://anjia0532.github.io/tags/swagger/"},{"name":"yapi","slug":"yapi","permalink":"https://anjia0532.github.io/tags/yapi/"},{"name":"openapi","slug":"openapi","permalink":"https://anjia0532.github.io/tags/openapi/"}]},{"title":"060-轻量级基于curl的seafile上传脚本","date":"2021-04-07T12:35:21.000Z","path":"2021/04/07/seafile-client-curl/","text":"这是坚持技术写作计划（含翻译）的第 60 篇，定个小目标 999，每周最少 2 篇。 本文主要讲解利用 bash 脚本在 linux 通过命令行上传文件到 seafile 服务器 seafile 有基于 python 2.x 的 client，但是年代比较久远，另外为了在服务器上转存文件就装个 python2.x 有点大材小用了，看了下 seafile 的 api 文档，比较简单，就基于 curl 撸了个 bash 脚本。 目前只有简单的上传单文件功能。 使用如何使用将下面脚本保存成 seafile-upload.sh ,并 chmod+x seafile-upload.sh #!/usr/bin/env bash# this script depend on jq,check it firstRED='\\033[0;31m'NC='\\033[0m' # No Colorif ! command -v jq &amp;&gt; /dev/nullthen echo -e \"$&#123;RED&#125;jq could not be found$&#123;NC&#125;, installed and restart plz!\\n\" exitfiusage () &#123; echo \"Usage : $0 -u &lt;username&gt; -p &lt;password&gt; -h &lt;seafile server host&gt; -f &lt;upload file path&gt; -d &lt;parent dir default value is /&gt; -r &lt;repo id&gt; -t &lt;print debug info switch off/on,default off&gt;\"; &#125;# parse argswhile getopts \"u:p:h:f:d:r:t:\" opts; do case $&#123;opts&#125; in u) USER=$&#123;OPTARG&#125; ;; p) PASSWORD=$&#123;OPTARG&#125; ;; h) HOST=$&#123;OPTARG&#125; ;; f) FILE=$&#123;OPTARG&#125; ;; d) PARENT_DIR=$&#123;OPTARG&#125; ;; r) REPO=$&#123;OPTARG&#125; ;; t) DEBUG=$&#123;OPTARG&#125; ;; *) usage; exit;; esacdone# those args must be not nullif [ ! \"$USER\" ] || [ ! \"$PASSWORD\" ] || [ ! \"$HOST\" ] || [ ! \"$FILE\" ] || [ ! \"$REPO\" ]then usage exit 1fi# optional args,set default value[ -z \"$DEBUG\" ] &amp;&amp; DEBUG=off[ -z \"$PARENT_DIR\" ] &amp;&amp; PARENT_DIR=/# print vars key and value when DEBUG eq on[[ \"on\" == \"$DEBUG\" ]] &amp;&amp; echo -e \"USER:$&#123;USER&#125; PASSWORD:$&#123;PASSWORD&#125; HOST:$&#123;HOST&#125; FILE:$&#123;FILE&#125; PARENT_DIR:$&#123;PARENT_DIR&#125; REPO:$&#123;REPO&#125; DEBUG:$&#123;DEBUG&#125;\"# login and get tokenTOKEN=$(curl -s --location --request POST \"$&#123;HOST&#125;/api2/auth-token/\" --header 'Content-Type: application/x-www-form-urlencoded' --data-urlencode \"username=$&#123;USER&#125;\" --data-urlencode \"password=$&#123;PASSWORD&#125;\" | jq -r \".token\")[ -z \"$TOKEN\" ] &amp;&amp; echo -e \"$&#123;RED&#125;login seafile faild$&#123;NC&#125;, call your administrator plz!\\n\" &amp;&amp; exit 1# gen upload linkUPLOAD_LINK=$(curl -s --header \"Authorization: Token $&#123;TOKEN&#125;\" \"$&#123;HOST&#125;/api2/repos/$&#123;REPO&#125;/upload-link/?p=$&#123;PARENT_DIR&#125;\" | jq -r \".\")[ -z \"$UPLOAD_LINK\" ] &amp;&amp; echo -e \"$&#123;RED&#125;get upload link faild$&#123;NC&#125;, call your administrator plz!\\n\" &amp;&amp; exit 1# upload fileUPLOAD_RESULT=$(curl -s --header \"Authorization: Token $&#123;TOKEN&#125;\" -F file=\"@$&#123;FILE&#125;\" -F filename=$(basename $&#123;FILE&#125;) -F parent_dir=\"$&#123;PARENT_DIR&#125;\" -F replace=1 \"$&#123;UPLOAD_LINK&#125;?ret-json=1\")[ -z \"$UPLOAD_RESULT\" ] &amp;&amp; echo -e \"$&#123;RED&#125;faild to upload $&#123;FILE&#125;$&#123;NC&#125;, call your administrator plz!\\n\" &amp;&amp; exit 1# print upload result[[ \"on\" == \"$DEBUG\" ]] &amp;&amp; echo -e \"TOKEN:$&#123;TOKEN&#125; UPLOAD_LINK:$&#123;UPLOAD_LINK&#125; UPLOAD_RESULT:$&#123;UPLOAD_RESULT&#125;\" # ubuntuapt install -y jq# centos# yum install -y jqchmod +x ./seafile-upload.sh./seafile-upload.sh -u &lt;username&gt; -p &lt;password&gt; -h &lt;seafile server host&gt; -f &lt;upload file path&gt; -d &lt;parent dir default value is /,must be start with /&gt; -r &lt;repo id&gt; -t &lt;print debug info switch off/on,default off&gt; 参数说明 -u seafile 用户名 -p seafile 密码 -h seafile 地址，https://xxx.xxx.com -f 需要上传的文件路径，比如/tmp/test.zip -d 上传目录，必须是/开头 -r 资料库 id -t 是否开启 debug 模式，如果是on 则会打印参数，否则啥都不打印 招聘小广告山东济南的小伙伴欢迎投简历啊 加入我们 , 一起搞事情。长期招聘，Java 程序员，大数据工程师，运维工程师，前端工程师。 参考资料 我的博客 我的掘金 官方 api 文档 Quick Start 官方 python-seafile client 文档","tags":[{"name":"linux","slug":"linux","permalink":"https://anjia0532.github.io/tags/linux/"},{"name":"bash","slug":"bash","permalink":"https://anjia0532.github.io/tags/bash/"},{"name":"seafile","slug":"seafile","permalink":"https://anjia0532.github.io/tags/seafile/"}]},{"title":"059-api网关之apache apisix初体验","date":"2021-03-10T20:35:21.000Z","path":"2021/03/10/apisix/","text":"这是坚持技术写作计划（含翻译）的第 59 篇，定个小目标 999，每周最少 2 篇。 本文简单讲解 apache apisix 和 apisix dashboard docker 安装及简单演示 apisix 简单介绍apisix 可能是 api 很 6 的的意思吧，哈哈基于 nginx 系(nginx/openresty/tengine)的网关比较多，得益于 nginx/openresty/tengine 的高性能，在一些性能要求比较高的场景用 nginx 系的比较多 比较有名的当属开源的kong和商业的 openresty edge（openresty 创始人搞的商业版）,以及新秀 apache apisix 关于 apisix 的特性和与 kong 的对比，详见 官方文档 ，就不复制粘贴了 apisix 安装apisix 支持容器化部署和裸机部署 关于 centos 和 ubuntu 的编译和安装，详见官方文档 编译和安装 关于容器化部署分两种，本地 quick start 的 docker-compose 和 主流的 k8s 的 helm-chart 安装 快速启动先跑个 demo，看看效果我将 apisix-dashboard 合并到 apisix 中了，参考 https://github.com/anjia0532/apisix-docker/commit/84c14d54745d33669555686bea93c00b2fb385ec，也给官方提 PR#150了（如果官方合并了后，建议用官方的库） git clone https://github.com/anjia0532/apisix-docker.git# 官方库# git clone https://github.com/apache/apisix-docker.gitcd example# 启动docker-compose up -d# 停止docker-compose down 启动后，查看服务概览http://localhost:9080 是 apisix 的 http 端口, http://localhost:9443 是 https 端口localhost:2379 是 etcd 端口 docker-compose ps Name Command State Ports--------------------------------------------------------------------------------------------------------------------example_apisix-dashboard_1 /usr/local/apisix-dashboar ... Up 0.0.0.0:9000-&gt;9000/tcpexample_apisix_1 sh -c /usr/bin/apisix init ... Up 0.0.0.0:9080-&gt;9080/tcp, 0.0.0.0:9443-&gt;9443/tcpexample_etcd_1 /entrypoint.sh etcd Up 0.0.0.0:2379-&gt;2379/tcp, 2380/tcpexample_web1_1 /docker-entrypoint.sh ngin ... Up 0.0.0.0:9081-&gt;80/tcpexample_web2_1 /docker-entrypoint.sh ngin ... Up 0.0.0.0:9082-&gt;80/tcp http://localhost:9000 是 apisix-dashboard 用户名，密码都是 admin 通过 api 创建路由服务启停插件，可以参考 官方文档-快速入门指南 小试牛刀此处简单示范一下，反代 http://httpbin.org/ 创建消费者并启用插件消费者，可以用于提供给下游的的 appid,比如用于限流，鉴权，开 zipkin 等操作，粒度到账号（注意这个账号是在 apisix 层面的，不涉及到后边应用）开启 key-auth 插件官方文档-key-auth开启限流 limit-count官方文档-limit-count修改 httpbin_test 路由，启用 key-auth 插件访问试一下 key-auth 试一下 limit-count,多刷新几次就会被拦截启用 serverless 插件官方文档-serverless 配合key-auth演示一下serverless-pre插件，假设原有系统有自己的 header，而apisix的key-auth要求名字必须是apikey，改造原系统？还是自己抄一个key-auth ？工作量都很大，完全可以使用serverless-pre来做 摘抄官方文档的描述 serverless 的插件有两个，分别是 serverless-pre-function 和 serverless-post-function， 前者会在指定阶段的最开始运行，后者是在指定阶段的最后运行。 serverless-pre 有两个参数，分别讲解下phase: 是执行阶段，枚举值 [“rewrite”, “access”, “header_filter”, “body_filter”, “log”, “balancer”]，借助 官方流程图会更好理解一点functions：是自己写的匿名函数 示例 &#123; \"functions\": [ \"return function() ngx.req.set_header(\\\"apikey\\\", ngx.req.get_headers()[\\\"my-api-id\\\"]); end\" ], \"phase\": \"rewrite\"&#125; 批量创建路由/基于 openapi 导入官方文档-Import OpenAPI Guide 自定义插件官方文档-自定义插件 招聘小广告山东济南的小伙伴欢迎投简历啊 加入我们 , 一起搞事情。长期招聘，Java 程序员，大数据工程师，运维工程师，前端工程师。 参考资料 我的博客 我的掘金 官方文档-快速入门指南","tags":[{"name":"docker","slug":"docker","permalink":"https://anjia0532.github.io/tags/docker/"},{"name":"apisix","slug":"apisix","permalink":"https://anjia0532.github.io/tags/apisix/"},{"name":"openresty","slug":"openresty","permalink":"https://anjia0532.github.io/tags/openresty/"},{"name":"nginx","slug":"nginx","permalink":"https://anjia0532.github.io/tags/nginx/"},{"name":"kong","slug":"kong","permalink":"https://anjia0532.github.io/tags/kong/"}]},{"title":"058-差不多是Java中最好用的Emoji库了","date":"2021-03-03T19:35:21.000Z","path":"2021/03/03/emoji-java/","text":"这是坚持技术写作计划（含翻译）的第 58 篇，定个小目标 999，每周最少 2 篇。 本文主要讲解 java 中最好用的 emoji 库 vdurmont/emoji-java ,以及我提交的 PR #175 用于解决 emoji-java 表情更新不及时，及本地化方面的改进 什么是 emojiemoji 是表情符号/颜文字/绘文字，与表情包堪称现代人社交离不开的两个功能，区别是，表情包一般是用于非正式场合甚至带点恶搞的意思，而 emoji 稍微正式些（比如拍领导马屁专用，赞:👍，拍手:👏）,而发给领导，则会有失业风险 在一些国际网络交流中，emoji 能够比较方便的增加双方交流，比如不存在的幽灵网站，某推，某书，某 ins，emoji 非常流行 欢迎大家来吐槽下，你是啥时候更深入的了解到 emoji 的(日常聊天除外)?或者说，有多少人是因为 mysql 阉割版 utf8 而被 emoji 坑过？ 一般用户昵称，用户评论属于重灾区。。。 解决方案无非两个，1，将 emoji 替换成空字符串，以 java 为例str.replaceAll(&quot;^\\\\p{L}\\\\p{M}\\\\p{N}\\\\p{P}\\\\p{Z}\\\\p{Cf}\\\\p{Cs}\\\\p{Sc}\\\\s]&quot;, &quot;&quot;)2，修改 mysql 列类型为 utf8mb4 或者换数据库 pgsql 等 emoji-java 简介及使用如果有人用过hutool 工具包，那可能有用过如下语法 参考 Emoji 工具-EmojiUtil String alias = EmojiUtil.toAlias(\"😄\");//:smile:String emoji = EmojiUtil.toUnicode(\":smile:\");//😄String alias = EmojiUtil.toHtml(\"😄\");//&amp;#128102; 此处，hutool 就是基于 vdurmont/emoji-java 库来做的 简单来说，emoji-java 库是一个 java 的 emoji 工具库，主要用于判断文本是否含有 emoji 表情，将 emoji 替换为文本描述(比如将 😄 替换成 :smile: ),也可以将描述，逆向成 emoji 表情，比如 :smile: 😄 移除 emoji 表情 String str = \"An 😀awesome 😃string with a few 😉emojis!\";Collection&lt;Emoji&gt; collection = new ArrayList&lt;Emoji&gt;();collection.add(EmojiManager.getForAlias(\"wink\")); // This is 😉System.out.println(EmojiParser.removeAllEmojis(str));System.out.println(EmojiParser.removeAllEmojisExcept(str, collection));System.out.println(EmojiParser.removeEmojis(str, collection));// Prints:// \"An awesome string with a few emojis!\"// \"An awesome string with a few 😉emojis!\"// \"An 😀awesome 😃string with a few emojis!\" 基本使用，参见他的README.md,功能很简单，也很实用目前支持的所有 emoji，参见他的EMOJIS.md ，里面没有列出来的，则暂未支持 是的，他采取的是白名单的做法，列出的是 emoji，没有列出的，则不是 emoji 下面例子可能会更方便理解 // https://unicode.org/emoji/charts/full-emoji-list.html#1f636_200d_1f32b_fe0fEmojiManager.isEmoji(\"😶‍🌫️\") //false 具体案例表情参见 https://unicode.org/emoji/charts/full-emoji-list.html#1f636_200d_1f32b_fe0f与 emoji 13.1 规范相比， emoji-java 5.1.1 一共缺失 244 个表情，详见 我提的 issues 对于一个公共库来说，算是缺失比较多的了 对 emoji-java 打补丁针对上一个问题，我抽空提交了一个feat(module): add emoji-json-generator module #175以后可以基于https://unicode.org/emoji/charts/full-emoji-list.html 自己生成 emoji.json，能够保证实时性 mvn exec:java -Dexec.mainClass=\"com.vdurmont.emoji.JsonGenerator\" [-Dexec.args=\"proxy=1270.0.1 port=1080 \\ path=path\\to\\already\\download\\emoji.html save_url=/path/to/emoji.json \\ url=https://unicode.org/emoji/charts/full-emoji-list.html \\ emoji_path=/path/to/already/emoji.json \\ emoji_i18n_path=/path/to/i18n_description/emoji_i18n.json \"] 简单说明下 []：包裹的，都是选填的，不写没关系 proxy 和 port: 是防止访问https://unicode.org/emoji/charts/full-emoji-list.html 失败，可以自己设置代理服务器（比如国外或者香港的） path：如果不想每次实时访问 https://unicode.org/emoji/charts/full-emoji-list.html 可以预先下载到本地，然后读本地的，这是路径地址 save_url: 这是重新生成的 emoji.json 地址 url: 防止 https://unicode.org/emoji/charts/full-emoji-list.html 改地址 emoji_path: 是为了兼容 emoji-java 官方库 https://github.com/anjia0532/emoji-java/blob/master/src/main/resources/emojis.json ，防止从 https://unicode.org/emoji/charts/full-emoji-list.html 生成的跟之前的不一样，导致库里对应不上，如果设置了 emoji_path,并且能够匹配上的，以 emoji_path 的为准 emoji_i18n_path:如果是想将 👀 对应的解释从 eyes 换成中文 两只眼睛 ，那么就设置需要翻译的 json 路径，格式参考 https://github.com/anjia0532/emoji-java/blob/master/emoji-table-generator/src/main/resources/emojis.i18n.json 自己生成的 emoji.json 如何使用呢第一种方案：自己 fork 并生成 emoji.json 覆盖原来的 emoji.json 并打包发到私服上，这样原代码不用动，兼容性最好，改动最小 第二种方案:自己 fork 并修改 EmojiManager，因为他本身写死了，不支持外部传入 emoji.json 的路径或者文件流 第三种方案:在自己项目里参考 EmojiManager 自行实现类似的静态工具类 主要是用 EmojiLoader 加载 emoji.json 转成 List，并转换成 EmojiTrie 招聘小广告山东济南的小伙伴欢迎投简历啊 加入我们 , 一起搞事情。长期招聘，Java 程序员，大数据工程师，运维工程师，前端工程师。 参考资料 我的博客 我的掘金","tags":[{"name":"java","slug":"java","permalink":"https://anjia0532.github.io/tags/java/"},{"name":"emoji","slug":"emoji","permalink":"https://anjia0532.github.io/tags/emoji/"}]},{"title":"057-基于frida的一键脱壳+反编译","date":"2021-02-04T19:35:20.000Z","path":"2021/02/04/frida-android-decompile/","text":"这是坚持技术写作计划（含翻译）的第 57 篇，定个小目标 999，每周最少 2 篇。 开场 冷知识 ，脱壳(qiao)不是脱壳(ke),当然大多数人还是习惯读 ke 基本上能看我这篇的基本都是脱壳一知半解的脚本小子（我自己也是），所以不会讲很高深的（比如 常见 android app 加固厂商脱壳方法研究） 。本文主要讲如何安装 frida(国内装 frida 有些坑)和常见脱壳操作。 安装 Frida安装 Python3 环境可以自行安装，也可以参考之前写的安装 anaconda 安装 Frida# pip安装组件pip install frida frida-tools 如果安装 frida 时卡在 Running setup.py install for frida ... – 超过 2 分钟，基本会下载失败，此时用别的姿势打开 https://pypi.org/project/frida/#files ，根据实际情况下载对应的 egg,比如你是装的 python3.8，那就搜 py3.8-win 比如 frida-14.2.10-py3.8-win-amd64.egg然后 easy_install frida-14.2.10-py3.8-win-amd64.egg ,重新执行 pip install frida frida-tools 安装虚拟机或者准备实体机本文假设使用虚拟机，比如 夜神打开虚拟机，开启开发者模式，启用usb调试打开 cmd，进入夜神安装目录\\bin # 测试adb是否已连接xxx\\Nox\\bin&gt;adb.exe devicesList of devices attached127.0.0.1:62001 device# 获取cpu架构xxx\\Nox\\bin&gt;adb.exe shell getprop ro.product.cpu.abix86 安装 frida 手机端https://github.com/frida/frida/releases (国内如果慢，可以用https://hub.fastgit.org/frida/frida/releases 加速下载)解压下载下来的 firda-server-${version}-android-x86.xz，并将 frida-server 移动到虚拟机里，有些 app 会监测 frida 的进程，所以将文件随便命名 xxx\\Nox\\bin&gt;adb push frida-server-14.2.10-android-x86 /data/local/tmp/abd[100%] /data/local/tmp/abdxxx\\Nox\\bin&gt;adb shell chmod +x /data/local/tmp/abd &amp;&amp; /data/local/tmp/abd# 转发frida端口xxx\\Nox\\bin&gt;adb forward tcp:27042 tcp:27042xxx\\Nox\\bin&gt;adb forward tcp:27043 tcp:27043xxx\\Nox\\bin&gt;adb forward tcp:38089 tcp:38089# 启动frida并修改监听端口（防止部分app监测默认端口）xxx\\Nox\\bin&gt;adb shell /data/local/tmp/abd -l 0.0.0.0:38089 另起一个 cmd， # 切换到安装frida 和frida-tools的环境下activate python3.8# 测试是否连上frida-server(python3.8) xxx\\Nox\\bin&gt;frida-ps -H 127.0.0.1:38089 | findstr net# 网易云音乐4336 com.netease.cloudmusic1892 netd 以网易云音乐为例，https://www.wandoujia.com/apps/293217/history为啥用豌豆荚下载，而不是别的应用市场，因为豌豆荚支持历史版本，意味着如果新版不好搞，可以多下几个版本，用最低能用版本作为切入点 开始脱壳安装# 如果端口改了需要clone后手动修改main.pygit clone https://github.com/hluwa/FRIDA-DEXDumpcd FRIDA-DEXDump/frida-dexdumppython main.py -h# 如果不改端口，可以直接用pip安装pip install frida-dexdumpfrida-dexdump -h 如果要修改默认连接地址，修改 https://github.com/hluwa/FRIDA-DEXDump/blob/master/frida_dexdump/main.py#L177-L183 的 connect_device 函数，如果是手机，使用 usb 连接的话，可以不用改 def connect_device(timeout=15): manager = frida.get_device_manager() device = manager.add_remote_device(\"127.0.0.1:38089\") return device 将夜神 bin 目录配置到环境变量里如果不配置 adb.exe 到环境变量，会报错 'adb' 不是内部或外部命令，也不是可运行的程序或批处理文件。 脱壳(python3.8) xxx\\FRIDA-DEXDump\\frida_dexdump&gt;python main.py -p 4336------------------------------------------------------------------------------------------------------------------------ ____________ ___________ ___ ______ _______ _______ | ___| ___ \\_ _| _ \\/ _ \\ | _ \\ ___\\ \\ / / _ \\ | |_ | |_/ / | | | | | / /_\\ \\______| | | | |__ \\ V /| | | |_ _ _ __ ___ _ __ | _| | / | | | | | | _ |______| | | | __| / \\| | | | | | | '_ ` _ \\| '_ \\ | | | |\\ \\ _| |_| |/ /| | | | | |/ /| |___/ /^\\ \\ |/ /| |_| | | | | | | |_) | \\_| \\_| \\_|\\___/|___/ \\_| |_/ |___/ \\____/\\/ \\/___/ \\__,_|_| |_| |_| .__/ | | |_| https://github.com/hluwa/FRIDA-DEXDump------------------------------------------------------------------------------------------------------------------------02-04/17:25:45 INFO [DEXDump]: found target [4336] com.netease.cloudmusic'adb' 不是内部或外部命令，也不是可运行的程序或批处理文件。[DEXDump]: DexSize=0x8c5e74, DexMd5=ae00d7d709366721d36acd3d9323463c, SavePath=xxx\\FRIDA-DEXDump\\frida_dexdump/com.netease.cloudmusic/0x9e1aa7dc.dex 类似使用 frida 脱壳的方案还有很多，可以参考 抖音数据采集 Frida 脱壳工具 反编译下载 jad-gui https://github.com/skylot/jadx/releases 招聘小广告山东济南的小伙伴欢迎投简历啊 加入我们 , 一起搞事情。长期招聘，Java 程序员，大数据工程师，运维工程师，前端工程师。 参考资料 我的博客 我的掘金 抖音数据采集 Frida 脱壳工具 [分享]Android 加固厂商特征 安卓应用的安全和破解","tags":[{"name":"frida","slug":"frida","permalink":"https://anjia0532.github.io/tags/frida/"},{"name":"android","slug":"android","permalink":"https://anjia0532.github.io/tags/android/"},{"name":"反编译","slug":"反编译","permalink":"https://anjia0532.github.io/tags/反编译/"},{"name":"脱壳","slug":"脱壳","permalink":"https://anjia0532.github.io/tags/脱壳/"},{"name":"逆向","slug":"逆向","permalink":"https://anjia0532.github.io/tags/逆向/"}]},{"title":"056-微信小程序抓包的三种方式","date":"2021-01-24T00:28:30.000Z","path":"2021/01/24/wechat-mini-program-capture/","text":"这是坚持技术写作计划（含翻译）的第 56 篇，定个小目标 999，每周最少 2 篇。 很多时候针对 app 和 h5 的分析都困难重重，不妨换个思路，去小程序碰碰运气。本文分别讲解了从 PC 端，Android 端，IOS 端对小程序抓包的三种方式 准备工作下载 Fiddler 最新版 https://www.telerik.com/download/fiddler安装 Fiddler，运行并配置 HttpsTools -&gt; Options…-&gt;Https 勾选捕获 Https 连接，并安装 https 证书配置运行远程连接及代理端口 PC 端用 PC 端微信好处是调试方便，缺点是，部分小程序有兼容性问题，所以极端场景下还得使用移动端抓包 IOS 端优先推荐使用 ios 版抓包（因为安卓版本 7.0+版本安全策略问题处理起来略微麻烦些）下载针对移动版的 fiddlercertmaker （fiddler 默认带的对于 ios13.x 经常抓不到包）设置 -&gt;通用-&gt; 描述文件 -&gt; DO_NOT_TRUST_FiddlerRoot -&gt;安装设置 -&gt;通用-&gt; 关于本机 -&gt; 证书信任设置 -&gt;DO_NOT_TRUST_FiddlerRoot 打开开关 （IOS 10+后需要手动信任）设置 -&gt; 无线局域网 -&gt; wifi 名称后的 i 图标 -&gt;HTTP 代理 -&gt;手动 -&gt; 设置局域网服务器 ip 和端口，不用填认证信息如果抓不到包的话，可以试试 charles ，一般就能抓到 Android 端android 7+版本针对 ssl 安全性做了加强，简单来说就是不认用户自己安装的证书，针对安卓端的 https 抓包有四种方案 降级到 android7.0 之前的版本，比如 5.x 6.x 将设备 root，把证书写到系统证书里 用虚拟机（比如网易 mumu 或者夜神）安装 7.0 之前的版本或者 7.0 以后的将证书放到系统证书里 使用 https://github.com/MegatronKing/HttpCanary 进行抓包 前三种不管哪种方案，弄好后，都修改 wifi 的代理设置，设置好代理后，进行抓包就行了 最后分享几个比较流行的抓包/流量分析工具 charles fiddler-everywhere fiddler HttpCanary wireshark 招聘小广告山东济南的小伙伴欢迎投简历啊 加入我们 , 一起搞事情。长期招聘，Java 程序员，大数据工程师，运维工程师，前端工程师。 参考资料 我的博客 我的掘金 推荐一款万能抓包神器：Fiddler Everywhere 轻松搞定 Charles 的 HTTPS 抓包（iOS13 可用）","tags":[{"name":"python","slug":"python","permalink":"https://anjia0532.github.io/tags/python/"},{"name":"爬虫","slug":"爬虫","permalink":"https://anjia0532.github.io/tags/爬虫/"},{"name":"微信","slug":"微信","permalink":"https://anjia0532.github.io/tags/微信/"},{"name":"小程序","slug":"小程序","permalink":"https://anjia0532.github.io/tags/小程序/"}]},{"title":"055-手把手教你如何抓取高德全部POI-基于ArcGIS 渔网分割","date":"2021-01-19T22:35:21.000Z","path":"2021/01/19/python-gaode-arcgis-poi/","text":"这是坚持技术写作计划（含翻译）的第 55 篇，定个小目标 999，每周最少 2 篇。 工作原因需要获取本地全部 poi，直接调用高德 api 会有数量限制（理论上超过 1000 条就容易丢失部分数据，而且这种丢失很隐蔽，难以校验） 最终经过一番周折，基于网上资料进行了整理 注册高德账号，获取高德 key 下载安装 ArcMap/ArcGIS 将抓取区域等距分割并导出多边形经纬度 基于切割后的经纬度重新轮高德 api 前置准备注册高德账号，并创建应用，获得 key ，这个看官网文档或者网上自己搜就行，不多说了 获取行政区划点位，https://lbs.amap.com/api/webservice/guide/api/district复制出 polyline,用任何一个现代化编辑器(vs code,notepad++等)将 ; 替换成换行符,在第一行插入 x,y 保存成 jn.csv 根据 ArcMap 0 （ArcGIS10.2 安装(完善版–能解决常见问题)） 下载并安装 ArcMap 10.2,并破解，但别汉化（后边点集转线的时候会报错） 获取分割后的坐标点位导入点集File-&gt;Add Data-&gt;Add XY Data…建议如果不会用 arcmap 切换文件夹的，直接将文件放入 文档\\ArcGIS\\ 下,自动带入 x,y 字段，点 OK 即可出现行政区划点图像了 点集转线ArcToolbox -&gt; Data Management Tools -&gt; Features -&gt;Points To Line 使用渔网功能等分切割行政区域cell size width/height 这俩别选，因为高德导入的是火星坐标，不属于标准 gps 坐标，ArcGis 不识别 所以只能自行计算，假设我需要将济南切割成 3km X 3km 的小格子，参考 经纬度 1 度等于多少米，经度 1 度=85.39km，纬度 1 度 = 大约 111km。那就拿出计算器算呗，(Right-Left)85.39/3=49.78826191,取整用 50 就行，同理 (Top-Bottom)111/3=57.060475,取整用 57 就行，我截图用的 58，懒得换了。 注意别选 Create Label Points(optional) 选项,因为用不到 将行政区划填充颜色ArcToolbox -&gt; Data Management Tools -&gt; Features -&gt; Feature To Polygon 取渔网和行政区划交集（擦除行政区划外的渔网网格部分）将其导出后边要用 获取网格点位的经纬度参考大佬的文章 Python3 爬取高德地图 POI ，下载作者开发的 渔网对角坐标获取工具链接：链接：https://pan.baidu.com/s/11nwWHDf75fSVTxs323opFQ提取码：rduv获取对角坐标 抓取高德 POI98%都是抄自 Python3 爬取高德地图 POI 代码，只是稍微处理了下从 dict 获取字段防止抛异常部分，以及加了省字段 import requestsimport jsonfrom pymongo import MongoClientimport timeclient = MongoClient('localhost',27017)db = client.POI_Jinanshicollection = db.table_1polygon_list = list()with open(\"jn2.txt\", 'r', encoding='UTF-8') as txt_file: for each_line in txt_file: if each_line != \"\" and each_line != \"\\n\": fields = each_line.split(\"\\n\") polygon = fields[0] polygon_list.append(polygon)def getjson(polygon, page): headers = &#123; 'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/70.0.3538.67 Safari/537.36' &#125; pa = &#123; 'key': 'xxxxxxxxxxxxxxxxxxxxxx', #从控制台申请 'polygon': polygon, 'types':'970000|990000', #不要过多 'city':'0531', 'offset': 20, 'page': page, 'extensions': 'all', 'output': 'JSON' &#125; r = requests.get('https://restapi.amap.com/v3/place/polygon?', params=pa, headers=headers) decodejson = json.loads(r.text) return decodejsonfor each_polygon in polygon_list: not_last_page = True page = 1 while not_last_page: decodejson = getjson(each_polygon, page) print(decodejson) count = decodejson.get('count',0) print(each_polygon, page) if decodejson['pois']: for eachone in decodejson['pois']: data=&#123; 'name':eachone.get('name',None), #POI名称 'types':eachone.get('type',None), #POI所属类别 'address':eachone.get('address',None), #POI地址 'location':eachone.get('location',None), #POI坐标 'city':eachone.get('cityname',None), #城市 'county':eachone.get('adname',None), #区县 'province':eachone.get('pname',None), # 省份 'count':count, # 条数 'polygon':each_polygon # 多边形经纬度，便于后边再次抓取 &#125; collection.insert_one(data) time.sleep(0.2) page += 1 else: not_last_page = False 招聘小广告山东济南的小伙伴欢迎投简历啊 加入我们 , 一起搞事情。长期招聘，Java 程序员，大数据工程师，运维工程师，前端工程师。 参考资料 我的博客 我的掘金 ArcMap 0 （ArcGIS10.2 安装(完善版–能解决常见问题)） Python3 爬取高德地图 POI python 获取高德 poi 经纬度 1 度等于多少米","tags":[{"name":"python","slug":"python","permalink":"https://anjia0532.github.io/tags/python/"},{"name":"arcmap","slug":"arcmap","permalink":"https://anjia0532.github.io/tags/arcmap/"},{"name":"arcgis","slug":"arcgis","permalink":"https://anjia0532.github.io/tags/arcgis/"},{"name":"gis","slug":"gis","permalink":"https://anjia0532.github.io/tags/gis/"}]},{"title":"054-微服务之真正的优雅停机","date":"2021-01-18T23:35:21.000Z","path":"2021/01/18/micro-elegant-shutdown/","text":"这是坚持技术写作计划（含翻译）的第 54 篇，定个小目标 999，每周最少 2 篇。 网上一些大佬主要集中在如何从负载均衡里安全的把实例摘除（🔥Serverless 微服务优雅关机实践| 🏆 技术专题第七期征文） 但是实际上你会使用_shutdown 断点去停掉实例么？ 使用 apollo/naocs/eureka 等注册中心来操作节点上下线会更优雅一些 对比 Shutdown Hook 来看，shutdown hook 的初衷是关机之前做一些善后工作（从注册中心/slb 摘除自己，关掉消息队列等），但是假如我只是想切换流量而不关机（比如发版时只切流量，另外版本继续运行待命，有问题流量再切回去），使用 shutdown hook 钩子就不合适了 本文主要讲解 shutdown hook + nacos 上下线事件实现的真正的优雅停机。 以 nacos 为例，项目启动时，监听 nacos 服务实例变更事件需要判断当前实例有没有发生变化（主要是是否上下线，如果需要判断权重或者元数据，需要自行修改，此处不提供），如果没有变化认为与己无关，丢弃就可以了 如果发生变化后，使用 SpringUtil.publishEvent 广播 Spring Event，这样项目内其他地方，包括但不限于消息队列，定时任务（比如 xxljob）等就可以自行 @EventListener(NacosEvent.class) 监听即可 import com.alibaba.nacos.api.naming.pojo.Instance;import lombok.Data;import lombok.experimental.Accessors;import org.springframework.context.ApplicationEvent;import java.util.Map;/** * Nacos事件对象 * * @author AnJia */public class NacosEvent extends ApplicationEvent &#123; /** * Create a new &#123;@code ApplicationEvent&#125;. * * @param source the object on which the event initially occurred or with * which the event is associated (never &#123;@code null&#125;) */ public NacosEvent(NacosModel source) &#123; super(source); &#125; /** * Nacos事件对象 * * @author AnJia */ @Data @Accessors(chain = true) public static class NacosModel &#123; /** * 当前服务可用列表 */ Map&lt;String, Instance&gt; instanceMap; /** * 本实例的实例id */ private String instanceId; /** * 本实例可用还是不可用 */ private Boolean enable; /** * 是否有变更 */ private boolean changed; &#125;&#125; import com.alibaba.cloud.nacos.NacosDiscoveryProperties;import com.alibaba.nacos.api.exception.NacosException;import com.alibaba.nacos.api.naming.listener.NamingEvent;import com.alibaba.nacos.api.naming.pojo.Instance;import com.shunzhongkeji.util.SpringUtil;import lombok.extern.slf4j.Slf4j;import org.springframework.beans.factory.annotation.Value;import org.springframework.context.annotation.Configuration;import javax.annotation.PostConstruct;import java.util.HashMap;import java.util.Map;@Slf4j@Configurationpublic class NacosConfiguration &#123; private final NacosDiscoveryProperties nacosDiscoveryProperties; private final String serviceName; private static boolean ENABLE = Boolean.FALSE; public NacosConfiguration(NacosDiscoveryProperties nacosDiscoveryProperties, @Value(\"$&#123;spring.application.name&#125;\") String serviceName) &#123; this.nacosDiscoveryProperties = nacosDiscoveryProperties; this.serviceName = serviceName; &#125; /** * 项目初始化时监听nacos上下线 * * @throws NacosException nacos报错 */ @PostConstruct public void init() throws NacosException &#123; nacosDiscoveryProperties.namingServiceInstance().subscribe(serviceName, event -&gt; &#123; Map&lt;String, Instance&gt; instanceMap = new HashMap&lt;&gt;(16); if (event instanceof NamingEvent) &#123; ((NamingEvent) event).getInstances() .forEach(instance -&gt; instanceMap.put(instance.getInstanceId(), instance)); &#125; // nacos 实例id，示例 192.168.40.65#9090#DEFAULT#DEFAULT_GROUP@@oms String instanceId = nacosDiscoveryProperties.getIp() + \"#\" + nacosDiscoveryProperties.getPort() + \"#\" + nacosDiscoveryProperties.getClusterName() + \"#\" + nacosDiscoveryProperties.getGroup() + \"@@\" + nacosDiscoveryProperties.getService(); boolean changed = (ENABLE != instanceMap.containsKey(instanceId)); ENABLE = instanceMap.containsKey(instanceId); NacosEvent.NacosModel nacosEvent = new NacosEvent.NacosModel() .setEnable(ENABLE) .setInstanceId(instanceId) .setInstanceMap(instanceMap) .setChanged(changed); SpringUtil.publishEvent(new NacosEvent(nacosEvent)); &#125;); &#125;&#125; @Slf4j@Configurationpublic class RabbitConfiguration &#123; private final RabbitListenerEndpointRegistry registry; public RabbitConfiguration(RabbitListenerEndpointRegistry registry) &#123; this.registry = registry; &#125; /** * MQ 监听nacos上下线事件 * * @param event nacos上下线事件 */ @Async @EventListener(NacosEvent.class) public void healthEventChange(NacosEvent event) &#123; NacosModel model = (NacosModel) event.getSource(); if (model.isChanged()) &#123; if (Boolean.TRUE.equals(model.getEnable())) &#123; registry.start(); log.info(\"&#123;&#125;实例上线,启用rabbit监听\", model.getInstanceId()); &#125; else &#123; registry.stop(); log.info(\"&#123;&#125;实例下线,禁用rabbit监听\", model.getInstanceId()); &#125; &#125; &#125;&#125; 关于 ShutDownHook 部分就不写了，别人写的太多了，可以参考 Spring 优雅关闭之：ShutDownHook 这样就可以结合 jenkins/gitlab ci 等 CI/CD 工具实现，优雅切流量/停机了，比如发布新版本后，可以默认让新版本是下线状态，这时一点流量没有（定时任务，外部流量，消息队列都没有），扩容等操作完成后（ready 状态），再上线，此时流量会同时到达新老版本，发现新版本有问题，可以把新版本下线，修复后重新发版，如果新版本没问题，可以把老版本下掉，并行运行一段时间（比如 1 小时），确定没问题后，老版本直接断电就行了 。 招聘小广告山东济南的小伙伴欢迎投简历啊 加入我们 , 一起搞事情。长期招聘，Java 程序员，大数据工程师，运维工程师，前端工程师。 参考资料 我的博客 我的掘金 🔥Serverless 微服务优雅关机实践| 🏆 技术专题第七期征文 Spring 优雅关闭之：ShutDownHook","tags":[{"name":"微服务","slug":"微服务","permalink":"https://anjia0532.github.io/tags/微服务/"},{"name":"eureka","slug":"eureka","permalink":"https://anjia0532.github.io/tags/eureka/"},{"name":"nacos","slug":"nacos","permalink":"https://anjia0532.github.io/tags/nacos/"},{"name":"springboot","slug":"springboot","permalink":"https://anjia0532.github.io/tags/springboot/"},{"name":"springcloud","slug":"springcloud","permalink":"https://anjia0532.github.io/tags/springcloud/"}]},{"title":"053-vagrant无法使用ubuntu20.04问题","date":"2021-01-14T20:35:21.000Z","path":"2021/01/14/vagrant-hang-when-use-ununtu-focal64/","text":"这是坚持技术写作计划（含翻译）的第 53 篇，定个小目标 999，每周最少 2 篇。 最近使用 vagrant 安装 ubuntu20.04(ubuntu/focal64)是发现无法正常启动。 vagrant+virtualbox 系列文章 036-win10 搭建 python 的 linux 开发环境(pycharm+vagrant+virtualbox) 037-vagrant 启动(up)后自动同步文件(rsync-auto) 040-解决 Linux 使用 virtualbox 共享文件夹问题 042-解决 win10 VirtualBox 无法启动(VERR_NEM_VM_CREATE_FAILED) 043-解决 vagrant 访问 virtualbox 共享文件夹报无权限问题(Permission denied)D) 051-vagrant 无法使用 ubuntu20.04 问题 过程# 离线下载 ubuntu/focal64 https://cloud-images.ubuntu.com/focal/current/focal-server-cloudimg-amd64-vagrant.box# vagrant box add ubuntu/focal64 /path/to/focal-server-cloudimg-amd64-vagrant.box # -*- mode: ruby -*-# vi: set ft=ruby :Vagrant.configure(\"2\") do |config| # Every Vagrant development environment requires a box. You can search for # boxes at https://vagrantcloud.com/search. config.vm.box_check_update = false config.vm.box = \"ubuntu/xenial64\" config.vm.hostname = \"redis\" config.vm.network \"private_network\", ip: \"172.17.8.102\" config.vm.provider \"virtualbox\" do |vb| vb.memory = \"4096\" vb.cpus = 2 vb.name = \"tdegine\" end config.vm.synced_folder \".\", \"/vagrant\", type: \"rsync\", rsync__verbose: true, rsync__exclude: ['.git*', 'node_modules*','*.log','*.box','Vagrantfile'] config.vm.provision \"shell\", inline: &lt;&lt;-SHELLsudo sed -i 's/archive.ubuntu.com/mirrors.tuna.tsinghua.edu.cn/g' /etc/apt/sources.listsudo apt update# 安装cmakesudo apt-get install -y cmake build-essential# 安装dockersudo apt-get remove docker docker-engine docker.iosudo apt-get install-y apt-transport-https ca-certificates curl gnupg2 software-properties-commoncurl -fsSL https://download.docker.com/linux/ubuntu/gpg | sudo apt-key add -sudo add-apt-repository \\ \"deb [arch=amd64] https://mirrors.tuna.tsinghua.edu.cn/docker-ce/linux/ubuntu \\ $(lsb_release -cs) \\ stable\"sudo apt-get updatesudo mkdir -p /etc/dockersudo apt-get install -y docker-ce SHELL end $ vagrant upBringing machine 'default' up with 'virtualbox' provider...==&gt; default: Importing base box 'ubuntu/focal64'...==&gt; default: Matching MAC address for NAT networking...==&gt; default: Checking if box 'ubuntu/focal64' version '20200804.0.0' is up to date...==&gt; default: Setting the name of the VM: jpc_default_1597236075101_37777==&gt; default: Clearing any previously set network interfaces...==&gt; default: Preparing network interfaces based on configuration...default: Adapter 1: natdefault: Adapter 2: hostonly==&gt; default: Forwarding ports...default: 22 (guest) =&gt; 2222 (host) (adapter 1)==&gt; default: Running 'pre-boot' VM customizations...==&gt; default: Booting VM...==&gt; default: Waiting for machine to boot. This may take a few minutes...default: SSH address: 127.0.0.1:2222default: SSH username: vagrantdefault: SSH auth method: private key 一直卡在 default: SSH auth method: private key 并且 virtualbox 也会卡死，并且无法强制关闭或者释放此 vm，需要杀死进程才行。 解决办法下面方法二选一就行 修改 vagrantfile 参数增加 vb.customize [&quot;modifyvm&quot;, :id, &quot;--uartmode1&quot;, &quot;file&quot;, File::NULL] # -*- mode: ruby -*-# vi: set ft=ruby :Vagrant.configure(\"2\") do |config| # Every Vagrant development environment requires a box. You can search for # boxes at https://vagrantcloud.com/search. config.vm.box_check_update = false config.vm.box = \"ubuntu/xenial64\" config.vm.hostname = \"redis\" config.vm.network \"private_network\", ip: \"172.17.8.102\" config.vm.provider \"virtualbox\" do |vb| vb.memory = \"4096\" vb.cpus = 2 vb.name = \"tdegine\" # 增加这行 vb.customize [\"modifyvm\", :id, \"--uartmode1\", \"file\", File::NULL] end config.vm.synced_folder \".\", \"/vagrant\", type: \"rsync\", rsync__verbose: true, rsync__exclude: ['.git*', 'node_modules*','*.log','*.box','Vagrantfile'] config.vm.provision \"shell\", inline: &lt;&lt;-SHELLsudo sed -i 's/archive.ubuntu.com/mirrors.tuna.tsinghua.edu.cn/g' /etc/apt/sources.listsudo apt update# 安装cmakesudo apt-get install -y cmake build-essential# 安装dockersudo apt-get remove docker docker-engine docker.iosudo apt-get install-y apt-transport-https ca-certificates curl gnupg2 software-properties-commoncurl -fsSL https://download.docker.com/linux/ubuntu/gpg | sudo apt-key add -sudo add-apt-repository \\ \"deb [arch=amd64] https://mirrors.tuna.tsinghua.edu.cn/docker-ce/linux/ubuntu \\ $(lsb_release -cs) \\ stable\"sudo apt-get updatesudo mkdir -p /etc/dockersudo apt-get install -y docker-ce SHELL end 换镜像https://app.vagrantup.com/bento/boxes/ubuntu-20.04 Vagrant.configure(\"2\") do |config| config.vm.box = \"bento/ubuntu-20.04\"end 招聘小广告山东济南的小伙伴欢迎投简历啊 加入我们 , 一起搞事情。长期招聘，Java 程序员，大数据工程师，运维工程师，前端工程师。 参考资料 我的博客 我的掘金 hashicorp/vagrant#11817#SSH auth method: private key Vagrant box startup timeout due to no serial port","tags":[{"name":"ubuntu","slug":"ubuntu","permalink":"https://anjia0532.github.io/tags/ubuntu/"},{"name":"vagrant","slug":"vagrant","permalink":"https://anjia0532.github.io/tags/vagrant/"},{"name":"virtualbox","slug":"virtualbox","permalink":"https://anjia0532.github.io/tags/virtualbox/"},{"name":"focal64","slug":"focal64","permalink":"https://anjia0532.github.io/tags/focal64/"}]},{"title":"052-听说你爬回来的都是乱码？以某团为例讲解四种方案解决CSS字体反爬","date":"2021-01-13T19:40:21.000Z","path":"2021/01/13/python-web-font/","text":"这是坚持技术写作计划（含翻译）的第 52 篇，定个小目标 999，每周最少 2 篇。 本文以某团为例讲解如何获取 css 字体的真实内容 关于 css3 字体在以前，前端工程师只能使用浏览器主机已经安装的字体，要实现一些比较风骚的字体效果，只能用 flash 或者图片，从 css3 以后，可以使用 @font-face 属性 实现，基本现代浏览器都支持，具体参考 https://www.caniuse.com/?search=font-face ，但是在人均爬虫时代，被玩出了新花样，包括但不限于 金额，数量，地址，名称等信息用 webfont 替代文本来抵挡一部分低级爬虫而又不影响用户阅读和查看。 访问 https://fontdrop.info/ ，下载 http://s3plus.meituan.net/v1/mss_73a511b8f91f43d0bdae92584ea6330b/font/6cf535d2.woff ，并上传就能看到了 方案一 OCR这个思路是基于任何产品都不会牺牲用户阅读体验来提升反爬门槛，也就是说，用户肉眼能看到最终呈现效果，所以你把他当做是图片，用 OCR 产品去识别就可以了，除了占资源较多，识别效率较低外，鲁棒性更高。 常见的开源方案是 tesseract 方案二 映射针对的是小站，自己费劲搞了一套 web font 万能不变，爬虫工程师定点爆破，假设有 100 套（这是往多了说的，实际上很可能就 1 套），把这些有限的 web font 都 down 下来，然后本地建立一个映射关系，爬取的内容 替换一下就行了 方案三 KNN/K 近邻/K 相邻方案二的基础是 web font 有限且不变的前提，如果像某音，某团这种的机器随机生成的，那就没法了，这时候可以用 KNN参考 python 爬虫： 使用 knn 算法破解猫眼动态字体反爬 方案四 欧氏距离方案三 有点杀鸡用牛刀了 就为了个字体反爬，至于用 KNN 么，还得自己弄样本数据 计算欧氏距离只需要一个样本，找到映射关系，其余的只需要跟样本比较就行了 # 下载 http://s3plus.meituan.net/v1/mss_73a511b8f91f43d0bdae92584ea6330b/font/6cf535d2.woffbase = TTFont(self.getFontFile(baseFontFile))font = TTFont(self.getFontFile(fontFile))# baseGlyf = base.get('glyf')# glyf = font.get('glyf')# np1 = np.array([j for j in baseGlyf[0].coordinates])# np2 = np.array([j for j in glyf[0].coordinates])np.linalg.norm(np1 -np2, 'constant', constant_values=0) 代码只贴出关键部分通过 TTFont 解析 font，取 glyf[n]coordinates 取出点数组，使用 numpy 计算欧式距离，进行排序，最接近的就是符合的（两层循环），甚至可以观察下，欧式距离普遍小于几，假设是 1500，那内层循环小于 1500 就跳出就行了，注意 np1,np2 要补齐成一样长，否则会报错 补充一下，如果后期平台可能会同比缩放点位，这样简单计算欧氏距离就白搭了，需要把 xy 点位同比进行处理 招聘小广告山东济南的小伙伴欢迎投简历啊 加入我们 , 一起搞事情。长期招聘，Java 程序员，大数据工程师，运维工程师，前端工程师。 参考资料 我的博客 我的掘金 CSS3 字体","tags":[{"name":"python","slug":"python","permalink":"https://anjia0532.github.io/tags/python/"},{"name":"meituan","slug":"meituan","permalink":"https://anjia0532.github.io/tags/meituan/"},{"name":"css","slug":"css","permalink":"https://anjia0532.github.io/tags/css/"},{"name":"反爬","slug":"反爬","permalink":"https://anjia0532.github.io/tags/反爬/"}]},{"title":"051-ffmpeg 研究笔记","date":"2021-01-12T20:21:35.000Z","path":"2021/01/12/ffmpeg-note/","text":"这是坚持技术写作计划（含翻译）的第 51 篇，定个小目标 999，每周最少 2 篇。 工作原因，需要对视频进行处理，趁机会对 ffmpeg 进行学习，并随手记录 关于 ffmpeg 和libav 的区别ffmpeg 基本成了开源音视频处理的基座了，能接触到的大部分商用，个人开发的音视频软件都有 ffmpeg，比如格式工厂，EV 录屏，QQ 影音，暴风影音等等 基本上你用 everything 等软件全局搜一下 ffmpeg 就知道了libav 是 ffmpeg 成员闹掰后 fork 出的一个分支，两者算是同源并且相互补充，经常互相合并基本上 ffmpeg 更底层一些，libav 更上层些 此处说的 ffmpeg 和 libav 是指的项目名（广义上的）以两个视频合并为例 # ffmpegffmpeg -i \"concat:1.mp4|2.mp4\" -codec copy full.mp4# libavavconv -i \"concat:1.mp4|2.mp4|3.mp4\" -codec copy full.mp4 常用库基本主流编程语言都对 ffmpeg 进行了封装，如果是轻量使用的话，会比直接自己背 ffmpeg 的命令会友好一些 Python-ffmpeg-python Java-ffmpeg-cli-wrapper golang-goav 常用语法 合并视频(拼接) ffmpeg -i \"concat:1.mp4|2.mp4\" -codec copy full.mp4 参考 stackoverflow 上的 ffmpeg 三种拼接视频的方法 九宫格/分屏视频拼接 ffmpeg -re -i test.mp4 -re -i test.mp4 -re -i test.mp4 -re -i test.mp4 -filter_complex \"nullsrc=size=1920x1080 [base];[0:v] setpts=PTS-STARTPTS,scale=960x540 [upperleft]; [1:v] setpts=PTS-STARTPTS, scale=960x540 [upperright]; [2:v] setpts=PTS-STARTPTS, scale=960x540 [lowerleft]; [3:v] setpts=PTS-STARTPTS, scale=960x540 [lowerright];[base][upperleft] overlay=shortest=1[tmp1]; [tmp1][upperright] overlay=shortest=1:x=960 [tmp2]; [tmp2][lowerleft] overlay=shortest=1:y=540 [tmp3];[tmp3][lowerright] overlay=shortest=1:x=960:y=540\" -c:v libx264 out_1080p.mp4 解释下 -re -i 多文件输入-filter_complex 滤镜nullsrc=size=1920x1080 [base] 创建基础画布，尺寸是宽1920,高1080,颜色默认是绿色，如果要自定义颜色，需要用color filter，例如 color=s=1920x1080:c=black （黑色背景）[0:v] setpts=PTS-STARTPTS,scale=960x540 [upperleft]; 其中 [0:v] 是0输入的视频部分，同理，[1:v] 是第二个视频,[0:a]是第一个视频的音频部分 setpts=PTS-STARTPTS 帧是按照时间戳顺序从每个输入视频中获取的，因此最好将所有叠加输入通过setpts = PTS-STARTPTS过滤器传递，以使它们以相同的零时间戳开始，从0开始计数PTS 就是用PTS-STARTPTS，如果要加速setpts=0.5*PTS，慢速setpts=2.0*PTS scale=960x540是缩放，可以强制尺寸，也可以设置同比缩放，scale = 320:-1,设置宽是320，高-1意味着是根据320同比缩放高度，scale = iw*0.5:-1 宽度缩放一半,高度同比，如果是指向缩放，不想放大 scale='min(iw,320)':-1, 如果宽度小于320像素，不缩放，大于320使用320，并且长度同比缩放[upperleft]是一路流(stream) 如果一组stream有多个filter，使用英文逗号:,分隔，别用;分隔[base][upperleft] overlay=shortest=1[tmp1] [base]是底层画布[upperleft]是左上方视频（名字随便起） overlay=shortest=1 overlay 是说[upperleft]悬浮到[base]左上方，（因为默认不写坐标是x=0,y=0,所以是左上方）,shortest=1 是说，两个视频合成的总视频长度，以最短的为终点(比如，1 30秒，2 40秒，最终的视频就是30秒), 如果想指定xy位置，可以参考 overlay=x=960:y=540，指的是悬浮视频处于背景画布的x=960:y=540-c:v libx264 指的是视频编码器用 libx264 另外一个例子 ffmpeg -i 1.mp4 -i 2.mp4 -v libx264 -ac 2 -filter_complex \"[0:v]scale=320:240[a];[a]pad=640:240[b];[b][1:v]overlay=320:0[out]\" -map \"[out]\" -map 1:a c.mp4 [a]pad=640:240[b]: 是保持a视频画面不变的情况下(320:240)，将视频尺寸放大到640:240,空白部分用黑屏填充[b][1:v]overlay=320:0[out] 将第二个视频[1:v]悬浮到[b]视频上，x=320,y=0,其实就是将原本的两个视频，强制压缩成320:240,并且左右分布拼接成一个-map \"[out]\" 用[out]做视频-map 1:a 用第二个视频的声音做音频 参考 ffmpeg 实现多宫格效果，视频拼接合成 ，参考 ffmpeg:多路视频合并之九宫格特效:福优学苑 添加水印/文字/字幕/画中画 如果是要添加视频/图片类型的，可以使用上面介绍的 overlay 即可 ffmpeg -i 1.mp4 -i 1.png -filter_complex overlay=0:0 1.mp4 ffmpeg -i 1.mp4 -vf \"drawtext=fontfile=/usr/share/fonts/TTF/Vera.ttf:text='%&#123;pts\\:hms&#125;': x=(w-tw)/2: y=h-(2*lh): fontcolor=white\" 2.mp4 -vf 视频滤镜,-af 是音频滤镜，filter_complex 和 lavfi是一样的drawtext 在视频上添加文本fontfile=/usr/share/fonts/TTF/Vera.ttf 文本文件，如果只是字母或者数字，可以不写，用默认字体就行了text='%&#123;pts\\:hms&#125;' 这是duration，也可以不用变量，自己写x=(w-tw)/2:y=h-(2*lh) 设置存在的x,y值fontcolor 文本颜色 参考 ffmpeg # drawtext 进阶 ，《ffmpeg basics》中文版 – 10.在视频上添加文本 插入空白帧/空白视频/音频 ffmpeg -y -loglevel warning -hide_banner -stats -vsync 2 -i 2.mp4 -filter_complex \"[0:a]adelay=4s:all=true[a0];[0:v]scale=368:640,tpad=start_duration=4[v0];[v0][a0]concat=n=1:v=1:a=1[v][a]\" -map \"[v]\" -map \"[a]\" 3.mp4 -y 如果同名直接覆盖，不需要交互-loglevel warning 只打印warning级别日志-hide_banner 隐藏 banner-stats 显示进度-vsync 2 输入帧从解码器到编码器，时间戳保持不变；如果出现相同时间戳的帧，则丢弃之[0:a]adelay=4s:all=true[a0] 第一个音频延迟4秒[0:v]scale=368:640,tpad=start_duration=4[v0] 第一个视频前面填充4秒空白视频[a0]concat=n=1:v=1:a=1[v][a] 拼接起来 招聘小广告山东济南的小伙伴欢迎投简历啊 加入我们 , 一起搞事情。长期招聘，Java 程序员，大数据工程师，运维工程师，前端工程师。 参考资料 我的博客 我的掘金","tags":[{"name":"python","slug":"python","permalink":"https://anjia0532.github.io/tags/python/"},{"name":"ffmpeg","slug":"ffmpeg","permalink":"https://anjia0532.github.io/tags/ffmpeg/"},{"name":"音视频","slug":"音视频","permalink":"https://anjia0532.github.io/tags/音视频/"}]},{"title":"050-vSphere6.7添加第三方网卡驱动（以realtek 8168为例）","date":"2020-06-19T23:21:35.000Z","path":"2020/06/19/vsphere-7-custom-network-adapter/","text":"这是坚持技术写作计划（含翻译）的第 50 篇，定个小目标 999，每周最少 2 篇。 本文原来是想解决 螃蟹卡+vSphere ESXi 7.0 的，结果，事实证明，天真了，详见 vmkapi Dependency error while Installing/upgrading to ESXi 7.0 (78389) ,然后把所有 7.0 的文字，图片，统统换了一遍。囧！ 趁着 618 攒了台 NAS,配置 AMD 2200G(带核显 Vega8)+华擎 A320M-HDV R4.0+8G 酷兽 DDR4 2666MHz*2+七彩虹 CN600 128G nvme +家里闲置垃圾盘 这配置高不成低不就的，既没有成品 NAS 的低功耗，又没有垃圾佬心头肉(蜗牛星际，玩客云，暴风酷云二期等）便宜，做家用机又略显不足。 本文主要记录如何华擎自带螃蟹卡 RealTek 8168 网卡驱动添加到 vSphere7 里，如果你觉得你头铁直接安装的话，100%会是 官方建议的是 vSphere ESXI Image Builder ,但是太底层了，比较难搞，好在有别人搞的第三方工具， ESXI-Customizer. 下载适合 VMWare ESXI 的网卡驱动程序此处以 Realtek 8168 为例，可以尝试从 google 或者 bing 国际搜 Realtek NIC drivers for ESXI 或者直接去 v-front 站找一下 List of currently available ESXi packages 直接 CTRL+F 搜具体型号，比如 8168如果找到了，直接点击超链接，最后面，从 Direct Download links 下载驱动 .vib.gz 或者 .zip 二选一就行 使用 ESXi-Customizer-PS 添加驱动同样还是 v-front 站 ESXi-Customizer-PS 但是官方的注意事项说了，该页面已过期，不再维护，转战gayhub了，而且支持最新的 7.0(网上常见的 ESXi-Customizer-PS 2.6.0 只到 6.7)，实际上对于螃蟹卡，并没有卵用，底层不支持。Intel 网卡可以。 但是用这个脚本有两点限制 VMWare PowerCLI5.1+ Install-Module -Name VMware.PowerCLI [-AllowClobber] [-Proxy http://ip:port] （毕竟从国外下载，PowerCLI 一共 320Mb+,如果有代理的话，可选的用 -Proxy 来加速下载， -AllowClobber 忽略警告，针对于，网络不稳定断开后，不加会提示本地已存在） 修改 PS 的安全策略 Set-ExecutionPolicy -ExecutionPolicy RemoteSigned 众所周知的原因，访问国外的网络一向不太稳定， 所以，本次构建直接没有基于 vft,而是自己下驱动和 VMware vSphere Hypervisor (ESXi 6.7) Offline Bundle 包从官网 https://my.vmware.com/zh/group/vmware/patch#search 下载 下载自己所需的版本，因为是家用，所以就下载 6.7 最新版（为嘛不用 7.0 我也想用 7.0，无奈华擎的螃蟹卡不支持 7.0，衰） .\\ESXi-Customizer-PS.ps1 -izip .\\ESXi670-202006001.zip -dpt .\\net55-r8168-8.045a-napi-offline_bundle.zip -load net55-r8168 如果是多个网卡驱动，把驱动放到 D:\\xxx\\xx 文件夹下.\\ESXi-Customizer-PS.ps1 -izip .\\ESXi670-202006001.zip -pkgDir D:\\xxx\\xx 如果是全局挂代理了，或者属于肉身 FQ 的，可以直接在线.\\ESXi-Customizer-PS.ps1 -v67 -vft -load net55-r8168 PS D:\\xxx\\Tools\\VMware\\PowerCLI&gt; .\\ESXi-Customizer-PS.ps1 -izip .\\ESXi670-202006001.zip -vft -load sata-xahci,net55-r8168,net-e1000e,esx-uiThis is ESXi-Customizer-PS Version 2.8.0 (visit https://ESXi-Customizer-PS.v-front.de for more information!)(Call with -help for instructions)Logging to C:\\Users\\xxx\\AppData\\Local\\Temp\\ESXi-Customizer-PS-69824.log ...Running with PowerShell version 5.1 and VMware PowerCLI version .. buildAdding base Offline bundle .\\ESXi670-202006001.zip ... [OK]Connecting the V-Front Online depot ... [OK]Getting Imageprofiles, please wait ... [OK]Using Imageprofile ESXi-6.7.0-20200604001-standard ...(Dated 06/04/2020 02:21:11, AcceptanceLevel: PartnerSupported,No Doc)Load additional VIBs from Online depots ... Add VIB sata-xahci 1.42-1 [New AcceptanceLevel: CommunitySupported] [OK, added] Add VIB net55-r8168 8.045a-napi [OK, added] Add VIB net-e1000e 3.2.2.1-2vmw.670.0.0.8169922 [IGNORED, already added] Add VIB esx-ui 1.33.7-15803439 [IGNORED, already added]Exporting the Imageprofile to 'D:\\xxx\\Tools\\VMware\\PowerCLI\\ESXi-6.7.0-20200604001-standard-customized.iso'. Please be patient ...All done. 做启动 U 盘使用 Rufus (用软碟通 UltraISO） 经常会不识别下载 Rufus 并且将 https://rufus.ie/files/syslinux-4.07/menu.c32 下载并保存到跟 Rufus 同目录下， 招聘小广告山东济南的小伙伴欢迎投简历啊 加入我们 , 一起搞事情。长期招聘，Java 程序员，大数据工程师，运维工程师，前端工程师。 参考资料 我的博客 我的掘金 024-VMWare VSphere 6.7(ESXI,VSCA) 下载 VMware ESXi 7.0.0 服务器虚拟化 PowerCLI Offline Installation Walkthrough 【更新】【下载】VMware vSphere 7.0 正式版 Adding Realtek 8111 driver to vSphere 6.7 image","tags":[{"name":"vsphere","slug":"vsphere","permalink":"https://anjia0532.github.io/tags/vsphere/"},{"name":"realtek","slug":"realtek","permalink":"https://anjia0532.github.io/tags/realtek/"},{"name":"螃蟹卡","slug":"螃蟹卡","permalink":"https://anjia0532.github.io/tags/螃蟹卡/"},{"name":"exsi","slug":"exsi","permalink":"https://anjia0532.github.io/tags/exsi/"}]},{"title":"049-Kong1.4 vs SC Gateway2.2 vs Zuul1.3 性能测试","date":"2019-11-17T22:15:41.000Z","path":"2019/11/17/kong-vs-sc-gateway-vs-zuul/","text":"这是坚持技术写作计划（含翻译）的第 49 篇，定个小目标 999，每周最少 2 篇。 本文主要对比常见 API 网关(kong 1.4,springcloud gateway 2.2, zuul 1.3)的性能测试（未涉及 service mesh、traefik 和 envoy） 下载测试代码$ git clone https://github.com/anjia0532/gateway-kong-zuul.git$ cd gateway-kong-zuul$ mvn clean package 或者从 github 下载我打包好的 $ wget https://github.com/anjia0532/gateway-kong-zuul/releases/download/0.0.1-SNAPSHOT/sc-gateway-0.0.1-SNAPSHOT.jar$ wget https://github.com/anjia0532/gateway-kong-zuul/releases/download/0.0.1-SNAPSHOT/web-0.0.1-SNAPSHOT.jar$ wget https://github.com/anjia0532/gateway-kong-zuul/releases/download/0.0.1-SNAPSHOT/zuul-0.0.1-SNAPSHOT.jar endpoint endpoint 描述 /api/ping 无入参，固定返回 “ok” /api/echo?str=xx 入参 str,返回 str /api/random-sleep?str=xx 入参 str,随机 sleep100 毫秒-10 秒，并返回 str 启动服务 命令 端口 描述 java -jar sc-gateway-0.0.1-SNAPSHOT.jar 7080 SpringCloudGateway java -jar web-0.0.1-SNAPSHOT.jar 8080 SpringMVC java -jar zuul-0.0.1-SNAPSHOT.jar 6080 Zuul | curl -i -X POST –url http://localhost:8001/services/ –data ‘name=test’ –data ‘url=http://localhost:8080‘ curl -i -X POST –url http://localhost:8001/services/test/routes –data ‘paths[]=/test’ | 9000 | Konghttp://localhost:8000/test/api/\\* | 安装 wrk$ git clone https://github.com/wg/wrk$ make 防止缓存，创建随机请求，注意第 6 行，在请求 8080，web，项目时，没有路由 /test 信息， wrk.method = \"GET\";wrk.body = \"\";request = function() ip = tostring(math.random(1, 255))..\".\"..tostring(math.random(1, 255))..\".\"..tostring(math.random(1, 255))..\".\"..tostring(math.random(1, 255)) path = \"/test/api/echo?str=\" .. ip return wrk.format(nil, path)end 注意，我这是在 vagrant+virtualbox 里运行的,配置是 2U4G，详见 Vagrantfile ## zuul (spring-cloud-starter-netflix-zuul 2.2.0.RC2 zuul-core 1.3.1)./wrk -t10 -c10 -d60s -s ./test.lua --latency http://127.0.0.1:6080Running 1m test @ http://127.0.0.1:6080 10 threads and 10 connections Thread Stats Avg Stdev Max +/- Stdev Latency 4.22ms 5.13ms 134.73ms 92.63% Req/Sec 292.26 116.64 1.37k 74.75% Latency Distribution 50% 3.11ms 75% 5.06ms 90% 8.09ms 99% 23.85ms 174662 requests in 1.00m, 24.24MB readRequests/sec: 2908.12Transfer/sec: 413.22KB## sc-gateway Spring Cloud Hoxton.RC2 (spring-cloud-gateway 2.2.0.RC2)./wrk -t10 -c10 -d60s -s ./test.lua --latency http://127.0.0.1:7080Running 1m test @ http://127.0.0.1:7080 10 threads and 10 connections Thread Stats Avg Stdev Max +/- Stdev Latency 3.11ms 2.53ms 55.45ms 84.39% Req/Sec 354.43 114.14 0.94k 68.56% Latency Distribution 50% 2.56ms 75% 4.01ms 90% 5.88ms 99% 12.12ms 211742 requests in 1.00m, 26.11MB readRequests/sec: 3526.95Transfer/sec: 445.35KB## Kong 1.4.0./wrk -t10 -c10 -d60s -s ./test.lua --latency http://127.0.0.1:8000Running 1m test @ http://127.0.0.1:8000 10 threads and 10 connections Thread Stats Avg Stdev Max +/- Stdev Latency 2.25ms 1.31ms 24.71ms 82.31% Req/Sec 461.43 140.31 1.76k 74.44% Latency Distribution 50% 1.96ms 75% 2.70ms 90% 3.70ms 99% 7.18ms 275682 requests in 1.00m, 58.17MB readRequests/sec: 4587.18Transfer/sec: 0.97MB## 直连 spring boot 2.2.1.RELEASE./wrk -t10 -c10 -d60s -s ./test.lua --latency http://127.0.0.1:8080Running 1m test @ http://127.0.0.1:8080 10 threads and 10 connections Thread Stats Avg Stdev Max +/- Stdev Latency 5.95ms 22.62ms 495.03ms 95.67% Req/Sec 1.22k 517.51 5.29k 69.52% Latency Distribution 50% 543.00us 75% 2.82ms 90% 11.86ms 99% 103.28ms 714560 requests in 1.00m, 86.88MB readRequests/sec: 11892.88Transfer/sec: 1.45MB 运行三次，取最后一次的结果（除 web 项目一直启动外，其余随用随启，用完即停） 从 QPS 看 直连&gt;Kong&gt;Spring Cloud Gateway&gt;Zuul 从内存和 CPU 看 直连肯定没有额外消耗，次之是 Kong，然后是 SC Gateway，最差的是 Zuul 从管理的易用性看，Kong 因为其便捷的插件体系及现有的插件生态完胜其余几样。 综合来看，建议使用 Kong 作为 API 网关。 招聘小广告山东济南的小伙伴欢迎投简历啊 加入我们 , 一起搞事情。长期招聘，Java 程序员，大数据工程师，运维工程师，前端工程师。 参考资料 我的博客 我的掘金","tags":[{"name":"微服务","slug":"微服务","permalink":"https://anjia0532.github.io/tags/微服务/"},{"name":"SpringCloud","slug":"SpringCloud","permalink":"https://anjia0532.github.io/tags/SpringCloud/"},{"name":"zuul","slug":"zuul","permalink":"https://anjia0532.github.io/tags/zuul/"},{"name":"Openresty","slug":"Openresty","permalink":"https://anjia0532.github.io/tags/Openresty/"},{"name":"Kong","slug":"Kong","permalink":"https://anjia0532.github.io/tags/Kong/"},{"name":"Nginx","slug":"Nginx","permalink":"https://anjia0532.github.io/tags/Nginx/"}]},{"title":"048-使用Kong替换Zuul(从Eureka同步列表)","date":"2019-11-15T19:35:21.000Z","path":"2019/11/15/kong-plugin-sync-eureka/","text":"这是坚持技术写作计划（含翻译）的第 48 篇，定个小目标 999，每周最少 2 篇。 本文主要是介绍如何使用 Kong 替换 Zuul 作为 SpringCloud 的网关。并解决自动从 Eureka 同步服务实例到 Kong 的问题。 安装 Kong 和 kong-plugin-sync-eureka 插件以 docker 安装为例，详细请参考 https://docs.konghq.com/install/docker/创建 docker-compose.yml version: \"2\"services: kong-plugins: image: kong:latest environment: KONG_LUA_PACKAGE_PATH: /usr/local/custom/share/lua/5.1/?.lua;; command: - luarocks - install - --tree - /usr/local/custom - kong-plugin-sync-eureka volumes: - /data/kong/custom/:/usr/local/custom/ postgres: image: postgres:11-alpine environment: POSTGRES_USER: root POSTGRES_PASSWORD: root POSTGRES_DB: kong volumes: - /data/postgresql/data:/var/lib/postgresql/data kong-migration: image: kong:latest environment: KONG_PG_HOST: postgres KONG_PG_PASSWORD: root KONG_PG_USER: root KONG_LUA_PACKAGE_PATH: /usr/local/custom/share/lua/5.1/?.lua;; command: - kong - migrations - bootstrap volumes: - /data/kong/custom/:/usr/local/custom/ depends_on: - postgres kong: image: kong:latest environment: KONG_PG_HOST: postgres KONG_PG_PASSWORD: root KONG_PG_USER: root KONG_ADMIN_LISTEN: 0.0.0.0:9001 KONG_PROXY_LISTEN: 0.0.0.0:9000 KONG_PROXY_LISTEN_SSL: 0.0.0.0:9443 KONG_LUA_PACKAGE_PATH: /usr/local/custom/share/lua/5.1/?.lua;; KONG_PLUGINS: bundled,sync-eureka volumes: - /data/kong/custom/:/usr/local/custom/ - /data/kong/logs/:/usr/local/kong/logs/ depends_on: - postgres - kong-migration - kong-plugins ports: - 9000:9000/tcp - 9001:9001/tcp docker-compose ps Name Command State Ports--------------------------------------------------------------------------------------------------------------------------------------------------------kong_kong-migration_1 /docker-entrypoint.sh kong ... Exit 0kong_kong-plugins_1 /docker-entrypoint.sh luar ... Exit 0kong_kong_1 /docker-entrypoint.sh kong ... Up 8000/tcp, 8001/tcp, 8443/tcp, 8444/tcp, 0.0.0.0:9000-&gt;9000/tcp, 0.0.0.0:9001-&gt;9001/tcpkong_postgres_1 docker-entrypoint.sh postgres Up 5432/tcp 启用插件$ curl -H \"Content-Type: application/json\" -X POST --data '&#123;\"config\":&#123;\"sync_interval\":10,\"eureka_url\":\"http://eureka_server/eureka\",\"clean_target_interval\":86400&#125;,\"name\":\"sync-eureka\"&#125;' http://localhost:9001/plugins$ docker-compose restart kong## 重启使插件生效## 稍等10秒钟左右，访问services查看是否同步生效$ curl http://localhost:9001/services 招聘小广告山东济南的小伙伴欢迎投简历啊 加入我们 , 一起搞事情。长期招聘，Java 程序员，大数据工程师，运维工程师，前端工程师。 参考资料 我的博客 我的掘金 anjia0532/kong-plugin-sync-eureka Install Kong Configuration Reference","tags":[{"name":"kong","slug":"kong","permalink":"https://anjia0532.github.io/tags/kong/"},{"name":"微服务","slug":"微服务","permalink":"https://anjia0532.github.io/tags/微服务/"},{"name":"eureka","slug":"eureka","permalink":"https://anjia0532.github.io/tags/eureka/"},{"name":"SpringCloud","slug":"SpringCloud","permalink":"https://anjia0532.github.io/tags/SpringCloud/"},{"name":"zuul","slug":"zuul","permalink":"https://anjia0532.github.io/tags/zuul/"}]},{"title":"047-零基础零成本使用vue开发婚礼请柬小程序","date":"2019-09-25T20:13:43.000Z","path":"2019/09/25/vue-wedding-invitation-wechat-applet/","text":"这是坚持技术写作计划（含翻译）的第 47 篇，定个小目标 999，每周最少 2 篇。 婚期定在 10.1，毕竟是程序员，就自告奋勇的跟老婆说自己写个小程序做婚礼请柬。在网友秋秋 QY分享的基础上，略作改进，整理了这篇零基础零成本小程序教程。（如果嫌麻烦，婚礼纪 啥的网上随便找个交差也行） 贴一个原作者的 小程序二维码 事前准备 Hbuilder X 微信开发者工具 注册小程序账号 版本控制软件-git 完善小程序设置补全信息获取小程序 ID 配置 hbuilder 和 uniapp配置 hbuilder 从 github 上 clone 下项目 git clone https://github.com/anjia0532/jiayuan.git 修改配置文件 /common/js/metadata.js 比如酒店坐标，新郎新娘电话等修改小程序配置文件 manifest.json 运行微信小程序 开通云开发环境 创建云开发数据库从 static/databases 复制文件名(去掉.json) 作为集合名称，创建。分别导入数据，其中 message 和 user 是空集合，导入失败，不用管。 设置数据库的读写权限 上传婚纱照修改为婚纱照地址，也可以从 json 文件改完，重新导入。 创建并上传云函数 体验预览 发给朋友体验 发布 后话本文主要是个人需要，结合网上大牛的开源项目，略作修改放出的，可能会有各种需要调整的地方，欢迎留言。我会尽量帮助各位新人。 招聘小广告山东济南的小伙伴欢迎投简历啊 加入我们 , 一起搞事情。长期招聘，Java 程序员，大数据工程师，运维工程师，前端工程师。 参考资料 我的博客 我的掘金 mpvue+小程序云开发，纯前端实现婚礼邀请函","tags":[{"name":"前端","slug":"前端","permalink":"https://anjia0532.github.io/tags/前端/"},{"name":"vuejs","slug":"vuejs","permalink":"https://anjia0532.github.io/tags/vuejs/"},{"name":"js","slug":"js","permalink":"https://anjia0532.github.io/tags/js/"},{"name":"vue","slug":"vue","permalink":"https://anjia0532.github.io/tags/vue/"},{"name":"请柬","slug":"请柬","permalink":"https://anjia0532.github.io/tags/请柬/"}]},{"title":"046-解决google jib多任务问题","date":"2019-09-22T23:30:01.000Z","path":"2019/09/22/google-jib-alpine-tini/","text":"这是坚持技术写作计划（含翻译）的第 46 篇，定个小目标 999，每周最少 2 篇。 本文主要讲解使用 google jib 打包应用时 如果 基础镜像是 openjdk 的 alpine 系列，运行成功后无法正常使用 jmap,jstack,arthas 等工具，报错信息如下 [ERROR] Start arthas failed, exception stack trace:com.sun.tools.attach.AttachNotSupportedException: Unable to get pid of LinuxThreads manager threadat sun.tools.attach.LinuxVirtualMachine.(LinuxVirtualMachine.java:86)at sun.tools.attach.LinuxAttachProvider.attachVirtualMachine(LinuxAttachProvider.java:78)at com.sun.tools.attach.VirtualMachine.attach(VirtualMachine.java:250)at com.taobao.arthas.core.Arthas.attachAgent(Arthas.java:72)at com.taobao.arthas.core.Arthas.(Arthas.java:25)at com.taobao.arthas.core.Arthas.main(Arthas.java:99)[ERROR] attach fail, targetPid: 1 在之前写的 使用 Maven 加速和简化构建 Docker(基于 Google jib) 最后有提过，但是没有详细展开。 google jib 和 Dragonfly 系列文章 使用 Maven 加速和简化构建 Docker(基于 Google jib) 012-P2P 加速 Docker 镜像分发(阿里 Dragonfly) 013-阿里 Dragonfly 体验之私有 registry 下载 046-解决 google jib 多任务问题 简述 google jib 和阿里 Dragonfly阿里的 dragonfly 和 google jib 其实都在解决类似的问题，如何最大化的重用依赖。但是是两个思路，dragonfly 是在不改动源镜像的基础上，类似 cdn 的思路在近源缓存数据，这样一来局域网内就可以不用重复从公网拉取镜像，同时因为使用了 p2p 传输，所以可以有效防止单机热点打满带宽的问题。(d7y 主要是使用 p2p 解决大文件传输问题，用于镜像传输只是捎带手的一个功能)，d7y 是解决制成品如何优化传输。 google jib 的思路是，侵入到构建过程中，发挥主人翁精神，我构建，我优化。比如在使用 gradle，maven 构建时，体积最大的是 jre 或者 jdk,其次是各种三方 jar 包，再次之的是 web 中的静态资源(那些往 resource 可劲塞文件的不在讨论范围内)，而这些东西往往又不会经常变动，而源码部分会经常变动，那么将其分离开，利用 docker 的 layer 进行缓存，既能节省空间，又能节省带宽，又能节省时间。 配置 google jibsettings.xml 增加 auth 配置settings.xml 增加 registry server 的 auth 认证，password 可以用 maven password encryption ,不建议存放明文密码 &lt;settings&gt; ... &lt;servers&gt; ... &lt;server&gt; &lt;id&gt;MY_REGISTRY&lt;/id&gt; &lt;username&gt;MY_USERNAME&lt;/username&gt; &lt;password&gt;&#123;MY_SECRET&#125;&lt;/password&gt; &lt;/server&gt; &lt;/servers&gt;&lt;/settings&gt; anjia0532/openjdk-8-alpine-lib 的 DockerfileFROM openjdk:8-jdk-alpineARG ARTHAS_VERSION=\"3.1.3\"ARG MIRROR=falseENV MAVEN_HOST=http://repo1.maven.org/maven2 \\ ALPINE_HOST=dl-cdn.alpinelinux.org \\ MIRROR_MAVEN_HOST=http://maven.aliyun.com/repository/public \\ MIRROR_ALPINE_HOST=mirrors.tuna.tsinghua.edu.cn# if use mirror change to aliyun mirror siteRUN if $MIRROR; then MAVEN_HOST=$&#123;MIRROR_MAVEN_HOST&#125; ;ALPINE_HOST=$&#123;MIRROR_ALPINE_HOST&#125; ; sed -i \"s/dl-cdn.alpinelinux.org/$&#123;ALPINE_HOST&#125;/g\" /etc/apk/repositories ; fiRUN \\ # https://github.com/docker-library/openjdk/issues/76 apk add --no-cache tiniRUN \\ # change to GMT+0800 timezone apk add --no-cache tzdata &amp;&amp; \\ cp /usr/share/zoneinfo/Asia/Shanghai /etc/localtime &amp;&amp; \\ echo \"Asia/Shanghai\" &gt; /etc/timezoneRUN \\ # download &amp; install arthas wget -qO /tmp/arthas.zip \"$&#123;MAVEN_HOST&#125;/com/taobao/arthas/arthas-packaging/$&#123;ARTHAS_VERSION&#125;/arthas-packaging-$&#123;ARTHAS_VERSION&#125;-bin.zip\" &amp;&amp; \\ mkdir -p /opt/arthas &amp;&amp; \\ unzip /tmp/arthas.zip -d /opt/arthas &amp;&amp; \\ rm /tmp/arthas.zip# Tini is now available at /sbin/tiniENTRYPOINT [\"/sbin/tini\", \"--\"] 构建命令 docker build --build-arg MIRROR=true . -t anjia0532/openjdk-8-alpine-lib 修改 pom.xml&lt;project&gt; &lt;groupId&gt;com.example.module&lt;/groupId&gt; &lt;artifactId&gt;demo&lt;/artifactId&gt; &lt;version&gt;0.0.1-SNAPSHOT&lt;/version&gt; &lt;packaging&gt;jar&lt;/packaging&gt; &lt;name&gt;demo&lt;/name&gt; ... &lt;build&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;groupId&gt;com.google.cloud.tools&lt;/groupId&gt; &lt;artifactId&gt;jib-maven-plugin&lt;/artifactId&gt; &lt;version&gt;1.6.1&lt;/version&gt; &lt;configuration&gt; &lt;from&gt; &lt;image&gt;anjia0532/openjdk-8-alpine-lib&lt;/image&gt; &lt;/from&gt; &lt;to&gt; &lt;image&gt;$&#123;project.artifactId&#125;:$&#123;project.version&#125;&lt;/image&gt; &lt;/to&gt; &lt;container&gt; &lt;entrypoint&gt; &lt;shell&gt;/sbin/tini&lt;/shell&gt; &lt;option&gt;--&lt;/option&gt; &lt;/entrypoint&gt; &lt;args&gt; &lt;arg&gt;java&lt;/arg&gt; &lt;arg&gt;-cp&lt;/arg&gt; &lt;arg&gt;/app/resources/:/app/classes/:/app/libs/*&lt;/arg&gt; &lt;arg&gt;com.example.application&lt;/arg&gt; &lt;/args&gt; &lt;ports&gt; &lt;port&gt;8080&lt;/port&gt; &lt;port&gt;8563&lt;/port&gt;&lt;!-- arthas 端口 --&gt; &lt;/ports&gt; &lt;environment&gt; &lt;_JAVA_OPTIONS&gt;-XX:+HeapDumpOnOutOfMemoryError -XX:HeapDumpPath=/var/log/&lt;/_JAVA_OPTIONS&gt; &lt;/environment&gt; &lt;/container&gt; &lt;/configuration&gt; &lt;/plugin&gt; &lt;/plugins&gt; &lt;/build&gt;&lt;/project&gt; 主要起作用的是 tini ,需要在 entrypoint 部分设置 /sbin/tini -- 但是 根据文档 https://github.com/GoogleContainerTools/jib/blob/master/docs/faq.md#what-would-a-dockerfile-for-a-jib-built-image-look-like 所述 ENTRYPOINT [\"java\", jib.container.jvmFlags, \"-cp\", \"/app/resources:/app/classes:/app/libs/*\", jib.container.mainClass]CMD [jib.container.args] jib 构建的应用，默认会使用 将启动命令放到 entrypoint 部分，会覆盖掉 baseimage 里写的 entryoint,如果在 pom 里定义的话，又会覆盖 jib 的默认启动命令，所以只能将启动项目放到 args 部分，但是又无法使用 jvmFlags，默认 cp，默认 main 类推断，必须要显式的自行声明。 生成镜像mvn compile -Pprod jib:build # 构建并推送到目标registry上，构建主机不需要安装dockermvn compile -Pprod jib:dockerBuild # 构建到本机docker daemonmvn compile -Pprod jib:buildTar # 构建并生成tar.gz,可以使用docker load --input target/jib-image.tar 导入 如果是在 jenkins 等 CICD 场景，每次让研发修改 pom 不太方便，可以使用命令行来构建。 mvn compile com.google.cloud.tools:jib-maven-plugin:1.6.1:dockerBuild \\ -Djib.to.image=myregistry/myimage:latest \\ -Djib.to.auth.username=$USERNAME \\ -Djib.to.auth.password=$PASSWORD \\ -Djib.container.environment=key1=\"value1\",key2=\"value2\" \\ -Djib.container.args=arg1,arg2,arg3 另外上述示例不管是 maven 还是 gradle 都是 java 类应用，对于 nodejs 或者 golang，jib 官方也支持用户基于jib core自行编写构建插件 招聘小广告山东济南的小伙伴欢迎投简历啊 加入我们 , 一起搞事情。长期招聘，Java 程序员，大数据工程师，运维工程师，前端工程师。 参考资料 我的博客 我的掘金 Jib - Containerize your Maven project jib core","tags":[{"name":"docker","slug":"docker","permalink":"https://anjia0532.github.io/tags/docker/"},{"name":"java","slug":"java","permalink":"https://anjia0532.github.io/tags/java/"},{"name":"google-jib","slug":"google-jib","permalink":"https://anjia0532.github.io/tags/google-jib/"}]},{"title":"045-解决packetbeat静默安装pcap问题","date":"2019-09-22T20:13:21.000Z","path":"2019/09/22/win-packetbeat-silent-pcap/","text":"这是坚持技术写作计划（含翻译）的第 45 篇，定个小目标 999，每周最少 2 篇。 在 windows 下安装elastic packetbeat 时 要求安装 pcap ，而团队内使用 ansible 同一部署，所以需要研究一下静默安装 pcap ansible-playbook - name: 安装Nmap依赖 win_package: path: \"https://nmap.org/dist/nmap-7.12-setup.exe\" product_id: nmap arguments: - /S - /winpcap_mode=yes 或者使用命令行安装下载 nmap-7.12-setup /path/to/nmap-7.12-setup.exe /S /winpcap_mode=yes 捎带手打个广告 https://github.com/anjia0532/ansible-beats fork 自 elastic 官方的 beats playbook，并增加了 windows 支持 招聘小广告山东济南的小伙伴欢迎投简历啊 加入我们 , 一起搞事情。长期招聘，Java 程序员，大数据工程师，运维工程师，前端工程师。 参考资料 我的博客 我的掘金 Winpcap - How to get silent installation back?","tags":[{"name":"windows","slug":"windows","permalink":"https://anjia0532.github.io/tags/windows/"},{"name":"beats","slug":"beats","permalink":"https://anjia0532.github.io/tags/beats/"},{"name":"elastic","slug":"elastic","permalink":"https://anjia0532.github.io/tags/elastic/"},{"name":"监控","slug":"监控","permalink":"https://anjia0532.github.io/tags/监控/"},{"name":"wireshark","slug":"wireshark","permalink":"https://anjia0532.github.io/tags/wireshark/"},{"name":"winpcap","slug":"winpcap","permalink":"https://anjia0532.github.io/tags/winpcap/"},{"name":"pcap","slug":"pcap","permalink":"https://anjia0532.github.io/tags/pcap/"},{"name":"silent-install","slug":"silent-install","permalink":"https://anjia0532.github.io/tags/silent-install/"}]},{"title":"044-wget免登陆下载jdk 8u291","date":"2019-09-18T19:35:21.000Z","path":"2019/09/18/wget-jdk-8u221/","text":"这是坚持技术写作计划（含翻译）的第 44 篇，定个小目标 999，每周最少 2 篇。 本文主要介绍如何使用 wget 免登陆下载可用的 jdk 8u221，介绍 6 种方式 下载最新的 jre8如果只是安装 jre 即可，则可以使用(长期有效) $ url=$(curl -s https://www.java.com/en/download/linux_manual.jsp | grep -E \".*x64.*javadl\" | grep -v \"RPM\" | sed \"s/.*href=\\\"//g;s/\\\".*//g\" | head -n 1)$ wget -c --content-disposition $url$ old=$(ls -hat | grep jre | head -n1)$ mv $old $(echo $old | awk -F\"?\" '&#123;print $1&#125;') 下载所有版本 jdk参考 gist 上大佬 rathaROG的办法https://gist.github.com/wavezhang/ba8425f24a968ec9b2a8619d7c2d86a6#gistcomment-3737227 先打开 https://www.oracle.com/java/technologies/javase/javase-jdk8-downloads.html 找到需要的二进制文件，右键 F12，找到该选项的 data-file 属性，复制出来例如 jdk 8u291 版本https://download.oracle.com/otn/java/jdk/8u291-b10/d7fc238d0cbf4b0dac67be84580cfb4b/jdk-8u291-windows-x64.exe从其中提取必要信息，替换成 https://javadl.oracle.com/webapps/download/GetFile/1.8.0_[version]-[build_number]/[encrypted_path]/windows-i586/[file_name_exe] 格式 [version]: 291 build_number: b10encrypted_path: d7fc238d0cbf4b0dac67be84580cfb4bfile_name_exe: jdk-8u291-windows-x64.exe 替换完后差不多是 https://javadl.oracle.com/webapps/download/GetFile/1.8.0_291-b10/d7fc238d0cbf4b0dac67be84580cfb4b/windows-i586/jdk-8u291-windows-x64.exe 下载 jdk8u221从 oracle 官方下载，但是不保证长期可用 $ wget -c --content-disposition \"https://javadl.oracle.com/webapps/download/AutoDL?BundleId=239835_230deb18db3e4014bb8e3e8324f81b43\"$ old=$(ls -hat | grep jre | head -n1)$ mv $old $(echo $old | awk -F\"?\" '&#123;print $1&#125;') windows jdk-8u221-windows-x64.exe 地址 https://javadl.oracle.com/webapps/download/AutoDL?BundleId=239842_230deb18db3e4014bb8e3e8324f81b43 下载 jdk8u131长期有效，也是 oracle 官方下载链接(8u131 以后的都 404 了) $ wget -O jdk-8u131-linux-x64.tar.gz --no-check-certificate --no-cookies --header \"Cookie: oraclelicense=accept-securebackup-cookie\" http://download.oracle.com/otn-pub/java/jdk/8u131-b11/d54c1d3a095b4ff2b6607d096fa80163/jdk-8u131-linux-x64.tar.gz 下载第三方 jdk自行判断校验码，不保证有效性和安全性 $ jdk_name=$(curl -s http://enos.itcollege.ee/~jpoial/allalaadimised/jdk8/ | grep tar.gz | grep -v demo |sed \"s/.*href=\\\"//g;s/\\\".*//g\"|head -n 1)$ wget -O \"$jdk_name\" \"http://enos.itcollege.ee/~jpoial/allalaadimised/jdk8/$jdk_name\" 下载第三方 openjdk长期有效，不保证安全性 Download Java SE Standard Compliant Liberica JDK 8u222 $ wget -O bellsoft-jdk8u222-linux-amd64.tar.gz \"https://download.bell-sw.com/java/8u222/bellsoft-jdk8u222-linux-amd64.tar.gz\" 从官方下载方法长期有效，但是 AuthParam 有时效性,无法写成脚本，也可以安装 openjdk 注册并登陆 oracle 账号 打开 https://www.oracle.com/technetwork/java/javase/downloads/jdk8-downloads-2133151.html 复制的地址类似 https://download.oracle.com/otn/java/jdk/8u221-b11/230deb18db3e4014bb8e3e8324f81b43/jdk-8u221-linux-x64.tar.gz?AuthParam=xxxxx_xxxxxxxxxxxxxxxxxx 其中 AuthParam 参数是有时效性的 wget -O ``jdk-8u221-linux-x64.tar.gz`` --no-check-certificate --no-cookies --header &quot;Cookie: oraclelicense=accept-securebackup-cookie&quot; &quot;``https://download.oracle.com/otn/java/jdk/8u221-b11/230deb18db3e4014bb8e3e8324f81b43/jdk-8u221-linux-x64.tar.gz?AuthParam=xxxxx_xxxxxxxxxxxxxxxxxx&quot; 题外话在网上找 wget 免密码下载 jdk 时，发现了一个有意思的项目The catalog may also be accessed using command-line tools, or through a simple HTTP API.虽然给出的 java 相关的因为 OTN 的原因，都挂了，但是别的还是有些能用的。挺方便的。 招聘小广告山东济南的小伙伴欢迎投简历啊 加入我们 , 一起搞事情。长期招聘，Java 程序员，大数据工程师，运维工程师，前端工程师。 参考资料 我的博客 我的掘金 适用于 Linux 的 Java 下载 hgomez/download-java8.sh","tags":[{"name":"linux","slug":"linux","permalink":"https://anjia0532.github.io/tags/linux/"},{"name":"java","slug":"java","permalink":"https://anjia0532.github.io/tags/java/"},{"name":"jdk8","slug":"jdk8","permalink":"https://anjia0532.github.io/tags/jdk8/"},{"name":"jdk","slug":"jdk","permalink":"https://anjia0532.github.io/tags/jdk/"},{"name":"wget","slug":"wget","permalink":"https://anjia0532.github.io/tags/wget/"}]},{"title":"043-解决vagrant访问virtualbox共享文件夹报无权限问题(Permission denied)","date":"2019-08-27T12:33:10.000Z","path":"2019/08/27/permission-denied-accessing-vbox/","text":"这是坚持技术写作计划（含翻译）的第 43 篇，定个小目标 999，每周最少 2 篇。 本文是在 windows 进行 jumpserver 二开时，需要用到 vbox 的共享文件夹(宿主&lt;-&gt;虚拟机双向读写)，vagrant 默认登录用户是 vagrant，而 vbox 的挂载文件夹是 vboxsf 组的，故而访问时会报 Permission denied 问题。 python+vagrant+virtualbox 系列文章 036-win10 搭建 python 的 linux 开发环境(pycharm+vagrant+virtualbox) 037-vagrant 启动(up)后自动同步文件(rsync-auto) 040-解决 Linux 使用 virtualbox 共享文件夹问题 042-解决 win10 VirtualBox 无法启动(VERR_NEM_VM_CREATE_FAILED) 043-解决 vagrant 访问 virtualbox 共享文件夹报无权限问题(Permission denied)D) 解决办法# 登录虚拟机$ vagrant ssh# 将当前用户添加到vboxsf组内$ sudo usermod -aG vboxsf $USER# 以vboxsf组的身份重新登录 (注销，重启也可以)$ newgrp - vboxsf 也可以参见我在 Stack Exchange 下 Permission denied when accessing VirtualBox shared folder when member of the vboxsf group 的回答 招聘小广告山东济南的小伙伴欢迎投简历啊 加入我们 , 一起搞事情。长期招聘，Java 程序员，大数据工程师，运维工程师，前端工程师。 参考资料 我的博客 我的掘金 Permission denied when accessing VirtualBox shared folder when member of the vboxsf group","tags":[{"name":"python","slug":"python","permalink":"https://anjia0532.github.io/tags/python/"},{"name":"虚拟机","slug":"虚拟机","permalink":"https://anjia0532.github.io/tags/虚拟机/"},{"name":"kvm","slug":"kvm","permalink":"https://anjia0532.github.io/tags/kvm/"},{"name":"vagrant","slug":"vagrant","permalink":"https://anjia0532.github.io/tags/vagrant/"},{"name":"virtualbox","slug":"virtualbox","permalink":"https://anjia0532.github.io/tags/virtualbox/"}]},{"title":"042-解决win10 VirtualBox无法启动(VERR_NEM_VM_CREATE_FAILED)","date":"2019-08-26T19:35:21.000Z","path":"2019/08/26/win-10-virtualbox-verr-nem-vm-create/","text":"这是坚持技术写作计划（含翻译）的第 42 篇，定个小目标 999，每周最少 2 篇。 最近将 win10 从 1809 升级到 1903，结果自己的 VirtualBox 无法启动，经过一番 google，问题已解决。 python+vagrant+virtualbox 系列文章 036-win10 搭建 python 的 linux 开发环境(pycharm+vagrant+virtualbox) 037-vagrant 启动(up)后自动同步文件(rsync-auto) 040-解决 Linux 使用 virtualbox 共享文件夹问题 042-解决 win10 VirtualBox 无法启动(VERR_NEM_VM_CREATE_FAILED) 043-解决 vagrant 访问 virtualbox 共享文件夹报无权限问题(Permission denied) 我的运行错误日志忘记保存了，从网上找的类似的 00:00:03.418689 VMSetError: F:\\tinderbox\\win-6.0\\src\\VBox\\VMM\\VMMR3\\NEMR3Native-win.cpp(1463) int __cdecl nemR3NativeInitAfterCPUM(struct VM *); rc=VERR_NEM_VM_CREATE_FAILED00:00:03.418732 VMSetError: Call to WHvSetupPartition failed: ERROR_SUCCESS (Last=0xc000000d/87)00:00:03.418771 NEM: Destroying partition 00000000013f29b0 with its 0 VCpus...00:00:03.548429 ERROR [COM]: aRC=E_FAIL (0x80004005) aIID=&#123;872da645-4a9b-1727-bee2-5585105b9eed&#125; aComponent=&#123;ConsoleWrap&#125; aText=&#123;Call to WHvSetupPartition failed: ERROR_SUCCESS (Last=0xc000000d/87) (VERR_NEM_VM_CREATE_FAILED)&#125;, preserve=false aResultDetail=-680500:00:03.548750 Console: Machine state changed to &apos;PoweredOff&apos;00:00:03.558813 Power up failed (vrc=VERR_NEM_VM_CREATE_FAILED, rc=E_FAIL (0X80004005))00:00:04.060139 GUI: UIMachineViewNormal::resendSizeHint: Restoring guest size-hint for screen 0 to 800x60000:00:04.060177 ERROR [COM]: aRC=E_ACCESSDENIED (0x80070005) aIID=&#123;ab4164db-c13e-4dab-842d-61ee3f0c1e87&#125; aComponent=&#123;DisplayWrap&#125; aText=&#123;The console is not powered up&#125;, preserve=false aResultDetail=000:00:04.060407 GUI: Aborting startup due to power up progress issue detected... 代码节选自 https://forums.virtualbox.org/viewtopic.php?f=6&amp;t=92260 解决办法是禁用 Hyper-V。Win+R -&gt; cmd -&gt; Ctrl+Shift+Enter -&gt; bcdedit /set hypervisorlaunchtype off -&gt; 重启电脑 -&gt; 启动 vbox 招聘小广告山东济南的小伙伴欢迎投简历啊 加入我们 , 一起搞事情。长期招聘，Java 程序员，大数据工程师，运维工程师，前端工程师。 参考资料 我的博客 我的掘金 vbox: WHvSetupPartition failed: ERROR_SUCCESS (VERR_NEM_VM_CREATE_FAILED) (Hyper-V conflict) #4587 VERR_NEM_VM_CREATE_FAILED after Activating Hyper-V features in Windows 10","tags":[{"name":"python","slug":"python","permalink":"https://anjia0532.github.io/tags/python/"},{"name":"虚拟机","slug":"虚拟机","permalink":"https://anjia0532.github.io/tags/虚拟机/"},{"name":"kvm","slug":"kvm","permalink":"https://anjia0532.github.io/tags/kvm/"},{"name":"vagrant","slug":"vagrant","permalink":"https://anjia0532.github.io/tags/vagrant/"},{"name":"virtualbox","slug":"virtualbox","permalink":"https://anjia0532.github.io/tags/virtualbox/"}]},{"title":"041-使用DM进行同步上游数据到tidb","date":"2019-08-22T19:35:21.000Z","path":"2019/08/22/tidb-dm-sync-data/","text":"这是坚持技术写作计划（含翻译）的第 41 篇，定个小目标 999，每周最少 2 篇。 回想一下之前数据同步一般会使用一些 ETL 工具，例如 DataX ,StreamSets ,Kettle,sqoop,nifi,当然也可能使用原始的 mysqldump 进行人肉苦逼同步。因为每个团队的背景不一样，没法简单的说哪种工具更好，更优，还是需要落地才行。所以本文就不过多介绍不同 ETL 工具间的优劣了，毕竟 PHP 是世界上最好的语言。 本文主要讲解，如何使用 tidb 官方的同步工具 DM 进行数据同步。先搬运一下 tidb 官方对 dm 的简介 DM (Data Migration) 是一体化的数据同步任务管理平台，支持从 MySQL 或 MariaDB 到 TiDB 的全量数据迁移和增量数据同步。使用 DM 工具有利于简化错误处理流程，降低运维成本。 略微吐槽下，tidb 的官方技术栈略有点复杂，比如，广义的 tidb，一般是指 pd,tidb,tikv 这类核心组件(参考 TiDB 整体架构)，但是，部署的话，得用 ansible 部署，监控呢，得学会看官方提供的 Prometheus+Grafana,同步数据的话，又的看 mydumper , loader,syncer, Data Migration ,TiDB Lightning , 管理 tidb 集群的话，又会用到一些工具，比如，pd control,pd recover,tikv control,tidb controller,如果要给 tidb 开启 binlog，用于同步到其他 tidb 或者 mysql 集群，又要研究 Pump,Drainer,binlogctl … 就感觉 tidb 团队，一看就是出身大户人家，看官方建议的集群配置吧。 tidb 集群最低配置要求 dm 实例配置 tidb-lighting 配置要求(超过 200G 以上的迁移，建议用 tidb-lighting) tidb binlog 的配置 所以，几乎每一个用 tidb 的人，第一件事，都是，如何修改 ansible 的参数，绕过检测 [手动滑稽]，人嘛，都是，一边吐槽 XX 周边工具太少，又会吐槽 XX 太多，学不动，像是初恋的少女，等远方的男友，怕他乱来，又怕他不来，哈哈 对比一下友商的 其实 tidb 的官方文档，写的还挺详细的，就是不太像是给入门的人看的 [手动捂脸]，本文主要是结合我在使用 DM 过程中，写一下遇到的问题，以及群内大牛的解答 简介DM 简化了单独使用 mysqldumper，loader，syncer 的工作量，从易用性，健壮性和可观测等方面来看，建议使用 DM。 注意一下官方文档写的限制条件。 部署 DM参考 使用 DM-Ansible 部署 DM 集群 如无特殊说明都按照官方文档操作。 第五步配置互信时，servers 是要部署 DM 的节点 ip，注意当前登录名，确保是 tidb(执行 woami ) vi hosts.ini[servers]172.16.10.71172.16.10.72172.16.10.73[all:vars]username = tidb 执行 ansible-playbook -i hosts.ini create_users.yml -u root -k 时，如果是使用 ssh key 的话，可以ansible-playbook -i hosts.ini create_users.yml -u root -k --private-key /path/to/your/keyfile 第 7 步配置 worker 时，需要注意，如果要增量或者全量，并且上游服务的 binlog 被删过，并且是 gtid 格式的，需要执行 show VARIABLES like &#39;gtid_purged&#39; 如果有值，则需要指定 relay_binlog_gtid ,否则会报 close sync with err: ERROR 1236 (HY000): The slave is connecting using CHANGE MASTER TO MASTER_AUTO_POSITION = 1, but the master has purged binary logs containing GTIDs that the slave requires. 此时停掉 worker 后，修改 relay_binlog_gtid 重启无效，是需要修改 meta 文件的 /tidb/deploy/dm_worker_/relay_log/f5df-11e7-a1dd.000001/relay.meta 感谢 军军另外需要配置 enable_gtid=true如果不是 gtid 格式的，则需要修改这个 relay_binlog_name （在 mysql 执行 show BINARY logs ）mysql_password 需要使用 dmctl -encrypt 你的密码 如果找不到 dmctl，确保执行了 ansible-playbook local_prepare.yml 后在 /path/to/dm-ansible/resources/bin/dmctl dm 的 worker 支持单机多实例，也支持单机单实例(推荐) ,如果因为资源问题，要开启单机多实例的话， [dm_worker_servers]dm_worker1_1 ansible_host=172.16.10.72 server_id=101 deploy_dir=/data1/dm_worker dm_worker_port=8262 mysql_host=172.16.10.81 mysql_user=root mysql_password='VjX8cEeTX+qcvZ3bPaO4h0C80pe/1aU=' mysql_port=3306dm_worker1_2 ansible_host=172.16.10.72 server_id=102 deploy_dir=/data2/dm_worker dm_worker_port=8263 mysql_host=172.16.10.82 mysql_user=root mysql_password='VjX8cEeTX+qcvZ3bPaO4h0C80pe/1aU=' mysql_port=3306dm_worker2_1 ansible_host=172.16.10.73 server_id=103 deploy_dir=/data1/dm_worker dm_worker_port=8262 mysql_host=172.16.10.83 mysql_user=root mysql_password='VjX8cEeTX+qcvZ3bPaO4h0C80pe/1aU=' mysql_port=3306dm_worker2_2 ansible_host=172.16.10.73 server_id=104 deploy_dir=/data2/dm_worker dm_worker_port=8263 mysql_host=172.16.10.84 mysql_user=root mysql_password='VjX8cEeTX+qcvZ3bPaO4h0C80pe/1aU=' mysql_port=3306 注意 server_id=101 deploy_dir=/data1/dm_worker dm_worker_port=8262 别冲突，尤其是 deploy_dir 和 dm_worker_port 第九步,如果部署 dm 的节点数太多，可以提升并发数 ansible-playbook deploy.yml -f 10第十步,启动 ansible-playbook start.yml 上述是简单操作， 如果涉及到复杂的，例如，扩容，缩容 dm 节点，重启 dm-master 或者 dm-worker，可以参考 DM 集群操作 配置 DM如何看文档配置 dm-worker 的 tasks，三段文档结合着看一般场景，使用 Data Migration 简单使用场景 即可满足。 库重命名库重命名,将上游的 user，备份成 user_north 库。另外，不支持实例内 databases 批量加前缀或者后缀。所以，有多少个需要重命名的，就乖乖写多少个吧 routes: ... instance-1-user-rule: schema-pattern: \"user\" target-schema: \"user_north\" 忽略库或者表black-white-list: log-ignored: ignore-dbs: [\"log\"] # 忽略同步log库 ignore-tables: - db-name: \"test\" # 忽略同步log库内的test表 tbl-name: \"log\" 尽量使用白名单个人建议尽量使用白名单进行同步，防止因为新增库 dm 校验不通过，导致 task 被 pause 掉。此时的假设是，同步任务是严谨的，不应该出现不可控因素。当然这只是建议。如果 上游数据库有，a,b,c 三个库，前期白名单只写了 a,b，进行全量+增量同步(all 模式),并且 task 的 unit 已经是 sync(非 dump)，如果此时要同步库，此时如果只是简单改白名单，然后 pause-task,update-task,resume-task,会报表不存在的错。具体的解决办法，可以参见 我在 tug 上提的问题 https://asktug.com/t/db/616 ，感谢 wangxj@pingCAP black-white-list: rule-1: do-dbs: [\"~^test-*\"] 同步所有test-开头的库 忽略 drop 和 truncate 操作毕竟使用 DM 是用于同步数据，在一定程度上也可以用于灾备场景使用，万一业务库被人 drop，truncate 了，tidb 这还可以救命，所以建议忽略这些危险操作，有必要的，可以人工去执行。 filters: ... store-filter-rule: schema-pattern: \"store\" events: [\"drop database\", \"truncate table\", \"drop table\"] action: Ignore 使用 DM Portal 生成配置文件，但是 Portal 生成的是不支持 gtid 的，详见 军军 的解释，详细使用，参见 DM Portal 简介 启动 DM常规操作参考 管理数据同步任务使用 ./dmctl -master-addr 172.16.30.14 进入交互式命令界面(不支持非交互式的，导致我在使用中遇到，当报错信息特别大时，超过缓冲区，会导致看不到有效的报错信息，check-task xx-task &gt;result.log 这种的不支持，希望后边能改进下 ) 启动任务 start-task /path/to/task.yaml 注意是 task 文件，而不是任务名 查询任务 query-status [task-name] task-name 是可选的，不填查所有，填了，只查指定的 暂停任务 pause-task task-name ,如果要更新 task 文件(update-task) task 一定要处于 pause 状态(报错导致的 pause 也行) 恢复同步 resume-task task-name 处于暂停(pause)的任务要恢复，需要使用 resume-task ,如果是 full 或者 all 时 unit 处于 dump 状态的(非 load)，resume-task 时会清空已经 dump 到本地的文件，重新拉取(想想 200 多 G 的数据库，到 99%了，突然 pause 了，就肝儿颤) 更新同步任务 update-task /path/to/task.yaml 注意是 task 文件，不是任务名,执行更新操作，必须是 pause 状态，所以，尽量别再 dump 时执行 update，要执行也是在前期执行。执行后，需要使用 resume-task 启动已 pause 的任务 停止任务 stop-task task-name 常见问题 check 通过，start 时报错，或者 start 也正常，query 时报错，这种错，有跟没有区别不大，只能 ssh 到 worker 节点，看日志 /path/to/deploy/log/ Couldn&#39;t acquire LOCK BINLOG FOR BACKUP, snapshots will not be consistent:Access denied; you need (at least one of) the SUPER privilege(s) for this operation 如果没有 reload 权限，会报错，但是不会终止操作，可以忽略注意，如果是阿里云的 rds 的话，默认是把 reload 权限给去掉的。 sql-mode 不一致引起的问题，mysql 默认的 sql-mode 是空字符串,参考 SQL 模式 ，排查方式 SELECT @@sql_mode ,如果是 tidb 是新库，可以 set global sql_mode=&#39;&#39;; 如果要改 mysql 的话，需要写到 my.ini 里，防止重启失效。 all 模式同步数据，如果 task 状态已经是 sync，此时这个 task 白名单新增库或者表会导致报错，表不存在，然后 task 被 pause。要么使用 full-task+incremental-task 两个文件，每次白名单新增时，先更新 full-task，再更新 incremental-task，要么直接新启一个 task，用于 full 更新白名单库，然后改 all 的 task，重启即可。 处于 dump 的任务，一旦 pause 了，再次 resume，会删除已 dump 的数据文件，重新拉取 招聘小广告山东济南的小伙伴欢迎投简历啊 加入我们 , 一起搞事情。长期招聘，Java 程序员，大数据工程师，运维工程师，前端工程师。 参考资料 我的博客 我的掘金 DataX 在有赞大数据平台的实践 Data Migration 常见问题 使用 DM-Ansible 部署 DM 集群","tags":[{"name":"mysql","slug":"mysql","permalink":"https://anjia0532.github.io/tags/mysql/"},{"name":"tidb","slug":"tidb","permalink":"https://anjia0532.github.io/tags/tidb/"},{"name":"tikv","slug":"tikv","permalink":"https://anjia0532.github.io/tags/tikv/"},{"name":"dm","slug":"dm","permalink":"https://anjia0532.github.io/tags/dm/"},{"name":"数据同步","slug":"数据同步","permalink":"https://anjia0532.github.io/tags/数据同步/"}]},{"title":"039-解决ubuntu使用preseed装机 base-installer/kernel/failed-package-install 问题","date":"2019-08-16T18:30:07.000Z","path":"2019/08/16/ubuntu-preseed-base-installer-kernel/","text":"这是坚持技术写作计划（含翻译）的第 39 篇，定个小目标 999，每周最少 2 篇。 本文主要介绍在使用 pressed 无人装机安装 ubuntu 时，偶尔出现 Unexpected error; command not executed: 'sh -c debconf-apt-progress --no-progress --logstederr -- apt-get -q -y --no-remove install busybox-initramfs'base-installer: error: exiting on error base-installer/kernel/failed-package-install 的解决方案。 之前写的几篇无人装机的文章(有基于 cobbler 和 cloudboot 的) 010-cloudboot 批量安装 rancheros 007-Cobbler 批量自动化部署 Windows10 和 Server 2019 及激活 006-Cobbler 批量自动化部署 CentOS/Ubuntu/Windows 排查过程首先，点击继续，返回上一层页面，选择 shell, cat /var/log/syslog 找到报错信息 base-installer: error: exiting on error base-installer/kernel/failed-package-install在百度和 google 搜索后，找到跟我类似的问题 XenServer 安装 ubuntu16.04 遇到的错误 但是使用作者的方式处理一遍后，没啥效果，但是阴差阳错的 get 了 ctrl+alt+f4 (参考 Reverting from Ctrl - Alt - F1 ) 能看安装日志就简单了，排查就行了，发现是安装 ubuntu security 时，国外 ip 被 ban 了，换成国内源即可。 修改 preseed d-i apt-setup/services-select multiselect securityd-i apt-setup/security_host string mirrors.aliyun.comd-i apt-setup/security_path string /ubuntu 招聘小广告山东济南的小伙伴欢迎投简历啊 加入我们 , 一起搞事情。长期招聘，Java 程序员，大数据工程师，运维工程师，前端工程师。 参考资料 我的博客 我的掘金 XenServer 安装 ubuntu16.04 遇到的错误 Reverting from Ctrl - Alt - F1 Headless Installation: Unable to install busybox-initramfs How do I configure a preseed to skip the language support question?","tags":[{"name":"pxe","slug":"pxe","permalink":"https://anjia0532.github.io/tags/pxe/"},{"name":"dhcp","slug":"dhcp","permalink":"https://anjia0532.github.io/tags/dhcp/"},{"name":"ubuntu","slug":"ubuntu","permalink":"https://anjia0532.github.io/tags/ubuntu/"},{"name":"cloudboot","slug":"cloudboot","permalink":"https://anjia0532.github.io/tags/cloudboot/"},{"name":"preseed","slug":"preseed","permalink":"https://anjia0532.github.io/tags/preseed/"}]},{"title":"040-解决Linux使用virtualbox共享文件夹问题","date":"2019-08-16T10:01:57.000Z","path":"2019/08/16/linux-virtualbox-shared-folder/","text":"date: 2019-08-16 19:05:03tags: [虚拟机,kvm,vagrant,virtualbox,python]categories: python 这是坚持技术写作计划（含翻译）的第 40 篇，定个小目标 999，每周最少 2 篇。 本文主要介绍，在使用 virtualbox 时，如何共享文件夹 rsync 是单向(宿主机修改了，定时同步到虚拟机里，但是虚拟机修改的不会对宿主造成影响) nfs 官方文档说 Windows users: NFS folders do not work on Windows hosts. Vagrant will ignore your request for NFS synced folders on Windows. 而且需要下载插件，新手十有八九会被坑 smb 兼容性比较好，支持 mac,linux,windows 访问(虚拟机),宿主机只限 mac 和 win，但是 win 需要管理员权限，mac 下操作挺复杂，还得进行配置，防止自动超时 VirtualBox 综合来看，virtualbox 不错，当然，如果文件量太多的话，也有性能问题,意思是别想着用来构建前端项目(一个 node_modules 搞死你啊)，可以结合 rsync 使用，rsync 可以设置排除目录，然后定时同步到虚拟机，需要双向的，再把文件复制到挂载为 virtualbox 的目录下，宿主机就可以访问了。 python+vagrant+virtualbox 系列文章 036-win10 搭建 python 的 linux 开发环境(pycharm+vagrant+virtualbox) 037-vagrant 启动(up)后自动同步文件(rsync-auto) 040-解决 Linux 使用 virtualbox 共享文件夹问题 042-解决 win10 VirtualBox 无法启动(VERR_NEM_VM_CREATE_FAILED) 043-解决 vagrant 访问 virtualbox 共享文件夹报无权限问题(Permission denied) # -*- mode: ruby -*-# vi: set ft=ruby :Vagrant.configure(\"2\") do |config| # The most common configuration options are documented and commented below. # For a complete reference, please see the online documentation at # https://docs.vagrantup.com. # Every Vagrant development environment requires a box. You can search for # boxes at https://vagrantcloud.com/search. config.vm.box_check_update = false config.vm.box = \"centos/7\" config.vm.hostname = \"ansible\" config.vm.network \"private_network\", ip: \"172.17.8.102\" config.vm.provider \"virtualbox\" do |vb| vb.memory = \"4096\" vb.cpus = 2 vb.name = config.vm.hostname end ## 单向同步 config.vm.synced_folder \".\", \"/vagrant\", type: \"rsync\", rsync__verbose: true, rsync__auto: true, rsync__exclude: ['.git*', 'node_modules*','*.log','*.box','Vagrantfile'] config.trigger.after :up do |t| t.info = \"rsync auto\" t.run = &#123;inline: \"vagrant rsync-auto\"&#125; end config.vm.provision \"shell\", inline: &lt;&lt;-SHELL## 配置xshell等可以使用密码登录sed -e \"s/#PasswordAuthentication yes/PasswordAuthentication yes/g\" -e \"s/PasswordAuthentication no/PasswordAuthentication yes/g\" -i /etc/ssh/sshd_configservice sshd restart## 设置yum的清华源（阿里云源不稳定）sudo sed -e \"/mirrorlist/d\" -e \"s/#baseurl/baseurl/g\" -e \"s/mirror\\.centos\\.org/mirrors\\.tuna\\.tsinghua\\.edu\\.cn/g\" -i /etc/yum.repos.d/CentOS-Base.reposudo yum makecachesudo yum install -y epel-release## 安装virtualbox需要kernel-headersyum install -y gcc make kernel-headers-$(uname -r) kernel-devel-$( uname -r)## 可以使用rsync同步目录，不用每次都联网下载curl -O http://download.virtualbox.org/virtualbox/6.0.10/VBoxGuestAdditions_6.0.10.isosudo mkdir /media/VBoxGuestAdditionssudo mount -o loop,ro VBoxGuestAdditions_6.0.10.iso /media/VBoxGuestAdditionssudo sh /media/VBoxGuestAdditions/VBoxLinuxAdditions.runrm VBoxGuestAdditions_6.0.10.isosudo umount /media/VBoxGuestAdditionssudo rmdir /media/VBoxGuestAdditions SHELLend 控制台输出如下所示，即为挂载成功。 招聘小广告山东济南的小伙伴欢迎投简历啊 加入我们 , 一起搞事情。长期招聘，Java 程序员，大数据工程师，运维工程师，前端工程师。 参考资料 我的博客 我的掘金 larsar/shared_folder_centos_virtualbox.txt Synced Folders How to sync folder with Vagrant in Windows? Automatically download and install VirtualBox guest additions in Vagrant","tags":[]},{"title":"038-拯救大兵瑞恩之Tidb如何在Tikv损坏的情况下恢复","date":"2019-08-01T22:35:41.000Z","path":"2019/08/01/tidb-tikv-bad-regions/","text":"这是坚持技术写作计划（含翻译）的第 38 篇，定个小目标 999，每周最少 2 篇。 很喜欢 TiDB 的设计哲学，比如，数据库就活该要么 OLAP，要么 OLTP 么，为嘛就不能兼顾一下？数据量大了后，就一定要反人类的分库分表么？你当分库分表好玩么？分库一时爽，维护火葬场！ 尤其在一些中小型团队里，为了数据分析搞一套 hadoop，约等于为了喝牛奶，从牛崽开始养一头奶牛。一路上明坑暗坑不断。 考虑到学习成本，迁移成本(高度兼容 MySQL-但不是 100%)，运维成本(支持 Ansible-团队有 ansible 运维经验)，使用成本(相比 hadoop)，硬件成本(相比 hadoop)，收益(不用分开分表，支持 olap 和 oltp，支持分布式事务,支持 TiSpark,支持 tikv，自带同步工具)等。 好了，疑似广告的一段话说完了，回归正题，介绍是如何悲催的遇上整栋大厦停电，并且恰好 tikv 文件损坏，以及如何在 Tidb 各位大佬的远程文字指导下，一步步把心态从删库跑路，转变成说不定还有救，以及，我擦，真救回来的坎坷心路旅程。 因为 Tidb 之前是别的同事负责，刚接过来不久，对 Tidb 整个的掌握还很初级。真·面向故障学习！ 全文主要是对本次事故的回溯，琐碎细节较多，介意的可以直接看最后。 集群环境 name ip service tikv-1 192.168.1.200 tikv tikv-2 192.168.1.201 tikv tikv-3 192.168.1.202 tikv(有坏 region) pd 192.168.1.203 pd tidb 192.168.1.204 tidb,monitoring sn-data-node-1 192.168.1.216 tidb sn-data-node-2 192.168.1.217 tidb tikv-4 192.168.1.218 tikv(有坏 region) 悲催之始上午 coding 正嗨，突发性停电来电后 ssh 到 tidb 的 ansible 主控机 ansible-playbook start.yml 事情有点不妙，但是扔不死心的， stop and start 一通后，仍是这个结果。事情有点大条。 好在之前偷偷潜伏到 TiDB 的官方群里，没事就听各位大佬吹水打屁，多少受了点熏陶。撸起袖子，开搞。 定位问题Round 1 懵逼树上懵逼果先看官方文档好吧，跟没看区别不大。 既然是 tidb 起不来，就先看 tidb 的日志(实际上应该看 http://prometheus:9090/targets ，因为不太熟悉，所以走了弯路，为嘛不看 grafana,是因为 tidb 那卡到后，ansible 就自动退出了，没有起 grafana)暴露的是连接两个 tikv 报错，这是前期比较关键的线索，起码有初步排查方向了。另外从日志看到，疑似报空间不足，实际上没意义，在两台 tikv 执行 df -i df -h 来看，都很充足。 群内 @张曾钧@PingCAP 大佬开始介入，并且开始了将近 8 个小时的细心和耐心的指导，讲真，PingCAP 团队是我见过最热心耐心的团队，素未蒙面，但乐于助人[呲牙] 此时，通过看官方文档，尝试性，试了下 Prometheus 可以打开，能看出有两个 TiKV down 掉，正好是上面两个。PS ,我是事后才发现的，当时我一直认为 TiKV 是起来的[捂脸]插播一下，TiDB 整体架构 ，不多解释。建议看看，可以了解一下 TiDB 的架构原理，比如，TiDB,TiKV,PD 等的职责。 小结： Round 1 以找出两个 TiKV down 结束，效率低到羞愧。 Round 2 懵逼树前排排坐注意，下面如无特殊说明，一律是 TiKV 关掉状态下，执行命令。使用@唐刘@PingCAP 的方法 grep -B 50 Welcome ,开始接触事发原因了。 更多的 grep 的方法(-A -B -C)，参考 man grep 或者 GREP(1) ，因为 tikv 启动会打印 Welcome，所以有理由认为，每次的 Welcome 之前的，肯定是上次退出的原因。 至此，出现了第一个坏掉的 region。当时执行了 ./pd-ctl store -d -u http://127.0.0.1:2379找到挂掉的两个 TiKV 的 store id，跟上图的 68935 能对起来。 此时救苦救难的 大佬 提供了 TiKV Control 使用说明#恢复损坏的-mvcc-数据实际上执行后，没啥效果，后来发现是因为此 region 超过一半副本出问题了，recover-mvcc 没法恢复。 Round 2 结束，找到了救命稻草，TiKV Control 和 PD Control,但是，事情远没这么简单。 Round 3 渐入佳境中间出了个差点搞死自己的小插曲/home/tidb/tidb-ansible/resources/bin/pd-ctl -u &quot;http://172.16.10.1:2379&quot; -d store delete 10 自作聪明的以为，TiKV 已经没救了，执行了 store delete 操作。但是实际上还有救，所以又变成了，如何把已经 delete 掉的 store，再度挂上去。根据 大佬的 curl -X POST http://${pd_ip}:2379/pd/api/v1/store/${store_id}/state?state=Up 成功挂上，当然还是 down 的状态。 根据tikv-ctl --db /path/to/tikv/db bad-regions 两台坏的，分别如下发现坏掉的 region 是 31101（实际上因为用的是 2.1.4，每次只显示一个，处理完后，才会显示下一个，效率很低，后来在 @戚铮 大佬的指导下，换用 tikv-ctl 3.x ，每次可以显示全部的坏的 region ）在好的节点上执行，也不是文中的 all regions are healthy ，实际上是因为，数据文件被占用，没法获取句柄，停掉就行 ansible-playbook stop.yml -l tikv_servers 停掉全部 tikv 节点 此时@张曾钧@PingCAP 提示用 tikv-ctl --db /path/to/tikv/db tombstone -p 127.0.0.1:2379 -r 把坏的 region 设置为 tombstone ，但是报错 通过执行 pd-ctl region 31101 发现这个 region 有两个副本是在坏节点上，超过一半损坏（剧透一下，实际上最后发现，出问题的都是损坏超过 1 半的，1/3 的都自己恢复了） 尝试执行 operator add remove-peer 发现删不掉。 此时 戚铮 大佬出场。经过一番测试，发现 region31101 很坚挺，使用 recover-mvcc 恢复不了，前面说了是因为损失超过一半副本的原因，使用 operator add remove-peer 删不了，估计也是。 Round 4 貌似解决不能因为一颗老鼠屎，坏了一锅汤，部分 region 坏掉了，先尝试强制恢复试试，保证别的正常吧。注意此命令是在好的 store 上执行此时启动 TiKV 集群，执行 region 31101，坏掉的已经删掉了，但是服务还是起不来。此时执行 此时在 @戚铮 老大的指导下，升级 tikv-ctl ,结果 202 这台，一共三个 region 坏了，处理了俩，感觉遥遥无期，下了 tikv-ctl 3.x 后发现，就还有一个坏的。胜利在望。 重复上述操作后，此节点终于 up 了 218 这个有 6 个坏的unsafe-recover remove-fail-stores 一通后，终于起来服务了。 Round 4 服务已可以启动，总结一下 先 stop tikv 如果坏的 region 少于一半，可以尝试 recover-mvcc 如果超过一半，就玄乎了，是在不行就 unsafe-recover remove-fail-stores,然后再 tikv-ctl –db /path/to/tikv/db tombstone -p 127.0.0.1:2379 -r 31101,xx,xx,xx 再 start tikv Round 5 最终局你以为万事大吉了？命运就是爱捉弄人。 回到原点。 最后还是损失了部分，但是量不大。 总结 对 TiDB 不够熟悉，很多流于表面 对 TiDB 的文档和工具使用不熟练 TiDB 的文档不太清晰，比如在故障处理里，没有内链像是 pd-ctl,tikv-ctl，甚至都没有提，在 pd-ctl 和 tikv-ctl 等工具没有提如何下载，在工具下载里，没有提包含啥工具。很佛系 多亏了群内各位大佬的热心指导 如果是 tikv 有问题，先 stop tikv 如果对于损坏数小于半数的，可以尝试 recover-mvcc 对于超过半数的，可以尝试 unsafe-recover remove-fail-stores ，再 将 store 设置 tombstone 再 start tikv 可以结合 tidb 损坏 tikv 节点怎么恢复集群 来做。 多试验，尤其是做极限测试，并且尝试处理，会积累很多经验。 虽然没有瑞恩没有全须全尾的拯救回来，但是缺胳膊少腿总好过没命啊。 一点小广告其实如果不考虑 OLTP 的场景，还可以尝试使用 clickhouse。这是之前整理的 clickhouse 的一些文章。 031-数据可视化之 redash(支持 43 种数据源) 033-史上最全-mysql 迁移到 clickhouse 的 5 种办法 035-解决 streamsets jdbc 全量模式数据重复问题 参考资料 我的博客 我的掘金 failed to write to engine #10596 使用 TiDB-Ansible 扩容缩容 TiDB 集群 TiDB 集群故障诊断 PD Control 使用说明 TiKV Control 使用说明 TiDB 工具下载 tidb 损坏 tikv 节点怎么恢复集群 Tidb 用户案例","tags":[{"name":"mysql","slug":"mysql","permalink":"https://anjia0532.github.io/tags/mysql/"},{"name":"数据库","slug":"数据库","permalink":"https://anjia0532.github.io/tags/数据库/"},{"name":"tidb","slug":"tidb","permalink":"https://anjia0532.github.io/tags/tidb/"},{"name":"tikv","slug":"tikv","permalink":"https://anjia0532.github.io/tags/tikv/"},{"name":"database","slug":"database","permalink":"https://anjia0532.github.io/tags/database/"},{"name":"dba","slug":"dba","permalink":"https://anjia0532.github.io/tags/dba/"}]},{"title":"博客模板","date":"2019-08-01T01:44:45.000Z","path":"2019/08/01/blog-template/","text":"date: 2010-08-01 19:35:21 tags: []categories: [] 这是坚持技术写作计划（含翻译）的第 50 篇，定个小目标 999，每周最少 2 篇。 本文 招聘小广告山东济南的小伙伴欢迎投简历啊 加入我们 , 一起搞事情。长期招聘，Java 程序员，大数据工程师，运维工程师，前端工程师。 参考资料 我的博客 我的掘金","tags":[]},{"title":"037-vagrant启动(up)后自动同步文件(rsync-auto)","date":"2019-07-29T00:37:45.000Z","path":"2019/07/29/vagrant-startup-run-rsync/","text":"date: 2019-08-14 12:30:00tags: [虚拟机,kvm,vagrant,virtualbox,python]categories: python 这是坚持技术写作计划（含翻译）的第 37 篇，定个小目标 999，每周最少 2 篇。 本文介绍两种 vagrant up 后自动同步文件(rsync) 分别基于 sync 和 nfs (如果不设置的话，需要再起一个终端，单独运行 vagrant rsync-auto ) python+vagrant+virtualbox 系列文章 036-win10 搭建 python 的 linux 开发环境(pycharm+vagrant+virtualbox) 037-vagrant 启动(up)后自动同步文件(rsync-auto) 040-解决 Linux 使用 virtualbox 共享文件夹问题 042-解决 win10 VirtualBox 无法启动(VERR_NEM_VM_CREATE_FAILED) 043-解决 vagrant 访问 virtualbox 共享文件夹报无权限问题(Permission denied) syncconfig.vm.synced_folder \".\", \"/vagrant\", type: \"rsync\", # rsync__verbose: true, # rsync__auto: true, rsync__exclude: ['.git*', 'node_modules*','*.log','*.box','Vagrantfile']config.trigger.after :up do |t| t.info = \"rsync auto\" t.run = &#123;inline: \"vagrant rsync-auto\"&#125; # 如果想后台运行，则使用下面语句 # t.run = &#123;inline: \"bash -c 'vagrant rsync-auto &amp;'\"&#125;end 参考 Vagrant Does not Start RSync-Auto on Up or Reload#briancain’s reply nfs经测试，在 win10 上，需要安装插件（vagrant-vbguest vagrant-winnfsd） vagrant plugin install vagrant-vbguest vagrant-winnfsd 如果报 Installing the 'vagrant-vbguest' plugin. This can take a few minutes...ERROR: SSL verification error at depth 3: unable to get local issuer certificate (20)ERROR: You must add /C=US/O=Starfield Technologies, Inc./OU=Starfield Class 2 Certification Authority to your local trusted storeVagrant failed to load a configured plugin source. This can be causedby a variety of issues including: transient connectivity issues, proxyfiltering rejecting access to a configured plugin source, or a configuredplugin source not responding correctly. Please review the error messagebelow to help resolve the issue: SSL_connect returned=1 errno=0 state=error: certificate verify failed (https://gems.hashicorp.com/specs.4.8.gz)Source: https://gems.hashicorp.com/ 需要设置 CAfile set SSL_CERT_FILE=\"path\\to\\Vagrant\\embedded\\cacert.pem\" 如果下载速度慢，并且有境外代理服务器，可以考虑设置代理 set http_proxy=http://username:password@ip:portset https_proxy=http://username:password@ip:port 设置 Vagrantfile # ... 忽略无关内容config.vm.synced_folder \".\", \"/vagrant\", type:\"nfs\"# ... 忽略无关内容 参考资料 我的博客 我的掘金 Vagrant Does not Start RSync-Auto on Up or Reload#briancain’s reply How to speed up Vagrant on Windows 10 using NFS","tags":[]},{"title":"036-win10搭建python的linux开发环境(pycharm+vagrant+virtualbox)","date":"2019-07-24T19:35:21.000Z","path":"2019/07/24/jumpserver-vagrant-virtualbox/","text":"这是坚持技术写作计划（含翻译）的第 36 篇，定个小目标 999，每周最少 2 篇。 本文以 jumpserver 为例，介绍如何在 windows 环境下进行 jumpserver 开发(jumpserver 依赖的一些库，只有 linux 环境才能用)，其实不局限于 jumpserver，其他项目也适用(不限于 python)。参考 打造跨平台一致性开发环境 python+vagrant+virtualbox 系列文章 036-win10 搭建 python 的 linux 开发环境(pycharm+vagrant+virtualbox) 037-vagrant 启动(up)后自动同步文件(rsync-auto) 040-解决 Linux 使用 virtualbox 共享文件夹问题 042-解决 win10 VirtualBox 无法启动(VERR_NEM_VM_CREATE_FAILED) 043-解决 vagrant 访问 virtualbox 共享文件夹报无权限问题(Permission denied) 初始化环境安装 vagrant+virtualbox参考 Vagrant 系列(一)—-win10 搭建 Vagrant+VirtualBox 环境 下载 centos 镜像可以使用境外服务器或者迅雷下载 https://cloud.centos.org/centos/7/vagrant/x86_64/images/CentOS-7-x86_64-Vagrant-1905_01.VirtualBox.box vagrant box add centos/7 \\ https://cloud.centos.org/centos/7/vagrant/x86_64/images/CentOS-7-x86_64-Vagrant-1905_01.VirtualBox.box## 或者vagrant box add centos/7 /path/to/CentOS-7-x86_64-Vagrant-1905_01.VirtualBox.box 下载 jumpserver 源代码并创建 vagrant如果下载速度慢，可以使用码云(gitee.com)自己创建个镜像项目，clone 码云上的 jumpserver git clone --depth=1 https://github.com/jumpserver/jumpserver.gitcd jumpserver 在 jumpserver 下创建 Vagrantfile # -*- mode: ruby -*-# vi: set ft=ruby :Vagrant.configure(\"2\") do |config| # Every Vagrant development environment requires a box. You can search for # boxes at https://vagrantcloud.com/search. config.vm.box_check_update = false config.vm.box = \"centos/7\" config.vm.hostname = \"jumpserver\" config.vm.network \"private_network\", ip: \"172.17.8.101\" config.vm.provider \"virtualbox\" do |vb| vb.memory = \"4096\" vb.cpus = 2 vb.name = \"jumpserver\" end config.vm.synced_folder \".\", \"/vagrant\", type: \"rsync\", rsync__verbose: true, rsync__exclude: ['.git*', 'node_modules*','*.log','*.box','Vagrantfile'] config.vm.provision \"shell\", inline: &lt;&lt;-SHELLsudo sed -e \"/mirrorlist/d\" -e \"s/#baseurl/baseurl/g\" -e \"s/mirror\\.centos\\.org/mirrors\\.tuna\\.tsinghua\\.edu\\.cn/g\" -i /etc/yum.repos.d/CentOS-Base.reposudo yum makecachesudo yum install -y epel-releasesudo yum install -y python36 python36-devel python36-pip \\ libtiff-devel libjpeg-devel libzip-devel freetype-devel \\ lcms2-devel libwebp-devel tcl-devel tk-devel sshpass \\ openldap-devel mariadb-devel mysql-devel libffi-devel \\ openssh-clients telnet openldap-clients gccmkdir /home/vagrant/.pipcat &lt;&lt; EOF | sudo tee -a /home/vagrant/.pip/pip.conf[global]timeout = 6000index-url = https://mirrors.aliyun.com/pypi/simple/[install]use-mirrors = truemirrors = https://mirrors.aliyun.com/pypi/simple/trusted-host=mirrors.aliyun.comEOFpython3.6 -m venv /home/vagrant/venvsource /home/vagrant/venv/bin/activateecho \"source /home/vagrant/venv/bin/activate\" &gt;&gt; /home/vagrant/.bash_profile SHELLend cd jumpservervagrant upvagrant ssh 安装 python3.6 及配置 pip 源如果使用我的 Vargrantfile，已经自动配置阿里云源和清华源并且安装必要依赖包了，不需要重复配置 ## 设置yum的清华源sudo sed -e \"/mirrorlist/d\" -e \"s/#baseurl/baseurl/g\" -e \"s/mirror\\.centos\\.org/mirrors\\.tuna\\.tsinghua\\.edu\\.cn/g\" -i /etc/yum.repos.d/CentOS-Base.reposudo yum makecachesudo yum install -y epel-release## 安装依赖包sudo yum install -y python36 python36-devel python36-pip \\ libtiff-devel libjpeg-devel libzip-devel freetype-devel \\ lcms2-devel libwebp-devel tcl-devel tk-devel sshpass \\ openldap-devel mariadb-devel mysql-devel libffi-devel \\ openssh-clients telnet openldap-clients gcc## 配置pip阿里云源mkdir ~/.pipcat &lt;&lt; EOF | sudo tee -a ~/.pip/pip.conf[global]timeout = 6000index-url = https://mirrors.aliyun.com/pypi/simple/[install]use-mirrors = truemirrors = https://mirrors.aliyun.com/pypi/simple/trusted-host=mirrors.aliyun.comEOF 安装依赖如果使用我的 Vargrantfile，不需要配置 python env 了，已经配置好了 vagrant sshpython3.6 -m venv /home/vagrant/venvsource /home/vagrant/venv/bin/activate 只需要执行这个即可 pip3 install -r /vagrant/requirements/requirements.txt 参考 安装文档 配置 pycharm 并启动 jumpserver配置 pycharmCtrl+Alt+S打开设置 如果正常，会显示已经安装的 pip 包，如果是空，或者只有两个，那意味着 python 的 env 设置的不对。 使用 PyCharm 专业版和 vagrant 进行同步开发 修改配置并初始化数据库cd jumpservercp config_example.yml config.yml## 修改config.yml的相关配置vagrant sshsource /home/vagrant/venv/bin/activatecd /vagrant/./utils/make_migrations.sh 启动项目浏览器打开 http://172.17.8.101:8080/auth/login/?next=/ 其他已经提交 PR，如果有需要的朋友， 可以在 PR 上投票，可以提高通过率added Vagrantfile to support windows dev#3036 （目前已合并到 jumpserver repo 中） jumpserver virtualbox 已上传百度云盘链接：https://pan.baidu.com/s/1mr6xM7UVkPJy3TPTyoM_NQ 密码：rci6 2019-08-28 更新如果遇到 ansible 无法执行的问题是因为上述方案只起了 django 的 server，没有启动 celery cd /path/to/host/jumpserver/vagrant ssh# 分别启动 celery和beat/vagrant/jms start celery/vagrant/jms start beat 至于为啥不直接 jms start all 而是使用 pycharm 启动 server，因为可以 debug jumpserver 。而用 jms start all 则不可以 参考资料 我的博客 我的掘金 Win10 10 月更新 VirtualBox VT-x is not available (VERR_VMX_NO_VMX). 解决 Vagrant 系列(一)—-win10 搭建 Vagrant+VirtualBox 环境 安装文档 使用 PyCharm 专业版和 vagrant 进行同步开发 打造跨平台一致性开发环境","tags":[{"name":"虚拟机","slug":"虚拟机","permalink":"https://anjia0532.github.io/tags/虚拟机/"},{"name":"kvm","slug":"kvm","permalink":"https://anjia0532.github.io/tags/kvm/"},{"name":"vagrant","slug":"vagrant","permalink":"https://anjia0532.github.io/tags/vagrant/"},{"name":"virtualbox","slug":"virtualbox","permalink":"https://anjia0532.github.io/tags/virtualbox/"},{"name":"jumpserver","slug":"jumpserver","permalink":"https://anjia0532.github.io/tags/jumpserver/"},{"name":"堡垒机","slug":"堡垒机","permalink":"https://anjia0532.github.io/tags/堡垒机/"}]},{"title":"035-解决streamsets jdbc全量模式数据重复问题","date":"2019-07-22T21:00:00.000Z","path":"2019/07/22/sdc-jdbc-full-mode/","text":"这是坚持技术写作计划（含翻译）的第 35 篇，定个小目标 999，每周最少 2 篇。 本文主要解决在使用 streamsets 的 JDBC Query Consumer Origin 组件消费时，使用全量模式(Full Mode)，数据重复问题。 在之前一篇《033-史上最全-mysql 迁移到 clickhouse 的 5 种办法》中，有介绍如何使用 JDBC Query Consumer 全量导出，但是有人反馈因为 streamsets 的管道(pipeline)一直在重复运行，导致最后数据是重复的。 实际上在官方文档有讲 Full and Incremental Mode 主要看提示(Tip)部分，如果只想执行一次查询后就停止 pipeline，应该配置 origin 的 generate events 并且使用 Pipeline Finisher 来自动停止 pipeline，更多信息参见 Event Generation. 在 jdbc origin 勾选 Produce Events 从组件选则 Pipeline Finisher，并且配置 Preconditions 为 ${record:eventType() == &#39;no-more-data&#39;} 即可 参考资料 我的博客 我的掘金 Full and Incremental Mode Event Generation Case Study: Stop the Pipeline","tags":[{"name":"数据分析","slug":"数据分析","permalink":"https://anjia0532.github.io/tags/数据分析/"},{"name":"数据处理","slug":"数据处理","permalink":"https://anjia0532.github.io/tags/数据处理/"},{"name":"streamsets","slug":"streamsets","permalink":"https://anjia0532.github.io/tags/streamsets/"},{"name":"sdc","slug":"sdc","permalink":"https://anjia0532.github.io/tags/sdc/"},{"name":"mysql","slug":"mysql","permalink":"https://anjia0532.github.io/tags/mysql/"},{"name":"binlog","slug":"binlog","permalink":"https://anjia0532.github.io/tags/binlog/"},{"name":"etl","slug":"etl","permalink":"https://anjia0532.github.io/tags/etl/"}]},{"title":"034-解决streamsets订阅过期binlog导致无法启动问题","date":"2019-07-22T20:00:52.000Z","path":"2019/07/22/fixed-sdc-mysql-binlog-master-purged/","text":"这是坚持技术写作计划（含翻译）的第 34 篇，定个小目标 999，每周最少 2 篇。 streamsets 停机时间过长，mysql master 设置了自动清除 binlog，服务启动时报 ERROR MysqlSource - BinaryLogClient server error: The slave is connecting using CHANGE MASTER TO MASTER_AUTO_POSITION = 1, but the master has purged binary logs containing GTIDs that the slave requires. 2019-07-20 11:14:19,713 [user:*admin] [pipeline:demo/demo-e2cf-4f6d-b2dc-ce7fc5aeb041] [runner:] [thread:ProductionPipelineRunnable-demo-e2cf-4f6d-b2dc-ce7fc5aeb041-demo] ERROR MysqlSource - BinaryLogClient server error: The slave is connecting using CHANGE MASTER TO MASTER_AUTO_POSITION = 1, but the master has purged binary logs containing GTIDs that the slave requires.com.github.shyiko.mysql.binlog.network.ServerException: The slave is connecting using CHANGE MASTER TO MASTER_AUTO_POSITION = 1, but the master has purged binary logs containing GTIDs that the slave requires. at com.github.shyiko.mysql.binlog.BinaryLogClient.listenForEventPackets(BinaryLogClient.java:882) at com.github.shyiko.mysql.binlog.BinaryLogClient.connect(BinaryLogClient.java:559) at com.github.shyiko.mysql.binlog.BinaryLogClient$7.run(BinaryLogClient.java:793) at java.lang.Thread.run(Thread.java:748)2019-07-20 11:14:19,717 [user:*admin] [pipeline:demo/demo-e2cf-4f6d-b2dc-ce7fc5aeb041] [runner:] [thread:ProductionPipelineRunnable-demo-e2cf-4f6d-b2dc-ce7fc5aeb041-demo] ERROR ProductionPipelineRunner - Pipeline execution failedcom.streamsets.pipeline.api.StageException: MYSQL_006 - MySql server error: The slave is connecting using CHANGE MASTER TO MASTER_AUTO_POSITION = 1, but the master has purged binary logs containing GTIDs that the slave requires. at com.streamsets.pipeline.stage.origin.mysql.MysqlSource.handleErrors(MysqlSource.java:389) at com.streamsets.pipeline.stage.origin.mysql.MysqlSource.produce(MysqlSource.java:225) at com.streamsets.datacollector.runner.StageRuntime.lambda$execute$2(StageRuntime.java:295) at com.streamsets.pipeline.api.impl.CreateByRef.call(CreateByRef.java:40) at com.streamsets.datacollector.runner.StageRuntime.execute(StageRuntime.java:243) at com.streamsets.datacollector.runner.StageRuntime.execute(StageRuntime.java:310) at com.streamsets.datacollector.runner.StagePipe.process(StagePipe.java:219) at com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.processPipe(ProductionPipelineRunner.java:817) at com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.runPollSource(ProductionPipelineRunner.java:561) at com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunner.run(ProductionPipelineRunner.java:385) at com.streamsets.datacollector.runner.Pipeline.run(Pipeline.java:529) at com.streamsets.datacollector.execution.runner.common.ProductionPipeline.run(ProductionPipeline.java:110) at com.streamsets.datacollector.execution.runner.common.ProductionPipelineRunnable.run(ProductionPipelineRunnable.java:75) at com.streamsets.datacollector.execution.runner.standalone.StandaloneRunner.start(StandaloneRunner.java:701) at com.streamsets.datacollector.execution.runner.common.AsyncRunner.lambda$start$3(AsyncRunner.java:151) at com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.lambda$call$0(SafeScheduledExecutorService.java:226) at com.streamsets.datacollector.security.GroupsInScope.execute(GroupsInScope.java:33) at com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.call(SafeScheduledExecutorService.java:222) at com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.lambda$call$0(SafeScheduledExecutorService.java:226) at com.streamsets.datacollector.security.GroupsInScope.execute(GroupsInScope.java:33) at com.streamsets.pipeline.lib.executor.SafeScheduledExecutorService$SafeCallable.call(SafeScheduledExecutorService.java:222) at java.util.concurrent.FutureTask.run(FutureTask.java:266) at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180) at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293) at com.streamsets.datacollector.metrics.MetricSafeScheduledExecutorService$MetricsTask.run(MetricSafeScheduledExecutorService.java:100) at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149) at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) at java.lang.Thread.run(Thread.java:748)Caused by: com.github.shyiko.mysql.binlog.network.ServerException: The slave is connecting using CHANGE MASTER TO MASTER_AUTO_POSITION = 1, but the master has purged binary logs containing GTIDs that the slave requires. at com.github.shyiko.mysql.binlog.BinaryLogClient.listenForEventPackets(BinaryLogClient.java:882) at com.github.shyiko.mysql.binlog.BinaryLogClient.connect(BinaryLogClient.java:559) at com.github.shyiko.mysql.binlog.BinaryLogClient$7.run(BinaryLogClient.java:793) ... 1 more 尝试了手动设置偏移量无果。(参考资料 MySQL Binary Log#Initial Offset ）通过查看运行日志，发现后台还有在运行之前的 offset，突然想起在官方文档. Note: If you change the GTID mode on the database server after you have run a pipeline with the MySQL Binary Log origin, you must reset the origin and change the format of the initial offset value. Otherwise, the origin cannot correctly read the offset.When the pipeline stops, the MySQL Binary Log origin notes the offset where it stops reading. When the pipeline starts again, the origin continues processing from the last saved offset. You can reset the origin to process all requested objects. 以及解决办法就简单了，直接在启动时，Reset Origin 即可。会从 server 的当前 binlog 进行订阅。 总结:多看官方文档，仔细看，另外，尽量别用翻译工具，否则类似该案例中的 origin 会被翻译成原点，起源等，会无法联想到 sdc 的一些概念用词。 参考资料 我的博客 我的掘金 sdc 官方文档&gt;MySQL Binary Log MySQL · 答疑解惑 · GTID 不一致分析 Mysql binlog 查看方法 Mysql 之 binlog 日志说明及利用 binlog 日志恢复数据操作记录 MySQL 的 binlog 日志","tags":[{"name":"数据分析","slug":"数据分析","permalink":"https://anjia0532.github.io/tags/数据分析/"},{"name":"数据处理","slug":"数据处理","permalink":"https://anjia0532.github.io/tags/数据处理/"},{"name":"streamsets","slug":"streamsets","permalink":"https://anjia0532.github.io/tags/streamsets/"},{"name":"sdc","slug":"sdc","permalink":"https://anjia0532.github.io/tags/sdc/"},{"name":"mysql","slug":"mysql","permalink":"https://anjia0532.github.io/tags/mysql/"},{"name":"binlog","slug":"binlog","permalink":"https://anjia0532.github.io/tags/binlog/"},{"name":"etl","slug":"etl","permalink":"https://anjia0532.github.io/tags/etl/"}]},{"title":"033-史上最全-mysql迁移到clickhouse的5种办法","date":"2019-07-17T22:15:38.000Z","path":"2019/07/17/mysql-to-clickhouse/","text":"这是坚持技术写作计划（含翻译）的第 33 篇，定个小目标 999，每周最少 2 篇。 数据迁移需要从 mysql 导入 clickhouse, 总结方案如下，包括 clickhouse 自身支持的三种方式，第三方工具两种。 create table engin mysqlCREATE TABLE [IF NOT EXISTS] [db.]table_name [ON CLUSTER cluster]( name1 [type1] [DEFAULT|MATERIALIZED|ALIAS expr1] [TTL expr1], name2 [type2] [DEFAULT|MATERIALIZED|ALIAS expr2] [TTL expr2], ... INDEX index_name1 expr1 TYPE type1(...) GRANULARITY value1, INDEX index_name2 expr2 TYPE type2(...) GRANULARITY value2) ENGINE = MySQL('host:port', 'database', 'table', 'user', 'password'[, replace_query, 'on_duplicate_clause']); 官方文档: https://clickhouse.yandex/docs/en/operations/table_engines/mysql/ 注意，实际数据存储在远端 mysql 数据库中，可以理解成外表。可以通过在 mysql 增删数据进行验证。 insert into select from-- 先建表CREATE TABLE [IF NOT EXISTS] [db.]table_name [ON CLUSTER cluster]( name1 [type1] [DEFAULT|MATERIALIZED|ALIAS expr1], name2 [type2] [DEFAULT|MATERIALIZED|ALIAS expr2], ...) ENGINE = engine-- 导入数据INSERT INTO [db.]table [(c1, c2, c3)] select 列或者* from mysql('host:port', 'db', 'table_name', 'user', 'password') 可以自定义列类型，列数，使用 clickhouse 函数对数据进行处理，比如 select toDate(xx) from mysql(&quot;host:port&quot;,&quot;db&quot;,&quot;table_name&quot;,&quot;user_name&quot;,&quot;password&quot;) create table as select fromCREATE TABLE [IF NOT EXISTS] [db.]table_nameENGINE =LogASSELECT *FROM mysql('host:port', 'db', 'article_clientuser_sum', 'user', 'password') 网友文章: http://jackpgao.github.io/2018/02/04/ClickHouse-Use-MySQL-Data/ 不支持自定义列，参考资料里的博主写的 ENGIN=MergeTree 测试失败。可以理解成 create table 和 insert into select 的组合 Altinity/clickhouse-mysql-data-readerAltinity 公司开源的一个 python 工具，用来从 mysql 迁移数据到 clickhouse(支持 binlog 增量更新和全量导入)，但是官方 readme 和代码脱节，根据 quick start 跑不通。 ## 创建表clickhouse-mysql \\ --src-host=127.0.0.1 \\ --src-user=reader \\ --src-password=Qwerty1# \\ --table-templates-with-create-database \\ --src-table=airline.ontime &gt; create_clickhouse_table_template.sql## 修改脚本vim create_clickhouse_table_template.sql## 导入建表clickhouse-client -mn &lt; create_clickhouse_table_template.sql## 数据导入clickhouse-mysql \\ --src-host=127.0.0.1 \\ --src-user=reader \\ --src-password=Qwerty1# \\ --table-migrate \\ --dst-host=127.0.0.1 \\ --dst-table=logunified \\ --csvpool 官方文档: https://github.com/Altinity/clickhouse-mysql-data-reader#mysql-migration-case-1—migrate-existing-data 注意，上述三种都是从 mysql 导入 clickhouse，如果数据量大，对于 mysql 压力还是挺大的。下面介绍两种离线方式(streamsets 支持实时，也支持离线)csv ## 忽略建表clickhouse-client \\ -h host \\ --query=\"INSERT INTO [db].table FORMAT CSV\" &lt; test.csv 但是如果源数据质量不高，往往会有问题，比如包含特殊字符(分隔符，转义符)，或者换行。被坑的很惨。 自定义分隔符, --format_csv_delimiter=&quot;|&quot; 遇到错误跳过而不中止， --input_format_allow_errors_num=10 最多允许 10 行错误, --input_format_allow_errors_ratio=0.1 允许 10%的错误 csv 跳过空值(null) ，报 Code: 27. DB::Exception: Cannot parse input: expected , before: xxxx: (at row 69) ERROR: garbage after Nullable(Date): &quot;8,002&lt;LINE FEED&gt;0205&quot; sed &#39; :a;s/,,/,\\\\N,/g;ta&#39; |clickhouse-client -h host --query &quot;INSERT INTO [db].table FORMAT CSV&quot; 将 ,, 替换成 ,\\N, python clean_csv.py --src=src.csv --dest=dest.csv --chunksize=50000 --cols --encoding=utf-8 --delimiter=, clean_csv.py 参考我另外一篇 032-csv 文件容错处理 streamsetsstreamsets 支持从 mysql 或者读 csv 全量导入，也支持订阅 binlog 增量插入，参考我另外一篇 025-大数据 ETL 工具之 StreamSets 安装及订阅 mysql binlog。本文只展示从 mysql 全量导入 clickhouse本文假设你已经搭建起 streamsets 服务启用并重启服务上传 mysql 和 clickhouse 的 jdbc jar 和依赖包便捷方式，创建 pom.xml，使用 maven 统一下载 &lt;project xmlns=\"http://maven.apache.org/POM/4.0.0\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation=\"http://maven.apache.org/POM/4.0.0 http://maven.apache.org/maven-v4_0_0.xsd\"&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;groupId&gt;com.anjia&lt;/groupId&gt; &lt;artifactId&gt;demo&lt;/artifactId&gt; &lt;packaging&gt;jar&lt;/packaging&gt; &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt; &lt;name&gt;demo&lt;/name&gt; &lt;url&gt;http://maven.apache.org&lt;/url&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;ru.yandex.clickhouse&lt;/groupId&gt; &lt;artifactId&gt;clickhouse-jdbc&lt;/artifactId&gt; &lt;version&gt;0.1.54&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;mysql&lt;/groupId&gt; &lt;artifactId&gt;mysql-connector-java&lt;/artifactId&gt; &lt;version&gt;5.1.47&lt;/version&gt; &lt;/dependency&gt; &lt;/dependencies&gt;&lt;/project&gt; 如果本地装有 maven，执行如下命令mvn dependency:copy-dependencies -DoutputDirectory=lib -DincludeScope=compile所有需要的 jar 会下载并复制到 lib 目录下然后拷贝到 streamsets /opt/streamsets-datacollector-3.9.1/streamsets-libs-extras/streamsets-datacollector-jdbc-lib/lib/ 目录下重启 streamsets 服务 参考资料 我的博客 我的掘金 Building data stream pipelines with CrateDB and StreamSets data collector JDBC Query Consumer Data Flow Pipeline Using StreamSets","tags":[{"name":"数据分析","slug":"数据分析","permalink":"https://anjia0532.github.io/tags/数据分析/"},{"name":"数据处理","slug":"数据处理","permalink":"https://anjia0532.github.io/tags/数据处理/"},{"name":"mysql","slug":"mysql","permalink":"https://anjia0532.github.io/tags/mysql/"},{"name":"数据库","slug":"数据库","permalink":"https://anjia0532.github.io/tags/数据库/"},{"name":"clickhouse","slug":"clickhouse","permalink":"https://anjia0532.github.io/tags/clickhouse/"}]},{"title":"032-csv文件容错处理","date":"2019-07-16T21:30:00.000Z","path":"2019/07/16/clean-csv/","text":"这是坚持技术写作计划（含翻译）的第 32 篇，定个小目标 999，每周最少 2 篇。 如果数据库有特殊字符(换行符，转义符),会导致生成的 csv 无法正常导入。 val1,val2,val3aa,bb,ccaa,bb,ccaa,bb,ccaa,bb,cca\\a,bb,cc 第一行 header 和第二行数据正常。第三行第一个列有换行符，此时导致第四行看着正常(3 列),但是数据又是错误的。第五行跟第三行类似第七行实际是第二个单元格首字符换行，导致第八行缺失一列。第九行有转义符 处理成 val1,val2,val3aa,bb,ccaa,bb,ccaa,bb,ccaa,bb,ccaa,bb,cc 利用空闲时间，用 python 写了个修补工具,原理是利用，csv 是从上往下读的，如果前一行列数不够，一定可以从后一列补上。但是可能存在补完后超过指定列(比如列内包含分隔符，导致数据库 3 列，变成 4 列)，所以需要对其切片，只保留指定列数。 clean_csv.py # -*- coding: utf-8 -*-# Author AnJia(anjia0532@gmail.com https://anjia0532.github.io)import argparseimport sys, osimport ioreload(sys)sys.setdefaultencoding('utf8')black_dict=&#123;\"\\\\\":\"\",\"\\\"\":\"\"&#125;def main(): parser = argparse.ArgumentParser() parser.add_argument('--cols', type=int, dest='cols', action='store', default=-1,help=\"count of columns,default first line's cells\") parser.add_argument('--src', type=str, dest='src', action='store', default='', help='path to source csv file') parser.add_argument('--dest', type=str, dest='dest', action='store', default='', help='path to dest csv file') parser.add_argument('--encoding', type=str, dest='encoding', action='store', default='utf-8', help='file encoding,default utf-8') parser.add_argument('--chunksize', type=int, dest='chunksize', action='store', default='10000', help='batch lines to write dest file,default 10000') parser.add_argument('--delimiter', type=str, dest='delimiter', action='store', default=',', help='csv delimiter,default ,') args = parser.parse_args() cols = args.cols src = args.src dest = args.dest encoding = args.encoding chunksize = args.chunksize delimiter = args.delimiter if not (src and dest) or chunksize &lt;= 0: print(\"invaild args!\") sys.exit(-1) olds=[] lines=[] with io.open(src,encoding=encoding) as fp: for line in fp.readlines(): line = line.strip() for k,v in black_dict.items(): if k in line: line=line.replace(k,v) cells = line.split(delimiter) if cols == -1: cols=len(cells) if(len(cells) &lt; cols or (len(olds)&gt;0 and len(olds) &lt; cols)): if not olds: olds = cells else: cells[0]=olds[-1]+cells[0] olds.pop() olds.extend(cells) if len(olds) &gt;= cols: cells=olds olds=[] if not olds: lines.append(delimiter.join(cells[0:cols])+\"\\n\") if len(lines) % chunksize == 0: write_to_file(dest=dest,lines=lines) lines=[] write_to_file(dest=dest,lines=lines)def write_to_file(dest,lines=[],encoding='utf-8'): p = os.path.split(dest)[0] if not os.path.exists(p): os.makedirs(p) with io.open(file=dest,mode=\"a+\",encoding=encoding) as fp: fp.writelines(lines)if __name__ == '__main__': main() 使用方式python clean_csv.py --src=src.csv --dest=dest.csv --chunksize=50000 --cols --encoding=utf-8 --delimiter=, 参考资料 我的博客 我的掘金 anjia0532/clean_csv.py","tags":[{"name":"python","slug":"python","permalink":"https://anjia0532.github.io/tags/python/"},{"name":"csv","slug":"csv","permalink":"https://anjia0532.github.io/tags/csv/"},{"name":"数据分析","slug":"数据分析","permalink":"https://anjia0532.github.io/tags/数据分析/"},{"name":"数据处理","slug":"数据处理","permalink":"https://anjia0532.github.io/tags/数据处理/"}]},{"title":"031-数据可视化之redash(支持43种数据源)","date":"2019-07-08T12:30:00.000Z","path":"2019/07/08/redash/","text":"这是坚持技术写作计划（含翻译）的第 31 篇，定个小目标 999，每周最少 2 篇。 本文是数据可视化系列第二篇,本系列会讲解 PowerBI/Excel,Metabase,Redash,Superset,CBoard 人类都是视觉动物，讲究一图胜千言。如果没了可视化，那么你在跟领导汇报工作时，很大程度会鸡同鸭讲。其实 excel2016+已经是一个不错的数据分析及可视化工具了(支持几十种数据源),但是，不方便权限控制，集中，及报警。 我一般将 redash 作为可视化工具、数据库查询编辑器(类似 navicat-premium)、数据挖掘探索工具来用。截止目前，自建 redash 支持 43 种数据源 安装 redash## 安装必要工具apt install -y pwgen python-pippip install pip -Upip config set global.index-url https://pypi.tuna.tsinghua.edu.cn/simplepip install docker-compose## 生成脚本cat &lt;&lt; EOF | sudo tee -a ./setup.sh#!/usr/bin/env bash# This script setups dockerized Redash on Ubuntu 18.04.set -euREDASH_BASE_PATH=/opt/redashcreate_directories() &#123; if [[ ! -e $REDASH_BASE_PATH ]]; then sudo mkdir -p $REDASH_BASE_PATH sudo chown $USER:$USER $REDASH_BASE_PATH fi if [[ ! -e $REDASH_BASE_PATH/postgres-data ]]; then mkdir $REDASH_BASE_PATH/postgres-data fi&#125;create_config() &#123; if [[ -e $REDASH_BASE_PATH/env ]]; then rm $REDASH_BASE_PATH/env touch $REDASH_BASE_PATH/env fi COOKIE_SECRET=$(pwgen -1s 32) SECRET_KEY=$(pwgen -1s 32) POSTGRES_PASSWORD=$(pwgen -1s 32) REDASH_DATABASE_URL=\"postgresql://postgres:$&#123;POSTGRES_PASSWORD&#125;@postgres/postgres\" echo \"PYTHONUNBUFFERED=0\" &gt;&gt; $REDASH_BASE_PATH/env echo \"REDASH_LOG_LEVEL=INFO\" &gt;&gt; $REDASH_BASE_PATH/env echo \"REDASH_REDIS_URL=redis://redis:6379/0\" &gt;&gt; $REDASH_BASE_PATH/env echo \"POSTGRES_PASSWORD=$POSTGRES_PASSWORD\" &gt;&gt; $REDASH_BASE_PATH/env echo \"REDASH_COOKIE_SECRET=$COOKIE_SECRET\" &gt;&gt; $REDASH_BASE_PATH/env echo \"REDASH_SECRET_KEY=$SECRET_KEY\" &gt;&gt; $REDASH_BASE_PATH/env echo \"REDASH_DATABASE_URL=$REDASH_DATABASE_URL\" &gt;&gt; $REDASH_BASE_PATH/env&#125;create_directoriescreate_configEOF## 生成必要配置文件chmod +x ./setup &amp;&amp; ./setup docker-compose.yml version: \"2\"x-redash-service: &amp;redash-service image: redash/redash:7.0.0.b18042 depends_on: - postgres - redis env_file: /opt/redash/env restart: alwaysservices: server: &lt;&lt;: *redash-service command: server ports: - \"5000:5000\" environment: REDASH_WEB_WORKERS: 4 scheduler: &lt;&lt;: *redash-service command: scheduler environment: QUEUES: \"celery\" WORKERS_COUNT: 1 scheduled_worker: &lt;&lt;: *redash-service command: worker environment: QUEUES: \"scheduled_queries,schemas\" WORKERS_COUNT: 1 adhoc_worker: &lt;&lt;: *redash-service command: worker environment: QUEUES: \"queries\" WORKERS_COUNT: 2 redis: image: redis:5.0-alpine restart: always postgres: image: postgres:9.5-alpine env_file: /opt/redash/env volumes: - /opt/redash/postgres-data:/var/lib/postgresql/data restart: always nginx: image: redash/nginx:latest ports: - \"80:80\" depends_on: - server links: - server:redash restart: always ## 配置数据库sudo docker-compose run --rm server create_db## 启动sudo docker-compose up -d 配置 redash 创建数据源 注意：为做演示，clickhouse 已导入官网提供的 2018 年航天数据，详见 https://clickhouse.yandex/docs/zh/getting_started/example_datasets/ontime/ 演示 redash创建查询 查询 2007 年各航空公司延误超过 10 分钟以上的百分比 SELECT Carrier, avg(DepDelay &gt; 10) * 100 AS c3 FROM ontime WHERE Year = 2018 GROUP BY Carrier ORDER BY Carrier 发布 创建仪表盘(Dashboard) 分享后的 dashboard，在底下有个 redash 的 logo 可以嵌入到已有系统里。 参考资料 我的博客 我的掘金 Knowledge Base 招聘小广告山东济南的小伙伴欢迎投简历啊 加入我们 , 一起搞事情。长期招聘，Java 程序员，大数据工程师，运维工程师，前端工程师。","tags":[{"name":"大数据","slug":"大数据","permalink":"https://anjia0532.github.io/tags/大数据/"},{"name":"hadoop","slug":"hadoop","permalink":"https://anjia0532.github.io/tags/hadoop/"},{"name":"CDH","slug":"CDH","permalink":"https://anjia0532.github.io/tags/CDH/"},{"name":"数据可视化","slug":"数据可视化","permalink":"https://anjia0532.github.io/tags/数据可视化/"},{"name":"Superset","slug":"Superset","permalink":"https://anjia0532.github.io/tags/Superset/"},{"name":"redash","slug":"redash","permalink":"https://anjia0532.github.io/tags/redash/"}]},{"title":"030-前端错误日志上报及网站统计(sentry+matomo)","date":"2019-07-07T15:00:00.000Z","path":"2019/07/07/sentry-and-matomo-install/","text":"这是坚持技术写作计划（含翻译）的第 30 篇，定个小目标 999，每周最少 2 篇。 本文配合 rancher1.6(手头一个测试集群没升级到最新的 2.x)讲解如何搭建并配置日志错误上报框架Sentry及网站统计分析框架matomo 的搭建及接入 vue(本文以iview-admin为例)项目。 背景简述 sentry 项目运行过程中，难免出现 bug，前端不像后端可以很方便的采集项目日志(比如 log4j + elk)，导致每次出问题后还原车祸现场费时费力。另外现在随着 vue 等兴起，构建项目时打成 min.js，无疑又加大了前端定位问题的难度。而 sentry 是一款专注于错误采集的框架，支持常见的主流语言采集，聚合，并推送错误信息。注意，sentry 并不是日志平台(e.g. log4j + elk)，也不是监控平台，sentry 专注于项目中的 Error 信息的采集，聚合，报警。 matomo 前身 Pwiki，是一款开源的 web 网站分析利器。类似于 Google Analytics。具体的特性，参见 Premium Web Analytics ，比如绘制页面热力图，录制会话，访问漏斗，A/B Test 等(这几样都是收费插件功能)。 注意：本文假设你已经有 rancher1.6 的环境 安装matomorancher 创建 matomo在 rancher 主机上 ## 创建必要文件夹mkdir -p /data/matomo/&#123;config,logs,php,maxmind&#125;/## 安装maxmind ip数据库wget -P /tmp/ https://github.com/maxmind/geoipupdate/releases/download/v4.0.3/geoipupdate_4.0.3_linux_amd64.debdpkg -i /tmp/geoipupdate_4.0.3_linux_amd64.debmv /etc/GeoIP.conf&#123;,.bak&#125;cat &lt;&lt; EOF | sudo tee -a /etc/GeoIP.confAccountID 0LicenseKey 000000000000EditionIDs GeoLite2-Country GeoLite2-City GeoLite2-ASNDatabaseDirectory /data/matomo/maxmindEOF## 下载最新maxmind数据库geoipupdatels -lah /data/matomo/maxmind/总用量 67Mdrwxr-xr-x 2 root root 4.0K 7月 7 17:25 .drwxr-xr-x 6 root root 4.0K 7月 7 17:23 ..-rw------- 1 root root 0 7月 7 17:25 .geoipupdate.lock-rw-r--r-- 1 root root 6.3M 7月 7 17:25 GeoLite2-ASN.mmdb-rw-r--r-- 1 root root 57M 7月 7 17:25 GeoLite2-City.mmdb-rw-r--r-- 1 root root 3.7M 7月 7 17:25 GeoLite2-Country.mmdb## 定时更新ip数据库cat &lt;&lt; EOF | sudo tee -a /etc/cron.d/geoipupdate50 2 * * 4 root /usr/bin/geoipupdateEOF## 设置php.inicat &lt;&lt; EOF | sudo tee -a /data/matomo/php/php.iniupload_max_filesize = 128Mpost_max_size = 128Mmax_execution_time = 200memory_limit = 256MEOF docker-compose.yaml version: \"2\"services: matomo: image: matomo:latest stdin_open: true volumes: - /data/matomo/config:/var/www/html/config - /data/matomo/logs:/var/www/html/logs - /data/matomo/php/php.ini:/usr/local/etc/php/php.ini - /data/matomo/maxmind/GeoLite2-City.mmdb:/var/www/html/misc/GeoLite2-City.mmdb - /data/matomo/maxmind/GeoLite2-Country.mmdb:/var/www/html/misc/GeoLite2-Country.mmdb - /data/matomo/maxmind/GeoLite2-ASN.mmdb:/var/www/html/misc/GeoLite2-ASN.mmdb tty: true ports: - 80:80/tcp - 443:443/tcp rancher-compose.yaml version: \"2\"services: matomo: scale: 1 start_on_create: true health_check: response_timeout: 2000 healthy_threshold: 2 port: 80 unhealthy_threshold: 3 initializing_timeout: 60000 interval: 2000 strategy: recreate reinitializing_timeout: 60000 配置 matomo选择中文系统检查配置数据库自动建表完成创建管理员用户(忘记截图了)设置分析网站(可以随便创建，后边再进行修改),注意跟进实际情况修改时区复制跟踪代码配置 matomo登陆 Sentryrancher 创建 Sentrydocker-compose.yml version: \"2\"services: cron: image: sentry:9 environment: SENTRY_MEMCACHED_HOST: memcached SENTRY_REDIS_HOST: redis SENTRY_POSTGRES_HOST: postgres SENTRY_EMAIL_HOST: smtp SENTRY_SECRET_KEY: SENTRY_SECRET_KEY_XXX stdin_open: true volumes: - /data/sentry-data:/var/lib/sentry/files - /data/sentry-data/config.yml:/etc/sentry/config.yml tty: true command: - run - cron memcached: image: memcached:1.5-alpine web: image: sentry:9 environment: SENTRY_MEMCACHED_HOST: memcached SENTRY_REDIS_HOST: redis SENTRY_POSTGRES_HOST: postgres SENTRY_EMAIL_HOST: smtp SENTRY_SECRET_KEY: SENTRY_SECRET_KEY_XXX stdin_open: true volumes: - /data/sentry-data:/var/lib/sentry/files - /data/sentry-data/config.yml:/etc/sentry/config.yml tty: true ports: - 9000:9000/tcp worker: image: sentry:9 environment: SENTRY_MEMCACHED_HOST: memcached SENTRY_REDIS_HOST: redis SENTRY_POSTGRES_HOST: postgres SENTRY_EMAIL_HOST: smtp SENTRY_SECRET_KEY: SENTRY_SECRET_KEY_XXX stdin_open: true volumes: - /data/sentry-data:/var/lib/sentry/files - /data/sentry-data/config.yml:/etc/sentry/config.yml tty: true command: - run - worker redis: image: redis:3.2-alpine postgres: restart: unless-stopped image: postgres:9.5 volumes: - /data/postgresql/data:/var/lib/postgresql/data ports: - 5432:5432/tcp 注意把 SENTRY_SECRET_KEY 换成 sentry 的实际 secret key rancher-compose.yml version: \"2\"services: cron: scale: 1 start_on_create: true memcached: scale: 1 start_on_create: true web: scale: 1 start_on_create: true health_check: response_timeout: 2000 healthy_threshold: 2 port: 9000 unhealthy_threshold: 3 initializing_timeout: 60000 interval: 2000 strategy: recreate reinitializing_timeout: 60000 worker: scale: 1 start_on_create: true redis: scale: 1 start_on_create: true postgres: scale: 1 start_on_create: true health_check: response_timeout: 2000 healthy_threshold: 2 port: 5432 unhealthy_threshold: 3 initializing_timeout: 60000 interval: 2000 strategy: recreate reinitializing_timeout: 60000 先将 docker-compose.yml 保存到服务器上，用来初始化 db 和创建账号 docker-compose run --rm web upgradeWould you like to create a user account now? [Y/n]: yEmail: anjia0532@gmail.comPassword:Repeat for confirmation:Should this user be a superuser? [y/N]: y## 直到输出Migrated: - sentry - sentry.nodestore - sentry.search - social_auth - sentry.tagstore - sentry_plugins.hipchat_ac - sentry_plugins.jira_acCreating missing DSNsCorrecting Group.num_comments counter## 并退出 配置 Sentry 配置 vue本文以 iview-admin 为例 git clone https://gitee.com/anjia/iview-admin.gitcd iview-admin sentry注意，网上很多文档，以讹传讹的使用过时的工具，raven-js .从 5.x 后官方建议使用@sentry/browser 和@sentry/integrations npm install --save @sentry/integrationsnpm install --save @sentry/browser 修改 iview-admin\\src\\main.js // The Vue build version to load with the `import` command// (runtime-only or standalone) has been set in webpack.base.conf with an alias.import Vue from \"vue\";import App from \"./App\";import router from \"./router\";import store from \"./store\";import iView from \"iview\";import i18n from \"@/locale\";import config from \"@/config\";import importDirective from \"@/directive\";import &#123; directive as clickOutside &#125; from \"v-click-outside-x\";import installPlugin from \"@/plugin\";import \"./index.less\";import \"@/assets/icons/iconfont.css\";import TreeTable from \"tree-table-vue\";import VOrgTree from \"v-org-tree\";import \"v-org-tree/dist/v-org-tree.css\";import * as Sentry from \"@sentry/browser\";import * as Integrations from \"@sentry/integrations\";// 实际打包时应该不引入mock/* eslint-disable */if (process.env.NODE_ENV !== \"production\") require(\"@/mock\");Vue.use(iView, &#123; i18n: (key, value) =&gt; i18n.t(key, value),&#125;);Vue.use(TreeTable);Vue.use(VOrgTree);/** * @description 注册admin内置插件 */installPlugin(Vue);/** * @description 生产环境关掉提示 */Vue.config.productionTip = false;/** * @description 全局注册应用配置 */Vue.prototype.$config = config;/** * 注册指令 */importDirective(Vue);Vue.directive(\"clickOutside\", clickOutside);/* eslint-disable no-new */new Vue(&#123; el: \"#app\", router, i18n, store, render: (h) =&gt; h(App),&#125;);Sentry.init(&#123; dsn: \"https://xxx@xxx.xxx.com/xxx\", integrations: [ new Integrations.Vue(&#123; Vue, attachProps: true, &#125;), ],&#125;); npm installnpm run dev 打开 http://localhost:8080/error_store/error_store_page分别点击两个按钮，模拟出错打开 sentry 发现已经有错误上报了，并且对错误进行聚合。点开查看详细内容。 如果需要生成 source-map ,可以参考官方文档 https://docs.sentry.io/platforms/javascript/sourcemaps/ matomo npm install --save vue-matomo 修改 iview-admin\\src\\main.js // The Vue build version to load with the `import` command// (runtime-only or standalone) has been set in webpack.base.conf with an alias.import Vue from \"vue\";import App from \"./App\";import router from \"./router\";import store from \"./store\";import iView from \"iview\";import i18n from \"@/locale\";import config from \"@/config\";import importDirective from \"@/directive\";import &#123; directive as clickOutside &#125; from \"v-click-outside-x\";import installPlugin from \"@/plugin\";import \"./index.less\";import \"@/assets/icons/iconfont.css\";import TreeTable from \"tree-table-vue\";import VOrgTree from \"v-org-tree\";import \"v-org-tree/dist/v-org-tree.css\";import * as Sentry from \"@sentry/browser\";import * as Integrations from \"@sentry/integrations\";import VueMatomo from \"vue-matomo\";// 实际打包时应该不引入mock/* eslint-disable */if (process.env.NODE_ENV !== \"production\") require(\"@/mock\");Vue.use(iView, &#123; i18n: (key, value) =&gt; i18n.t(key, value),&#125;);Vue.use(TreeTable);Vue.use(VOrgTree);/** * @description 注册admin内置插件 */installPlugin(Vue);/** * @description 生产环境关掉提示 */Vue.config.productionTip = false;/** * @description 全局注册应用配置 */Vue.prototype.$config = config;/** * 注册指令 */importDirective(Vue);Vue.directive(\"clickOutside\", clickOutside);/* eslint-disable no-new */new Vue(&#123; el: \"#app\", router, i18n, store, render: (h) =&gt; h(App),&#125;);Sentry.init(&#123; dsn: \"https://xxx@xxx.xxx.com/xxx\", integrations: [ new Integrations.Vue(&#123; Vue, attachProps: true, &#125;), ],&#125;);Vue.use(VueMatomo, &#123; // Configure your matomo server and site by providing host: \"//xxxx.xxxx.com/\", siteId: xx, // Changes the default .js and .php endpoint's filename // Default: 'piwik' trackerFileName: \"matomo.js\", // Overrides the autogenerated tracker endpoint entirely // Default: undefined trackerUrl: \"//xxxx.xxxx.com/matomo.php\", // Enables automatically registering pageviews on the router router: router, // Enables link tracking on regular links. Note that this won't // work for routing links (ie. internal Vue router links) // Default: true enableLinkTracking: true, // Require consent before sending tracking information to matomo // Default: false requireConsent: false, // Whether to track the initial page view // Default: true trackInitialView: true, // Whether or not to log debug information // Default: false debug: false,&#125;);// orwindow._paq.push;// or throughwindow.Piwik.getTracker; 打开 http://localhost:8080, 随便访问几个菜单,然后打开 matomo路由已经有数据了并且将用户的常规数据聚合起来 更多其实本文只是 sentry 和 matomo 简单介绍更深入的使用，比如 sentry，推送邮件，文中一带而过的 sourcemap，单点登录(集成内部的权限认证)，自定义上报内容(将错误与用户 id 关联起来)，,敏感数据脱敏等比如 matomo, 每日发送分析报表，增加 kafka 插件，进行更深层次的挖掘，自定义上报内容(购物车等),大数据量情况下的优化，优化用户设备指纹，使用了 nginx 等反代软件后，如何正确识别真实 ip，热力图，A/B test,漏斗图等 参考资料 我的个人博客 我的掘金 matomo 官网 INSTALLING MATOMO Sentry 官网 Installation with Docker Automatic Updates for GeoIP2 and GeoIP Legacy Databases vue 中如何使用 sentry 对错误日志进行监控","tags":[{"name":"运维","slug":"运维","permalink":"https://anjia0532.github.io/tags/运维/"},{"name":"sentry","slug":"sentry","permalink":"https://anjia0532.github.io/tags/sentry/"},{"name":"日志","slug":"日志","permalink":"https://anjia0532.github.io/tags/日志/"},{"name":"前端","slug":"前端","permalink":"https://anjia0532.github.io/tags/前端/"},{"name":"vuejs","slug":"vuejs","permalink":"https://anjia0532.github.io/tags/vuejs/"},{"name":"matomo","slug":"matomo","permalink":"https://anjia0532.github.io/tags/matomo/"},{"name":"网站分析","slug":"网站分析","permalink":"https://anjia0532.github.io/tags/网站分析/"}]},{"title":"029-解决sentry禁用qq邮箱问题","date":"2019-07-01T20:00:00.000Z","path":"2019/07/01/sentry-qq-mail/","text":"这是坚持技术写作计划（含翻译）的第 29 篇，定个小目标 999，每周最少 2 篇。 Sentry 是一款错误日志采集、聚合框架。有 Saas 版，也可以本地部署。部署可以参考官网或者我之前写的 30-前端错误日志上报及网站统计(sentry+matomo) 本文主要讲解 Sentry 默认禁用 qq 邮箱的排查思路以及如何解决。 添加和自行注册 qq 邮箱都报无效邮箱。 但是 QQ 邮箱，烂归烂，在国内存量还是挺大的。 排查思路F12 大法，看到错误信息是从服务端返回的。 拿到 错误提示 Enter a valid email address. 去 github 搜，拿到 INVALID_EMAIL_ADDRESS_PATTERN 再次搜索居然是硬编码到代码里的。发现有两个相关的 issues. 通过 getsentry/sentry How to custom INVALID_EMAIL_ADDRESS_PATTERN? #13541 了解到，官方发现，qq.com 是有很多滥用行为，所以直接硬编码拉黑 [捂脸] . 解决解决的办法也简单，如果是本地运行的，修改 /usr/local/lib/python2.7/site-packages/sentry/conf/server.py ,如果是 sass 版的，换个邮箱。 注意，如果是 docker 运行的， docker exec -it sentry /bin/sh -&gt; sed -i &quot;s/qq/xx/g&quot; /usr/local/lib/python2.7/site-packages/sentry/conf/server.py ,重新拉取镜像时，又会变回 qq.com 可以 将 /usr/local/lib/python2.7/site-packages/sentry/conf/server.py 挂载到宿主机 docker run -v /opt/sentry/server.py:/usr/local/lib/python2.7/site-packages/sentry/conf/server.py .... 参考资料 我的个人博客 我的掘金 getsentry/sentry How to custom INVALID_EMAIL_ADDRESS_PATTERN? #13541","tags":[{"name":"运维","slug":"运维","permalink":"https://anjia0532.github.io/tags/运维/"},{"name":"sentry","slug":"sentry","permalink":"https://anjia0532.github.io/tags/sentry/"},{"name":"日志","slug":"日志","permalink":"https://anjia0532.github.io/tags/日志/"}]},{"title":"028-解决cdh6.2 报 Failed to install Oozie ShareLib","date":"2019-06-12T12:30:53.000Z","path":"2019/06/12/failed-to-install-oozie-share-lib/","text":"这是坚持技术写作计划（含翻译）的第 28 篇，定个小目标 999，每周最少 2 篇。 本文主要参考 0590-6.1.0-C6 升级过程中 Oozie 共享库的问题分析 ，这个问题是，cdh6.2 的通病，只要安装 oozie 就会出现(无论是升级，还是新装)。 纠正解决方案里的软连接问题 cd /opt/cloudera/parcels/CDH/lib/oozie/libtoolsln -s ../../../jars/logredactor-2.0.7.jar logredactor-2.0.7.jar 此方案需要在部署 oozie 的主机上执行(我一开始执行错节点了)，执行完后重启 oozie。","tags":[{"name":"hadoop","slug":"hadoop","permalink":"https://anjia0532.github.io/tags/hadoop/"},{"name":"CDH","slug":"CDH","permalink":"https://anjia0532.github.io/tags/CDH/"},{"name":"oozie","slug":"oozie","permalink":"https://anjia0532.github.io/tags/oozie/"}]},{"title":"026-Kettle表输入表输出提升50倍的秘诀","date":"2019-06-12T12:30:53.000Z","path":"2019/06/12/kettle-speed-on/","text":"这是坚持技术写作计划（含翻译）的第 26 篇，定个小目标 999，每周最少 2 篇。 最近工作需要，需要从 Oracle 导数据到 Mysql，并且需要进行适当的清洗，转换。数据量在 5 亿条左右，硬件环境为 Winserver 2008R2 64 位 ，64G，48 核，1T hdd，kettle 是 8.2，从 Oracle（11G,linux 服务器，局域网连接）抽到 mysql(5.7,本机，win server)。优化前的速度是读 1000r/s(Oracle)左右，写 1000r/s 左右。优化后的速度是读 8Wr/s(Oracle)左右，写 4Wr/s 左右。因为表的字段大小和类型以及是否有索引都有关系，所以总体来说，提升了 20-50 倍左右。 mysql 优化mysql 此处只是为了迁移数据用，实际上用 csv，或者 clickhouse 也行。但是担心 csv 在处理日期时可能有问题，而 clickhouse 不能在 win 下跑，而条件所限，没有多余的 linux 资源，而 mysql 第三方开源框架(不管是导入 hdfs)，还是作为 clickhouse 的外表，还是数据展示(supserset,metabase 等)，还是迁移到 tidb，都很方便。所以最终决定用 mysql。 Note:此处的 mysql 只做临时数据迁移用，所以可以随便重启跟修改 mysqld 参数。如果是跟业务混用时，需要咨询 dba，确保不会影响其他业务。 mysql 安装及配置优化 从 https://dev.mysql.com/downloads/mysql/5.7.html#downloads 下载 64 位 zip mysql 解压 mysql-5.7.26-winx64.zip 到目录，比如 D:\\mysql-5.7.26-winx64 创建 D:\\mysql-5.7.26-winx64\\my.ini [mysqld]port=3306basedir=D:\\mysql-5.7.26-winx64\\datadir=D:\\mysql-5.7.26-winx64\\datanet_buffer_length=5242880max_allowed_packet=104857600bulk_insert_buffer_size=104857600max_connections = 1000innodb_flush_log_at_trx_commit = 2# 本场景下测试MyISAM比InnoDB 提升1倍左右default-storage-engine=MyISAMgeneral_log = 1general_log_file=D:\\mysql-5.7.26-winx64\\logs\\mysql.loginnodb_buffer_pool_size = 36Ginnodb_log_files_in_group=2innodb_log_file_size = 500Minnodb_log_buffer_size = 50Msync_binlog=1innodb_lock_wait_timeout = 50innodb_thread_concurrency = 16key_buffer_size=82Mread_buffer_size=64Kread_rnd_buffer_size=256Ksort_buffer_size=256Kmyisam_max_sort_file_size=100Gmyisam_sort_buffer_size=100Mtransaction_isolation=READ-COMMITTED 参考 2.3.5 Installing MySQL on Microsoft Windows Using a noinstall ZIP Archive 进行安装 启动 mysql 服务 Kettle 优化启动参数优化本机内存较大，为了防止 OOM，所以调大内存参数，创建环境变量 PENTAHO_DI_JAVA_OPTIONS = -Xms20480m -Xmx30720m -XX:MaxPermSize=1024m 起始 20G，最大 30G 表输入和表输出开启多线程表输入如果开启多线程的话，会导致数据重复。比如 select * from test ,起 3 个线程，就会查 3 遍，最后的数据就是 3 份。肯定不行，没达到优化的目的。因为 source 是 oracle，利用 oracle 的特性： rownum 和函数： mod ,以及 kettle 的参数: Internal.Step.Unique.Count,Internal.Step.Unique.Number select * from (SELECT test.*,rownum rn FROM test ) where mod(rn,$&#123;Internal.Step.Unique.Count&#125;) = $&#123;Internal.Step.Unique.Number&#125; 解释一下 rownum 是 oracle 系统顺序分配为从查询返回的行的编号,返回的第一行分配的是 1,第二行是 2，意味着，如果排序字段或者数据有变化的话，rownum 也会变（也就是跟物理数据没有对应关系,如果要对应关系的话，应该用 rowid,但是 rowid 不是数字，而是类似 AAAR3sAAEAAAACXAAA 的编码），所以需要对 rownum 进行固化，所以将 SELECT test.*,rownum rn FROM test 作为子查询 mod 是 oracle 的取模运算函数，比如， mod(5,3) 意即 5%3=2 ，就是 5/3=1...2 中的 2,也就是如果能获取到总线程数，以及当前线程数，取模，就可以对结果集进行拆分了。 mod(行号,总线程数)=当前线程序号 kettle 内置函数 ${Internal.Step.Unique.Count} 和 ${Internal.Step.Unique.Number} 分别代表线程总数和当前线程序号 而表输出就无所谓了，开多少线程，kettle 都会求总数然后平摊的。 右键选择表输入或者表输出，选择 改变开始复制的数量... 注意，不是一味的调大就一定能提升效率，要进行测试的。表输入时，注意勾选替换变量 修改提交数量(默认 100，但是不是越大越好) 去掉裁剪表，因为是多线程，你肯定不希望，A 线程刚插入的，B 给删掉。 必须要指定数据库字段，因为表输入的时候，会多一个行号字段。会导致插入失败。当然如果你在创建表时，多加了行号字段，当做自增 id 的话，那就不需要这一步了。 开启批量插入 Note: 通过开启多线程，速度能提升 5 倍以上。 开启线程池及优化 jdbc 参数 运行观察结果注意调整不同的参数(线程数，提交数),观察速度。 其余提升空间 换 ssd 继续优化 mysql 参数 换引擎，比如，tokudb 换抽取工具，比如 streamsets,datax 换数据库，比如 clickhouse,tidb,Cassandra kettle 集群 招聘小广告山东济南的小伙伴欢迎投简历啊 加入我们 , 一起搞事情。长期招聘，Java 程序员，大数据工程师，运维工程师，前端工程师。","tags":[{"name":"ETL","slug":"ETL","permalink":"https://anjia0532.github.io/tags/ETL/"},{"name":"Kettle","slug":"Kettle","permalink":"https://anjia0532.github.io/tags/Kettle/"},{"name":"PDI","slug":"PDI","permalink":"https://anjia0532.github.io/tags/PDI/"},{"name":"pentaho","slug":"pentaho","permalink":"https://anjia0532.github.io/tags/pentaho/"}]},{"title":"025-大数据ETL工具之StreamSets安装及订阅mysql binlog","date":"2019-06-10T21:00:01.000Z","path":"2019/06/10/cdh-streamsets/","text":"这是坚持技术写作计划（含翻译）的第 25 篇，定个小目标 999，每周最少 2 篇。 本文主要介绍 CDH6.2+StreamSets3.9。 StreamSets 是一个大数据采集和数据处理工具。可以通过拖拽式的可视化操作，实现数据管道(Pipelines)的设计和调度。其特点有： 拖拽式的可视化界面操作，上手快。 对常见数据处理(数据源、数据操作、数据输出)支持较好。 内置监控，可以对数据流进行观测。 类似的开源产品还有 Apache NiFi , 网上有关于 NiFi 和 StreamSets 的对比 Open Source ETL: Apache NiFi vs Streamsets (网上有中文翻译版版) 国内接触较多的 ETL 工具，可能是 DataX 、 Kettle 、Sqoop。此处有个简单的对比，数据集成之 kettle、sqoop、datax、streamSets 比较 安装 StreamSets 3.9下载 parcel 安装包从 https://archives.streamsets.com/index.html 下载 3.9 的并上传到 http 服务器的 www 目录下，本文以 centos7.6 为例 wget -P /var/www/html/streamsets3.9.0/ https://archives.streamsets.com/datacollector/3.9.0/parcel/manifest.jsonwget -P /var/www/html/streamsets3.9.0/ https://archives.streamsets.com/datacollector/3.9.0/parcel/STREAMSETS_DATACOLLECTOR-3.9.0-el7.parcel.shawget -P /var/www/html/streamsets3.9.0/ https://archives.streamsets.com/datacollector/3.9.0/parcel/STREAMSETS_DATACOLLECTOR-3.9.0-el7.parcel 配置 csd从 https://streamsets.com/opensource 下载 wget -P /opt/cloudera/csd/ https://archives.streamsets.com/datacollector/3.9.0/csd/STREAMSETS-3.9.0.jarcd /opt/cloudera/csd/sudo chown cloudera-scm:cloudera-scm STREAMSETS-3.9.0.jar &amp;&amp; sudo chmod 644 STREAMSETS-3.9.0.jarsystemctl restart cloudera-scm-server 下载分发 Parcel 包下载并激活，但是，我实际测试时，总大小，4.6G，实际下载后，5.2G，导致 sha1sum 校验失败，报 在 cm 所在主机， ls -lah /opt/cloudera/parcel-repo 把下载的 https://archives.streamsets.com/datacollector/3.9.0/parcel/STREAMSETS_DATACOLLECTOR-3.9.0-el7.parcel 复制到 /opt/cloudera/parcel-repo 下如果已经不信邪，试过下载，并报 hash 错误后，直接替换后，这个页面还是提示 hash，此时再次点击下载，就会变成分配。激活后如下所示创建完毕 streamsets 简单使用打开 streamsets，默认用户名密码 admin/admin ![image.png](https://cdn.nlark.com/yuque/0/2019/png/226273/1561003595012-472339dd-c7c0-49be-9be3-855d9fe21016.png &quot;image.png&quot;) 官方教程，参考 Basic Tutorial 本文主要讲解订阅 mysql binlog 进行数据同步 mysql binlog开启 binlog修改 mysql 配置文件，my.cnf，在 mysqld 下增加（注意 5.7 的不加 server-id 无法正常启动） server-id=1log-bin=mysql-binbinlog_format=ROW 创建并配置同步账号GRANT ALL on slave_test.* to 'slave_test'@'%' identified by 'slave_test';GRANT SELECT, REPLICATION CLIENT, REPLICATION SLAVE on *.* to 'slave_test'@'%';FLUSH PRIVILEGES; 安装 mysql jdbc 驱动wget -P /opt/cloudera/parcels/STREAMSETS_DATACOLLECTOR/streamsets-libs/streamsets-datacollector-mysql-binlog-lib/lib/ https://repo1.maven.org/maven2/mysql/mysql-connector-java/5.1.47/mysql-connector-java-5.1.47.jar 重启 streamsets 创建 pipeline 配置 mysql binlog 解析及处理配置目标端 运行 测试此处使用 mysql 自带的压测工具 mysqlslap.exe 进行测试 bin/mysqlslap --user=root --password=xxxxxx --concurrency=50 --number-int-cols=5 --number-char-cols=20 --auto-generate-sql --number-of-queries=100000 --auto-generate-sql-load-type=write --host=192.168.0.123 --port=3306--user 用户(需要有建库建表权限)--password 密码--concurrency 并发数--number-int-cols 表内有5个数字列--number-char-cols 表内有20个字符串列--auto-generate-sql 自动生成脚本--number-of-queries 总执行次数--auto-generate-sql-load-type=write 只执行写入操作--host mysql 主机--port 端口 下方有监控报表 常见错误![image.png](https://cdn.nlark.com/yuque/0/2019/png/226273/1561021775509-fa60a34d-8e71-4e30-aa65-88a23521fb26.png &quot;image.png&quot;) 同步不一致导致的错误，手动从设置偏移量 如果报错 Pipeline Status: RUNNING_ERROR: For input string: &quot;&quot;xxxx&quot; ，把 my.cnf 改成 server-id=1log-bin=mysql-binbinlog_format=ROWsync_binlog=1binlog_gtid_simple_recovery=ONlog_slave_updates=ONgtid_mode=ONenforce_gtid_consistency=ON 参考资料 腾讯工程师带你深入解析 MySQL binlog Home/Origins/MySQL Binary Log Home/Tutorial/Basic Tutorial 如何在 CDH 中安装和使用 StreamSets 如何使用 StreamSets 实现 MySQL 中变化数据实时写入 HBase","tags":[{"name":"大数据","slug":"大数据","permalink":"https://anjia0532.github.io/tags/大数据/"},{"name":"hadoop","slug":"hadoop","permalink":"https://anjia0532.github.io/tags/hadoop/"},{"name":"CDH","slug":"CDH","permalink":"https://anjia0532.github.io/tags/CDH/"},{"name":"ETL","slug":"ETL","permalink":"https://anjia0532.github.io/tags/ETL/"},{"name":"StreamSets","slug":"StreamSets","permalink":"https://anjia0532.github.io/tags/StreamSets/"},{"name":"SDC","slug":"SDC","permalink":"https://anjia0532.github.io/tags/SDC/"}]},{"title":"027-解决cdh6.2中datanode无法启动问题","date":"2019-06-10T21:00:01.000Z","path":"2019/06/10/hdfs-datanode-start-failed/","text":"这是坚持技术写作计划（含翻译）的第 27 篇，定个小目标 999，每周最少 2 篇。 今天安装 cdh 时遇到 hdfs 启动失败问题，解决起来倒是不麻烦，简单记录下。 关键信息 java.io.IOException: Incompatible clusterIDs in /dfs/dn: namenode clusterID = cluster74; datanode clusterID = cluster14关键信息，namenode 的 clusterID 和 datanode 的不一致。 原因：执行 hdfs namenode -format 后，current 目录会删除并重新生成，其中 VERSION 文件中的 clusterID 也会随之变化，而 datanode 的 VERSION 文件中的 clusterID 保持不变，造成两个 clusterID 不一致。 方案： 如果是新建的集群，则直接主机目录 /dfs/dn （cdh-&gt;hdfs-&gt;配置-&gt; dfs.datanode.data.dir ）下的 current 目录下的文件删除 rm -rf /dfs/dn/current/* 如果集群内有数据，则只改 /dfs/dn/current/VERSION 中的 clusterID=clusterXX XX 为正确的 namenode 的 clusterID 重启 datanode 即可","tags":[{"name":"大数据","slug":"大数据","permalink":"https://anjia0532.github.io/tags/大数据/"},{"name":"hadoop","slug":"hadoop","permalink":"https://anjia0532.github.io/tags/hadoop/"},{"name":"CDH","slug":"CDH","permalink":"https://anjia0532.github.io/tags/CDH/"},{"name":"hdfs","slug":"hdfs","permalink":"https://anjia0532.github.io/tags/hdfs/"},{"name":"datanode","slug":"datanode","permalink":"https://anjia0532.github.io/tags/datanode/"}]},{"title":"024-VMWare VSphere 6.7(ESXI,VSCA) 下载","date":"2019-05-20T21:30:00.000Z","path":"2019/05/20/vmware-vsphere-6-7/","text":"这是坚持技术写作计划（含翻译）的第 24 篇，定个小目标 999，每周最少 2 篇。 VSphere 是一套组件的合成，类似，word,excel,ppt 合称 office。而 ESXI 是虚拟组件，虚拟机跑在 ESXI 上，而 VSCA 是 vcenter,是一个集群管理软件。提供企业级功能，比如虚拟机高可用等。 本文主要讲解如何下载 ESXI 和 VSCA。 下载 ESXI 转至 VMware vSphere Hypervisor（ESXi）6.7 下载页面 登陆或者创建一个 VMware 账号 下载最新的 6.7.0U2。 安装到硬件设备上 如果只是个人用，则可以使用上图打马赛克的个人许可证。 VSCAvcenter 是企业套件，无法通过官网免费下载。通过 google 搜索得到https://technet24.ir/vmware-vcenter-server-6-7-13940其实 technet24.ir 也提供 EXSI ISO 的下载方式 注意，为了安全起见，下载后，需要去跟官网的摘要进行比对，https://my.vmware.com/cn/group/vmware/details?downloadGroup=VC67U2A&amp;productId=742#errorCheckDiv 安装和使用方式，参考 Install VCSA 6.7.1 参考资料 VMware vSphere Hypervisor（ESXi）6.7 下载页面 Vmware ESXi upgrade 11 月 9 日 Install VCSA 6.7.1 VMware VCenter Server 6.7 U2a VMware ESXi Patch Tracker VMware ESXi Image Profiles vmware 6 虚拟化 全系列 序列号","tags":[{"name":"云计算","slug":"云计算","permalink":"https://anjia0532.github.io/tags/云计算/"},{"name":"虚拟化","slug":"虚拟化","permalink":"https://anjia0532.github.io/tags/虚拟化/"},{"name":"企业级虚拟化","slug":"企业级虚拟化","permalink":"https://anjia0532.github.io/tags/企业级虚拟化/"},{"name":"私有云","slug":"私有云","permalink":"https://anjia0532.github.io/tags/私有云/"}]},{"title":"019-批量修改redis TTL和批量删除key","date":"2019-05-10T08:37:14.000Z","path":"2019/05/10/redis-batch-changed-ttl/","text":"这是坚持技术写作计划（含翻译）的第 19 篇，定个小目标 999，每周最少 2 篇。 如果因为历史原因，导致 redis 里存在无用且没有设置 ttl 的 key，会造成浪费。本文主要讲如何在不阻塞 redis 的情况下批量修改 redis 的 ttl 和使用通配符删除 key。 通配符删除 keyredis-cli [-a password] [-h localhost] [-p 6379] --scan --pattern pattern* | xargs redis-cli [-a password] [-h localhost] [-p 6379] del 其中 [] 包裹的都是可选项 -p 端口 -h 是 redis 主机 -a 是密码 pattern* 是通配符 SCAN,SSCAN,HSCAN,ZSCAN 四个命令都支持增量式迭代， 它们每次执行都只会返回少量元素， 所以这些命令可以用于生产环境， 而不会出现像 KEYS 命令、 SMEMBERS 命令带来的问题 —— 当 KEYS 命令被用于处理一个大的数据库时， 又或者 SMEMBERS 命令被用于处理一个大的集合键时， 它们可能会阻塞服务器达数秒之久。 参考资料 redis 命令 SCAN 批量打印或者修改 TTL使用方式 $ pip install redis$ python keys.py --helpusage: keys.py [-h] [-p PORT] [-d DB_LIST] [--host HOST] [--password PASSWORD] [--expire EXPIRE] [--random_upper RANDOM_UPPER] [--max_ttl MAX_TTL]optional arguments: -h, --help show this help message and exit -p PORT port of redis -d DB_LIST ex : -d all / -d 1,2,3,4 --host HOST ex : --host 127.0.0.1 --password PASSWORD ex : --password password --expire EXPIRE unit: sec ,ex 1 days = 86400 sec: --expire 86400 --random_upper RANDOM_UPPER unit: sec ,ex 1 mins = 60 sec: --random_upper 60 --max_ttl MAX_TTL unit: sec ,ex 1 mins = 60 sec: --max_ttl 60 # encoding: utf-8\"\"\"author: yangyi@youzan.comtime: 2018/4/26 下午4:34func: 获取数据库中没有设置ttl的 keyauthor: anjia0532@gmail.comtime: 2019/05/10 上午8:19desc: 增加cli选项，增加批量修改ttl功能\"\"\"import redisimport argparseimport timeimport sys, osimport randomclass ShowProcess: \"\"\" 显示处理进度的类 调用该类相关函数即可实现处理进度的显示 \"\"\" i = 0 # 当前的处理进度 max_steps = 0 # 总共需要处理的次数 max_arrow = 50 # 进度条的长度 # 初始化函数，需要知道总共的处理次数 def __init__(self, max_steps): self.max_steps = max_steps self.i = 0 # 显示函数，根据当前的处理进度i显示进度 # 效果为[&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;]100.00% def show_process(self, i = None): if i is not None: self.i = i else: self.i += 1 num_arrow = int(self.i * self.max_arrow / self.max_steps) # 计算显示多少个'&gt;' num_line = self.max_arrow - num_arrow # 计算显示多少个'-' percent = self.i * 100.0 / self.max_steps # 计算完成进度，格式为xx.xx% process_bar = '[' + '&gt;' * num_arrow + ' ' * num_line + ']'\\ + '%.2f' % percent + '%' + '\\r' # 带输出的字符串，'\\r'表示不换行回到最左边 sys.stdout.write(process_bar) # 这两句打印字符到终端 sys.stdout.flush() def close(self, words='done'): print(words) self.i = 0def check_ttl(redis_conn, dbindex,max_ttl,random_upper,expire): start_time = time.time() changed_ttl_num = 0 keys_num = redis_conn.dbsize() print( \"there are &#123;num&#125; keys in db &#123;index&#125; \".format(num=keys_num, index=dbindex)) process_bar = ShowProcess(keys_num) for key in redis_conn.scan_iter(count=1000): process_bar.show_process() ttl = redis_conn.ttl(key) if ttl &gt; max_ttl or ttl == -1: changed_ttl_num += 1 redis_conn.expire(key, expire + random.randint(0, random_upper)) else: continue process_bar.close() print(\"cost time(s):\", time.time() - start_time) print(\"changed ttl keys number:\", changed_ttl_num)def main(): parser = argparse.ArgumentParser() parser.add_argument('--port', type=int, dest='port', action='store', default=6379,help='port of redis ') parser.add_argument('--db_list', type=str, dest='db_list', action='store', default='0', help='ex : -d all / -d 1,2,3,4 ') parser.add_argument('--host', type=str, dest='host', action='store', default='127.0.0.1', help='ex : --host 127.0.0.1 ') parser.add_argument('--password', type=str, dest='password', action='store', default='', help='ex : --password password ') parser.add_argument('--expire', type=int, dest='expire', action='store', default='0', help='unit: sec ,ex 1 days = 86400 sec: --expire 86400 ') parser.add_argument('--random_upper', type=int, dest='random_upper', action='store', default='60', help='unit: sec ,ex 1 mins = 60 sec: --random_upper 60 ') parser.add_argument('--max_ttl', type=int, dest='max_ttl', action='store', default='60', help='unit: sec ,ex 1 mins = 60 sec: --max_ttl 60 ') args = parser.parse_args() port = args.port expire = args.expire random_upper = args.random_upper max_ttl = args.max_ttl host = args.host password = args.password if args.db_list == 'all': db_list = [i for i in range(0, 16)] else: db_list = [int(i) for i in args.db_list.split(',')] for index in db_list: try: pool = redis.ConnectionPool(host=host, port=port, db=index,password=password) r = redis.StrictRedis(connection_pool=pool) except redis.exceptions.ConnectionError as e: print(e) else: check_ttl(r, index,max_ttl,random_upper,expire)if __name__ == '__main__': main() 参考资料 【Redis】获取没有设置 ttl 的 key 脚本 招聘小广告山东济南的小伙伴欢迎投简历啊 加入我们 , 一起搞事情。长期招聘，Java 程序员，大数据工程师，运维工程师，前端工程师。","tags":[{"name":"python","slug":"python","permalink":"https://anjia0532.github.io/tags/python/"},{"name":"redis","slug":"redis","permalink":"https://anjia0532.github.io/tags/redis/"}]},{"title":"022-会Excel就会数据分析(Kylin2.6.1+Excel+Power BI)","date":"2019-05-04T19:30:00.000Z","path":"2019/05/04/kylin-excel/","text":"这是坚持技术写作计划（含翻译）的第 22 篇，定个小目标 999，每周最少 2 篇。 本文主要介绍如何使用 excel/power BI 连接 kylin2.6.1 前提准备下载 kylin odbcapache 官网已经停止提供 odbc 驱动了，只能从 csdn 等下载别人上传的，安全性毫无保证。后来转念一想，kylin 的商业公司https://kyligence.io，应该会提供吧，一番打探，果然有。 下载地址：Download Kyligence ODBC Driver for Apache Kylin 需要填写邮箱进行下载 配置 odbc 数据源Win+R-&gt; Control -&gt; 管理工具 -&gt; ODBC 数据源(64 位) 下载 powerQueryExcel 2016 及以后版本，自带 PowerQuery 之前版本需要自行下载 PowerQuery https://www.microsoft.com/zh-CN/download/details.aspx?id=39379 Excel 连接 KylinExcel 配置 Kylin ODBC 数据源 选择刚刚配置的 KylinDSN 填入用户名密码 可以选择表进行预览点击加载按钮进行加载 PowerBI 连接 Kylin下载并安装 PowerBI下载地址 https://www.microsoft.com/zh-CN/download/details.aspx?id=45331 参考资料 Excel 及 Power BI 教程 Power BI Desktop 入门 招聘小广告山东济南的小伙伴欢迎投简历啊 加入我们 , 一起搞事情。长期招聘，Java 程序员，大数据工程师，运维工程师，前端工程师。","tags":[{"name":"大数据","slug":"大数据","permalink":"https://anjia0532.github.io/tags/大数据/"},{"name":"hadoop","slug":"hadoop","permalink":"https://anjia0532.github.io/tags/hadoop/"},{"name":"CDH","slug":"CDH","permalink":"https://anjia0532.github.io/tags/CDH/"},{"name":"KYLIN","slug":"KYLIN","permalink":"https://anjia0532.github.io/tags/KYLIN/"},{"name":"OLAP","slug":"OLAP","permalink":"https://anjia0532.github.io/tags/OLAP/"},{"name":"麒麟","slug":"麒麟","permalink":"https://anjia0532.github.io/tags/麒麟/"},{"name":"Excel","slug":"Excel","permalink":"https://anjia0532.github.io/tags/Excel/"},{"name":"PowerBI","slug":"PowerBI","permalink":"https://anjia0532.github.io/tags/PowerBI/"}]},{"title":"021-cdh6.2+kylin2.6.2","date":"2019-05-03T20:00:01.000Z","path":"2019/05/03/cm6-kylin/","text":"这是坚持技术写作计划（含翻译）的第 21 篇，定个小目标 999，每周最少 2 篇。 本文主要介绍，如何使用大数据神兽 Kylin(2.6.2)连接 cdh6.2。 提示 因为 cdh6.2 使用的是 hadoop3，而目前的 kylin3.0beta 版本只是 hadoop2,所以只能安装 kylin2.5+,此处选择 kylin2.6.2-cdh60（cdh6.0 版） 安装 kylin下载 kylin2.6.2 二进制包wget http://mirrors.tuna.tsinghua.edu.cn/apache/kylin/apache-kylin-2.6.2/apache-kylin-2.6.2-bin-cdh60.tar.gztar zxf apache-kylin-2.6.2-bin-cdh60.tar.gz -C /usr/local/ln -s /usr/local/apache-kylin-2.6.2-bin-cdh60 /usr/local/kylin 配置 kylin 环境变量cat &lt;&lt; EOF | sudo tee -a /etc/profile#设置java环境export JAVA_HOME=/usr/java/jdk1.8.0_181-cloudera/export CLASSPATH=.:\\$JAVA_HOME/lib:\\$JAVA_HOME/jre/lib:\\$CLASSPATHexport KYLIN_HOME=/usr/local/kylinexport PATH=\\$JAVA_HOME/bin:\\$JAVA_HOME/jre/bin:\\$PATHexport CDH_HOME=/opt/cloudera/parcels/CDHexport HBASE_HOME=\\$&#123;CDH_HOME&#125;/lib/hbaseexport HBASE_CLASSPATH=\\$&#123;HBASE_HOME&#125;/lib/hbase-common-2.1.0-cdh6.2.0.jarEOFsource /etc/profile 如果不加 $HBASE_HOME 会报 hbase-common lib not found Retrieving hadoop conf dir...KYLIN_HOME is set to /usr/local/kylinRetrieving hive dependency...Retrieving hbase dependency...Error: Could not find or load main class org.apache.hadoop.hbase.util.GetJavaPropertyhbase-common lib not found 在 hdfs 创建 kylin 和 spark 目录export HADOOP_USER_NAME=hdfs 否则会报 $KYLIN_HOME/bin/check-env.shRetrieving hadoop conf dir...Error: Could not find or load main class org.apache.hadoop.hbase.util.GetJavaPropertyKYLIN_HOME is set to /usr/local/kylinmkdir: Permission denied: user=root, access=WRITE, inode=\"/kylin\":hdfs:supergroup:drwxr-xr-xFailed to create hdfs:///kylin/spark-history. Please make sure the user has right to access hdfs:///kylin/spark-history yum install -y net-tools 否则会报 $KYLIN_HOME/bin/check-env.shRetrieving hadoop conf dir...Error: Could not find or load main class org.apache.hadoop.hbase.util.GetJavaPropertyKYLIN_HOME is set to /usr/local/kylin/usr/local/kylin/bin/check-port-availability.sh: line 27: netstat: command not found 下载 spark$KYLIN_HOME/bin/download-spark.sh 否则会报 $KYLIN_HOME/bin/kylin.sh startRetrieving hadoop conf dir...错误: 找不到或无法加载主类 org.apache.hadoop.hbase.util.GetJavaPropertyKYLIN_HOME is set to /usr/local/kylinRetrieving hive dependency...Retrieving hbase dependency...错误: 找不到或无法加载主类 org.apache.hadoop.hbase.util.GetJavaPropertyRetrieving hadoop conf dir...错误: 找不到或无法加载主类 org.apache.hadoop.hbase.util.GetJavaPropertyRetrieving kafka dependency...Retrieving Spark dependency...spark not found, set SPARK_HOME, or run bin/download-spark.sh 如果知己指定了不兼容的 spark 版本，可能会导致 404，参考 Kylin web UI http 404 error 启动 kylin$KYLIN_HOME/bin/kylin.sh start 如果成功会输出 A new Kylin instance is started by root. To stop it, run &apos;kylin.sh stop&apos;Check the log at /usr/local/kylin/logs/kylin.logWeb UI is at http://&lt;hostname&gt;:7070/kylin 浏览器打开 http://IP:7070/kylin ，用户名密码是 ADMIN/KYLIN 使用 kylin(以官方 demo 演示)导入数据$KYLIN_HOME/bin/sample.shRetrieving hadoop conf dir...Error: Could not find or load main class org.apache.hadoop.hbase.util.GetJavaPropertyLoading sample data into HDFS tmp path: /tmp/kylin/sample_cube/dataGoing to create sample tables in hive to database DEFAULT by cliWARNING: Use \"yarn jar\" to launch YARN applications.SLF4J: Class path contains multiple SLF4J bindings.SLF4J: Found binding in [jar:file:/opt/cloudera/parcels/CDH-6.2.0-1.cdh6.2.0.p0.967373/jars/log4j-slf4j-impl-2.8.2.jar!/org/slf4j/impl/StaticLoggerBinder.class]SLF4J: Found binding in [jar:file:/opt/cloudera/parcels/CDH-6.2.0-1.cdh6.2.0.p0.967373/jars/slf4j-log4j12-1.7.25.jar!/org/slf4j/impl/StaticLoggerBinder.class]SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.SLF4J: Actual binding is of type [org.apache.logging.slf4j.Log4jLoggerFactory]Logging initialized using configuration in jar:file:/opt/cloudera/parcels/CDH-6.2.0-1.cdh6.2.0.p0.967373/jars/hive-common-2.1.1-cdh6.2.0.jar!/hive-log4j2.properties Async: falseOK//....Sample cube is created successfully in project 'learn_kylin'.** Restart Kylin Server or click Web UI =&gt; System Tab =&gt; Reload Metadata to take effect ** 重新加载元数据选择 learn_kylin 构建 Cube选择 Model，选择 kylin_sales_model,选择 build此处选择起止日期。如果没关闭 hdfs 权限校验，此处肯定会 build 失败。可以通过右侧 &gt; 图标点击查看进度。build 成功后，回到 Insight 界面，此时已经成功构建出 5 张表了。 讲解 demo 表Kylin 的示例是销售业务分析 KYLIN_SALES 事实表，存有销售订单的详细信息(卖家，商品分类，订单金额，商品数量等) KYLIN_COUNTRY 维度表，存有国家信息(简写，名称等) KYLIN_CATEGORY_GROUPINGS 维度表，存有商品分类的详细介绍(分类名称等) KYLIN_CAL_DT 维度表，存有时间扩展信息(日期所在年始，月始，周始，年份，月份等) KYLIN_ACCOUNT 维度表，存有账户信息(账户 id，卖家等级，买家等级，国家等) 运行查询语句执行 select count(1) from kylin_sales 点击 submit，下方会显示执行结果，以及执行耗时(此处是 1.8 秒)。kylin 会缓存执行结果，再次执行发现变成了 0.18 秒执行稍微复杂的 SQL 语句 select sum(KYLIN_SALES.PRICE)as price_sum,KYLIN_CATEGORY_GROUPINGS.META_CATEG_NAME,KYLIN_CATEGORY_GROUPINGS.CATEG_LVL2_NAMEfrom KYLIN_SALES inner join KYLIN_CATEGORY_GROUPINGSon KYLIN_SALES.LEAF_CATEG_ID = KYLIN_CATEGORY_GROUPINGS.LEAF_CATEG_ID andKYLIN_SALES.LSTG_SITE_ID = KYLIN_CATEGORY_GROUPINGS.SITE_IDgroup by KYLIN_CATEGORY_GROUPINGS.META_CATEG_NAME,KYLIN_CATEGORY_GROUPINGS.CATEG_LVL2_NAMEorder by KYLIN_CATEGORY_GROUPINGS.META_CATEG_NAME asc,KYLIN_CATEGORY_GROUPINGS.CATEG_LVL2_NAME desc 自带简单的可视化。 参考资料 如何在 CDH 中部署及使用 Kylin Kylin web UI http 404 error Kylin 2.6.1 on Ambari 2.7.1.0 花式踩坑集锦 招聘小广告山东济南的小伙伴欢迎投简历啊 加入我们 , 一起搞事情。长期招聘，Java 程序员，大数据工程师，运维工程师，前端工程师。","tags":[{"name":"大数据","slug":"大数据","permalink":"https://anjia0532.github.io/tags/大数据/"},{"name":"hadoop","slug":"hadoop","permalink":"https://anjia0532.github.io/tags/hadoop/"},{"name":"CDH","slug":"CDH","permalink":"https://anjia0532.github.io/tags/CDH/"},{"name":"KYLIN","slug":"KYLIN","permalink":"https://anjia0532.github.io/tags/KYLIN/"},{"name":"OLAP","slug":"OLAP","permalink":"https://anjia0532.github.io/tags/OLAP/"},{"name":"麒麟","slug":"麒麟","permalink":"https://anjia0532.github.io/tags/麒麟/"}]},{"title":"020-CM配置集群","date":"2019-04-29T18:10:00.000Z","path":"2019/04/29/cm6-cluster/","text":"这是坚持技术写作计划（含翻译）的第 20 篇，定个小目标 999，每周最少 2 篇。 本文主要介绍，如何配置 CM 集群。 提示 安装完后，打开 http://masterIP:7180/ 进行登录，用户名/密码 是 admin/admin 安装过程中，如果出现 和多按几次 Ctrl+Shift+R 即可 选择协议注意授权问题，建议选择 Cloudera Express 版，防止使用试用版收费项目后，60 天过期后停用掉导致的问题。 配置集群填上 FQDN 或者 ip，多台用英文逗号隔开，然后点搜索。并选中需要安装的服务器，点击继续。国内使用官方公开库，那等装完了，起码得以天为单位，此处使用自建 repo，参考 018-CDH6.2 构建本地源加速 CDH 安装 , 如果嫌麻烦，并且中科大的免费镜像能用的话，可以用中科大的，参考 ustclug/mirrorrequest#56选择更多选项，把乱七八糟的都删掉，只留一个即可。 如果已经安装了 jdk 1.8 可以跳过。填主机密码或者 ssh key点击继续，即会在对应主机执行安装操作。点继续，进行健康检查，如果是 Inspect Network 和 Hosts 都是绿色的，则继续，否则可以点击，显示检查结果，进行排查，排查，改正后，点击重新运行。选择需要安装的模块，点击继续配置角色（各个主机需要安装的组件）配置元数据库信息，点击测试连接（如果提示找不到数据库驱动，需要参考之前的文章 017-Centos7.6+CDH 6.2 安装和使用，安装驱动）点击继续后，会显示安装进度。点击继续，则安装结束。 参考资料 018-CDH6.2 构建本地源加速 CDH 安装 ustclug/mirrorrequest#56 017-Centos7.6+CDH 6.2 安装和使用 招聘小广告山东济南的小伙伴欢迎投简历啊 加入我们 , 一起搞事情。长期招聘，Java 程序员，大数据工程师，运维工程师，前端工程师。","tags":[{"name":"大数据","slug":"大数据","permalink":"https://anjia0532.github.io/tags/大数据/"},{"name":"hadoop","slug":"hadoop","permalink":"https://anjia0532.github.io/tags/hadoop/"},{"name":"CDH","slug":"CDH","permalink":"https://anjia0532.github.io/tags/CDH/"}]},{"title":"018-CDH6.2构建本地源加速CDH安装","date":"2019-04-28T19:10:00.000Z","path":"2019/04/28/cdh-local-parcel-repo/","text":"这是坚持技术写作计划（含翻译）的第 18 篇，定个小目标 999，每周最少 2 篇。 目前国内还没有机构或者个人提供 CDH 的公共加速源，导致 CDH 安装时超慢，并且一旦失败后，还得不支持断点安装(linux 机制)，配置 CDH 本地 repo 是学习 cdh 的第一步，否则单是安装就需要以小时为单位。 本文以 centos7.6 为例（其余发行版类似），介绍 CDH 自定义 parcel 和 package 镜像源（parcel 是 cdh 自定义格式） 创建内网 repo配置 web 服务器可以用 apache2，也可以用 nginx，任何提供 http 服务的都可以 $ sudo apt-get install -y httpd$ sudo systemctl start httpd$ sudo systemctl enable httpd 下载 packages这是给 centos 安装 cm6 用的 $ sudo mkdir -p /var/www/html/cloudera-repos$ sudo wget --recursive --no-parent --no-host-directories https://archive.cloudera.com/cm6/6.2.0/redhat7/ -P /var/www/html/cloudera-repos$ sudo wget https://archive.cloudera.com/cm6/6.2.0/allkeys.asc -P /var/www/html/cloudera-repos/cm6/6.2.0/$ sudo chmod -R ugo+rX /var/www/html/cloudera-repos/cm6 下载和发布 parcel repo 下载 manifest.json 和 parcel 文件CDH6 CDH 6 parcel 中包含 Apache Impala, Apache Kudu, Apache Spark 2, and Cloudera Search 等组件，以 6.2.0 为例，在 web 服务器上运行下面指令，用来下载最新版的 cdh 6.2，如果要换成 cdh6.x 的其他版本，只需要替换命令中的 6.2.0 即可。更多 6.x 版本信息参见 CDH 6 Download Information 。 $ sudo mkdir -p /var/www/html/cloudera-repos$ sudo wget --recursive --no-parent --no-host-directories https://archive.cloudera.com/cdh6/6.2.0/parcels/ -P /var/www/html/cloudera-repos$ sudo wget --recursive --no-parent --no-host-directories https://archive.cloudera.com/gplextras6/6.2.0/parcels/ -P /var/www/html/cloudera-repos$ sudo chmod -R ugo+rX /var/www/html/cloudera-repos/cdh6$ sudo chmod -R ugo+rX /var/www/html/cloudera-repos/gplextras6 CDH5CDH 5 parcel 中包含 Impala, Kudu, Spark 1, and Search 等组件，以 5.14.4 为例，在 web 服务器上运行以下指令，如果要换成 cdh5.x 的其他版本,需要替换命令中的 5.14.4 为指定版本号，更多 5.x 版本信息参见 CDH Download Information $ sudo mkdir -p /var/www/html/cloudera-repos$ sudo wget --recursive --no-parent --no-host-directories https://archive.cloudera.com/cdh5/parcels/5.14.4/ -P /var/www/html/cloudera-repos$ sudo wget --recursive --no-parent --no-host-directories https://archive.cloudera.com/gplextras5/parcels/5.14.4/ -P /var/www/html/cloudera-repos$ sudo chmod -R ugo+rX /var/www/html/cloudera-repos/cdh5$ sudo chmod -R ugo+rX /var/www/html/cloudera-repos/gplextras5 如果像本文实例一样，只需支持单一版本（centos7.6）cdh 即可，为了节省时间，可以只下载具体版本。以 CDH6 的为例，增加 --accept-regex &quot;el7|manifest&quot; ,代表只下载包含 xenial 和 maifest 的文件 # 官方命令sudo wget --recursive --no-parent --no-host-directories https://archive.cloudera.com/cdh6/6.2.0/parcels/ -P /var/www/html/cloudera-repos# 改后命令sudo wget --recursive --no-parent --accept-regex \"el7|manifest\" --no-host-directories https://archive.cloudera.com/cdh6/6.2.0/parcels/ -P /var/www/html/cloudera-repos 如果想再快点，可以使用迅雷，axel，aria2 等多线程工具快速下载后，上传到 web 服务器。 Apache Accumulo for CDH以下载 Accumulo1.7.2 为例,如果换成别的版本，替换命令中 1.7.2 即可 $ sudo mkdir -p /var/www/html/cloudera-repos$ sudo wget --recursive --no-parent --no-host-directories https://archive.cloudera.com/accumulo-c5/parcels/1.7.2/ -P /var/www/html/cloudera-repos$ sudo chmod -R ugo+rX /var/www/html/cloudera-repos/accumulo-c5 CDS Powered By Apache Spark 2 for CDH以下载 CDS2.3.0.cloudera3 为例,更多版本信息参见 CDS Powered By Apache Spark Version Information $ sudo mkdir -p /var/www/html/cloudera-repos$ sudo wget --recursive --no-parent --no-host-directories https://archive.cloudera.com/spark2/parcels/2.3.0.cloudera3/ -P /var/www/html/cloudera-repos$ sudo chmod -R ugo+rX /var/www/html/cloudera-repos/spark2 Cloudera Navigator Key Trustee Server Key Trustee KMS parcel 中包含 Cloudera Navigator HSM KMS ，从 download page 下载 Key Trustee KMS，选择指定 Version，比如 Navigator Key Trustee KMS 6.2.0 ,选择 Package or Parcel,选择 Parcel ,选择 DOWNLOAD NOW ,将下载 Key Trustee KMS parcels 和 manifest.json ，将下载的 .tar.gz 上传到 web 服务器上，并解压，以 Key Trustee KMS 6.2.0 为例 $ sudo mkdir -p /var/www/html/cloudera-repos/keytrustee-kms$ sudo tar xvfz /path/to/keytrustee-kms-6.2.0-parcels.tar.gz -C /var/www/html/cloudera-repos/keytrustee-kms --strip-components=1$ sudo chmod -R ugo+rX /var/www/html/cloudera-repos/keytrustee-kms Sqoop Connectors以下载最新版 Sqoop 为例 $ sudo mkdir -p /var/www/html/cloudera-repos$ sudo wget --recursive --no-parent --no-host-directories http://archive.cloudera.com/sqoop-connectors/parcels/latest/ -P /var/www/html/cloudera-repos$ sudo chmod -R ugo+rX /var/www/html/cloudera-repos/sqoop-connectors 访问 repo 地址 http://&lt;Web_server&gt;/cloudera-repos/ 确保你下载的文件能够正常访问。 配置 Cloudera Manager 使用 Parcel repo 两种方法二选一，配置 parcel Navigation bar - 导航条 点击 navigation bar 的 parcel 图标或者点击 Hosts 然后点击 Parcels 标签 点击 Configuration 按钮 Menu - 菜单 选择 Administration (管理) -&gt; Settings (设置) 选择 Category &gt; Parcels 在 Remote Pacel Respository URLs 点击添加按钮，并添加。 填上 parcel 地址，比如 http://&lt;web_server&gt;/cloudera-parcels/cdh6/6.2.0/ 填写 Reason for change 变更原因,点击 Save Changes 提交保存。 国内镜像源本文写完后，发现中科大有一个 CDH 的反代，速度还挺快，可以按需使用。参考 ustclug/mirrorrequest#56 ，经测试，特别不稳定，持续两天，访问不通。 参考资料 Configuring a Local Package Repository Configuring a Local Parcel Repository","tags":[{"name":"大数据","slug":"大数据","permalink":"https://anjia0532.github.io/tags/大数据/"},{"name":"hadoop","slug":"hadoop","permalink":"https://anjia0532.github.io/tags/hadoop/"},{"name":"CDH","slug":"CDH","permalink":"https://anjia0532.github.io/tags/CDH/"}]},{"title":"017-Centos7.6+CDH 6.2 安装和使用","date":"2019-04-25T19:10:00.000Z","path":"2019/04/25/cdh-6-2-x/","text":"这是坚持技术写作计划（含翻译）的第 17 篇，定个小目标 999，每周最少 2 篇。 本文主要介绍 hadoop 发行版 CDH 最新版(6.2)的安装。 准备硬件配置 IP HostName OS Cores Mem Disk Rules 192.168.20.24 cdh01.anjia.com centos7.6 mini 4 16G 100G CM6,CDH agent 192.168.20.25 cdh02.anjia.com centos7.6 mini 4 16G 100G CDH agent 192.168.20.28 cdh03.anjia.com centos7.6 mini 4 16G 100G CDH agent 软件包本地搭建镜像源，加速构建。参考 018-CDH6.2 构建本地源加速 CDH 安装 安装前准备CM 存储空间规划参考 Storage Space Planning for Cloudera Manager 配置网络名# cdh01.anjia.com 192.168.20.24sudo hostnamectl set-hostname cdh01.anjia.comcat &lt;&lt; EOF | sudo tee -a /etc/hosts192.168.20.24 cdh01.anjia.com cdh01192.168.20.25 cdh02.anjia.com cdh02192.168.20.28 cdh03.anjia.com cdh03EOFecho \"HOSTNAME=cdh01.anjia.com\" &gt;&gt; /etc/sysconfig/network# cdh02.anjia.com 192.168.20.25sudo hostnamectl set-hostname cdh02.anjia.comcat &lt;&lt; EOF | sudo tee -a /etc/hosts192.168.20.24 cdh01.anjia.com cdh01192.168.20.25 cdh02.anjia.com cdh02192.168.20.28 cdh03.anjia.com cdh03EOFecho \"HOSTNAME=cdh02.anjia.com\" &gt;&gt; /etc/sysconfig/network# cdh03.anjia.com 192.168.20.28sudo hostnamectl set-hostname cdh03.anjia.comcat &lt;&lt; EOF | sudo tee -a /etc/hosts192.168.20.24 cdh01.anjia.com cdh01192.168.20.25 cdh02.anjia.com cdh02192.168.20.28 cdh03.anjia.com cdh03EOFecho \"HOSTNAME=cdh03.anjia.com\" &gt;&gt; /etc/sysconfig/network 参考 Configure Network Names 禁用防火墙每台都执行 sudo iptables-save &gt; ~/firewall.rulessudo systemctl disable firewalldsudo systemctl stop firewalld 参考 Disabling the Firewall 开启 ntp 同步时钟每台都执行 yum install -y ntpsed -i \"/^server/ d\" /etc/ntp.confcat &lt;&lt; EOF | sudo tee -a /etc/ntp.confserver ntp1.aliyun.comserver ntp2.aliyun.comserver ntp3.aliyun.comserver ntp4.aliyun.comEOFsudo systemctl start ntpdsudo systemctl enable ntpdntpdate -u ntp1.aliyun.comhwclock --systohc 修改 repo每台都执行 sudo wget https://archive.cloudera.com/cm6/6.2.0/redhat7/yum/cloudera-manager.repo -P /etc/yum.repos.d/sed -i \"s/https\\:\\/\\/archive.cloudera.com/http\\:\\/\\/192.168.20.24\\/cloudera-repos/g\" /etc/yum.repos.d/cloudera-manager.reposudo rpm --import https://archive.cloudera.com/cm6/6.2.0/redhat7/yum/RPM-GPG-KEY-cloudera 优化虚拟内存需求率每台都执行 echo 'vm.swappiness = 10' &gt;&gt; /etc/sysctl.confsysctl -p 解决透明大页面问题echo never &gt; /sys/kernel/mm/transparent_hugepage/defragecho never &gt; /sys/kernel/mm/transparent_hugepage/enabled 安装 jdk每台都执行 sudo yum install -y oracle-j2sdk1.8cat &lt;&lt; EOF | sudo tee -a /etc/profile#设置java环境export JAVA_HOME=/usr/java/jdk1.8.0_181-cloudera/export CLASSPATH=.:\\$JAVA_HOME/lib:\\$JAVA_HOME/jre/lib:\\$CLASSPATHexport PATH=\\$JAVA_HOME/bin:\\$JAVA_HOME/jre/bin:\\$PATHEOFsource /etc/profile 安装 CM 和 CDH安装 CM在 cdh01.anjia.com 执行 sudo yum install -y cloudera-manager-daemons cloudera-manager-agent cloudera-manager-server 启用 Auto-TLS,在 CM6.2.0 人工不启用 auto-tls 会导致登陆不成功 sudo JAVA_HOME=/usr/java/jdk1.8.0_181-cloudera /opt/cloudera/cm-agent/bin/certmanager --location /opt/cloudera/CMCA setup --configure-services 安装数据库本文选择 MariaDB在 cdh01.anjia.com 执行 sudo yum install -y mariadb-serversudo systemctl stop mariadbcat &lt;&lt; EOF | sudo tee -a /etc/my.cnf.d/cdh-db.cnf[mysqld]transaction-isolation = READ-COMMITTED# Disabling symbolic-links is recommended to prevent assorted security risks;# to do so, uncomment this line:symbolic-links = 0# Settings user and group are ignored when systemd is used.# If you need to run mysqld under a different user or group,# customize your systemd unit file for mariadb according to the# instructions in http://fedoraproject.org/wiki/Systemdkey_buffer = 16Mkey_buffer_size = 32Mmax_allowed_packet = 32Mthread_stack = 256Kthread_cache_size = 64query_cache_limit = 8Mquery_cache_size = 64Mquery_cache_type = 1max_connections = 550#expire_logs_days = 10#max_binlog_size = 100M#log_bin should be on a disk with enough free space.#Replace '/var/lib/mysql/mysql_binary_log' with an appropriate path for your#system and chown the specified folder to the mysql user.log_bin=/var/lib/mysql/mysql_binary_log#In later versions of MariaDB, if you enable the binary log and do not set#a server_id, MariaDB will not start. The server_id must be unique within#the replicating group.server_id=1binlog_format = mixedread_buffer_size = 2Mread_rnd_buffer_size = 16Msort_buffer_size = 8Mjoin_buffer_size = 8M# InnoDB settingsinnodb_file_per_table = 1innodb_flush_log_at_trx_commit = 2innodb_log_buffer_size = 64Minnodb_buffer_pool_size = 4Ginnodb_thread_concurrency = 8innodb_flush_method = O_DIRECTinnodb_log_file_size = 512MEOFsudo systemctl enable mariadbsudo systemctl start mariadbsudo /usr/bin/mysql_secure_installation[...]Enter current password for root (enter for none):OK, successfully used password, moving on...[...]Set root password? [Y/n] YNew password:Re-enter new password:[...]Remove anonymous users? [Y/n] Y[...]Disallow root login remotely? [Y/n] N[...]Remove test database and access to it [Y/n] Y[...]Reload privilege tables now? [Y/n] Y[...]All done! If you've completed all of the above steps, your MariaDBinstallation should now be secure.Thanks for using MariaDB! 安装数据库驱动每台都执行 wget https://dev.mysql.com/get/Downloads/Connector-J/mysql-connector-java-5.1.46.tar.gztar zxvf mysql-connector-java-5.1.46.tar.gzsudo mkdir -p /usr/share/java/cd mysql-connector-java-5.1.46sudo cp mysql-connector-java-5.1.46-bin.jar /usr/share/java/mysql-connector-java.jar 创建数据库在 cdh01.anjia.com 执行 mysql -u root -p&lt;password&gt;CREATE DATABASE &lt;database&gt; DEFAULT CHARACTER SET utf8 DEFAULT COLLATE utf8_general_ci;GRANT ALL ON &lt;database&gt;.* TO '&lt;user&gt;'@'%' IDENTIFIED BY '&lt;password&gt;'; 这一步 scm 是必须的，其余的数据库可以等后边真实使用时再创建。 Service Database User Cloudera Manager Server scm scm Activity Monitor amon amon Reports Manager rman rman Hue hue hue Hive Metastore Server metastore hive Sentry Server sentry sentry Cloudera Navigator Audit Server nav nav Cloudera Navigator Metadata Server navms navms Oozie oozie oozie 配置 CM 数据库sudo /opt/cloudera/cm/schema/scm_prepare_database.sh [options] &lt;databaseType&gt; &lt;databaseName&gt; &lt;databaseUser&gt; &lt;password&gt;# 输出JAVA_HOME=/usr/java/jdk1.8.0_181-clouderaVerifying that we can write to /etc/cloudera-scm-serverCreating SCM configuration file in /etc/cloudera-scm-serverExecuting: /usr/java/jdk1.8.0_181-cloudera/bin/java -cp /usr/share/java/mysql-connector-java.jar:/usr/share/java/oracle-connector-java.jar:/usr/share/java/postgresql-connector-java.jar:/opt/cloudera/cm/schema/../lib/* com.cloudera.enterprise.dbutil.DbCommandExecutor /etc/cloudera-scm-server/db.properties com.cloudera.cmf.db.[ main] DbCommandExecutor INFO Successfully connected to database.All done, your SCM database is configured correctly! 详细参数，参考 Syntax for scm_prepare_database.sh 安装 CDH 和其他软件sudo systemctl start cloudera-scm-server# 启动后，监听server日志，大约1-3分钟左右sudo tail -f /var/log/cloudera-scm-server/cloudera-scm-server.log# 直到日志出现，如下内容，即启动成功。2019-05-08 13:12:26,523 INFO WebServerImpl:com.cloudera.server.cmf.WebServerImpl: Started Jetty server. 参考资料 CDH 6.2.x Packaging","tags":[{"name":"大数据","slug":"大数据","permalink":"https://anjia0532.github.io/tags/大数据/"},{"name":"hadoop","slug":"hadoop","permalink":"https://anjia0532.github.io/tags/hadoop/"},{"name":"spark","slug":"spark","permalink":"https://anjia0532.github.io/tags/spark/"},{"name":"cdh","slug":"cdh","permalink":"https://anjia0532.github.io/tags/cdh/"},{"name":"hdp","slug":"hdp","permalink":"https://anjia0532.github.io/tags/hdp/"}]},{"title":"016-JDK8+可用的反编译工具(JD_GUI+Procyon)","date":"2019-04-18T12:10:00.000Z","path":"2019/04/18/java-decompiler/","text":"这是坚持技术写作计划（含翻译）的第 16 篇，定个小目标 999，每周最少 2 篇。 本文是源于一次逆向 android app，辛苦脱壳后得到 classes_dumped_29-dex2jar.jar ，要得到源码，但是又不想降级 jdk 到 1.7 来迁就 jd_gui。花了一分钟，找到 jd_gui 在 1.8 下的用法,至于 基于 procyon 的 UI luyten 纯是凑数。 JD_GUI打开 http://java-decompiler.github.io/其实官网已经很明显了，大家之所以以讹传讹，认为 JD_GUI 不支持 1.8，大多是被度娘或者 CSDN 荼毒。1.4.0 及以前的 jd_gui，在 1.8 打开一般是 下载并解压预览版，然后 java -jar jd-gui-1.4.1.jar熟悉的界面，熟悉的配方。 官方截图 procyon + luyten下载最新版的 luyten.jar ,然后 java -jar luyten-0.5.4.jar只是轻度使用的话，两个差不多，建议用 jd_gui,起码搜索速度能甩 luyten 10 条街啊。 结语是不是以为会有类似 lambda 反编译比对一类的评测文？答案是，你想多了。这些工具只要有数就行，一个不好用，换另一个就行。 其实，一般情况下，使用独立反编译工具的可能性很小,一般是 IDE 的插件居多，比如，cnfree/Eclipse-Class-Decompiler ,而 idea 默认有简易版的反编译插件。足以应付日常工作中零星的反编译用途。 招聘小广告山东济南的小伙伴欢迎投简历啊 加入我们 , 一起搞事情。长期招聘，Java 程序员，大数据工程师，运维工程师，前端工程师。","tags":[{"name":"java","slug":"java","permalink":"https://anjia0532.github.io/tags/java/"},{"name":"反编译","slug":"反编译","permalink":"https://anjia0532.github.io/tags/反编译/"},{"name":"jdk8","slug":"jdk8","permalink":"https://anjia0532.github.io/tags/jdk8/"}]},{"title":"015-Ansible批量安装Elastic Beats(支持Linux和Windows)","date":"2019-04-13T20:41:00.000Z","path":"2019/04/13/ansible-beats/","text":"这是坚持技术写作计划（含翻译）的第 15 篇，定个小目标 999，每周最少 2 篇。 使用elastic beats进行拨测，metric 采集，主机监控，但是批量化安装仍是个问题，好在 elastic 官方有开源的 ansible-beats 但是只支持 Linux，而我们在某些业务场景下，还有 WinServer 的存在。故而在官方基础上 fork 并增加了 windows 的支持（已提交 PR，但是官方不一定给合并 [捂脸] ）。关于 Ansible 管理 windows 可以参考我之前写的一篇文章 Ansible2.7 批量管理 Windows。 实验环境 类型 系统 ip Server(主控) Ubuntu Server 16.04.5 LTS X64 192.168.0.22 Client(受控) Windows Server 2008 R2 SP1 192.168.0.23 Clinet(受控) Ubuntu Server 16.04.5 LTS X64 192.168.0.24 Clinet(受控) CentOS 7.6.1810 (Core) 192.168.0.25 注意: 主控端需要安装 Ansible 2.7.12 可参考 步骤此处已假设主控端已安装 Ansible 2.7+，被控端的 Windows 的 WinRM 已配置完成 安装anjia0532.ansible_beats在主控端(192.168.0.22)执行以下命令 root@ubuntu:/root/# ansible-galaxy install anjia0532.ansible_beats- downloading role 'ansible_beats', owned by anjia0532- downloading role from https://github.com/anjia0532/ansible-beats/archive/master.tar.gz- extracting anjia0532.ansible_beats to /root/.ansible/roles/anjia0532.ansible_beats- anjia0532.ansible_beats (master) was installed successfully 创建 inventorys创建 inventorys/hosts.yml beats: hosts: 192.168.0.23: ansible_user: Administrator ansible_password: password ansible_connection: winrm ansible_winrm_transport: basic ansible_port: 5985 192.168.0.24: ansible_user: root ansible_ssh_private_key_file: /root/.ssh/id_rsa 192.168.0.25: ansible_user: root ansible_ssh_private_key_file: /root/.ssh/id_rsa 创建 task创建 beats.yml - name: Example playbook for installing packetbeat hosts: beats roles: - &#123; role: anjia0532.ansible_beats, beat: \"packetbeat\", beat_conf: &#123; \"interfaces\": &#123; \"device\": \"any\" &#125;, \"protocols\": &#123; \"dns\": &#123; \"ports\": [53], \"include_authorities\": true &#125;, \"http\": &#123; \"ports\": [80, 8080, 8000, 5000, 8002] &#125;, \"memcache\": &#123; \"ports\": [11211] &#125;, \"mysql\": &#123; \"ports\": [3306] &#125;, \"pgsql\": &#123; \"ports\": [5432] &#125;, \"redis\": &#123; \"ports\": [6379] &#125;, \"thrift\": &#123; \"ports\": [9090] &#125;, \"mongodb\": &#123; \"ports\": [27017] &#125;, &#125;, &#125;, output_conf: &#123; \"elasticsearch\": &#123; \"hosts\": [\"localhost:9200\"] &#125; &#125;, &#125; vars: use_repository: true 安装 beats# ansible-playbook -i inventorys/hosts.yml ./beats.yml// 忽略输出PLAY RECAP *******************************************************************************************************************************************************************************************************************************************************************192.168.0.23 : ok=17 changed=17 unreachable=0 failed=0192.168.0.24 : ok=19 changed=19 unreachable=0 failed=0192.168.0.25 : ok=19 changed=19 unreachable=0 failed=0 表明都成功了 查看配置文件和日志ssh root@192.168.0.24cat /etc/packetbeat/packetbeat.yml ################### packetbeat Configuration ###################################################### packetbeat ######################################interfaces: device: anyprotocols: dns: include_authorities: true ports: - 53 http: ports: - 80 - 8080 - 8000 - 5000 - 8002 memcache: ports: - 11211 mongodb: ports: - 27017 mysql: ports: - 3306 pgsql: ports: - 5432 redis: ports: - 6379 thrift: ports: - 9090############################################################################################################ Libbeat Config ################################### Base config file used by all other beats for using libbeat features############################# Output ##########################################output: elasticsearch: hosts: - localhost:9200############################# Logging #########################################logging: files: rotateeverybytes: 10485760 # less /var/log/packetbeat/packetbeat2019-04-13T09:38:44.865+0800 INFO instance/beat.go:611 Home path: [/usr/share/packetbeat] Config path: [/etc/packetbeat] Data path: [/var/lib/packetbeat] Logs path: [/var/log/packetbeat]2019-04-13T09:38:44.868+0800 INFO instance/beat.go:618 Beat UUID: 8fbd86a8-0bbc-4349-8aca-d4dc8c897ba22019-04-13T09:38:44.868+0800 INFO [seccomp] seccomp/seccomp.go:116 Syscall filter successfully installed2019-04-13T09:38:44.868+0800 INFO [beat] instance/beat.go:931 Beat info &#123;\"system_info\": &#123;\"beat\": &#123;\"path\": &#123;\"config\": \"/etc/packetbeat\", \"data\": \"/var/lib/packetbeat\", \"home\": \"/usr/share/packetbeat\", \"logs\": \"/var/log/packetbeat\"&#125;, \"type\": \"packetbeat\", \"uuid\": \"8fbd86a8-0bbc-4349-8aca-d4dc8c897ba2\"&#125;&#125;&#125;2019-04-13T09:38:44.868+0800 INFO [beat] instance/beat.go:940 Build info &#123;\"system_info\": &#123;\"build\": &#123;\"commit\": \"1d55b4bd9dbf106a4ad4bc34fe9ee425d922363b\", \"libbeat\": \"6.7.1\", \"time\": \"2019-04-02T15:15:12.000Z\", \"version\": \"6.7.1\"&#125;&#125;&#125;2019-04-13T09:38:44.868+0800 INFO [beat] instance/beat.go:943 Go runtime info &#123;\"system_info\": &#123;\"go\": &#123;\"os\":\"linux\",\"arch\":\"amd64\",\"max_procs\":4,\"version\":\"go1.10.8\"&#125;&#125;&#125;2019-04-13T09:38:44.872+0800 INFO [beat] instance/beat.go:947 Host info &#123;\"system_info\": &#123;\"host\": &#123;\"architecture\":\"x86_64\",\"boot_time\":\"2019-04-12T20:58:45+08:00\",\"containerized\":true,\"name\":\"localhost.localdomain\",\"ip\":[\"127.0.0.1/8\",\"::1/128\",\"172.60.20.116/24\",\"fe80::536d:17d0:e9f6:57c/64\"],\"kernel_version\":\"3.10.0-957.el7.x86_64\",\"mac\":[\"00:50:56:9f:8b:b7\"],\"os\":&#123;\"family\":\"redhat\",\"platform\":\"centos\",\"name\":\"CentOS Linux\",\"version\":\"7 (Core)\",\"major\":7,\"minor\":6,\"patch\":1810,\"codename\":\"Core\"&#125;,\"timezone\":\"CST\",\"timezone_offset_sec\":28800,\"id\":\"cd7bb2d0c80a41c89bb5b596c22fc85e\"&#125;&#125;&#125;2019-04-13T09:38:44.873+0800 INFO [beat] instance/beat.go:976 Process info &#123;\"system_info\": &#123;\"process\": &#123;\"capabilities\": &#123;\"inheritable\":null,\"permitted\":[\"chown\",\"dac_override\",\"dac_read_search\",\"fowner\",\"fsetid\",\"kill\",\"setgid\",\"setuid\",\"setpcap\",\"linux_immutable\",\"net_bind_service\",\"net_broadcast\",\"net_admin\",\"net_raw\",\"ipc_lock\",\"ipc_owner\",\"sys_module\",\"sys_rawio\",\"sys_chroot\",\"sys_ptrace\",\"sys_pacct\",\"sys_admin\",\"sys_boot\",\"sys_nice\",\"sys_resource\",\"sys_time\",\"sys_tty_config\",\"mknod\",\"lease\",\"audit_write\",\"audit_control\",\"setfcap\",\"mac_override\",\"mac_admin\",\"syslog\",\"wake_alarm\",\"block_suspend\"],\"effective\":[\"chown\",\"dac_override\",\"dac_read_search\",\"fowner\",\"fsetid\",\"kill\",\"setgid\",\"setuid\",\"setpcap\",\"linux_immutable\",\"net_bind_service\",\"net_broadcast\",\"net_admin\",\"net_raw\",\"ipc_lock\",\"ipc_owner\",\"sys_module\",\"sys_rawio\",\"sys_chroot\",\"sys_ptrace\",\"sys_pacct\",\"sys_admin\",\"sys_boot\",\"sys_nice\",\"sys_resource\",\"sys_time\",\"sys_tty_config\",\"mknod\",\"lease\",\"audit_write\",\"audit_control\",\"setfcap\",\"mac_override\",\"mac_admin\",\"syslog\",\"wake_alarm\",\"block_suspend\"],\"bounding\":[\"chown\",\"dac_override\",\"dac_read_search\",\"fowner\",\"fsetid\",\"kill\",\"setgid\",\"setuid\",\"setpcap\",\"linux_immutable\",\"net_bind_service\",\"net_broadcast\",\"net_admin\",\"net_raw\",\"ipc_lock\",\"ipc_owner\",\"sys_module\",\"sys_rawio\",\"sys_chroot\",\"sys_ptrace\",\"sys_pacct\",\"sys_admin\",\"sys_boot\",\"sys_nice\",\"sys_resource\",\"sys_time\",\"sys_tty_config\",\"mknod\",\"lease\",\"audit_write\",\"audit_control\",\"setfcap\",\"mac_override\",\"mac_admin\",\"syslog\",\"wake_alarm\",\"block_suspend\"],\"ambient\":null&#125;, \"cwd\": \"/\", \"exe\": \"/usr/share/packetbeat/bin/packetbeat\", \"name\": \"packetbeat\", \"pid\": 9683, \"ppid\": 1, \"seccomp\": &#123;\"mode\":\"filter\"&#125;, \"start_time\": \"2019-04-13T09:38:44.350+0800\"&#125;&#125;&#125;2019-04-13T09:38:44.874+0800 INFO instance/beat.go:280 Setup Beat: packetbeat; Version: 6.7.12019-04-13T09:38:44.874+0800 INFO elasticsearch/client.go:164 Elasticsearch url: http://localhost:92002019-04-13T09:38:44.875+0800 INFO [publisher] pipeline/module.go:110 Beat name: localhost.localdomain2019-04-13T09:38:44.875+0800 INFO procs/procs.go:101 Process watcher disabled2019-04-13T09:38:44.877+0800 INFO instance/beat.go:402 packetbeat start running.2019-04-13T09:38:44.877+0800 INFO [monitoring] log/log.go:117 Starting metrics logging every 30s2019-04-13T09:39:14.887+0800 INFO [monitoring] log/log.go:144 Non-zero metrics in the last 30s &#123;\"monitoring\": &#123;\"metrics\": &#123;\"beat\":&#123;\"cpu\":&#123;\"system\":&#123;\"ticks\":160,\"time\":&#123;\"ms\":162&#125;&#125;,\"total\":&#123;\"ticks\":610,\"time\":&#123;\"ms\":614&#125;,\"value\":0&#125;,\"user\":&#123;\"ticks\":450,\"time\":&#123;\"ms\":452&#125;&#125;&#125;,\"handles\":&#123;\"limit\":&#123;\"hard\":4096,\"soft\":1024&#125;,\"open\":7&#125;,\"info\":&#123;\"ephemeral_id\":\"691a2203-1433-44d4-b173-938a52dbea22\",\"uptime\":&#123;\"ms\":30042&#125;&#125;,\"memstats\":&#123;\"gc_next\":36201104,\"memory_alloc\":18724416,\"memory_total\":23093208,\"rss\":45715456&#125;&#125;,\"libbeat\":&#123;\"config\":&#123;\"module\":&#123;\"running\":0&#125;&#125;,\"output\":&#123;\"type\":\"elasticsearch\"&#125;,\"pipeline\":&#123;\"clients\":0,\"events\":&#123;\"active\":0&#125;&#125;&#125;,\"system\":&#123;\"cpu\":&#123;\"cores\":4&#125;,\"load\":&#123;\"1\":0.1,\"15\":0.06,\"5\":0.05,\"norm\":&#123;\"1\":0.025,\"15\":0.015,\"5\":0.0125&#125;&#125;&#125;&#125;&#125;&#125; 参考资料 Latest Releases via Apt (Ubuntu) Windows Guides Document npcap requires WinPcap Compatible Mode 招聘小广告山东济南的小伙伴欢迎投简历啊 加入我们 , 一起搞事情。长期招聘，Java 程序员，大数据工程师，运维工程师，前端工程师。","tags":[{"name":"ansible","slug":"ansible","permalink":"https://anjia0532.github.io/tags/ansible/"},{"name":"运维","slug":"运维","permalink":"https://anjia0532.github.io/tags/运维/"},{"name":"linux","slug":"linux","permalink":"https://anjia0532.github.io/tags/linux/"},{"name":"beats","slug":"beats","permalink":"https://anjia0532.github.io/tags/beats/"},{"name":"es","slug":"es","permalink":"https://anjia0532.github.io/tags/es/"},{"name":"elasticsearch","slug":"elasticsearch","permalink":"https://anjia0532.github.io/tags/elasticsearch/"}]},{"title":"014-活该你爬虫被封之Scrapy Ip代理中间件","date":"2019-04-02T20:41:00.000Z","path":"2019/04/02/scrapy-proxy/","text":"这是坚持技术写作计划（含翻译）的第 14 篇，定个小目标 999，每周最少 2 篇。 背景: 房租到期了。需求: 找到便宜，交通便利的房源，了解当前租房行情，便于砍价。 在爬取 58，赶集，链家，安居客的数据时，被封是常事，基于此，fork 并修改了两个库。用于抓取免费代理 ip，用于支持爬取租房数据。 注意：租房网站的数据，大概率失真，仅做参考。 其中部分数据截图 本文只介绍 Scrapy 的 ip 代理中间件，不多讲如何爬取租房网站数据以及数据分析，后边可能会写。 获取代理 ip如果有付费的代理 ip 更好，如果没有的话，可以用我构建的 docker 镜像 docker run -p8765:8765 -d anjia0532/ipproxy-dockerfile 稍等 2-5 分钟，访问 http://${docker ip}:8765/ ,如果有值，则抓取代理 ip 成功。 scrapy-proxies-tool安装pip install scrapy-proxies-tool 配置修改 Scrapy settings.py，源repo 只支持从文件读取代理 ip # Retry many times since proxies often failRETRY_TIMES = 10# Retry on most error codes since proxies fail for different reasonsRETRY_HTTP_CODES = [500, 503, 504, 400, 403, 404, 408]DOWNLOADER_MIDDLEWARES = &#123; 'scrapy.downloadermiddlewares.retry.RetryMiddleware': 90, 'scrapy_proxies.RandomProxy': 100, 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware': 110,&#125;PROXY_SETTINGS = &#123; # Proxy list containing entries like # http://host1:port # http://username:password@host2:port # http://host3:port # ... # if PROXY_SETTINGS[from_proxies_server] = True , proxy_list is server address (ref https://github.com/qiyeboy/IPProxyPool and https://github.com/awolfly9/IPProxyTool ) # Only support http(ref https://github.com/qiyeboy/IPProxyPool#%E5%8F%82%E6%95%B0) # list : ['http://localhost:8765?protocol=0'], 'list':['/path/to/proxy/list.txt'], # disable proxy settings and use real ip when all proxies are unusable 'use_real_when_empty':False, 'from_proxies_server':False, # If proxy mode is 2 uncomment this sentence : # 'custom_proxy': \"http://host1:port\", # Proxy mode # 0 = Every requests have different proxy # 1 = Take only one proxy from the list and assign it to every requests # 2 = Put a custom proxy to use in the settings 'mode':0&#125; 可以通过爬取 http://myip.ipip.net/ 来判断代理 ip 是否生效。 参考资料 https://github.com/anjia0532/IPProxyPool https://hub.docker.com/r/anjia0532/ipproxy-dockerfile https://github.com/aivarsk/scrapy-proxies https://github.com/anjia0532/scrapy-proxies","tags":[{"name":"python","slug":"python","permalink":"https://anjia0532.github.io/tags/python/"},{"name":"scrapy","slug":"scrapy","permalink":"https://anjia0532.github.io/tags/scrapy/"},{"name":"proxy","slug":"proxy","permalink":"https://anjia0532.github.io/tags/proxy/"}]},{"title":"013-阿里Dragonfly体验之私有registry下载","date":"2019-03-30T10:17:00.000Z","path":"2019/03/30/d7y-private-registry/","text":"这是坚持技术写作计划（含翻译）的第 13 篇，定个小目标 999，每周最少 2 篇。 书接上篇 012-P2P 加速 Docker 镜像分发(阿里 Dragonfly) ,讲解了如何快速搭建 Dragonfly,但是访问的是公开镜像，本文主要讲解如何下载私有镜像。 实验环境主机 类型 主机名 系统 ip docker version supernode d7y-1 Ubuntu Server 16.04.6 LTS X64 192.168.0.75 17.06.2ubuntu clinet1 d7y-2 Ubuntu Server 16.04.6 LTS X64 192.168.0.76 17.06.2ubuntu clinet2 d7y-3 Ubuntu Server 16.04.6 LTS X64 192.168.0.77 17.06.2ubuntu 私有 registry本次以阿里云私有镜像库为例，可以自行开通。 文档之坑官方文档比较简单,甚至带有误导性，下意识的以为应该在 dfdaemon 节点上配置 auth 信息，并且配的是真实的私有 registry，如果真这么搞了，肯定被坑。（但是也能解释通，比较绕，dfdaemon 本身就是一个伪装成 registry，用来加速私有 registry，那么登陆信息就应该换成 dfdaemon ip，只是示例不太恰当而已，对初学者相当不友好倒是真的） supernode 步骤安装 supernoderoot@d7y-1:~# docker run --name dragonfly-supernode --restart=always \\ -d -p 8001:8001 -p 8002:8002 -v /data/dragonfly/supernode:/home/admin/supernode \\ registry.cn-hangzhou.aliyuncs.com/dragonflyoss/supernode:0.3.0 \\ -Dsupernode.advertiseIp=192.168.0.75root@d7y-1:~# docker psCONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMESbe7fb931db0b registry.cn-hangzhou.aliyuncs.com/dragonflyoss/supernode:0.3.0 \"/bin/sh -c '/root...\" About a minute ago Up About a minute 0.0.0.0:8001-8002-&gt;8001-8002/tcp dragonfly-supernoderoot@d7y-1:/data/dragonfly/supernode/logs# cat app.log2019-03-30 01:04:40.065 INFO [ main] c.d.d.s.SuperNodeStarter - Starting SuperNodeStarter on be7fb931db0b with PID 9 (/supernode.jar started by root in /)2019-03-30 01:04:40.069 INFO [ main] c.d.d.s.SuperNodeStarter - No active profile set, falling back to default profiles: default2019-03-30 01:04:42.151 INFO [ main] c.d.d.s.c.SupernodeProperties - init local ip of supernode, use ip:192.168.0.752019-03-30 01:04:42.253 INFO [ main] c.d.d.s.c.SupernodeProperties - cluster members: [&#123;\"downloadPort\":8001,\"ip\":\"localhost\",\"registerPort\":8002&#125;]2019-03-30 01:04:42.263 INFO [ main] c.d.d.s.c.util.MonitorService - available processors count is 42019-03-30 01:04:42.272 ERROR [ Thread-2] c.d.d.s.c.util.MonitorService - process fields:null errorjava.io.IOException: Cannot run program \"tsar\": error=2, No such file or directory at java.lang.ProcessBuilder.start(ProcessBuilder.java:1048) at java.lang.Runtime.exec(Runtime.java:620) at java.lang.Runtime.exec(Runtime.java:450) at java.lang.Runtime.exec(Runtime.java:347) at com.dragonflyoss.dragonfly.supernode.common.util.MonitorService$1.run(MonitorService.java:56) at java.lang.Thread.run(Thread.java:748)Caused by: java.io.IOException: error=2, No such file or directory at java.lang.UNIXProcess.forkAndExec(Native Method) at java.lang.UNIXProcess.&lt;init&gt;(UNIXProcess.java:247) at java.lang.ProcessImpl.start(ProcessImpl.java:134) at java.lang.ProcessBuilder.start(ProcessBuilder.java:1029) ... 5 common frames omitted2019-03-30 01:04:43.507 INFO [ main] c.d.d.s.SuperNodeStarter - Started SuperNodeStarter in 3.906 seconds (JVM running for 4.59)2019-03-30 01:04:49.472 INFO [ spring-1] c.d.d.s.s.p.PreheatServiceImpl - deleteExpiresPreheatTask, count:0 从 2019-03-30 01:04:42.151 INFO [ main] c.d.d.s.c.SupernodeProperties - init local ip of supernode, use ip:192.168.0.75 看，启动 ip 设置成功. 注意，官方的镜像没改时区，默认是 UTC 时间，比北京东八区早 8 小时。 登陆私有 registry 并推送镜像root@d7y-1:~# docker login https://registry.cn-qingdao.aliyuncs.comUsername: //你阿里云账号Password: //你阿里云密码Login Succeededroot@d7y-1:~# docker pull nginx:alpineroot@d7y-1:~# docker tag nginx:alpine registry.cn-qingdao.aliyuncs.com/d7y-test/nginx:alpineroot@d7y-1:~# docker push registry.cn-qingdao.aliyuncs.com/d7y-test/nginx:alpinealpine: digest: sha256:857e6f195df0e9b497be0c7fad0f013126407aaeb71edcef66a24e8b990d94b3 size: 1153 dfdaemon 步骤安装 dfdaemon在两台 client 节点分别执行如下命令 root@d7y-2:~# cat &lt;&lt;EOD &gt;/etc/dragonfly.conf[node]address=192.168.0.75EODroot@d7y-2:~# docker run --name dragonfly-dfclient --restart=always \\ -d -p 65001:65001 -v /root/.small-dragonfly:/root/.small-dragonfly \\ -v /etc/dragonfly.conf:/etc/dragonfly.conf dragonflyoss/dfclient:v0.3.0 \\ --registry=https://registry.cn-qingdao.aliyuncs.com --ratelimit 100MUnable to find image 'dragonflyoss/dfclient:v0.3.0' locallyv0.3.0: Pulling from dragonflyoss/dfclient169185f82c45: Pull completef58f64214283: Pull completebd8f062dc2d2: Pull completeDigest: sha256:5bcabd5b34f4da0c2d489c8f99a23a401fb9ec57e54d4fa90457a93c5a85371fStatus: Downloaded newer image for dragonflyoss/dfclient:v0.3.0b491e90489a584119b82ca934cf2ae087abc136f7f9de3542e14fb12bc1c7512root@d7y-2:~# cat &lt;&lt;EOD &gt;/etc/docker/daemon.json&#123;\"registry-mirrors\": [\"http://127.0.0.1:65001\"]&#125;EODroot@d7y-2:~# systemctl restart dockerroot@d7y-2:~# docker psCONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMESb491e90489a5 dragonflyoss/dfclient:v0.3.0 \"/dfclient/dfdaemo...\" 28 seconds ago Up 4 seconds 0.0.0.0:65001-&gt;65001/tcp dragonfly-dfclientroot@d7y-2:~/.small-dragonfly/logs# cat dfdaemon.log2019-03-30 01:18:21.331 INFO sign:1 : init...2019-03-30 01:18:21.331 INFO sign:1 : rotate log routine start...2019-03-30 01:18:21.338 INFO sign:1 : dfget version:2019-03-30 01:18:21.338 ERRO sign:1 : init properties failed:open /etc/dragonfly/dfdaemon.yml: no such file or directory2019-03-30 01:18:21.338 INFO sign:1 : init properties:&#123;\"Registries\":[&#123;\"Schema\":\"https\",\"Host\":\"registry.cn-qingdao.aliyuncs.com\",\"Certs\":null,\"Regx\":\"(^localhost$)|(^127.0.0.1$)|(^127.0.0.1$)\"&#125;]&#125;2019-03-30 01:18:21.338 INFO sign:1 : init finish2019-03-30 01:18:21.338 INFO sign:1 : start dfdaemon param: &amp;&#123;DfPath:/dfclient/dfget DFRepo:/root/.small-dragonfly/dfdaemon/data/ RateLimit:100M CallSystem:com_ops_dragonfly URLFilter:Signature&amp;Expires&amp;OSSAccessKeyId Notbs:true MaxProcs:4 Version:false Verbose:false HostIP:127.0.0.1 Port:65001 Registry:https://registry.cn-qingdao.aliyuncs.com DownRule: CertFile: KeyFile: TrustHosts:[] ConfigPath:/etc/dragonfly/dfdaemon.yml&#125;2019-03-30 01:18:21.338 INFO sign:1 : launch dfdaemon http server on 127.0.0.1:65001 登陆 dfdaemonroot@d7y-2:~# docker login http://127.0.0.1:65001Username: //你阿里云账号Password: //你阿里云密码Login Succeededroot@d7y-2:~# cat ~/.docker/config.json&#123; \"auths\": &#123; \"127.0.0.1:65001\": &#123; \"auth\": \"zzxxxxxx=\" &#125; &#125;&#125; pull 私有镜像root@d7y-2:~# docker pull 127.0.0.1:65001/d7y-test/nginx:alpinealpine: Pulling from d7y-test/nginx8e402f1a9c57: Pull complete56b0d9b69cc9: Pull completeb66c8bb200cc: Pull complete4ec77fc9c55f: Pull completeDigest: sha256:857e6f195df0e9b497be0c7fad0f013126407aaeb71edcef66a24e8b990d94b3Status: Downloaded newer image for 127.0.0.1:65001/d7y-test/nginx:alpine 可以通过 iftop 等命令，观察流量。 其他排错如果有遇到其他问题，可以通过查看日志来获取更多信息。dfdaemon log : /root/.small-dragonfly/logs/{dfclient.log,dfdaemon.log,dfserver.log}supernode log: /home/admin/supernode/{app.log,data-gc.log,downloader.log,piece-hit.log,space-gc.log} 公开和私有 registry 混用如果大量都是私有 registry 的话，可以在/etc/docker/daemon.json 中配置 dfdaemon 和加速器，如果是一半一半的话，那就干脆起两个 dfdaemon 就行了，一个–registry 写私有的，一个–registry 写公有的，然后也是配置 /etc/docker/daemon.json cat /etc/docker/daemon.json&#123; \"registry-mirrors\": [\"http://127.0.0.1:65001\",\"https://xxx.mirror.aliyuncs.com\"], \"dns\": [\"223.5.5.5\"]&#125; 吐槽再次吐槽一下 d7y 的产品很好，解决了很大问题。但是这文档，真心不是给新手看的。从未见过如此坑多且深的文档。没见过哪家 quick start 写的这么复杂。 鸣谢非常感谢钉钉群内的 d7y 的 contributor 太云-lowzj 耐心解答，从开始研究 d7y 开始，遇到的很多坑都是在 太云-lowzj 帮助下蹚过去的。但是还是觉得，如果文档足够友好，肯定会减少群内被打扰的次数，进而节省自己时间的。 招聘小广告山东济南的小伙伴欢迎投简历啊 加入我们 , 一起搞事情。 长期招聘，Java 程序员，大数据工程师，运维工程师，前端工程师。","tags":[{"name":"docker","slug":"docker","permalink":"https://anjia0532.github.io/tags/docker/"},{"name":"k8s","slug":"k8s","permalink":"https://anjia0532.github.io/tags/k8s/"},{"name":"kubernetes","slug":"kubernetes","permalink":"https://anjia0532.github.io/tags/kubernetes/"},{"name":"alibaba","slug":"alibaba","permalink":"https://anjia0532.github.io/tags/alibaba/"},{"name":"Dragonfly","slug":"Dragonfly","permalink":"https://anjia0532.github.io/tags/Dragonfly/"}]},{"title":"012-P2P加速Docker镜像分发(阿里Dragonfly)","date":"2019-03-25T16:58:00.000Z","path":"2019/03/25/dragonfly/","text":"这是坚持技术写作计划（含翻译）的第 12 篇，定个小目标 999，每周最少 2 篇。 吐槽一下，最近有点懒，居然欠了 4 篇，后续会慢慢补上。 介绍如果说，微服务和容器是最佳拍档，那么模块多实例是肯定少不了。假如没有使用类似 Google jib 等手段进行镜像分层（利用镜像缓存），势必会造成 带宽浪费：尤其是公网带宽，如果是自建 harbor，那么会容易导致单节点网卡被打满，如果用了 harbor 联邦，又会导致数据同步等运维问题。 集群拉起慢：镜像下载慢，必然会导致服务拉起慢。 关于 Google jib 可以参见我另外一篇 加速和简化构建 Docker(基于 Google jib) ，本文只介绍 Dragonfly + dfdaemon Dragonfly 是阿里巴巴自研并开源的一款基于 P2P 协议的文件分发系统。除了使用 dfget 进行文件下载外，还支持 dfdaemon 进行 docker 镜像下载。 关于 Dragonfly 的镜像分发的原理性说明，可参见 直击阿里双 11 神秘技术：PB 级大规模文件分发系统“蜻蜓” ，文中介绍很详细，此处不多说明。 实验环境 类型 系统 ip docker version supernode Ubuntu Server 16.04.6 LTS X64 192.168.0.44 17.06.2~ce-0~ubuntu clinet1 Ubuntu Server 16.04.6 LTS X64 192.168.0.40 17.06.2~ce-0~ubuntu clinet2 Ubuntu Server 16.04.6 LTS X64 192.168.0.45 17.06.2~ce-0~ubuntu 注意：如果是实验目的，建议用 Vmware，并且在关键操作时备份快照（比如，刚装完环境），这样能够及时，干净的还原现场，节省每次重装系统导致的时间浪费 安装 吐槽一下 Dragonfly 的文档，简直让人不知所以。结合 issues + 钉钉群内请教，遂整理出最简使用文档。 supernode可选：给 supernode 增加 docker 加速器，可以参考 https://cr.console.aliyun.com/cn-hangzhou/instances/mirrors ，如果不需要，可以去掉。 $ cat &lt;&lt;EOD &gt;/etc/docker/daemon.json&#123;\"registry-mirrors\": [\"https://xxxx.mirror.aliyuncs.com\"]&#125;EOD$ systemctl restart docker $ docker run --name dragonfly-supernode --restart=always -d -p 8001:8001 -p 8002:8002 -v /data/dragonfly/supernode:/home/admin/supernode registry.cn-hangzhou.aliyuncs.com/dragonflyoss/supernode:0.3.0 -Dsupernode.advertiseIp=192.168.0.44 说明： –restart=always 在容器退出时，自动重启容器，防止异常 kill 或者 oom 导致的异常退出 registry.cn-hangzhou.aliyuncs.com/dragonflyoss/supernode:0.3.0 dragonfly 的 supernode 目前没有 docker hub 镜像，只能用阿里云的 -v /data/dragonfly/supernode:/home/admin/supernode 将 supernode 的 data dir 挂载到宿主机上 -Dsupernode.advertiseIp=192.168.0.44 设置 clinet 可以访问的 supernode ip,这是一个大坑。如果不设置，有可能会导致 client 无法连接 supernode，届时，docker pull 会走 clinet 的网络，从真实的 registry 直接下载镜像 dfdaemon$ cat &lt;&lt;EOD &gt;/etc/dragonfly.conf[node]address=192.168.0.44EOD$ docker run --name dragonfly-dfclient --restart=always -d -p 65001:65001 -v /root/.small-dragonfly:/root/.small-dragonfly -v /etc/dragonfly.conf:/etc/dragonfly.conf dragonflyoss/dfclient:v0.3.0 --registry=https://xxx.mirror.aliyuncs.com --ratelimit 100M$ cat &lt;&lt;EOD &gt;/etc/docker/daemon.json&#123;\"registry-mirrors\": [\"http://127.0.0.1:65001\"]&#125;EOD$ systemctl restart docker 说明： 在 /etc/dragonfly.conf 中配置 client 可以访问的 supernode 的 ip 地址，但是，目前官方没有做 HA，supernode 没法组集群，撑死算是联邦，不能共享文件信息，而且最坑的是，快速开始里，中英文均未提供需要配置此文件，而是在 Downloading Files with Dragonfly 等有所提及（我都是被坑完后，用关键词在 d7y 的 org 里搜索，类似知道答案后，找出处 手动[捂脸]） -v /root/.small-dragonfly:/root/.small-dragonfly ,将容器中的关键目录挂载到宿主机上，防止重启或者镜像升级时，数据丢失 –registry=https://xxx.mirror.aliyuncs.com 从何处下载镜像，可以写 harbor 地址，也可以写加速器地址。默认是 https://index.docker.io ，但是，因为国内网络原因，会导致大概率性失败。很灵异。而官方文档是写的 --registry https://xxx.xx.x 不能算是坑，但是，对于 docker 不熟悉的，往往会不知能不能用加速器。 –ratelimit 100M 是限速，默认是 20M ,这肯定不算坑哈，这是正常特性，在 dfdaemon#Options 有说明，但是，文档是有误的 -ratelimit 而实际是 --ratelimit ,如果不改此参数，会发现，下载很慢。 修改/etc/docker/daemon.json 是为了让 docker engine 走 dfdaemon systemctl restart docker 是为了让 daemon 生效 测试大文件测试$ docker pull anjia0532/kubeflow-images-public.tensorflow-1.6.0-notebook-gpu:v20180604-b3733835 可以通过 iftop 等软件，查看带宽使用情况判断是否生效，也可以通过查看日志来判断。但是会经常性的出现 error pulling image configuration: received unexpected HTTP status: 502 Bad Gateway 最后需要结合实际情况，配置相关参数，比如，文件失效时间，用来平衡文件有效期及磁盘使用量。 参考资料 直击阿里双 11 神秘技术：PB 级大规模文件分发系统“蜻蜓” 深度解读阿里巴巴云原生镜像分发系统 Dragonfly Dragonfly Quick Start 加速和简化构建 Docker(基于 Google jib) 浙江移动容器云基于 Dragonfly 的统一文件分发平台生产实践 招聘小广告山东济南的小伙伴欢迎投简历啊 加入我们 , 一起搞事情。 长期招聘，Java 程序员，大数据工程师，运维工程师，前端工程师。","tags":[{"name":"docker","slug":"docker","permalink":"https://anjia0532.github.io/tags/docker/"},{"name":"k8s","slug":"k8s","permalink":"https://anjia0532.github.io/tags/k8s/"},{"name":"kubernetes","slug":"kubernetes","permalink":"https://anjia0532.github.io/tags/kubernetes/"},{"name":"alibaba","slug":"alibaba","permalink":"https://anjia0532.github.io/tags/alibaba/"},{"name":"Dragonfly","slug":"Dragonfly","permalink":"https://anjia0532.github.io/tags/Dragonfly/"}]},{"title":"011-openresty的maxminddb插件","date":"2019-03-14T23:26:00.000Z","path":"2019/03/14/openresty-maxminddb/","text":"这是坚持技术写作计划（含翻译）的第 11 篇，定个小目标 999，每周最少 2 篇。 本文主要介绍我之前基于 openresty 写的 maxminddb 的解析插件 – anjia0532/lua-resty-maxminddb (已开源)。主要用途是根据 ip 获取地理位置。国内精确度不如国内ipip.net ，但是胜在免费。在精确度要求不高的场景，还是可以用的。 如果要用 ipip.net 的 lua 库，可以参考官方的 ipipdotnet/ipdb-luajit 前提条件OpenResty# import our GPG key:wget -qO - https://openresty.org/package/pubkey.gpg | sudo apt-key add -# for installing the add-apt-repository command# (you can remove this package and its dependencies later):sudo apt-get -y install software-properties-common# add the our official APT repository:sudo add-apt-repository -y \"deb http://openresty.org/package/ubuntu $(lsb_release -sc) main\"# to update the APT index:sudo apt-get updatesudo apt-get install openresty maxmind/libmaxminddb &amp;&amp; maxmind/geoipupdatesudo add-apt-repository ppa:maxmind/ppasudo apt updatesudo apt install libmaxminddb0 libmaxminddb-dev mmdb-bin geoipupdate 配置 geoipupdatesudo tee /etc/GeoIP.conf &lt;&lt;-'EOF'# The following AccountID and LicenseKey are required placeholders.# For geoipupdate versions earlier than 2.5.0, use UserId here instead of AccountID.AccountID 0LicenseKey 000000000000# Include one or more of the following edition IDs:# * GeoLite2-City - GeoLite 2 City# * GeoLite2-Country - GeoLite2 Country# For geoipupdate versions earlier than 2.5.0, use ProductIds here instead of EditionIDs.EditionIDs GeoLite2-City GeoLite2-CountryEOFsudo /usr/local/bin/geoipupdate 安装和使用 lua-resty-maxminddb安装opm get anjia0532/lua-resty-maxminddb 配置 openrestylocal cjson = require 'cjson'local geo = require 'resty.maxminddb'if not geo.initted() then geo.init(\"/path/to/GeoLite2-City.mmdb\")endlocal res,err = geo.lookup(ngx.var.arg_ip or ngx.var.remote_addr) --support ipv6 e.g. 2001:4860:0:1001::3004:ef68if not res then ngx.log(ngx.ERR,'failed to lookup by ip ,reason:',err)endngx.say(\"full :\",cjson.encode(res))if ngx.var.arg_node then ngx.say(\"node name:\",ngx.var.arg_node,\" ,value:\", cjson.encode(res[ngx.var.arg_node] or &#123;&#125;))end 测试#ipv4curl localhost/ip=114.114.114.114&amp;node=city#ipv6#curl localhost/ip=2001:4860:0:1001::3004:ef68&amp;node=countryfull :&#123;\"city\":&#123;\"geoname_id\":1799962,\"names\":&#123;\"en\":\"Nanjing\",\"ru\":\"Нанкин\",\"fr\":\"Nankin\",\"pt-BR\":\"Nanquim\",\"zh-CN\":\"南京\",\"es\":\"Nankín\",\"de\":\"Nanjing\",\"ja\":\"南京市\"&#125;&#125;,\"subdivisions\":[&#123;\"geoname_id\":1806260,\"names\":&#123;\"en\":\"Jiangsu\",\"fr\":\"Province de Jiangsu\",\"zh-CN\":\"江苏省\"&#125;,\"iso_code\":\"32\"&#125;],\"country\":&#123;\"geoname_id\":1814991,\"names\":&#123;\"en\":\"China\",\"ru\":\"Китай\",\"fr\":\"Chine\",\"pt-BR\":\"China\",\"zh-CN\":\"中国\",\"es\":\"China\",\"de\":\"China\",\"ja\":\"中国\"&#125;,\"iso_code\":\"CN\"&#125;,\"registered_country\":&#123;\"geoname_id\":1814991,\"names\":&#123;\"en\":\"China\",\"ru\":\"Китай\",\"fr\":\"Chine\",\"pt-BR\":\"China\",\"zh-CN\":\"中国\",\"es\":\"China\",\"de\":\"China\",\"ja\":\"中国\"&#125;,\"iso_code\":\"CN\"&#125;,\"location\":&#123;\"time_zone\":\"Asia\\/Shanghai\",\"longitude\":118.7778,\"accuracy_radius\":50,\"latitude\":32.0617&#125;,\"continent\":&#123;\"geoname_id\":6255147,\"names\":&#123;\"en\":\"Asia\",\"ru\":\"Азия\",\"fr\":\"Asie\",\"pt-BR\":\"Ásia\",\"zh-CN\":\"亚洲\",\"es\":\"Asia\",\"de\":\"Asien\",\"ja\":\"アジア\"&#125;,\"code\":\"AS\"&#125;&#125;node name:city ,value:&#123;\"geoname_id\":1799962,\"names\":&#123;\"en\":\"Nanjing\",\"ru\":\"Нанкин\",\"fr\":\"Nankin\",\"pt-BR\":\"Nanquim\",\"zh-CN\":\"南京\",\"es\":\"Nankín\",\"de\":\"Nanjing\",\"ja\":\"南京市\"&#125;&#125; 格式化一下 full: &#123; \"city\": &#123; \"geoname_id\": 1799962, \"names\": &#123; \"en\": \"Nanjing\", \"ru\": \"Нанкин\", \"fr\": \"Nankin\", \"pt-BR\": \"Nanquim\", \"zh-CN\": \"南京\", \"es\": \"Nankín\", \"de\": \"Nanjing\", \"ja\": \"南京市\" &#125; &#125;, \"subdivisions\": [&#123; \"geoname_id\": 1806260, \"names\": &#123; \"en\": \"Jiangsu\", \"fr\": \"Province de Jiangsu\", \"zh-CN\": \"江苏省\" &#125;, \"iso_code\": \"32\" &#125; ], \"country\": &#123; \"geoname_id\": 1814991, \"names\": &#123; \"en\": \"China\", \"ru\": \"Китай\", \"fr\": \"Chine\", \"pt-BR\": \"China\", \"zh-CN\": \"中国\", \"es\": \"China\", \"de\": \"China\", \"ja\": \"中国\" &#125;, \"iso_code\": \"CN\" &#125;, \"registered_country\": &#123; \"geoname_id\": 1814991, \"names\": &#123; \"en\": \"China\", \"ru\": \"Китай\", \"fr\": \"Chine\", \"pt-BR\": \"China\", \"zh-CN\": \"中国\", \"es\": \"China\", \"de\": \"China\", \"ja\": \"中国\" &#125;, \"iso_code\": \"CN\" &#125;, \"location\": &#123; \"time_zone\": \"Asia\\/Shanghai\", \"longitude\": 118.7778, \"accuracy_radius\": 50, \"latitude\": 32.0617 &#125;, \"continent\": &#123; \"geoname_id\": 6255147, \"names\": &#123; \"en\": \"Asia\", \"ru\": \"Азия\", \"fr\": \"Asie\", \"pt-BR\": \"Ásia\", \"zh-CN\": \"亚洲\", \"es\": \"Asia\", \"de\": \"Asien\", \"ja\": \"アジア\" &#125;, \"code\": \"AS\" &#125;&#125;node name: city, value: &#123; \"geoname_id\": 1799962, \"names\": &#123; \"en\": \"Nanjing\", \"ru\": \"Нанкин\", \"fr\": \"Nankin\", \"pt-BR\": \"Nanquim\", \"zh-CN\": \"南京\", \"es\": \"Nankín\", \"de\": \"Nanjing\", \"ja\": \"南京市\" &#125;&#125; 压测 &amp; 性能事先安装好 wrk sudo tee /tmp/wrk.lua &lt;&lt;-'EOF'wrk.method = \"GET\";wrk.body = \"\";logfile = io.open(\"wrk.log\", \"w\");request = function()ip = tostring(math.random(1, 255))..\".\"..tostring(math.random(1, 255))..\".\"..tostring(math.random(1, 255))..\".\"..tostring(math.random(1, 255))path = \"/?ip=\" .. ipreturn wrk.format(nil, path)endresponse = function(status,header,body)logfile:write(\"\\nbody:\" .. body .. \"\\n-----------------\");endEOFsudo wrk -t50 -c200 -d120s -s /tmp/wrk.lua --latency http://127.0.0.1 参考资料 OpenResty® Linux Packages Automatic Updates for GeoIP2 and GeoIP Legacy Databases maxmind/libmaxminddb maxmind/geoipupdate wg/wrk#wiki MMDB_free_entry_data_list (entry_data_list=0x23) at maxminddb.c:1860 #9 招聘小广告山东济南的小伙伴欢迎投简历啊 加入我们 , 一起搞事情。 长期招聘，Java 程序员，大数据工程师，运维工程师，前端工程师。","tags":[{"name":"openresty","slug":"openresty","permalink":"https://anjia0532.github.io/tags/openresty/"},{"name":"nginx","slug":"nginx","permalink":"https://anjia0532.github.io/tags/nginx/"},{"name":"maxminddb","slug":"maxminddb","permalink":"https://anjia0532.github.io/tags/maxminddb/"},{"name":"maxmind","slug":"maxmind","permalink":"https://anjia0532.github.io/tags/maxmind/"},{"name":"ipip","slug":"ipip","permalink":"https://anjia0532.github.io/tags/ipip/"}]},{"title":"010-cloudboot批量安装rancheros","date":"2019-03-10T10:41:55.000Z","path":"2019/03/10/cloudboot-ros/","text":"这是坚持技术写作计划（含翻译）的第 10 篇，定个小目标 999，每周最少 2 篇。 本文主要讲解如何使用cloudboot简单批量安装rancheros。 介绍cloudbootcloudboot是 云霁科技 科技开源的一款简单易用的装机系统，类似 cobbler ,但是功能更强大，更易用。(可参考我之前写的 007-Cobbler 批量自动化部署 Windows10 和 Server 2019 和 006-Cobbler 批量自动化部署 CentOS/Ubuntu/Windows) rancherosrancheros 是 rancher lab 开源的一款容器操作系统，类似coreos,RancherOS 是 RancherLab 设计的小巧、专用的容器操作系统，可用安装到服务器本地硬盘中，也可以部署到公有云上，或者配合 DockerMachine 使用。与 Ubuntu 和 CentOS 不同，RancherOS 使用 cloud-config.yml 配置文件来管理机器的配置信息，包括系统启动时的服务、网络相关的配置信息、存储配置、容器配置等等，都可以放到配置文件中进行管理。 安装 cloudboot参考 cloudboot 一键部署 不多赘述 挂载 rancheros 镜像wget -P /tmp/ http://releases.rancher.com/os/latest/rancheros.isomkdir -p $PWD/cloudboot/deploy/iso/rancheros/1.5.1/mount -o loop /tmp/rancheros.iso /mediarsync -a /media/ $PWD/cloudboot/deploy/iso/rancheros/1.5.1/umount /media 创建软连接docker exec -it cloudboot /bin/shln -s /data/iso/rancheros /home/www/rancheros 注意： cloudboot 默认用户名密码是 admin/admin 登陆后需要配置 dhcp(【系统管理】-&gt; 【系统设置】) 需要配置网段(【网段管理】-&gt;【应用网段】) 本文讲的是 vmware，所以不需要配置 OOB 需要配置设备位置(【模板管理】-&gt;【位置管理】) 如果 cloudboot 和 rancheros 都装在 vmware 虚拟机里，需要把 vmware 的网络设置中的 dhcp 去掉，否则会冲突 pxe 安装 rancheros参考 rancheros#docs#iPXE 和 cloudboot PXE 模板定制规范 PXE 模板管理从【模板管理】-&gt;【PXE 模板管理】 新增 rancheros-1.5.1 DEFAULT rancherosLABEL rancherosKERNEL http://osinstall.idcos.com/rancheros/1.5.1/boot/vmlinuz-4.14.85-rancherAPPEND initrd=http://osinstall.idcos.com/rancheros/1.5.1/boot/initrd-v1.5.1 rancher.cloud_init.datasources=[url:http://osinstall.idcos.com/api/osinstall/v1/device/getSystemBySn?sn=&#123;sn&#125;] rancher.autologin=tty1 rancher.autologin=ttyS0 rancher.autologin=ttyS1 rancher.autologin=ttyS1 console=tty1 console=ttyS0 console=ttyS1 printk.devkmsg=on panic=10IPAPPEND 2 系统模板管理从【模板管理】-&gt;【系统模板管理】 新增 rancheros-1.5.1 把 docker mirror 换成实际的加速器，如果不需要，可以删除，ssh_authorized_keys 换成真实的 ssh key #cloud-configrancher: console: alpine docker: registry_mirror: \"https://xxx.mirror.aliyuncs.com\"runcmd: - sh -c 'curl http://osinstall.idcos.com/scripts/rancheros.sh | bash'ssh_authorized_keys: - ssh-rsa AAAA....ZZZZ user@user 自定义脚本在 cloudboot 宿主机上，运行 docker exec -it cloudboot /bin/sh ,然后运行 vim /home/www/scripts/rancheros.sh #!/bin/bashprogress() &#123; curl -H \"Content-Type: application/json\" -X POST -d \"&#123;\\\"Sn\\\":\\\"$_sn\\\",\\\"Title\\\":\\\"$1\\\",\\\"InstallProgress\\\":$2,\\\"InstallLog\\\":\\\"$3\\\"&#125;\" http://osinstall.idcos.com/api/osinstall/v1/report/deviceInstallInfo&#125;_sn=$(sed q /sys/class/net/eth0/address)progress \"配置主机名和网络\" 0.7 \"6YWN572u5Li75py65ZCN5ZKM572R57uc\"# config networkcurl -o /tmp/networkinfo \"http://osinstall.idcos.com/api/osinstall/v1/device/getNetworkBySn?sn=$&#123;_sn&#125;&amp;type=raw\"source /tmp/networkinfocat &gt; /etc/network/interfaces &lt;&lt;EOFauto loiface lo inet loopbackauto eth0iface eth0 inet staticaddress $IPADDRnetmask $NETMASKgateway $GATEWAYEOFecho \"$HOSTNAME\" &gt; /etc/hostnamesudo hostname \"$HOSTNAME\"progress \"配置alpine镜像源\" 0.8 \"6YWN572uYWxwaW5l6ZWc5YOP5rqQ\"sed -i 's/dl-cdn.alpinelinux.org/mirrors.aliyun.com/g' /etc/apk/repositoriesprogress \"安装完成\" 1 \"5a6J6KOF5a6M5oiQ\"sudo ros install -c http://osinstall.idcos.com/api/osinstall/v1/device/getSystemBySn?sn=$_sn\" -d /dev/sda -f 自动化安装 rancheros从 vmware 创建 空盘 -&gt; 其他 Linux4.x 或更高版本内核 64 位，2 核 2G 虚拟机，然后上电虚拟机会从 PXE 拉取cloudboot 的 bootos 安装到内存中，并且往 cloudboot 上注册待录入的设备（待屏幕变蓝色） 从 http://${cloudboot host}/#/dashboard/device/scan/list 会发现新设备，选中后，点击录入新设备 bootos 会自动轮询是否有自动装机任务，所以静候即可。如果等不及，可以在录入成功后，手动重启虚拟机。在【正在安装的设备】中，会自动出现要安装的设备 点击【详情】会在滚动模式下试试看到安装进度 在【设备列表】可以看到已安装成功的设备 注意不知道为嘛，安装后需要重启一下虚拟机后，才能使用 ssh 进行连接。 根据 rancher labs 大神腩哥指点 booting from ISO 首次启动，整个系统都在内存中。 执行 ros install 后，安装 bootloader 和 initrd/vmlinuz 到磁盘。 再次启动后，就是完整的运行在硬盘上的操作系统。 脑洞其实是正规操作，可以在 cloud config 配置自定义服务，这样装机后，就可以直接启动服务，不需要 ssh 到 ros 上，手动执行命令，例如配置 rancher client 的添加主机的命令，这样就可以直接添加到已有集群。 更多参考 Custom System Services #cloud-configrancher: services: nginxapp: image: nginx restart: always 参考资料 cloudboot 一键部署 cloudboot PXE 模板定制规范 rancheros#docs#iPXE 006-Cobbler 批量自动化部署 CentOS/Ubuntu/Windows 007-Cobbler 批量自动化部署 Windows10 和 Server 2019 招聘小广告山东济南的小伙伴欢迎投简历啊 加入我们 , 一起搞事情。 长期招聘，Java 程序员，大数据工程师，运维工程师，前端工程师。","tags":[]},{"title":"009-时间不同步导致Sentinel监控异常","date":"2019-03-07T19:10:00.000Z","path":"2019/03/07/sentinel-timestamp/","text":"这是坚持技术写作计划（含翻译）的第 9 篇，定个小目标 999，每周最少 2 篇。 背景描述在公司测试服务器调试ahas（Sentinel 商业版）时，发现频发性无规律的出现 Ahas 控制台【监控详情】不显示,甚至应用直接消失的问题。 开始以为是非 Spring boot 应用的问题(因为另外一个产品线是 spring boot 的，测试没问题)，反复翻看开源sentinel 的 wiki和商业 ahas 的帮助文档 ,并且结合 Sentinel 的日志排查，毫无头绪。但是换成开源的 Sentinel Dashboard 没问题 解决步骤问题原因上文提到的，Spring boot 可以，是因为其部署在阿里云 ecs 上，而阿里云主机默认都有 ntp 同步 而测试机连 Sentinel 的 Dashboard 没问题，换成 ahas 就有问题，是因为 Sentinel 的 client 和 dashboard，部署在同一台服务器，不存在时间差问题。 后来通过 @乐有 和 @云寅 的帮助，定位到时钟问题, 据 @乐有 介绍 Sentinel 允许的最大时间误差是 30s，而实验中，测试机和北京时间误差超过 55s。 windows 自动同步时间及修改同步频率 如果同步出错，可以重启一下 Windows Time 服务，再次同步。 但是过了半天后，时钟又差 1 分钟，所以需要调整一下 NTP 同步频率打开注册表，找到 SpecialPollInterval (HKEY_LOCAL_MACHINE\\SYSTEM\\CurrentControlSet\\Services\\W32Time\\TimeProviders\\NtpClien\\SpecialPollInterval ) 发现默认值是十六进制 93a80 ，换成 10 进制是 604800 (7 天24 小时60 分钟60 秒=604800)，间隔太长了 ,改成 300(5 分钟60 秒)即可。 参考资料 Sentinel#Wiki#FAQ 配置 Windows 实例 NTP 服务 使用阿里云 NTP 服务器 招聘小广告山东济南的小伙伴欢迎投简历啊 加入我们 , 一起搞事情。 长期招聘，Java 程序员，大数据工程师，运维工程师，前端工程师。","tags":[{"name":"微服务","slug":"微服务","permalink":"https://anjia0532.github.io/tags/微服务/"},{"name":"sentinel","slug":"sentinel","permalink":"https://anjia0532.github.io/tags/sentinel/"},{"name":"hystrix","slug":"hystrix","permalink":"https://anjia0532.github.io/tags/hystrix/"},{"name":"spring boot","slug":"spring-boot","permalink":"https://anjia0532.github.io/tags/spring-boot/"},{"name":"spring cloud","slug":"spring-cloud","permalink":"https://anjia0532.github.io/tags/spring-cloud/"},{"name":"熔断","slug":"熔断","permalink":"https://anjia0532.github.io/tags/熔断/"}]},{"title":"008-Sentinel清洗RESTful的@PathVariable","date":"2019-03-05T18:30:00.000Z","path":"2019/03/05/sentinel-restful/","text":"这是坚持技术写作计划（含翻译）的第 8 篇，定个小目标 999，每周最少 2 篇。 前段时间的文章多是运维方面的，最近放出一波后端相关的。 背景最近开始使用 Sentinel 进行流量保护，但是默认的 web servlet filter 是拦截全部 http 请求。在传统的项目中问题不大。但是如果项目中用了 Spring MVC，并且用了@PathVariable 就尴尬了。比如 uri pattern 是 /foo/{id} ,而从 Sentinel 监控看 /foo/1 和 /foo/2 就是两个资源了，并且 Sentinel 最大支持 6000 个资源，再多就不生效了。 解决办法官方给的方案是:UrlCleanerWebCallbackManager.setUrlCleaner(new UrlCleaner() &#123; @Override public String clean(String originUrl) &#123; if (originUrl.startsWith(fooPrefix)) &#123; return \"/foo/*\"; &#125; return originUrl; &#125; &#125;); 但是想想就吐， /v1/{foo}/{bar}/qux/{baz} 这种的来个 20 来个，截一个我看看。 AOP换种思路，uri pattern 难搞，用笨办法 aop 总行吧？答案是可以的。 @Aspectpublic class SentinelResourceAspect &#123; @Pointcut(\"within(com.anjia.*.web.rest..*)\") public void sentinelResourcePackagePointcut() &#123; // Method is empty as this is just a Pointcut, the implementations are // in the advices. &#125; @Around(\"sentinelResourcePackagePointcut()\") public Object sentinelResourceAround(ProceedingJoinPoint joinPoint) throws Throwable &#123; Entry entry = null; // 务必保证finally会被执行 try &#123; // 资源名可使用任意有业务语义的字符串 // 注意此处只是类名#方法名，方法重载是合并的，如果需要进行区分， // 可以获取参数类型加入到资源名称上 entry = SphU.entry(joinPoint.getSignature().getDeclaringTypeName()+ \"#\"+joinPoint.getSignature().getName()); // 被保护的业务逻辑 // do something... &#125; catch (BlockException ex) &#123; // 资源访问阻止，被限流或被降级 // 进行相应的处理操作 &#125; finally &#123; if (entry != null) &#123; entry.exit(); &#125; &#125; return result; &#125;&#125; 拦截器温习一下 Spring mvc 的执行流程 doFilter -&gt; doService -&gt; dispatcher -&gt; preHandle -&gt; controller -&gt; postHandle -&gt; afterCompletion -&gt; filterAfter 核心的是 String pattern = (String) request.getAttribute(HandlerMapping.BEST_MATCHING_PATTERN_ATTRIBUTE); 但是是在 dispatcher 阶段才赋值的，所以在 CommFilter 是取不到的，所以导致使用官方的 Filter 是不行的。只能用拦截器 import com.alibaba.csp.sentinel.EntryType;import com.alibaba.csp.sentinel.SphU;import com.alibaba.csp.sentinel.adapter.servlet.callback.RequestOriginParser;import com.alibaba.csp.sentinel.adapter.servlet.callback.UrlCleaner;import com.alibaba.csp.sentinel.adapter.servlet.callback.WebCallbackManager;import com.alibaba.csp.sentinel.adapter.servlet.util.FilterUtil;import com.alibaba.csp.sentinel.context.ContextUtil;import com.alibaba.csp.sentinel.log.RecordLog;import com.alibaba.csp.sentinel.slots.block.BlockException;import com.alibaba.csp.sentinel.util.StringUtil;import org.apache.commons.lang3.StringUtils;import org.springframework.web.servlet.HandlerInterceptor;import org.springframework.web.servlet.HandlerMapping;import org.springframework.web.servlet.ModelAndView;import javax.servlet.http.HttpServletRequest;import javax.servlet.http.HttpServletResponse;@Componentpublic class SentinelHandlerInterceptor implements HandlerInterceptor &#123; @Override public boolean preHandle(HttpServletRequest request, HttpServletResponse response, Object handler) throws Exception &#123; String origin = parseOrigin(request); String pattern = (String) request.getAttribute(HandlerMapping.BEST_MATCHING_PATTERN_ATTRIBUTE); String uriTarget = StringUtils.defaultString(pattern,FilterUtil.filterTarget(request)); try &#123; // Clean and unify the URL. // For REST APIs, you have to clean the URL (e.g. `/foo/1` and `/foo/2` -&gt; `/foo/:id`), or // the amount of context and resources will exceed the threshold. UrlCleaner urlCleaner = WebCallbackManager.getUrlCleaner(); if (urlCleaner != null) &#123; uriTarget = urlCleaner.clean(uriTarget); &#125; RecordLog.info(String.format(\"[Sentinel Pre Filter] Origin: %s enter Uri Path: %s\", origin, uriTarget)); SphU.entry(uriTarget, EntryType.IN); return true; &#125; catch (BlockException ex) &#123; RecordLog.warn(String.format(\"[Sentinel Pre Filter] Block Exception when Origin: %s enter fall back uri: %s\", origin, uriTarget), ex); WebCallbackManager.getUrlBlockHandler().blocked(request, response, ex); return false; &#125; &#125; @Override public void postHandle(HttpServletRequest request, HttpServletResponse response, Object handler, ModelAndView modelAndView) throws Exception &#123; while (ContextUtil.getContext() != null &amp;&amp; ContextUtil.getContext().getCurEntry() != null) &#123; ContextUtil.getContext().getCurEntry().exit(); &#125; ContextUtil.exit(); &#125; @Override public void afterCompletion(HttpServletRequest request, HttpServletResponse response, Object handler, Exception ex) throws Exception &#123; &#125; private String parseOrigin(HttpServletRequest request) &#123; RequestOriginParser originParser = WebCallbackManager.getRequestOriginParser(); String origin = EMPTY_ORIGIN; if (originParser != null) &#123; origin = originParser.parseOrigin(request); if (StringUtil.isEmpty(origin)) &#123; return EMPTY_ORIGIN; &#125; &#125; return origin; &#125; private static final String EMPTY_ORIGIN = \"\";&#125; import org.springframework.context.annotation.Configuration;import org.springframework.web.servlet.config.annotation.InterceptorRegistry;import org.springframework.web.servlet.config.annotation.WebMvcConfigurationSupport;@Configurationpublic class WebConfig extends WebMvcConfigurerAdapter &#123; @Inject SentinelHandlerInterceptor sentinelHandlerInterceptor; @Override public void addInterceptors(InterceptorRegistry registry) &#123; registry.addInterceptor(sentinelHandlerInterceptor); &#125;&#125; UrlBlockHandler 和 UrlCleaner 和 WebServletConfig.setBlockPage(blockPage)上面说过，UrlCleaner 是为了归并请求，清洗 url 用的。而 UrlBlockHandler 是在被拦截后的默认处理器。但是 clean 和 handler 都不是链式的，所以如果有多种处理，需要自己在一个方法里，进行逻辑判断。 UrlCleaner WebCallbackManager.setUrlCleaner(new UrlCleaner() &#123; @Override public String clean(String originUrl) &#123; if (originUrl.startsWith(fooPrefix)) &#123; return \"/foo/*\"; &#125; return originUrl; &#125; &#125;); UrlBlockHandler如果通用一点的，可以自己根据 request 的 content-type 进行自适应返回内容(PLAN_TEXT 和 JSON) WebCallbackManager.setUrlBlockHandler((request, response, ex) -&gt; &#123; response.addHeader(\"Content-Type\",\"application/json;charset=UTF-8\"); PrintWriter out = response.getWriter(); out.print(\"&#123;\\\"code\\\"\":429,\\\"msg\\\":\\\"系统繁忙，请稍后重试\\\"\"&#125;\"); out.flush(); out.close();&#125;); WebServletConfig.setBlockPage(blockPage) WebServletConfig.setBlockPage(\"http://www.baidu.com\") 注意，三个方法都不是不支持调用链，比如我写两个 UrlBlockHandler,只认最后一个。 参考资料 wiki/主流框架的适配#web-servlet issues#REST API pattern UrlCleaner 同一处理 招聘小广告山东济南的小伙伴欢迎投简历啊 加入我们 , 一起搞事情。 长期招聘，Java 程序员，大数据工程师，运维工程师，前端工程师。","tags":[{"name":"微服务","slug":"微服务","permalink":"https://anjia0532.github.io/tags/微服务/"},{"name":"sentinel","slug":"sentinel","permalink":"https://anjia0532.github.io/tags/sentinel/"},{"name":"hystrix","slug":"hystrix","permalink":"https://anjia0532.github.io/tags/hystrix/"},{"name":"spring boot","slug":"spring-boot","permalink":"https://anjia0532.github.io/tags/spring-boot/"},{"name":"spring cloud","slug":"spring-cloud","permalink":"https://anjia0532.github.io/tags/spring-cloud/"},{"name":"熔断","slug":"熔断","permalink":"https://anjia0532.github.io/tags/熔断/"}]},{"title":"007-Cobbler批量自动化部署Windows10和Server 2019","date":"2019-02-22T15:46:00.000Z","path":"2019/02/22/cobbler-win10-win-server-2019/","text":"这是坚持技术写作计划（含翻译）的第 7 篇，定个小目标 999，每周最少 2 篇。 本文主要讲解通过 CentOS7.6 Minimal + Cobbler 自动化安装 CentOS,Ubuntu,Windows 10 和 Windows Server 2019。 请注意，一般安装 windows 是用MDT或者 WDS 居多，毕竟是巨硬自己家的，而且 WDT 还支持分布式镜像传输（主要是巨硬家的 OS，动辄超过 4G，万兆网卡也会卡啊）。本文不涉及到 WDT 或者 WDS 相关操作，感兴趣的可自行百度或者 msdn。 准备 Windows ADK (分别下载 Download the Windows ADK for Windows 10, version 1809 和 Download the Windows PE add-on for the ADK) 下载 Windows 10 (business edition), version 1809 (Updated Feb 2019) (x64) - DVD (Chinese-Simplified) 下载 Windows Server 2019 (x64) - DVD (Chinese-Simplified) 注意，adk 的两个都要下载，这俩都是引导包，真正的安装程序会由这俩软件进行下载。其中 WinPE 需要用到 5G 左右的磁盘空间，简直不能忍受。。。msdn i tell u 堪称良心站，是 windows 装机神站啊，不过，没有直达页面挺不爽。为了防止下错，特意截图。 安装 ADK 和 WinPE我已经装过，且忘记截图了，这是事后补图，只需要勾选必须的就行 安装完后，以管理员身份打开部署和映像工具环境 定制 Win 10 PE copype amd64 C:\\winpeDism /mount-image /imagefile:C:\\winpe\\media\\sources\\boot.wim /index:1 /mountdir:C:\\winpe\\mountecho net use z: \\\\192.168.0.253\\share &gt;&gt; C:\\winpe\\mount\\Windows\\System32\\startnet.cmdecho z:\\win\\setup.exe /unattend:z:\\win\\win10_x64_bios_auto.xml &gt;&gt; C:\\winpe\\mount\\Windows\\System32\\startnet.cmdDism /unmount-image /mountdir:C:\\winpe\\mount /commitMakeWinPEMedia /ISO C:\\winpe C:\\winpe\\winpe_win10_amd64.iso 本地生成 winpe 文件目录 dism 挂载 winpe 的启动文件到 winpe 的 mount 目录 将启动命令硬编码写死到 winpe 的 startnet.cmd 文件里 无人值守安装 卸载 winpe 的挂载（一定要执行，否则直接强制删除文件夹会出一些稀奇古怪的问题） 制作 win10 镜像，名为 winpe_win10_amd64.iso 第三步的硬编码是无奈之举，因为要想挂载共享文件夹，必须要知道 smb 主机，但是这个参数又很难传递进来。如果是 U 盘启动，可以写死 U 盘路径，大不了插上 U 盘后，手动改卷标(当然因为 U 盘挂载顺序不一致，可以通过 for 循环 A-Z 盘，挨个盘访问某个文件名，如果存在，即认为此盘是自己 U 盘，设置环境变量)。而网上说的，startnet.cmd 调用另外一个 bat，多是基于这个原理。 而如果 PXE 要达到跟上述要求，动态设置 smb 主机，要么写死域名，然后劫持或者配置域名，加上 bat 文件，在 winpe 启动时，通过 startnet.cmd 下载，并执行。要么找办法，看看能不能在启动时，传入参数（目前我还没找到），当然还可以用 MDT 方案，看着比 PXE+无人应答文件简单很多。 配置 Cobbler Server导入 Cobbler使用 WinScp 等工具，将 winpe_win10_amd64.iso 上传到 Cobbler 服务器上 [root@localhost ~]# cobbler distro add --name=windows_10_x64 --kernel=/var/lib/tftpboot/memdisk --initrd=/root/winpe_win10_amd64.iso --kopts=\"raw iso\"[root@localhost ~]# touch /var/lib/cobbler/kickstarts/winpe.xml[root@localhost ~]# cobbler profile add --name=windows_10_x64 --distro=windows_10_x64 --kickstart=/var/lib/cobbler/kickstarts/winpe.xml 创建自动应答文件直接从 Windows Answer File Generator#win10_x86_64 通过简单配置后，下载即可（只支持简单操作，比如，装系统，格式化磁盘，设置密码等）。当然也可以使用 【Windows 系统映像管理器】，不过挺难用的，具体用法可以参考 How to create an unattended installation of Windows 10。也可以通过 MDT 简化操作。 但是如果使用直接生成的，有点问题，即使页面设置了安装语言，但是仍旧需要手动选择，经过多方研究，发现主要卡在 UILanguage 和 Inputlocale 上，全写 zh-CN 无效。 &lt;?xml version=\"1.0\" encoding=\"utf-8\"?&gt;&lt;component 此处忽略&gt; &lt;SetupUILanguage&gt; &lt;UILanguage&gt;en-US&lt;/UILanguage&gt; &lt;/SetupUILanguage&gt; &lt;InputLocale&gt;0804:&#123;81D4E9C9-1D3B-41BC-9E6C-4B40BF79E35E&#125;&#123;FA550B04-5AD7-411f-A5AC-CA038EC515D7&#125;&lt;/InputLocale&gt; &lt;SystemLocale&gt;zh-CN&lt;/SystemLocale&gt; &lt;UILanguage&gt;zh-CN&lt;/UILanguage&gt; &lt;UILanguageFallback&gt;zh-CN&lt;/UILanguageFallback&gt; &lt;UserLocale&gt;zh-CN&lt;/UserLocale&gt;&lt;/component&gt; 另外就是安装密钥,统一替换为 VK7JG-NPHTM-C97JM-9MPGT-3V66T 下面是我的应答文件，仅做参考。 &lt;!--*************************************************Windows 10 Answer File GeneratorCreated using Windows AFG found at:;http://www.windowsafg.comInstallation NotesLocation: zh-CNNotes: Enter your comments here...**************************************************--&gt;&lt;?xml version=\"1.0\" encoding=\"utf-8\"?&gt;&lt;unattend xmlns=\"urn:schemas-microsoft-com:unattend\"&gt; &lt;settings pass=\"windowsPE\"&gt; &lt;component name=\"Microsoft-Windows-International-Core-WinPE\" processorArchitecture=\"x86\" publicKeyToken=\"31bf3856ad364e35\" language=\"neutral\" versionScope=\"nonSxS\" xmlns:wcm=\"http://schemas.microsoft.com/WMIConfig/2002/State\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\"&gt; &lt;SetupUILanguage&gt; &lt;UILanguage&gt;en-US&lt;/UILanguage&gt; &lt;/SetupUILanguage&gt; &lt;InputLocale&gt;0804:&#123;81D4E9C9-1D3B-41BC-9E6C-4B40BF79E35E&#125;&#123;FA550B04-5AD7-411f-A5AC-CA038EC515D7&#125;&lt;/InputLocale&gt; &lt;SystemLocale&gt;zh-CN&lt;/SystemLocale&gt; &lt;UILanguage&gt;zh-CN&lt;/UILanguage&gt; &lt;UILanguageFallback&gt;zh-CN&lt;/UILanguageFallback&gt; &lt;UserLocale&gt;zh-CN&lt;/UserLocale&gt; &lt;/component&gt; &lt;component name=\"Microsoft-Windows-International-Core-WinPE\" processorArchitecture=\"amd64\" publicKeyToken=\"31bf3856ad364e35\" language=\"neutral\" versionScope=\"nonSxS\" xmlns:wcm=\"http://schemas.microsoft.com/WMIConfig/2002/State\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\"&gt; &lt;SetupUILanguage&gt; &lt;UILanguage&gt;en-US&lt;/UILanguage&gt; &lt;/SetupUILanguage&gt; &lt;InputLocale&gt;0804:&#123;81D4E9C9-1D3B-41BC-9E6C-4B40BF79E35E&#125;&#123;FA550B04-5AD7-411f-A5AC-CA038EC515D7&#125;&lt;/InputLocale&gt; &lt;SystemLocale&gt;zh-CN&lt;/SystemLocale&gt; &lt;UILanguage&gt;zh-CN&lt;/UILanguage&gt; &lt;UILanguageFallback&gt;zh-CN&lt;/UILanguageFallback&gt; &lt;UserLocale&gt;zh-CN&lt;/UserLocale&gt; &lt;/component&gt; &lt;component name=\"Microsoft-Windows-Setup\" processorArchitecture=\"x86\" publicKeyToken=\"31bf3856ad364e35\" language=\"neutral\" versionScope=\"nonSxS\" xmlns:wcm=\"http://schemas.microsoft.com/WMIConfig/2002/State\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\"&gt; &lt;DiskConfiguration&gt; &lt;Disk wcm:action=\"add\"&gt; &lt;CreatePartitions&gt; &lt;CreatePartition wcm:action=\"add\"&gt; &lt;Order&gt;1&lt;/Order&gt; &lt;Type&gt;Primary&lt;/Type&gt; &lt;Size&gt;100&lt;/Size&gt; &lt;/CreatePartition&gt; &lt;CreatePartition wcm:action=\"add\"&gt; &lt;Extend&gt;true&lt;/Extend&gt; &lt;Order&gt;2&lt;/Order&gt; &lt;Type&gt;Primary&lt;/Type&gt; &lt;/CreatePartition&gt; &lt;/CreatePartitions&gt; &lt;ModifyPartitions&gt; &lt;ModifyPartition wcm:action=\"add\"&gt; &lt;Active&gt;true&lt;/Active&gt; &lt;Format&gt;NTFS&lt;/Format&gt; &lt;Label&gt;System Reserved&lt;/Label&gt; &lt;Order&gt;1&lt;/Order&gt; &lt;PartitionID&gt;1&lt;/PartitionID&gt; &lt;TypeID&gt;0x27&lt;/TypeID&gt; &lt;/ModifyPartition&gt; &lt;ModifyPartition wcm:action=\"add\"&gt; &lt;Active&gt;true&lt;/Active&gt; &lt;Format&gt;NTFS&lt;/Format&gt; &lt;Label&gt;OS&lt;/Label&gt; &lt;Letter&gt;C&lt;/Letter&gt; &lt;Order&gt;2&lt;/Order&gt; &lt;PartitionID&gt;2&lt;/PartitionID&gt; &lt;/ModifyPartition&gt; &lt;/ModifyPartitions&gt; &lt;DiskID&gt;0&lt;/DiskID&gt; &lt;WillWipeDisk&gt;true&lt;/WillWipeDisk&gt; &lt;/Disk&gt; &lt;/DiskConfiguration&gt; &lt;ImageInstall&gt; &lt;OSImage&gt; &lt;InstallTo&gt; &lt;DiskID&gt;0&lt;/DiskID&gt; &lt;PartitionID&gt;2&lt;/PartitionID&gt; &lt;/InstallTo&gt; &lt;InstallToAvailablePartition&gt;false&lt;/InstallToAvailablePartition&gt; &lt;/OSImage&gt; &lt;/ImageInstall&gt; &lt;UserData&gt; &lt;AcceptEula&gt;true&lt;/AcceptEula&gt; &lt;FullName&gt;AnJia&lt;/FullName&gt; &lt;Organization&gt;AnJia&lt;/Organization&gt; &lt;ProductKey&gt; &lt;Key&gt;VK7JG-NPHTM-C97JM-9MPGT-3V66T&lt;/Key&gt; &lt;/ProductKey&gt; &lt;/UserData&gt; &lt;/component&gt; &lt;component name=\"Microsoft-Windows-Setup\" processorArchitecture=\"amd64\" publicKeyToken=\"31bf3856ad364e35\" language=\"neutral\" versionScope=\"nonSxS\" xmlns:wcm=\"http://schemas.microsoft.com/WMIConfig/2002/State\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\"&gt; &lt;DiskConfiguration&gt; &lt;Disk wcm:action=\"add\"&gt; &lt;CreatePartitions&gt; &lt;CreatePartition wcm:action=\"add\"&gt; &lt;Order&gt;1&lt;/Order&gt; &lt;Type&gt;Primary&lt;/Type&gt; &lt;Size&gt;100&lt;/Size&gt; &lt;/CreatePartition&gt; &lt;CreatePartition wcm:action=\"add\"&gt; &lt;Extend&gt;true&lt;/Extend&gt; &lt;Order&gt;2&lt;/Order&gt; &lt;Type&gt;Primary&lt;/Type&gt; &lt;/CreatePartition&gt; &lt;/CreatePartitions&gt; &lt;ModifyPartitions&gt; &lt;ModifyPartition wcm:action=\"add\"&gt; &lt;Active&gt;true&lt;/Active&gt; &lt;Format&gt;NTFS&lt;/Format&gt; &lt;Label&gt;System Reserved&lt;/Label&gt; &lt;Order&gt;1&lt;/Order&gt; &lt;PartitionID&gt;1&lt;/PartitionID&gt; &lt;TypeID&gt;0x27&lt;/TypeID&gt; &lt;/ModifyPartition&gt; &lt;ModifyPartition wcm:action=\"add\"&gt; &lt;Active&gt;true&lt;/Active&gt; &lt;Format&gt;NTFS&lt;/Format&gt; &lt;Label&gt;OS&lt;/Label&gt; &lt;Letter&gt;C&lt;/Letter&gt; &lt;Order&gt;2&lt;/Order&gt; &lt;PartitionID&gt;2&lt;/PartitionID&gt; &lt;/ModifyPartition&gt; &lt;/ModifyPartitions&gt; &lt;DiskID&gt;0&lt;/DiskID&gt; &lt;WillWipeDisk&gt;true&lt;/WillWipeDisk&gt; &lt;/Disk&gt; &lt;/DiskConfiguration&gt; &lt;ImageInstall&gt; &lt;OSImage&gt; &lt;InstallTo&gt; &lt;DiskID&gt;0&lt;/DiskID&gt; &lt;PartitionID&gt;2&lt;/PartitionID&gt; &lt;/InstallTo&gt; &lt;InstallToAvailablePartition&gt;false&lt;/InstallToAvailablePartition&gt; &lt;/OSImage&gt; &lt;/ImageInstall&gt; &lt;UserData&gt; &lt;AcceptEula&gt;true&lt;/AcceptEula&gt; &lt;FullName&gt;AnJia&lt;/FullName&gt; &lt;Organization&gt;AnJia&lt;/Organization&gt; &lt;ProductKey&gt; &lt;Key&gt;VK7JG-NPHTM-C97JM-9MPGT-3V66T&lt;/Key&gt; &lt;/ProductKey&gt; &lt;/UserData&gt; &lt;/component&gt; &lt;/settings&gt; &lt;settings pass=\"offlineServicing\"&gt; &lt;component name=\"Microsoft-Windows-LUA-Settings\" processorArchitecture=\"x86\" publicKeyToken=\"31bf3856ad364e35\" language=\"neutral\" versionScope=\"nonSxS\" xmlns:wcm=\"http://schemas.microsoft.com/WMIConfig/2002/State\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\"&gt; &lt;EnableLUA&gt;false&lt;/EnableLUA&gt; &lt;/component&gt; &lt;/settings&gt; &lt;settings pass=\"offlineServicing\"&gt; &lt;component name=\"Microsoft-Windows-LUA-Settings\" processorArchitecture=\"amd64\" publicKeyToken=\"31bf3856ad364e35\" language=\"neutral\" versionScope=\"nonSxS\" xmlns:wcm=\"http://schemas.microsoft.com/WMIConfig/2002/State\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\"&gt; &lt;EnableLUA&gt;false&lt;/EnableLUA&gt; &lt;/component&gt; &lt;/settings&gt; &lt;settings pass=\"generalize\"&gt; &lt;component name=\"Microsoft-Windows-Security-SPP\" processorArchitecture=\"x86\" publicKeyToken=\"31bf3856ad364e35\" language=\"neutral\" versionScope=\"nonSxS\" xmlns:wcm=\"http://schemas.microsoft.com/WMIConfig/2002/State\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\"&gt; &lt;SkipRearm&gt;1&lt;/SkipRearm&gt; &lt;/component&gt; &lt;/settings&gt; &lt;settings pass=\"generalize\"&gt; &lt;component name=\"Microsoft-Windows-Security-SPP\" processorArchitecture=\"amd64\" publicKeyToken=\"31bf3856ad364e35\" language=\"neutral\" versionScope=\"nonSxS\" xmlns:wcm=\"http://schemas.microsoft.com/WMIConfig/2002/State\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\"&gt; &lt;SkipRearm&gt;1&lt;/SkipRearm&gt; &lt;/component&gt; &lt;/settings&gt; &lt;settings pass=\"specialize\"&gt; &lt;component name=\"Microsoft-Windows-International-Core\" processorArchitecture=\"x86\" publicKeyToken=\"31bf3856ad364e35\" language=\"neutral\" versionScope=\"nonSxS\" xmlns:wcm=\"http://schemas.microsoft.com/WMIConfig/2002/State\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\"&gt; &lt;InputLocale&gt;0804:&#123;81D4E9C9-1D3B-41BC-9E6C-4B40BF79E35E&#125;&#123;FA550B04-5AD7-411f-A5AC-CA038EC515D7&#125;&lt;/InputLocale&gt; &lt;SystemLocale&gt;zh-CN&lt;/SystemLocale&gt; &lt;UILanguage&gt;zh-CN&lt;/UILanguage&gt; &lt;UILanguageFallback&gt;zh-CN&lt;/UILanguageFallback&gt; &lt;UserLocale&gt;zh-CN&lt;/UserLocale&gt; &lt;/component&gt; &lt;component name=\"Microsoft-Windows-International-Core\" processorArchitecture=\"amd64\" publicKeyToken=\"31bf3856ad364e35\" language=\"neutral\" versionScope=\"nonSxS\" xmlns:wcm=\"http://schemas.microsoft.com/WMIConfig/2002/State\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\"&gt; &lt;InputLocale&gt;0804:&#123;81D4E9C9-1D3B-41BC-9E6C-4B40BF79E35E&#125;&#123;FA550B04-5AD7-411f-A5AC-CA038EC515D7&#125;&lt;/InputLocale&gt; &lt;SystemLocale&gt;zh-CN&lt;/SystemLocale&gt; &lt;UILanguage&gt;zh-CN&lt;/UILanguage&gt; &lt;UILanguageFallback&gt;zh-CN&lt;/UILanguageFallback&gt; &lt;UserLocale&gt;zh-CN&lt;/UserLocale&gt; &lt;/component&gt; &lt;component name=\"Microsoft-Windows-Security-SPP-UX\" processorArchitecture=\"x86\" publicKeyToken=\"31bf3856ad364e35\" language=\"neutral\" versionScope=\"nonSxS\" xmlns:wcm=\"http://schemas.microsoft.com/WMIConfig/2002/State\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\"&gt; &lt;SkipAutoActivation&gt;true&lt;/SkipAutoActivation&gt; &lt;/component&gt; &lt;component name=\"Microsoft-Windows-Security-SPP-UX\" processorArchitecture=\"amd64\" publicKeyToken=\"31bf3856ad364e35\" language=\"neutral\" versionScope=\"nonSxS\" xmlns:wcm=\"http://schemas.microsoft.com/WMIConfig/2002/State\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\"&gt; &lt;SkipAutoActivation&gt;true&lt;/SkipAutoActivation&gt; &lt;/component&gt; &lt;component name=\"Microsoft-Windows-SQMApi\" processorArchitecture=\"x86\" publicKeyToken=\"31bf3856ad364e35\" language=\"neutral\" versionScope=\"nonSxS\" xmlns:wcm=\"http://schemas.microsoft.com/WMIConfig/2002/State\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\"&gt; &lt;CEIPEnabled&gt;0&lt;/CEIPEnabled&gt; &lt;/component&gt; &lt;component name=\"Microsoft-Windows-SQMApi\" processorArchitecture=\"amd64\" publicKeyToken=\"31bf3856ad364e35\" language=\"neutral\" versionScope=\"nonSxS\" xmlns:wcm=\"http://schemas.microsoft.com/WMIConfig/2002/State\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\"&gt; &lt;CEIPEnabled&gt;0&lt;/CEIPEnabled&gt; &lt;/component&gt; &lt;component name=\"Microsoft-Windows-Shell-Setup\" processorArchitecture=\"x86\" publicKeyToken=\"31bf3856ad364e35\" language=\"neutral\" versionScope=\"nonSxS\" xmlns:wcm=\"http://schemas.microsoft.com/WMIConfig/2002/State\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\"&gt; &lt;ComputerName&gt;AnJia-PC&lt;/ComputerName&gt; &lt;ProductKey&gt;VK7JG-NPHTM-C97JM-9MPGT-3V66T&lt;/ProductKey&gt; &lt;/component&gt; &lt;component name=\"Microsoft-Windows-Shell-Setup\" processorArchitecture=\"amd64\" publicKeyToken=\"31bf3856ad364e35\" language=\"neutral\" versionScope=\"nonSxS\" xmlns:wcm=\"http://schemas.microsoft.com/WMIConfig/2002/State\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\"&gt; &lt;ComputerName&gt;AnJia-PC&lt;/ComputerName&gt; &lt;ProductKey&gt;VK7JG-NPHTM-C97JM-9MPGT-3V66T&lt;/ProductKey&gt; &lt;/component&gt; &lt;/settings&gt; &lt;settings pass=\"oobeSystem\"&gt; &lt;component name=\"Microsoft-Windows-Shell-Setup\" processorArchitecture=\"x86\" publicKeyToken=\"31bf3856ad364e35\" language=\"neutral\" versionScope=\"nonSxS\" xmlns:wcm=\"http://schemas.microsoft.com/WMIConfig/2002/State\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\"&gt; &lt;AutoLogon&gt; &lt;Password&gt; &lt;Value&gt;&lt;/Value&gt; &lt;PlainText&gt;true&lt;/PlainText&gt; &lt;/Password&gt; &lt;Enabled&gt;true&lt;/Enabled&gt; &lt;Username&gt;AnJia&lt;/Username&gt; &lt;/AutoLogon&gt; &lt;OOBE&gt; &lt;HideEULAPage&gt;true&lt;/HideEULAPage&gt; &lt;HideOEMRegistrationScreen&gt;true&lt;/HideOEMRegistrationScreen&gt; &lt;HideOnlineAccountScreens&gt;true&lt;/HideOnlineAccountScreens&gt; &lt;HideWirelessSetupInOOBE&gt;true&lt;/HideWirelessSetupInOOBE&gt; &lt;NetworkLocation&gt;Work&lt;/NetworkLocation&gt; &lt;SkipUserOOBE&gt;true&lt;/SkipUserOOBE&gt; &lt;SkipMachineOOBE&gt;true&lt;/SkipMachineOOBE&gt; &lt;ProtectYourPC&gt;1&lt;/ProtectYourPC&gt; &lt;/OOBE&gt; &lt;UserAccounts&gt; &lt;LocalAccounts&gt; &lt;LocalAccount wcm:action=\"add\"&gt; &lt;Password&gt; &lt;Value&gt;&lt;/Value&gt; &lt;PlainText&gt;true&lt;/PlainText&gt; &lt;/Password&gt; &lt;Description&gt;AnJia&lt;/Description&gt; &lt;DisplayName&gt;AnJia&lt;/DisplayName&gt; &lt;Group&gt;Administrators&lt;/Group&gt; &lt;Name&gt;AnJia&lt;/Name&gt; &lt;/LocalAccount&gt; &lt;/LocalAccounts&gt; &lt;/UserAccounts&gt; &lt;RegisteredOrganization&gt;AnJia&lt;/RegisteredOrganization&gt; &lt;RegisteredOwner&gt;AnJia&lt;/RegisteredOwner&gt; &lt;DisableAutoDaylightTimeSet&gt;false&lt;/DisableAutoDaylightTimeSet&gt; &lt;FirstLogonCommands&gt; &lt;SynchronousCommand wcm:action=\"add\"&gt; &lt;Description&gt;Control Panel View&lt;/Description&gt; &lt;Order&gt;1&lt;/Order&gt; &lt;CommandLine&gt;reg add \"HKEY_CURRENT_USER\\Software\\Microsoft\\Windows\\CurrentVersion\\Explorer\\ControlPanel\" /v StartupPage /t REG_DWORD /d 1 /f&lt;/CommandLine&gt; &lt;RequiresUserInput&gt;true&lt;/RequiresUserInput&gt; &lt;/SynchronousCommand&gt; &lt;SynchronousCommand wcm:action=\"add\"&gt; &lt;Order&gt;2&lt;/Order&gt; &lt;Description&gt;Control Panel Icon Size&lt;/Description&gt; &lt;RequiresUserInput&gt;false&lt;/RequiresUserInput&gt; &lt;CommandLine&gt;reg add \"HKEY_CURRENT_USER\\Software\\Microsoft\\Windows\\CurrentVersion\\Explorer\\ControlPanel\" /v AllItemsIconView /t REG_DWORD /d 0 /f&lt;/CommandLine&gt; &lt;/SynchronousCommand&gt; &lt;SynchronousCommand wcm:action=\"add\"&gt; &lt;Order&gt;3&lt;/Order&gt; &lt;RequiresUserInput&gt;false&lt;/RequiresUserInput&gt; &lt;CommandLine&gt;cmd /C wmic useraccount where name=\"AnJia\" set PasswordExpires=false&lt;/CommandLine&gt; &lt;Description&gt;Password Never Expires&lt;/Description&gt; &lt;/SynchronousCommand&gt; &lt;/FirstLogonCommands&gt; &lt;TimeZone&gt;China Standard Time&lt;/TimeZone&gt; &lt;/component&gt; &lt;component name=\"Microsoft-Windows-Shell-Setup\" processorArchitecture=\"amd64\" publicKeyToken=\"31bf3856ad364e35\" language=\"neutral\" versionScope=\"nonSxS\" xmlns:wcm=\"http://schemas.microsoft.com/WMIConfig/2002/State\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\"&gt; &lt;AutoLogon&gt; &lt;Password&gt; &lt;Value&gt;&lt;/Value&gt; &lt;PlainText&gt;true&lt;/PlainText&gt; &lt;/Password&gt; &lt;Enabled&gt;true&lt;/Enabled&gt; &lt;Username&gt;AnJia&lt;/Username&gt; &lt;/AutoLogon&gt; &lt;OOBE&gt; &lt;HideEULAPage&gt;true&lt;/HideEULAPage&gt; &lt;HideOEMRegistrationScreen&gt;true&lt;/HideOEMRegistrationScreen&gt; &lt;HideOnlineAccountScreens&gt;true&lt;/HideOnlineAccountScreens&gt; &lt;HideWirelessSetupInOOBE&gt;true&lt;/HideWirelessSetupInOOBE&gt; &lt;NetworkLocation&gt;Work&lt;/NetworkLocation&gt; &lt;SkipUserOOBE&gt;true&lt;/SkipUserOOBE&gt; &lt;SkipMachineOOBE&gt;true&lt;/SkipMachineOOBE&gt; &lt;ProtectYourPC&gt;1&lt;/ProtectYourPC&gt; &lt;/OOBE&gt; &lt;UserAccounts&gt; &lt;LocalAccounts&gt; &lt;LocalAccount wcm:action=\"add\"&gt; &lt;Password&gt; &lt;Value&gt;&lt;/Value&gt; &lt;PlainText&gt;true&lt;/PlainText&gt; &lt;/Password&gt; &lt;Description&gt;AnJia&lt;/Description&gt; &lt;DisplayName&gt;AnJia&lt;/DisplayName&gt; &lt;Group&gt;Administrators&lt;/Group&gt; &lt;Name&gt;AnJia&lt;/Name&gt; &lt;/LocalAccount&gt; &lt;/LocalAccounts&gt; &lt;/UserAccounts&gt; &lt;RegisteredOrganization&gt;AnJia&lt;/RegisteredOrganization&gt; &lt;RegisteredOwner&gt;AnJia&lt;/RegisteredOwner&gt; &lt;DisableAutoDaylightTimeSet&gt;false&lt;/DisableAutoDaylightTimeSet&gt; &lt;FirstLogonCommands&gt; &lt;SynchronousCommand wcm:action=\"add\"&gt; &lt;Description&gt;Control Panel View&lt;/Description&gt; &lt;Order&gt;1&lt;/Order&gt; &lt;CommandLine&gt;reg add \"HKEY_CURRENT_USER\\Software\\Microsoft\\Windows\\CurrentVersion\\Explorer\\ControlPanel\" /v StartupPage /t REG_DWORD /d 1 /f&lt;/CommandLine&gt; &lt;RequiresUserInput&gt;true&lt;/RequiresUserInput&gt; &lt;/SynchronousCommand&gt; &lt;SynchronousCommand wcm:action=\"add\"&gt; &lt;Order&gt;2&lt;/Order&gt; &lt;Description&gt;Control Panel Icon Size&lt;/Description&gt; &lt;RequiresUserInput&gt;false&lt;/RequiresUserInput&gt; &lt;CommandLine&gt;reg add \"HKEY_CURRENT_USER\\Software\\Microsoft\\Windows\\CurrentVersion\\Explorer\\ControlPanel\" /v AllItemsIconView /t REG_DWORD /d 0 /f&lt;/CommandLine&gt; &lt;/SynchronousCommand&gt; &lt;SynchronousCommand wcm:action=\"add\"&gt; &lt;Order&gt;3&lt;/Order&gt; &lt;RequiresUserInput&gt;false&lt;/RequiresUserInput&gt; &lt;CommandLine&gt;cmd /C wmic useraccount where name=\"AnJia\" set PasswordExpires=false&lt;/CommandLine&gt; &lt;Description&gt;Password Never Expires&lt;/Description&gt; &lt;/SynchronousCommand&gt; &lt;/FirstLogonCommands&gt; &lt;TimeZone&gt;China Standard Time&lt;/TimeZone&gt; &lt;/component&gt; &lt;/settings&gt;&lt;/unattend&gt; 配置 samba在 Cobbler 上执行 安装 samba[root@localhost ~]# yum install samba -y 修改 smb config[root@localhost ~]# vi /etc/samba/smb.conf# /etc/samba/smb.conf[global]log file = /var/log/samba/log.%mmax log size = 5000security = userguest account = nobodymap to guest = Bad Userload printers = yescups options = raw[share]comment = share directory目录path = /smb/directory mask = 0755create mask = 0755guest ok=yeswritable=yes 启动 smb 服务[root@localhost ~]# service smb start[root@localhost ~]# systemctl enable smb 挂载 win10 系统通过 winscp 等软件将 cn_windows_10_business_edition_version_1809_updated_sept_2018_x64_dvd_84ac403f.iso 上传到 cobbler 服务器上,并将创建的应答文件，上传到 cobbler /smb/win/win10_x64_bios_auto.xml [root@localhost ~]# mkdir -p /smb/win[root@localhost ~]# mount -o loop,ro /tmp/cn_windows_10_business_edition_version_1809_updated_sept_2018_x64_dvd_84ac403f.iso /mnt/[root@localhost ~]# cp -r /mnt/* /smb/win[root@localhost ~]# umount /mnt/ 自动化安装 Windows10从 vmware 创建一台内存 4G，cpu2 核，磁盘 60G 的空盘，win10 虚拟机，然后开机。记得选 BIOS，别选 UEFI。 至于如何激活，参考 vlmcsd 搭建 KMS 服务器，成功激活 Server 2019 数据中心版本，全网应是我首发 Windows Server 2019因为 2019 用的也是 1809 版本的，所以制作步骤一样的，在此不再赘述。 参考资料 使用 Cobbler 批量部署 Linux 和 Windows：Windows 系统批量安装（三） WINPE 镜像制作-startnet.cmd 详解 Windows 中的默认输入配置文件（输入区域设置）.aspx&gt;) Answer files (unattend.xml) Windows Answer File Generator#win10_x86_64 WinPE: Mount and Customize Components How to create an unattended installation of Windows 10 vlmcsd 搭建 KMS 服务器，成功激活 Server 2019 数据中心版本，全网应是我首发 招聘小广告山东济南的小伙伴欢迎投简历啊 加入我们 , 一起搞事情。 长期招聘，Java 程序员，大数据工程师，运维工程师，前端工程师。","tags":[{"name":"windows","slug":"windows","permalink":"https://anjia0532.github.io/tags/windows/"},{"name":"pxe","slug":"pxe","permalink":"https://anjia0532.github.io/tags/pxe/"},{"name":"dhcp","slug":"dhcp","permalink":"https://anjia0532.github.io/tags/dhcp/"},{"name":"cobbler","slug":"cobbler","permalink":"https://anjia0532.github.io/tags/cobbler/"},{"name":"centos","slug":"centos","permalink":"https://anjia0532.github.io/tags/centos/"},{"name":"ubuntu","slug":"ubuntu","permalink":"https://anjia0532.github.io/tags/ubuntu/"},{"name":"tftp","slug":"tftp","permalink":"https://anjia0532.github.io/tags/tftp/"},{"name":"win10","slug":"win10","permalink":"https://anjia0532.github.io/tags/win10/"},{"name":"server-2019","slug":"server-2019","permalink":"https://anjia0532.github.io/tags/server-2019/"}]},{"title":"006-Cobbler批量自动化部署CentOS/Ubuntu/Windows","date":"2019-02-22T15:46:00.000Z","path":"2019/02/22/cobbler/","text":"这是坚持技术写作计划（含翻译）的第 6 篇，定个小目标 999，每周最少 2 篇。 本文主要讲解通过 CentOS7.6 Minimal + Cobbler 自动化安装 CentOS,Ubuntu,Windows 准备从阿里镜像站，下载 CentOS-7-x86_64-Minimal-1810.iso 和 ubuntu-16.04.5-desktop-amd64.iso ，使用 VMware 创建一台 CentOS7 的虚拟机。 环境初始化1.改为阿里源 # yum源# 备份系统默认源[root@localhost ~]# mkdir /etc/yum.repos.d/old &amp;&amp; mv /etc/yum.repos.d/C* /etc/yum.repos.d/old/[root@localhost ~]# yum clean all# 设置阿里yum源[root@localhost ~]# curl -o /etc/yum.repos.d/CentOS-Base.repo http://mirrors.aliyun.com/repo/Centos-7.repo[root@localhost ~]# curl -o /etc/yum.repos.d/epel.repo http://mirrors.aliyun.com/repo/epel-7.repo# pip源(2.8.4的bug)[root@localhost ~]# mkdir ~/.pip[root@localhost ~]# cat &gt; ~/.pip/pip.conf &lt;&lt; EOF[global]trusted-host=mirrors.aliyun.comindex-url=https://mirrors.aliyun.com/pypi/simple/EOF 2.配置 ssh 默认 ssh_config 启用了 DNS 解析，导致每次远程 ssh 时都特别慢 [root@localhost ~]# sed -i 's%#UseDNS yes%UseDNS no%' /etc/ssh/sshd_config[root@localhost ~]# service sshd restart 3.配置 SElinux如果要在 Centos 上开启 Cobbler 的支持，需要用 root 用户运行 setsebool ，注意 -P 参数确保重启仍然生效。同时需要配置 SELinux 上下文规则(CentOS 7 Minimal 默认不安装 semanage )，用于提供引导镜像。按照红帽的 5.4 的教程，设置不生效，所以，禁用 SELinux #//.. setsebool -P httpd_can_network_connect true#//.. yum provides semanage#//.. yum -y install policycoreutils-python.x86_64#//.. semanage fcontext -a -t public_content_t \"/var/lib/tftpboot/.*\"[root@localhost ~]# sed -i '/SELINUX/s/enforcing/disabled/' /etc/selinux/config[root@localhost ~]# setenforce 0 4.配置防火墙 # TFTP[root@localhost ~]# firewall-cmd --zone=public --add-port=69/tcp --permanent[root@localhost ~]# firewall-cmd --zone=public --add-port=69/udp --permanent# HTTPD[root@localhost ~]# firewall-cmd --zone=public --add-port=80/tcp --permanent[root@localhost ~]# firewall-cmd --zone=public --add-port=443/tcp --permanent# Cobbler[root@localhost ~]# firewall-cmd --zone=public --add-port=25150/tcp --permanent[root@localhost ~]# firewall-cmd --zone=public --add-port=25150/udp --permanent# Koan 如果未用到，可以不开放[root@localhost ~]# firewall-cmd --zone=public --add-port=25151/tcp --permanent# samba window安装需要用到samba,否则可以不开放[root@localhost ~]# firewall-cmd --zone=public --add-port=139/tcp --permanent[root@localhost ~]# firewall-cmd --zone=public --add-port=445/tcp --permanent[root@localhost ~]# firewall-cmd --zone=public --add-port=137/udp --permanent[root@localhost ~]# firewall-cmd --zone=public --add-port=138/udp --permanent# 更新防火墙规则[root@localhost ~]# firewall-cmd --reload# 查看所有打开的端口[root@localhost ~]# firewall-cmd --zone=public --list-ports 安装 Cobbler安装依赖软件[root@localhost ~]# yum install -y cobbler cobbler-web dhcp tftp-server pykickstart httpd xinetd 设置开机自启动[root@localhost ~]# systemctl enable httpd[root@localhost ~]# systemctl enable xinetd[root@localhost ~]# systemctl enable rsyncd[root@localhost ~]# systemctl enable tftp[root@localhost ~]# systemctl enable cobblerd 启动服务[root@localhost ~]# systemctl start httpd[root@localhost ~]# systemctl start xinetd[root@localhost ~]# systemctl start tftp[root@localhost ~]# systemctl start cobblerd 检查配置[root@localhost ~]# cobbler checkThe following are potential configuration items that you may want to fix:1 : The 'server' field in /etc/cobbler/settings must be set to something other than localhost, or kickstarting features will not work. This should be a resolvable hostname or IP for the boot server as reachable by all machines that will use it.2 : For PXE to be functional, the 'next_server' field in /etc/cobbler/settings must be set to something other than 127.0.0.1, and should match the IP of the boot server on the PXE network.3 : SELinux is enabled. Please review the following wiki page for details on ensuring cobbler works correctly in your SELinux environment: https://github.com/cobbler/cobbler/wiki/Selinux4 : change 'disable' to 'no' in /etc/xinetd.d/tftp5 : Some network boot-loaders are missing from /var/lib/cobbler/loaders, you may run 'cobbler get-loaders' to download them, or, if you only want to handle x86/x86_64 netbooting, you may ensure that you have installed a *recent* version of the syslinux package installed and can ignore this message entirely. Files in this directory, should you want to support all architectures, should include pxelinux.0, menu.c32, elilo.efi, and yaboot. The 'cobbler get-loaders' command is the easiest way to resolve these requirements.6 : debmirror package is not installed, it will be required to manage debian deployments and repositories7 : The default password used by the sample templates for newly installed machines (default_password_crypted in /etc/cobbler/settings) is still set to 'cobbler' and should be changed, try: \"openssl passwd -1 -salt 'random-phrase-here' 'your-password-here'\" to generate new one8 : fencing tools were not found, and are required to use the (optional) power management features. install cman or fence-agents to use themRestart cobblerd and then run 'cobbler sync' to apply changes. 1,2：cobbler_ip 为 cobbler 主机 ipnext_server 是 dhcp 主机 ip，但是本实验 dhcp 和 cobbler 是一台 [root@localhost ~]# export cobbler_ip=192.168.0.12[root@localhost ~]# sed -i \"s%^server: 127.0.0.1%server: $&#123;cobbler_ip&#125;%g\" /etc/cobbler/settings[root@localhost ~]# sed -i \"s%^next_server: 127.0.0.1%next_server: $&#123;cobbler_ip&#125;%g\" /etc/cobbler/settings 3： 可以忽略，因为已经配置 SELinux 和防火墙了 4：开启 tftp 功能 [root@localhost ~]# sed -i '/disable\\&gt;/s/\\&lt;yes\\&gt;/no/' /etc/xinetd.d/tftp 5：下载 bootload [root@localhost ~]# cobbler get-loaders 6：下载 ubuntu 本地包镜像（不装 ubuntu 的，可以不用改） [root@localhost ~]# yum install -y debmirror[root@localhost ~]# sed -i 's%^@dists=\"sid\"%#@dists=\"sid\"%g;s%@arches=\"i386\"%#@arches=\"i386\"%g' /etc/debmirror.conf 7：设置安装系统后的 root 密码 [root@localhost ~]# export root_pwd=$(openssl passwd -1 -salt `openssl rand 15 -base64` 'Abcd1234!@#$')[root@localhost ~]# sed -i \"s%^default_password_crypted.*%default_password_crypted: \\\"$&#123;root_pwd&#125;\\\"%g\" /etc/cobbler/settings 8：电源管理模块(非必选)，cman 和 ence-agents 二选一即可,此处忽略 其余修改： [root@localhost ~]# sed -i \"s%manage_dhcp: 0%manage_dhcp: 1%g\" /etc/cobbler/settings[root@localhost ~]# sed -i \"s%pxe_just_once: 0%pxe_just_once: 1%g\" /etc/cobbler/settings 修改 dhcp [root@localhost ~]# vi /etc/cobbler/dhcp.template\\#仅列出修改过的部分\\......subnet 192.168.0.0 netmask 255.255.255.0 &#123; option routers 192.168.0.1; option domain-name-servers 192.168.0.1; option subnet-mask 255.255.255.0; range dynamic-bootp 192.168.0.100 192.168.0.200;\\...... 重启服务 [root@localhost ~]# systemctl restart httpd[root@localhost ~]# systemctl restart xinetd[root@localhost ~]# systemctl restart tftp[root@localhost ~]# systemctl restart cobblerd 再次校验,发现只有两条信息了，忽略即可。 [root@localhost ~]# cobbler checkThe following are potential configuration items that you may want to fix:1 : SELinux is enabled. Please review the following wiki page for details on ensuring cobbler works correctly in your SELinux environment: https://github.com/cobbler/cobbler/wiki/Selinux2 : fencing tools were not found, and are required to use the (optional) power management features. install cman or fence-agents to use themRestart cobblerd and then run 'cobbler sync' to apply changes. 执行 cobbler sync 同步信息 [root@localhost ~]# cobbler synctask started: 2019-02-22_184309_synctask started (id=Sync, time=Fri Feb 22 18:43:09 2019)running pre-sync triggers# ....忽略running python trigger cobbler.modules.scm_trackrunning shell triggers from /var/lib/cobbler/triggers/change/**** TASK COMPLETE *** cobbler-web修复 2.8.4 bug打开 https://${cobbler_ip}/cobbler_web 注意是 https 但是 2.8.4 有个 bug，会导致打开后报 500 Internal Server Error 错误 ,是因为 django 版本太高了 (参加 cobbler 2.8.4/2.8.0 on centos 7 error ) [root@localhost ~]# yum install -y python-pip[root@localhost ~]# pip2.7 install -U django==1.9.13[root@localhost ~]# systemctl restart cobblerd 设置用户名密码默认用户名密码是 cobbler/cobbler [root@localhost ~]# htdigest -c /etc/cobbler/users.digest Cobbler cobbler # 后边这个是用户名[root@localhost ~]# systemctl restart cobblerd 再次打开 https://${cobbler_ip}/cobbler_web 挂载镜像通过 winscp,mobaxterm 等将 ubuntu 和 centos 镜像上传到 Cobbler 服务器上的 /tmp/ 目录下,其中 net.ifnames=0 biosdevname=0 noipv6 是让网卡统一命名成 eth0 [root@localhost ~]# mount -t iso9660 -o loop /tmp/CentOS-7-x86_64-Minimal-1810.iso /mnt/[root@localhost ~]# cobbler import --name=CentOS-7.6.1810-x86_64 --path=/mnt/ --arch=x86_64[root@localhost ~]# cobbler profile edit --name=CentOS-7.6.1810-x86_64 --kopts='net.ifnames=0 biosdevname=0'[root@localhost ~]# mount -t iso9660 -o loop /tmp/ubuntu-16.04.5-server-amd64.iso /mnt/[root@localhost ~]# cobbler import --name=ubuntu-16.04.5-server-x86_64 --path=/mnt/ --arch=x86_64 测试 PXE 安装系统在 vmware 创建两个虚拟机(选择空白盘),内存 2G，CPU2 核，磁盘 20G，创建完后，记得打个快照，后边做实验失败后，直接恢复即可。选择 CentOS，然后回车，系统将自动安装 优化配置CentOS ks[root@localhost ~]# cobbler profile report --name CentOS-7.6.1810-x86_64Name : CentOS-7.6.1810-x86_64#//...忽略Kickstart : /var/lib/cobbler/kickstarts/sample_end.ks#//...忽略#//复制一份ks，并且进行修改[root@localhost ~]# cp /var/lib/cobbler/kickstarts/sample_end.ks /var/lib/cobbler/kickstarts/centos-7-6.ks[root@localhost ~]# cobbler profile edit --name CentOS-7.6.1810-x86_64 --kickstart=/var/lib/cobbler/kickstarts/centos-7-6.ks[root@localhost ~]# cp /var/lib/cobbler/kickstarts/sample.seed /var/lib/cobbler/kickstarts/ubuntu-16-4-5.seed[root@localhost ~]# cobbler profile edit --name ubuntu-16.04.5-server-x86_64 --kickstart=/var/lib/cobbler/kickstarts/ubuntu-16-4-5.seed 具体 CentOS 的 ks 语法可以参考这里：KICKSTART 语法参考。另外可以参考 运维工作笔记-Cobbler 配置文件具体 Ubuntu 的 Preseed 可以参考这里：Preseed 语法参考。 吐槽一下，cobbler 代码中检测到是 ubuntu 时，会自动将 ks 换成 url(强制走 preseed)，而用惯了 ks 的，用 preseed 还是很不习惯的，可以看一下 Support selection of automatic installation file format in distros which allow it (Debian/Ubuntu allows kickstart and preseed) 和 Problems Provisioning Ubuntu with Cobbler and Kickstart Profiles此处贴一下 /var/lib/cobbler/kickstarts/ubuntu-16-4-5.seed # Mostly based on the Ubuntu installation guide# https://help.ubuntu.com/16.04/installation-guide/# Debian sample# https://www.debian.org/releases/stable/example-preseed.txt## Part 1. Localization# Preseeding only locale sets language, country and locale.d-i debian-installer/locale string en_US# Keyboard selection.# Disable automatic (interactive) keymap detection.d-i console-setup/ask_detect boolean falsed-i keyboard-configuration/toggle select No togglingd-i keyboard-configuration/layoutcode string usd-i keyboard-configuration/variantcode string## Part 2. Network configuration# netcfg will choose an interface that has link if possible. This makes it# skip displaying a list if there is more than one interface.#set $myhostname = $getVar('hostname',$getVar('name','cobbler')).replace(\"_\",\"-\")d-i netcfg/choose_interface select autod-i netcfg/get_hostname string $myhostname# If non-free firmware is needed for the network or other hardware, you can# configure the installer to always try to load it, without prompting. Or# change to false to disable asking.# d-i hw-detect/load_firmware boolean true## Part 3 NTP/Time# NTP/Time Setupd-i time/zone string Asia/Shanghaid-i clock-setup/utc boolean trued-i clock-setup/ntp boolean trued-i clock-setup/ntp-server string ntp1.aliyun.com## Part 4. Mirror settings# Setup the installation sourced-i mirror/country string manuald-i mirror/http/hostname string $http_serverd-i mirror/http/directory string $install_source_directoryd-i mirror/http/proxy string#set $os_v = $getVar('os_version','')#if $breed == \"ubuntu\" and $os_v and ($os_v.lower()[0] &gt; 'p' or $os_v.lower()[0] &lt; 'd')# Required at least for ubuntu 12.10+ , so test os_v is higher than precise and lower than drapperd-i live-installer/net-image string http://$http_server/cobbler/links/$distro_name/install/filesystem.squashfs#end if# Suite to install.# d-i mirror/suite string precise# d-i mirror/udeb/suite string precise# Components to use for loading installer components (optional).#d-i mirror/udeb/components multiselect main, restricted## Part 4. Partitioning# Disk Partitioning# Use LVM, and wipe out anything that already existsd-i partman/choose_partition select finishd-i partman/confirm boolean trued-i partman/confirm_nooverwrite boolean trued-i partman-auto/method string lvmd-i partman-lvm/device_remove_lvm boolean trued-i partman-lvm/confirm boolean trued-i partman-lvm/confirm_nooverwrite boolean trued-i partman-md/device_remove_md boolean trued-i partman-partitioning/confirm_write_new_label boolean true# You can choose one of the three predefined partitioning recipes:# - atomic: all files in one partition# - home: separate /home partition# - multi: separate /home, /usr, /var, and /tmp partitionsd-i partman-auto/choose_recipe select atomic# If you just want to change the default filesystem from ext3 to something# else, you can do that without providing a full recipe.# d-i partman/default_filesystem string ext4## Part 5. Account setup# root account and passwordd-i passwd/root-login boolean trued-i passwd/root-password-crypted password $default_password_crypted# skip creation of a normal user account.d-i passwd/make-user boolean trued-i passwd/user-fullname string anjiad-i passwd/username string anjiad-i passwd/user-password-crypted password $default_password_crypted## Part 6. Apt setup# You can choose to install restricted and universe software, or to install# software from the backports repository.# d-i apt-setup/restricted boolean true# d-i apt-setup/universe boolean true# d-i apt-setup/backports boolean true# Uncomment this if you don't want to use a network mirror.# d-i apt-setup/use_mirror boolean true# Select which update services to use; define the mirrors to be used.# Values shown below are the normal defaults.# d-i apt-setup/services-select multiselect security# d-i apt-setup/security_host string mirrors.aliyun.com# d-i apt-setup/security_path string /ubuntu$SNIPPET('preseed_apt_repo_config')# Enable deb-src lines# d-i apt-setup/local0/source boolean true# URL to the public key of the local repository; you must provide a key or# apt will complain about the unauthenticated repository and so the# sources.list line will be left commented out# d-i apt-setup/local0/key string http://local.server/key# By default the installer requires that repositories be authenticated# using a known gpg key. This setting can be used to disable that# authentication. Warning: Insecure, not recommended.# d-i debian-installer/allow_unauthenticated boolean true## Part 7. Package selection# Default for minimaltasksel tasksel/first multiselect standard# Default for server# tasksel tasksel/first multiselect standard, web-server# Default for gnome-desktop# tasksel tasksel/first multiselect standard, gnome-desktop# Individual additional packages to install# wget is REQUIRED otherwise quite a few things won't work# later in the build (like late-command scripts)d-i pkgsel/include string ntp ssh wget# Debian needs this for the installer to avoid any question for grub# Please verify that it suit your needs as it may overwrite any usb stick#if $breed == \"debian\"d-i grub-installer/grub2_instead_of_grub_legacy boolean trued-i grub-installer/bootdev string default#end if# Use the following option to add additional boot parameters for the# installed system (if supported by the bootloader installer).# Note: options passed to the installer will be added automatically.d-i debian-installer/add-kernel-opts string $kernel_options_post# Avoid that last message about the install being complete.d-i finish-install/reboot_in_progress note## Figure out if we're kickstarting a system or a profile#if $getVar('system_name','') != ''#set $what = \"system\"#else#set $what = \"profile\"#end if# This first command is run as early as possible, just after preseeding is read.# d-i preseed/early_command string [command]d-i preseed/early_command string wget -O- \\ http://$http_server/cblr/svc/op/script/$what/$name/?script=preseed_early_default | \\ /bin/sh -s# This command is run immediately before the partitioner starts. It may be# useful to apply dynamic partitioner preseeding that depends on the state# of the disks (which may not be visible when preseed/early_command runs).# d-i partman/early_command \\# string debconf-set partman-auto/disk \"\\$(list-devices disk | head -n1)\"# This command is run just before the install finishes, but when there is# still a usable /target directory. You can chroot to /target and use it# directly, or use the apt-install and in-target commands to easily install# packages and run commands in the target system.# d-i preseed/late_command string [command]d-i preseed/late_command string wget -O- \\ http://$http_server/cblr/svc/op/script/$what/$name/?script=preseed_late_default | \\ chroot /target /bin/sh -s 创建 snippets安装完后，自动安装软件,参考 Using template scripts for Debian and Ubuntu seeds [root@localhost ~]# tee /var/lib/cobbler/snippets/ubuntu_apt_install_soft &lt;&lt;-'EOF'apt-get updateapt-get install -y language-pack-zh-hans apt-transport-https ca-certificates software-properties-common git ansible openssh-server vim curl htop iotop iftop ncducurl -fsSL http://mirrors.aliyun.com/docker-ce/linux/ubuntu/gpg | sudo apt-key add -sudo add-apt-repository \"deb [arch=amd64] http://mirrors.aliyun.com/docker-ce/linux/ubuntu $(lsb_release -cs) stable\"apt-get updateapt-get install -y docker-ce=18.06.2~ce~3-0~ubuntuapt-mark hold docker-cesystemctl enable dockerEOF## // d-i preseed/late_command 阶段执行[root@localhost ~]# echo '$SNIPPET(\"ubuntu_apt_install_soft\") &gt;&gt; /var/lib/cobbler/snippets/late_apt_repo_config 设置 ubuntu package repo[root@localhost ~]# cobbler repo edit --name=ubuntu-16.04.5-server-x86_64 --arch=x86_64 --breed=apt --mirror=http://mirrors.aliyun.com/ubuntu --owners=admin --mirror-locally=False --apt-components='main universe' --apt-dists='xenial xenial-updates xenial-security'[root@localhost ~]# cobbler profile edit --name=ubuntu-16.04.5-server-x86_64 --repos=ubuntu-16.04.5-server-x86_64 限于篇幅，下一篇，将介绍 Cobbler 安装 Windows 常见错误[root@localhost ~]# cobbler checkcobblerd does not appear to be running/accessible: error(111, 'Connection refused') 原因：未启动相关服务 [root@localhost ~]# cobbler checkhttpd does not appear to be running and proxying cobbler, or SELinux is in the way. Original traceback:Traceback (most recent call last): File \"/usr/lib/python2.7/site-packages/cobbler/cli.py\", line 251, in check_setup s.ping() File \"/usr/lib64/python2.7/xmlrpclib.py\", line 1233, in __call__ return self.__send(self.__name, args) File \"/usr/lib64/python2.7/xmlrpclib.py\", line 1591, in __request verbose=self.__verbose File \"/usr/lib64/python2.7/xmlrpclib.py\", line 1273, in request return self.single_request(host, handler, request_body, verbose) File \"/usr/lib64/python2.7/xmlrpclib.py\", line 1321, in single_request response.msg,ProtocolError: &lt;ProtocolError for 127.0.0.1:80/cobbler_api: 503 Service Unavailable&gt; 未关闭防火墙 [root@localhost ~]# cobbler syncreceived on stderr: Redirecting to /bin/systemctl restart dhcpd.serviceJob for dhcpd.service failed because the control process exited with error code. See \"systemctl status dhcpd.service\" and \"journalctl -xe\" for details.Exception occured: &lt;class 'cobbler.cexceptions.CX'&gt;Exception value: 'cobbler trigger failed: cobbler.modules.sync_post_restart_services'Exception Info: File \"/usr/lib/python2.7/site-packages/cobbler/remote.py\", line 82, in run rc = self._run(self) File \"/usr/lib/python2.7/site-packages/cobbler/remote.py\", line 181, in runner return self.remote.api.sync(self.options.get(\"verbose\",False),logger=self.logger) File \"/usr/lib/python2.7/site-packages/cobbler/api.py\", line 763, in sync return sync.run() File \"/usr/lib/python2.7/site-packages/cobbler/action_sync.py\", line 144, in run utils.run_triggers(self.api, None, \"/var/lib/cobbler/triggers/sync/post/*\", logger=self.logger) File \"/usr/lib/python2.7/site-packages/cobbler/utils.py\", line 928, in run_triggers raise CX(\"cobbler trigger failed: %s\" % m.__name__)!!! TASK FAILED !!! 没改 dhcp 模板，导致 sync 同步出问题 [root@localhost ~]# cat /var/log/httpd/ssl_error_log[Fri Feb 22 20:07:49.460442 2019] [:error] [pid 6910] [remote 127.0.0.1:204] mod_wsgi (pid=6910): Exception occurred processing WSGI script '/usr/share/cobbler/web/cobbler.wsgi'.[Fri Feb 22 20:07:49.460559 2019] [:error] [pid 6910] [remote 127.0.0.1:204] Traceback (most recent call last):[Fri Feb 22 20:07:49.460605 2019] [:error] [pid 6910] [remote 127.0.0.1:204] File \"/usr/share/cobbler/web/cobbler.wsgi\", line 26, in application[Fri Feb 22 20:07:49.460668 2019] [:error] [pid 6910] [remote 127.0.0.1:204] _application = get_wsgi_application()[Fri Feb 22 20:07:49.460684 2019] [:error] [pid 6910] [remote 127.0.0.1:204] File \"/usr/lib/python2.7/site-packages/django/core/wsgi.py\", line 13, in get_wsgi_application[Fri Feb 22 20:07:49.460723 2019] [:error] [pid 6910] [remote 127.0.0.1:204] django.setup(set_prefix=False)[Fri Feb 22 20:07:49.460737 2019] [:error] [pid 6910] [remote 127.0.0.1:204] File \"/usr/lib/python2.7/site-packages/django/__init__.py\", line 22, in setup[Fri Feb 22 20:07:49.460768 2019] [:error] [pid 6910] [remote 127.0.0.1:204] configure_logging(settings.LOGGING_CONFIG, settings.LOGGING)[Fri Feb 22 20:07:49.460781 2019] [:error] [pid 6910] [remote 127.0.0.1:204] File \"/usr/lib/python2.7/site-packages/django/conf/__init__.py\", line 56, in __getattr__[Fri Feb 22 20:07:49.460812 2019] [:error] [pid 6910] [remote 127.0.0.1:204] self._setup(name)[Fri Feb 22 20:07:49.460824 2019] [:error] [pid 6910] [remote 127.0.0.1:204] File \"/usr/lib/python2.7/site-packages/django/conf/__init__.py\", line 41, in _setup[Fri Feb 22 20:07:49.460852 2019] [:error] [pid 6910] [remote 127.0.0.1:204] self._wrapped = Settings(settings_module)[Fri Feb 22 20:07:49.460871 2019] [:error] [pid 6910] [remote 127.0.0.1:204] File \"/usr/lib/python2.7/site-packages/django/conf/__init__.py\", line 110, in __init__[Fri Feb 22 20:07:49.460900 2019] [:error] [pid 6910] [remote 127.0.0.1:204] mod = importlib.import_module(self.SETTINGS_MODULE)[Fri Feb 22 20:07:49.460911 2019] [:error] [pid 6910] [remote 127.0.0.1:204] File \"/usr/lib64/python2.7/importlib/__init__.py\", line 37, in import_module[Fri Feb 22 20:07:49.460953 2019] [:error] [pid 6910] [remote 127.0.0.1:204] __import__(name)[Fri Feb 22 20:07:49.460973 2019] [:error] [pid 6910] [remote 127.0.0.1:204] File \"/usr/share/cobbler/web/settings.py\", line 89, in &lt;module&gt;[Fri Feb 22 20:07:49.460995 2019] [:error] [pid 6910] [remote 127.0.0.1:204] from django.conf.global_settings import TEMPLATE_CONTEXT_PROCESSORS[Fri Feb 22 20:07:49.461043 2019] [:error] [pid 6910] [remote 127.0.0.1:204] ImportError: cannot import name TEMPLATE_CONTEXT_PROCESSORS pip2.7 install -U django==1.9.13 参考资料 配置防火墙 cobbler 2.8.4/2.8.0 on centos 7 error KICKSTART 语法参考 运维工作笔记-Cobbler 配置文件 Preseed 语法参考 Support selection of automatic installation file format in distros which allow it (Debian/Ubuntu allows kickstart and preseed) Problems Provisioning Ubuntu with Cobbler and Kickstart Profiles Using template scripts for Debian and Ubuntu seeds 招聘小广告山东济南的小伙伴欢迎投简历啊 加入我们 , 一起搞事情。 长期招聘，Java 程序员，大数据工程师，运维工程师，前端工程师。","tags":[{"name":"windows","slug":"windows","permalink":"https://anjia0532.github.io/tags/windows/"},{"name":"pxe","slug":"pxe","permalink":"https://anjia0532.github.io/tags/pxe/"},{"name":"dhcp","slug":"dhcp","permalink":"https://anjia0532.github.io/tags/dhcp/"},{"name":"cobbler","slug":"cobbler","permalink":"https://anjia0532.github.io/tags/cobbler/"},{"name":"centos","slug":"centos","permalink":"https://anjia0532.github.io/tags/centos/"},{"name":"ubuntu","slug":"ubuntu","permalink":"https://anjia0532.github.io/tags/ubuntu/"},{"name":"tftp","slug":"tftp","permalink":"https://anjia0532.github.io/tags/tftp/"}]},{"title":"005-blocked by：[FORBIDDEN/12/index read-only / allow delete (api)]","date":"2019-02-19T08:31:34.000Z","path":"2019/02/19/es-forbidden-12/","text":"这是坚持技术写作计划（含翻译）的第 5 篇，定个小目标 999，每周最少 2 篇。 吐槽一下，最近有点招 bug，前两天磁盘异常爆满，今天 es 又挂了。 Logstash ClusterBlockExceptionlogstash 日志中周期性出现 FORBIDDEN/12/index read-only / allow delete (api)] ，并且 es 中无法写入新数据。原因是 ES 主动保护功能，防止 es 集群状态变成红色(RED)或者黄色(YELLOW)原因有两个: 内存不足：JVMMemoryPressure 超过 92%并持续 30 分钟时，ES 触发保护机制，并且阻止写入操作，以防止集群达到红色状态，启用写保护后，写入操作将失败，并且抛出 ClusterBlockException ，无法创建新索引，并且抛出 IndexCreateBlockException ,当五分钟内恢复到 88%以下时，将禁用写保护 磁盘空间不足：es 的默认磁盘水位警戒线是 85%，一旦磁盘使用率超过 85%，es 不会再为该节点分配分片，es 还有一个磁盘水位警戒线是 90%，超过后，将尝试将分片重定位到其他节点。 解决方案 磁盘扩容 删除无用索引 将旧索引的副本数调小 增加数据节点 手动将 index.blocks.read_only_allow_delete 改成 false 另还有一种报错是 blocked by: [FORBIDDEN/8/index write (api)]; 后续再补充 参考资料 AWS elastic-search. FORBIDDEN/8/index write (api). Unable to write to index Dynamic Index Settings 招聘小广告山东济南的小伙伴欢迎投简历啊 加入我们 , 一起搞事情。 长期招聘，Java 程序员，大数据工程师，运维工程师，前端工程师。","tags":[{"name":"运维","slug":"运维","permalink":"https://anjia0532.github.io/tags/运维/"},{"name":"es","slug":"es","permalink":"https://anjia0532.github.io/tags/es/"},{"name":"elasticsearch","slug":"elasticsearch","permalink":"https://anjia0532.github.io/tags/elasticsearch/"}]},{"title":"004-零失败快速搞定通配符SSL证书","date":"2019-02-18T12:43:00.000Z","path":"2019/02/18/lets-encrypt-acme-sh/","text":"这是坚持技术写作计划（含翻译）的第四篇，定个小目标 999，每周最少 2 篇。 过去几年中，我们一直主张站点采用 HTTPS，以提升其安全性。去年的时候，我们还通过将更大的 HTTP 页面标记为‘不安全’以帮助用户。不过从 2018 年 7 月开始，随着 Chrome 68 的发布，浏览器会将所有 HTTP 网站标记为‘不安全’。引用自 chrome 68 发布说明 得益于 Google 等大厂的消灭 HTTP 运动和Let’s Encrypt 非盈利组织的努力，越来越多的站点开始迁移到 HTTPS，下图是Let’s Encrypt 的统计数据 什么是 Let’s Encrypt部署 HTTPS 网站的时候需要证书，证书由 CA 机构签发，大部分传统 CA 机构签发证书是需要收费的，这不利于推动 HTTPS 协议的使用。 Let’s Encrypt 是一个国外的非盈利的 CA 证书机构，旨在以自动化流程消除手动创建和安装证书的复杂流程，并推广使万维网服务器的加密连接无所不在，为安全网站提供免费的 SSL/TLS 证书。 由 Linux 基金会托管，许多国内外互联网大厂都对其进行赞助，目前主流浏览器均已信任 Let’s Encrypt 发放的证书。 注意，Let’s Encrypt 颁发的都是 DV 证书，不提供 OV,EV 证书。 本文主要讲解 如何使用 Let’s Encrypt 颁发通配符证书。 通配符证书通配符 SSL 证书旨在保护主域名以及旗下不限数量的子域，即用户可通过单个通配符 SSL 证书可保护任意数量的子域。如果用户拥有多个子域名平台，可通过通配符 SSL 证书保护这些子域名。 但是目前 Let’s Encrypt 只支持同级子域名通配符。例如 *.demo.com 只支持 xx.demo.com 这种的，而不支持 xx.xx.demo.com ，而要支持二级通配符，需要再次颁发二级通配符证书 类似 *.demo.demo.com ，注意，这种的二级通配符，要求，一级域名是固定的，意即，不支持 *.*.demo.com 使用 acme.sh 简化证书颁发操作官方建议使用Certbot ，但是很长一段时期 Certbot 不支持通配符（现在已经支持），而且对于证书自动续期支持的也不好。并且操作时也挺麻烦。 安装 acme.sh$ curl https://get.acme.sh | sh# 或者$ wget -O - https://get.acme.sh | sh# 或者$ git clone https://github.com/Neilpang/acme.sh.git$ ./acme.sh/acme.sh --install DNS Api 颁发通配符证书acme.sh 功能很强大，此处只介绍使用 Dns Api 自动化颁发通配符证书. 目前支持包含阿里和 DNSPod 在内的 60 家 dns 服务商（参见 Currently acme.sh supports） 如果你的 DNS 服务商不提供 API 或者 acme.sh 暂未支持，或者处于安全方面的考虑，不想将重要的域名的 API 权限暴露给 acme.sh，可以申请一个测试域名，然后在重要域名上设置 CNAME（参见 DNS alias mode） 假设您的域名在 DNSPod 托管，登陆 DNSPod 后台，依次打开 用户中心-&gt;安全设置-&gt; API Token-&gt;查看-&gt;创建 API Token-&gt; 输入任意 token 名称-&gt;确定-&gt; 保存 ID 和 Token 值（图中打码部分） $ export DP_Id=\"你的ID\"$ export DP_Key=\"你的Token\"$ acme.sh --issue --dns dns_dp -d example.com -d *.example.com# 如果 使用了DNS别名，还需要增加 --challenge-alias 别名域名 参数# 为了防止dns不生效，脚本会暂停2分钟，并倒计时(Sleep 120 seconds for the txt records to take effect),等待即可# 如果成功会出现 Cert success. 字样# 不建议直接用~/.acme.sh 下的证书，参考 https://github.com/Neilpang/acme.sh/wiki/说明#3-copy安装-证书# 需要使用 --installcert 复制到指定目录$ acme.sh --installcert \\ -d example.com -d *.example.com \\ --key-file /etc/letsencrypt/live/example.com/privkey.pem \\ --fullchain-file /etc/letsencrypt/live/example.com/fullchain.pem \\ --reloadcmd \"service nginx reload\" 优化 HTTPS 配置本文以 Mozilla SSL Configuration Generator 生成的 nginx 为例，同样也可以生成 Apache 和 IIS server &#123; listen 80 default_server; listen [::]:80 default_server; # Redirect all HTTP requests to HTTPS with a 301 Moved Permanently response. return 301 https://$host$request_uri;&#125;server &#123; listen 443 ssl http2; listen [::]:443 ssl http2; # certs sent to the client in SERVER HELLO are concatenated in ssl_certificate ssl_certificate /etc/letsencrypt/live/example.com/fullchain.pem; ssl_certificate_key /etc/letsencrypt/live/example.com/privkey.pem; ssl_session_timeout 1d; ssl_session_cache shared:SSL:50m; ssl_session_tickets off; # Diffie-Hellman parameter for DHE ciphersuites, recommended 2048 bits # openssl dhparam -out /etc/letsencrypt/live/example.com/ 2048 ssl_dhparam /etc/letsencrypt/live/example.com/dhparam.pem; # intermediate configuration. tweak to your needs. ssl_protocols TLSv1 TLSv1.1 TLSv1.2; ssl_ciphers 'ECDHE-ECDSA-CHACHA20-POLY1305:ECDHE-RSA-CHACHA20-POLY1305:ECDHE-ECDSA-AES128-GCM-SHA256:ECDHE-RSA-AES128-GCM-SHA256:ECDHE-ECDSA-AES256-GCM-SHA384:ECDHE-RSA-AES256-GCM-SHA384:DHE-RSA-AES128-GCM-SHA256:DHE-RSA-AES256-GCM-SHA384:ECDHE-ECDSA-AES128-SHA256:ECDHE-RSA-AES128-SHA256:ECDHE-ECDSA-AES128-SHA:ECDHE-RSA-AES256-SHA384:ECDHE-RSA-AES128-SHA:ECDHE-ECDSA-AES256-SHA384:ECDHE-ECDSA-AES256-SHA:ECDHE-RSA-AES256-SHA:DHE-RSA-AES128-SHA256:DHE-RSA-AES128-SHA:DHE-RSA-AES256-SHA256:DHE-RSA-AES256-SHA:ECDHE-ECDSA-DES-CBC3-SHA:ECDHE-RSA-DES-CBC3-SHA:EDH-RSA-DES-CBC3-SHA:AES128-GCM-SHA256:AES256-GCM-SHA384:AES128-SHA256:AES256-SHA256:AES128-SHA:AES256-SHA:DES-CBC3-SHA:!DSS'; ssl_prefer_server_ciphers on; # HSTS (ngx_http_headers_module is required) (15768000 seconds = 6 months) add_header Strict-Transport-Security max-age=15768000; # OCSP Stapling --- # fetch OCSP records from URL in ssl_certificate and cache them ssl_stapling on; ssl_stapling_verify on; ## verify chain of trust of OCSP response using Root CA and Intermediate certs # ssl_trusted_certificate /path/to/root_CA_cert_plus_intermediates; resolver &lt;IP DNS resolver&gt;; ....&#125; 检查 HTTPS 得分访问 https://www.ssllabs.com/ssltest/ 提交自己域名，进行评分 参考资料 Chrome 将不再标记 HTTPS 页面为安全站点 Let’s Encrypt Stats About Let’s Encrypt Mozilla SSL Configuration Generator DV 型、OV 型、EV 型证书的主要区别 Neilpang/acme.sh#Wiki#安装说明 Neilpang/acme.sh#Wiki#How to Install Neilpang/acme.sh#Wiki#How to use DNS API 招聘小广告山东济南的小伙伴欢迎投简历啊 加入我们 , 一起搞事情。 长期招聘，Java 程序员，大数据工程师，运维工程师，前端工程师。","tags":[{"name":"ssl","slug":"ssl","permalink":"https://anjia0532.github.io/tags/ssl/"},{"name":"https","slug":"https","permalink":"https://anjia0532.github.io/tags/https/"},{"name":"http2","slug":"http2","permalink":"https://anjia0532.github.io/tags/http2/"},{"name":"lets-encrypt","slug":"lets-encrypt","permalink":"https://anjia0532.github.io/tags/lets-encrypt/"},{"name":"acme","slug":"acme","permalink":"https://anjia0532.github.io/tags/acme/"},{"name":"acme-sh","slug":"acme-sh","permalink":"https://anjia0532.github.io/tags/acme-sh/"}]},{"title":"【译】单应用跨多k8s集群的部署与管理","date":"2019-02-15T14:08:00.000Z","path":"2019/02/15/rancher2-k8s-multi-cluster-app/","text":"引言近日(春节前后)，Rancher labs 宣布，其旗下的开源企业级 Kubernetes 管理平台 Rancher，发布了 Rancher 2.2 Preview 2（预览版 2），它包含了许多在 k8s 集群操作的强大特性 可以通过访问发布页面和发布说明来了解所发布的新功能 本文将介绍其中一个特性：多集群应用(multi-cluster applications)，下面将为您介绍，该特性将如何显著减少您的工作量，并提高多集群操作的可靠性。 概览假如您有用过 k8s，并且有两个及以上的集群运维经验，那么您遇到下面的情况 当跨多个可用区部署(AZs)时，应用需要具有更高的容错性 在具有数百个集群的边缘计算场景中，同一个应用需要在多个集群上运行。 在高可靠性的情况下，运维操作人员通常通过将节点从多个可用区纳入到一个集群内来降低单个可用区不可用风险。但是这个方案的问题在于，虽然抵抗了可用区故障，但是防不住集群本身故障，集群故障的可能性高于可用区故障，而且一旦集群出故障后，可能会影响集群中在运行的程序。 另外一种方法是，每个可用区中运行单独的集群，病症每个集群上运行应用程序的副本。相当于每个可用区都有一套 k8s 集群，但是每个集群手动维护应用程序成本高，又易错。 边缘计算场景跟多可用区集群相同的问题：应用程序手动维护，既耗时，又容易出错，即使运维团队给力，创建了复杂的脚本来部署和升级，但是又多了一个故障点，而且这些脚本也需要升级和维护，并且要求负责的运维人员不仅要编写流程（升级发版流程），还要在脚本失败时能够转成人肉运维。 从Rancher 2.2 Preview 2 开始，Rancher 支持在任意数量的 k8s 集群中同时部署和升级同一应用程序的副本。 同时也扩展了基于 Helm 软件包管理器的应用商店(Application Catalogs)，在此之前，应用商店仅适用于单个集群,我们在全局级别增加了一个附加功能，权限允许的情况下，可以将应用程序部署到 Rancher 管理的任意集群上。 有关 Rancher 2.2 Preview2 的功能的完整演示，请加入 Rancher2 月份的在线 MeetUp ，届时将提供新功能的演示，并在 Q&amp;A 环节进行答疑。 下面将演示，在 Rancher 中如何便捷的管理多集群应用。 功能快速入门 登陆 Rancher 后，将看到纳管的所有集群的列表，同时在菜单栏新增了一个 多集群应用(Multi-Cluster Apps) 的按钮 单击 多集群应用 按钮后，将看到两个按钮，管理Catalogs 和 启动 。管理Catalogs 将跳到 应用商店(Catalogs) 的管理页，您开源在其中启用主要 Helm repo 或者添加其他第三方 Helm repo。 单击 启动 按钮以启动新应用程序。 从显示的可以部署的应用中，选择 Grafana(用于演示)。 按照要求配置详细信息，使用表单或者直接用提供 YAML 进行配置，注意，在此处的设置将应用到部署此应用程序的集群中。 在 配置选项 下，在 Target（目标） 下拉框中选择目标集群的指定项目。 选择升级策略。此处为了演示，我们将选择 滚动更新 并提供每批 1 个，间隔 20 秒。此设置可以确保以后升级应用时，一次只更新一个集群，并且每个集群升级操作的间隔为 20 秒。 如果要调整集群间的差异，可以在 Answer Overrides 部分进行设置。 一切准备妥当，点击底部 启动 ,然后将跳到结果页，显示刚刚已安装的多集群应用(此处是演示用的 Grafana)。每个应用将显示当前状态和目标集群以及项目列表。 当应用程序可以升级时，应用状态将显示 Upgrade Available 要启动升级，请单击应用上的菜单按钮（三个点的菜单），然后选择升级 验证是否已选择 滚动更新 选项 更改一些设置，然后点击底部的 升级 按钮 打开目标集群的 工作负载 选项卡，将看到其中一个状态更改为 更新 ,此集群中的应用将被更新，然后 Rancher 将暂停 20s（刚刚设置的间隔时间）,然后继续更新下一个集群的应用。 总结多集群应用程序将减少运维团队的工作量，并使跨集群快速可靠的部署和升级应用成为可能。要在实验室或者开发环境中测试这些功能，请安装最新的 Alpha 版本，如果有任何反馈意见，请在Github 上提交 Issues 或者加入论坛 或Slack 。 参考资料 rancher 博客原文–Introducing Multi-Cluster Applications in Rancher 2.2 Preview 2 Rancher 中国微信公众号–革命性新特性 | 单一应用跨多 Kubernetes 集群的部署与管理 招聘小广告山东济南的小伙伴欢迎投简历啊 加入我们 , 一起搞事情。 长期招聘，Java 程序员，大数据工程师，运维工程师，前端工程师。","tags":[{"name":"运维","slug":"运维","permalink":"https://anjia0532.github.io/tags/运维/"},{"name":"k8s","slug":"k8s","permalink":"https://anjia0532.github.io/tags/k8s/"},{"name":"rancher","slug":"rancher","permalink":"https://anjia0532.github.io/tags/rancher/"},{"name":"rancher2","slug":"rancher2","permalink":"https://anjia0532.github.io/tags/rancher2/"},{"name":"集群","slug":"集群","permalink":"https://anjia0532.github.io/tags/集群/"},{"name":"翻译","slug":"翻译","permalink":"https://anjia0532.github.io/tags/翻译/"}]},{"title":"Linux磁盘空间占满问题快速排雷","date":"2019-02-14T14:36:00.000Z","path":"2019/02/14/linux-ncdu-no-space/","text":"情人节一大早就接到报警，一台测试服务器磁盘满了，这很程序员。 磁盘排雷三连反手一个 df 先看是否是真满了(参考 df(1) - Linux man page )需要注意，如果磁盘空间未满，但是仍然报 No space left on device ,需要执行 df -i 排查 inode $ df -h文件系统 容量 已用 可用 已用% 挂载点udev 47G 0 47G 0% /devtmpfs 9.4G 620M 8.8G 7% /run/dev/sda2 1.1T 1.1T 0G 100% /tmpfs 47G 8.7M 47G 1% /dev/shmtmpfs 5.0M 4.0K 5.0M 1% /run/locktmpfs 47G 0 47G 0% /sys/fs/cgroup/dev/sda1 511M 1.2M 510M 1% /boot/efitmpfs 9.4G 108K 9.4G 1% /run/user/1000tmpfs 9.4G 40K 9.4G 1% /run/user/0$ df -i文件系统 Inode 已用(I) 可用(I) 已用(I)% 挂载点udev 12277823 525 12277298 1% /devtmpfs 12285255 1368 12283887 1% /run/dev/sda2 71041024 2250210 68790814 4% /tmpfs 12285255 83 12285172 1% /dev/shmtmpfs 12285255 5 12285250 1% /run/locktmpfs 12285255 17 12285238 1% /sys/fs/cgroup/dev/sda1 0 0 0 - /boot/efitmpfs 12285255 44 12285211 1% /run/user/1000tmpfs 12285255 15 12285240 1% /run/user/0 通过 df -h 只能看出磁盘满了，但是看不出每个文件夹的大小，所以需要使用 du -ahd1 ,如果文件不是很多，很大，一般速度还能接受，但是今天执行相当慢，所以 Ctrl+C 中止。此处简单说明一下 -ahd1 的意思(可以通过 man du 或者 du --help 自行查阅帮助文档,参考 du(1) - Linux man page) $ du --help用法：du [选项]... [文件]... 或：du [选项]... --files0-from=F -a, --all write counts for all files, not just directories (所有文件，不止目录) -h, --human-readable print sizes in human readable format (e.g., 1K 234M 2G) (易读单位，会损失精度) -d, --max-depth=N print the total for a directory (or file, with --all) (只扫描一层目录) only if it is N or fewer levels below the command line argument; --max-depth=0 is the same as --summarize $ du -ahd1 /1.6M /dev4.0K /mnt4.0K /lib64455M /boot0 /sys0 /vmlinuz.old689G /data370M /tmp15M /etc8.0K /mediadu: 无法访问'/proc/24390/task/24390/fd/4': 没有那个文件或目录du: 无法访问'/proc/24390/task/24390/fdinfo/4': 没有那个文件或目录du: 无法访问'/proc/24390/fd/3': 没有那个文件或目录du: 无法访问'/proc/24390/fdinfo/3': 没有那个文件或目录^C# 慢的要死，Ctrl+C 终止 如果被删除的文件 df -h 快满了，而 du -ahd1 却很小，往往是文件被删除，而文件句柄没释放导致的,祭出 lsof | grep deleted ，解决办法，要么 kill 掉 pid，释放句柄(治本)，要么就 &gt; /path/to/deleted/file 把内容覆盖掉(治标)。当然还有别的玩法，比如，不小心 rm -rf / 了，先别着急跑路，万一 lsof | grep deleted 还存在的，都还有救，约等于 windows 下的回收站的作用。 参考 lsof(8) - Linux man page $ lsof -i | grep deleted# 当然也不快 ncdu针对 du -d1 大文件场景下的龟速表现，有人开发了 ncdu,以 ubuntu 为例 # 从APT安装(版本较旧目前是v1.11)$ sudo apt-get update$ sudo apt-get install -y ncdu# 从源码编译安装(此处是1.14版本)$ sudo apt-get install -y libncurses5-dev # 如果不安装会报 configure: error: required header file not found$ wget https://dev.yorhel.nl/download/ncdu-1.14.tar.gz$ tar zxf ncdu-1.14.tar.gz$ cd ncdu-1.14$ ./configure --prefix=/usr$ make &amp;&amp; make install 参考官方文档 Ncdu Manual 额外通过 man 查询命令时，手册中会带有数字(例如 du(1) , lsof(8) )，这代表的是手册的不同部分，可以通过 man man 或者 Linux man pages 来查看 MANUAL SECTIONS The standard sections of the manual include: 1 User Commands 2 System Calls 3 C Library Functions 4 Devices and Special Files 5 File Formats and Conventions 6 Games et. al. 7 Miscellanea 8 System Administration tools and Daemons Distributions customize the manual section to their specifics, which often include additional sections. 参考资料 What do the numbers in a man page mean? df(1) - Linux man page du(1) - Linux man page lsof(8) - Linux man page Ncdu Manual 招聘小广告山东济南的小伙伴欢迎投简历啊 加入我们 , 一起搞事情。 长期招聘，Java 程序员，大数据工程师，运维工程师。","tags":[{"name":"运维","slug":"运维","permalink":"https://anjia0532.github.io/tags/运维/"},{"name":"devops","slug":"devops","permalink":"https://anjia0532.github.io/tags/devops/"},{"name":"linux","slug":"linux","permalink":"https://anjia0532.github.io/tags/linux/"},{"name":"排雷","slug":"排雷","permalink":"https://anjia0532.github.io/tags/排雷/"},{"name":"磁盘","slug":"磁盘","permalink":"https://anjia0532.github.io/tags/磁盘/"},{"name":"ncdu","slug":"ncdu","permalink":"https://anjia0532.github.io/tags/ncdu/"}]},{"title":"Ansible2.7批量管理Windows","date":"2019-02-14T00:58:00.000Z","path":"2019/02/14/ansible-2-7-windows/","text":"简述背景Ansible 是一款轻量级的开源的自动化运维工具，支持 linux 和 windows(只支持 client，并且部分模块)，利用 Ansible 可以简单批量的配置系统，安装软件，或者更高级的运维任务（比如滚动升级）。 Ansible 之类的运维工具对运维工作进行抽象及规范，能够极大的降低运维难度。本文只是为了演示如何通过 ansible 的各模块对 windows 进行传输文件,管理账号,执行脚本等批量自动化管理工作 实验环境 类型 系统 ip Server Ubuntu Server 16.04.5 LTS X64 192.168.0.22 Client Windows Server 2008 R2 SP1 192.168.0.23 注意： 如果是实验目的，建议用 Vmware，并且在关键操作时备份快照（比如，刚装完环境，升级完 PS 和.Net 后），这样能够及时，干净的还原现场，节省每次重装系统导致的时间浪费 Windows 被控端(Ansible Client)Ansible 只支持 Powershell 4.0 及以上(用 3.0 会报 Process is terminated due to StackOverflowException.)，所以要求最低要求 Win7,或者 Win server 2008,详见 Ansible Doc host requirements 升级 PowerShell 和.Net Framework官方文档要求升级至 ps3.0 即可，但是实验发现，3.0 会报错 Win+R -&gt; PowerShell 打开 PowerShell 输入 $PSVersionTable 查看 PSVersion 确保大于等于 4.0(PowerShell 4.0),以及 CLRVersion 大于等于 4.0(.NET Framework 4.0) ,如果版本过低，则执行下面代码，直接复制到 PowerShell 执行即可,建议使用 5.1(参考 hotfixv4.trafficmanager.net dont work 和 安装和配置 WMF 5.1) 注意： 注意用户名密码改成管理员的用户名密码 确保能够访问外网 PowerShell 以管理员模式打开 PS3 不能直升 PS5，需要卸载 PS3 或者保存 PSModulePath 安装 PS5 需要先打最新 SP 补丁 PS5 要求 .NET Framework 不低于 4.5.2 安装成功后会自动重启服务器，注意别影响其他服务 $url = \"https://raw.githubusercontent.com/jborean93/ansible-windows/master/scripts/Upgrade-PowerShell.ps1\"$file = \"$env:temp\\Upgrade-PowerShell.ps1\"$username = \"管理员用户名\"$password = \"管理员密码\"(New-Object -TypeName System.Net.WebClient).DownloadFile($url, $file)Set-ExecutionPolicy -ExecutionPolicy Unrestricted -Force# PowerShell 版本，只能用 3.0, 4.0 和 5.1&amp;$file -Version 5.1 -Username $username -Password $password -Verbose 重启后，再次打开 PS ,输入 $PSVersionTable 查看版本 安装 WinRM，并且配置监听## 配置WinRM$url = &quot;https://raw.githubusercontent.com/ansible/ansible/devel/examples/scripts/ConfigureRemotingForAnsible.ps1&quot;$file = &quot;$env:temp\\ConfigureRemotingForAnsible.ps1&quot;(New-Object -TypeName System.Net.WebClient).DownloadFile($url, $file)powershell.exe -ExecutionPolicy ByPass -File $file Linux 主控端(Ansible Server)安装 Ansible 和 pywinrm参考 Installing the Control Machine $ sudo apt-get update$ sudo apt-get install -y software-properties-common$ sudo apt-add-repository --yes --update ppa:ansible/ansible$ sudo apt-get install -y ansible$ ansible --versionansible 2.7.7 config file = /etc/ansible/ansible.cfg configured module search path = [u'/root/.ansible/plugins/modules', u'/usr/share/ansible/plugins/modules'] ansible python module location = /usr/lib/python2.7/dist-packages/ansible executable location = /usr/bin/ansible python version = 2.7.12 (default, Nov 12 2018, 14:36:49) [GCC 5.4.0 20160609]$ pip install \"pywinrm&gt;=0.3.0\" 配置 Inventory参考 Working with Inventory 默认是 Inventory /etc/ansible/hosts ,此处改为手动指定，Ansible 的 Inventory 支持 ini 格式和 yaml 格式，本文采用 yaml 格式 $ mkdir ansible$ tee ansible/test_hosts.yaml &lt;&lt;-'EOF'winserver: hosts: 192.168.0.23: vars: ansible_user: Administrator ansible_password: 密码 ansible_connection: winrm ansible_port: 5986 ansible_winrm_server_cert_validation: ignoreEOF 探测主机是否存活$ ansible -i ansible/test_hosts.yaml winserver -m win_ping 192.168.0.23 | SUCCESS =&gt; &#123; \"changed\": false, \"ping\": \"pong\"&#125; 如果报错 TASK [Gathering Facts] *******************************************************************************************************************************************************************************************************************************************************fatal: [192.168.0.23]: UNREACHABLE! =&gt; &#123;\"changed\": false, \"msg\": \"ssl: HTTPSConnectionPool(host='192.168.0.23', port=5986): Max retries exceeded with url: /wsman (Caused by SSLError(SSLError(\\\"bad handshake: Error([('SSL routines', 'tls_process_server_certificate', 'certificate verify failed')],)\\\",),))\", \"unreachable\": true&#125; 降级一下 pip install &quot;pywinrm==0.2.2&quot; 更多实验，参见参考资料中的两篇 51cto 中的博文 可用的 Windows 模块根据 What modules are available? 绝大部分 Module 都是针对 Linux 编写的，大部分在 windows 下不能正常使用，有一些专用的 windows module 使用 ps 编写的，可用在 windows 下使用，详细列表参见 Windows modules Windows 常见问题官方文档中列举了 Ansible windows 常见问题，建议仔细阅读 Ansible PlaybookAnsible 配合playbook食用更佳，上述中的 ansible 命令是adhoc 命令模式，类似在 bash 中手动执行命令，多用于简单，并且不需要复用场景，而 ansible-playbook 类似 bash 脚本，但是更强大，适合复杂任务编排场景。 考虑后期出一个 playbook 的文章 推荐配合vscode的ansible 插件(github repo 地址 https://github.com/VSChina/vscode-ansible) 效果如下所示，比 idea 的 ansible 强大很多。 参考资料 官方文档 官方文档-windows 指南 官方文档-windows 指南-winrm 步骤 Ansible 批量远程管理 Windows 主机(部署与配置) ansible 自动化管理 windows 系统实战 安装和配置 WMF 5.1 hotfixv4.trafficmanager.net dont work 招聘小广告山东济南的小伙伴欢迎投简历啊 加入我们 , 一起搞事情。 长期招聘，Java 程序员，大数据工程师，运维工程师。","tags":[{"name":"ansible","slug":"ansible","permalink":"https://anjia0532.github.io/tags/ansible/"},{"name":"运维","slug":"运维","permalink":"https://anjia0532.github.io/tags/运维/"},{"name":"devops","slug":"devops","permalink":"https://anjia0532.github.io/tags/devops/"},{"name":"windows","slug":"windows","permalink":"https://anjia0532.github.io/tags/windows/"},{"name":"ansible-playbook","slug":"ansible-playbook","permalink":"https://anjia0532.github.io/tags/ansible-playbook/"}]},{"title":"加速和简化构建Docker(基于Google jib)","date":"2019-02-08T21:26:00.000Z","path":"2019/02/08/google-jib/","text":"介绍其实 jib 刚发布时就有关注，但是一直没有用于生产，原因有二 基于 spotify/docker-maven-plugin (原作者已经停止维护 docker-maven-plugin，建议使用 spotify/dockerfile-maven)的原有流程跑的好好的，没动力换成 jib Google jib 一直没有发布 1.x ，担心其不稳定 先简单介绍一下: google jib 是 Google 于 18 年 7 月发布的一个针对 Java 应用的构建镜像的工具(支持Maven和Gradle) ，好处是能够复用构建缓存，能够加快构建，减小传输体积（后文会详细讲解），并且让 Java 工程师不需要理解 Docker 相关知识就可以简单构建镜像并且发布到指定 registry 里（不需要 docker build , tag, push） 本文会依次讲解三种 java 构建镜像的方法，分别是 正统的 Dockerfile ，spotify/dockerfile-maven ，Google jib 附赠 alibaba/arthas 的集成和使用方法 准备 Maven3.5 Git Jdk 1.8 Docker $ git clone https://github.com/anjia0532/jib-demo.git$ cd jib-demo$ mvn clean package -DskipTests$ mkdir docker$ cp ./target/*.jar ./docker Dockerfile创建 ./docker/Dockerfile ,内容如下，需要注意此处为了方便理解，没有进行改进（比如限制用户，安装必要软件等） FROM openjdk:8-jdk-alpineADD *.jar /app.jarEXPOSE 8080CMD java $&#123;JAVA_OPTS&#125; /app.jar 详情参见 官方文档 Dockerfile reference $ cd ./docker$ sudo docker build . -t jib-demo$ docker images --查看本地images$ docker tag jib-demo anjia0532/jib-demo --不写registry，则默认为docker hub registry,可以在build时，直接写$ docker push anjia0532/jib-demo -- 推送到registry 小结优点： 不需要改造 pom，灵活，配合 CI 工具，可以不侵入项目，运维可以针对性的进行安全加固，并且可以做到标准化 缺点： 命令复杂，Java 程序员需要学习 Dockerfile 命令，或者运维和 java 沟通不畅时，时区，软件，甚至目录等都可能有出问题 spotify/dockerfile-maven需要注意，spotify/dockerfile-maven 是需要 pom+Dockerfile 一块用的，而 docker-maven-plugin 是可选的 在项目根目录创建 Dockerfile，如下所示 FROM openjdk:8-jdk-alpineEXPOSE 8080ARG JAR_FILEADD target/$&#123;JAR_FILE&#125; /usr/share/myservice/myservice.jarENTRYPOINT [\"/usr/bin/java\", \"-jar\", \"/usr/share/myservice/myservice.jar\"] 在 pom 里增加 dockerfile-maven-plugin 到 build 标签里 &lt;build&gt; &lt;plugins&gt; ... &lt;plugin&gt; &lt;groupId&gt;com.spotify&lt;/groupId&gt; &lt;artifactId&gt;dockerfile-maven-plugin&lt;/artifactId&gt; &lt;version&gt;$&#123;dockerfile-maven-version&#125;&lt;/version&gt; &lt;executions&gt; &lt;execution&gt; &lt;id&gt;default&lt;/id&gt; &lt;goals&gt; &lt;goal&gt;build&lt;/goal&gt; &lt;goal&gt;push&lt;/goal&gt; &lt;/goals&gt; &lt;/execution&gt; &lt;/executions&gt; &lt;configuration&gt; &lt;repository&gt;anjia0532/dockerfile-maven-demo&lt;/repository&gt; &lt;tag&gt;$&#123;project.version&#125;&lt;/tag&gt; &lt;buildArgs&gt; &lt;JAR_FILE&gt;$&#123;project.build.finalName&#125;.jar&lt;/JAR_FILE&gt; &lt;/buildArgs&gt; &lt;/configuration&gt; &lt;/plugin&gt; ... &lt;plugins&gt;&lt;build&gt; 运行如下命令进行构建 $ mvn package -DskipTests 详情参见 官方文档 spotify/dockerfile-maven 小结优点： 减少了 docker build &amp; tag &amp; push 的操作，Java 程序员能够控制镜像名 缺点： 其实就是省了 docker build &amp; tag &amp; push 的操作，别的缺点一点没落不说，还得改动 pom，还得要求写 Dockerfile，tag 只支持一个等等 Google jib修改默认 settings.xml，增加 registry 认证,参见Authentication Methods &lt;settings&gt; ... &lt;servers&gt; ... &lt;server&gt; &lt;id&gt;docker_hub&lt;/id&gt; &lt;username&gt;MY_USERNAME&lt;/username&gt; &lt;password&gt;&#123;MY_SECRET&#125;&lt;/password&gt; &lt;/server&gt; &lt;/servers&gt;&lt;/settings&gt; 改动 pom.xml 增加 jib 插件 &lt;project&gt; ... &lt;build&gt; &lt;plugins&gt; ... &lt;plugin&gt; &lt;groupId&gt;com.google.cloud.tools&lt;/groupId&gt; &lt;artifactId&gt;jib-maven-plugin&lt;/artifactId&gt; &lt;version&gt;1.0.0&lt;/version&gt; &lt;configuration&gt; &lt;from&gt; &lt;!-- 如果不需要arthas可以改为 registry.hub.docker.com/openjdk:8-jdk-alpine --&gt; &lt;image&gt;registry.hub.docker.com/hengyunabc/arthas:latest&lt;/image&gt; &lt;credHelper&gt;docker_hub&lt;/credHelper&gt; &lt;/from&gt; &lt;to&gt; &lt;image&gt;$&#123;project.artifactId&#125;&lt;/image&gt; &lt;tags&gt; &lt;tag&gt;latest&lt;/tag&gt; &lt;tag&gt;$&#123;project.version&#125;&lt;/tag&gt; &lt;/tags&gt; &lt;/to&gt; &lt;container&gt; &lt;mainClass&gt;$&#123;start-class&#125;&lt;/mainClass&gt; &lt;ports&gt; &lt;port&gt;8080&lt;/port&gt; &lt;port&gt;5701/udp&lt;/port&gt; &lt;port&gt;8563&lt;/port&gt; &lt;/ports&gt; &lt;entrypoint&gt; &lt;shell&gt;sh&lt;/shell&gt; &lt;option&gt;-c&lt;/option&gt; &lt;arg&gt;java -cp /app/resources/:/app/classes/:/app/libs/* com.example.demo.DemoApplication&lt;/arg&gt; &lt;/entrypoint&gt; &lt;appRoot&gt;/app&lt;/appRoot&gt; &lt;useCurrentTimestamp&gt;true&lt;/useCurrentTimestamp&gt; &lt;/container&gt; &lt;/configuration&gt; &lt;/plugin&gt; ... &lt;/plugins&gt; &lt;/build&gt; ...&lt;/project&gt; 执行mvn clean compile jib:dockerBuild 构建 docker 镜像 注意： pom 中用的是 registry.hub.docker.com/hengyunabc/arthas:latest 是 alibaba/arthas (阿里开源的一个 Java 诊断工具，便于线上调试)封装的 docker 镜像，如果不需要可以改成 registry.hub.docker.com/openjdk:8-jdk-alpine $ docker run -d --init -p8563:8563 --name demo demo:latest## 下面是启动arthas，如果使用的是openjdk镜像请勿执行$ docker exec -it demo /bin/sh$ jid=$(jps | grep App | awk '&#123;print $1&#125;')$ java -jar /opt/arthas/arthas-boot.jar --target-ip 0.0.0.0 $&#123;jid&#125; 如果使用了 arthas 镜像，可以访问 http://ip:8563 ，在页面上填上宿主 ip，点击 Connect， 然后参考Arthas/命令列表 了解 Arthas 命令用法 小结优点： 充分利用缓存，加快构建，不强制依赖 docker daemon，依赖简单（在 maven 或 gradle 增加插件即可） 缺点： 不支持 Docker RUN 命令(jib 官方建议将 run 封装到 base 镜像)，对 entrypoint 和 cmd 支持不太好(alpine 默认不支持多任务，跑 java 应用默认是 pid 1 ，运行 jmap 等命令会报错，参考 jmap not happy on alpine ) jib 缓存策略项目每次发布实际上变更的代码量不大，尤其依赖的 jar 变动的可能性较小，如果按照前两种方案构建镜像，会导致每次都全量构建，会导致存储和带宽资源浪费。 &gt; Jib 如何让开发变得更美好 Jib 利用了 Docker 镜像的分层机制，将其与构建系统集成，并通过以下方式优化 Java 容器镜像的构建： 简单——Jib 使用 Java 开发，并作为 Maven 或 Gradle 的一部分运行。你不需要编写 Dockerfile 或运行 Docker 守护进程，甚至无需创建包含所有依赖的大 JAR 包。因为 Jib 与 Java 构建过程紧密集成，所以它可以访问到打包应用程序所需的所有信息。在后续的容器构建期间，它将自动选择 Java 构建过的任何变体。 快速——Jib 利用镜像分层和注册表缓存来实现快速、增量的构建。它读取你的构建配置，将你的应用程序组织到不同的层（依赖项、资源、类）中，并只重新构建和推送发生变更的层。在项目进行快速迭代时，Jib 只讲发生变更的层（而不是整个应用程序）推送到注册表来节省宝贵的构建时间。 可重现——Jib 支持根据 Maven 和 Gradle 的构建元数据进行声明式的容器镜像构建，因此，只要输入保持不变，就可以通过配置重复创建相同的镜像。 可以可以通过 mvn clean compile jib:buildTar 生成 target/jib-image.tar 然后用解压缩工具解压后进行分析，实际上 jib 会将 lib 中非快照部分放到一个层，将快照部分放到一个层，将源码编译后放到一个层。。。 参考资料 谷歌开源 Java 镜像构建工具 Jib jib 自定义 entrypoint jib 打包 docker 镜像实战 Jib - Containerize your Maven project","tags":[{"name":"docker","slug":"docker","permalink":"https://anjia0532.github.io/tags/docker/"},{"name":"k8s","slug":"k8s","permalink":"https://anjia0532.github.io/tags/k8s/"},{"name":"微服务","slug":"微服务","permalink":"https://anjia0532.github.io/tags/微服务/"},{"name":"容器","slug":"容器","permalink":"https://anjia0532.github.io/tags/容器/"},{"name":"google-jib","slug":"google-jib","permalink":"https://anjia0532.github.io/tags/google-jib/"},{"name":"jib","slug":"jib","permalink":"https://anjia0532.github.io/tags/jib/"},{"name":"arthas","slug":"arthas","permalink":"https://anjia0532.github.io/tags/arthas/"},{"name":"jvm","slug":"jvm","permalink":"https://anjia0532.github.io/tags/jvm/"}]},{"title":"订阅github release","date":"2019-01-29T12:32:00.000Z","path":"2019/01/29/ifttt-github-release/","text":"关注的 github repo 项目多了后，往往不能及时获取最新的 release 信息。本文整理了两种（官方自带+IFTTT）易于使用的订阅方式 官方自带 release 提醒github 于 2018-11-28 日推出仅订阅 release 功能，喜大普奔啊，之前都是 IFTTT 或者自己写脚本轮或者订阅 rss 一旦有新的 release，就会发到 github 绑定的邮箱里了 详见 Watching and unwatching releases for a repository IFTTTIFTTT 是 If This Then That ，简单来说就是如果(IF)发生了某事(This)那么就做啥(That).用在此处就是如果关注的 github repo 发布了 release，那么就通知我(email 或者 weibo) 注册 IFTTT 账号打开 https://ifttt.com/join 填写邮箱和密码进行注册 创建 IFTTT 小程序打开 https://ifttt.com/create/ 选择 +this选择 RSS Feed -&gt; New feed itemFeed URL 输入 https://github.com/用户名/repo名/releases.atom 比如我的一个 repo 的地址是 https://github.com/anjia0532/elastalert-wechat-plugin/releases.atom点 Create Trigger 点 蓝色的 +that 部分选择 Email -&gt; Send me an email点击 Create action 一旦发布 releases 就会收到 email可以通过 https://ifttt.com/activity 查看小程序运行情况 Q&amp;AQ: 有了 github 的 watch 了，为嘛还要折腾 IFTTT？A: 因为在 github 出来之前就用了 IFTTT 了，再一个，IFTTT 不光可以发 email，还可以发微博和 twitter，让你分分钟成为一个技术潮人。新鲜资讯早知道啊.","tags":[{"name":"github","slug":"github","permalink":"https://anjia0532.github.io/tags/github/"},{"name":"ifttt","slug":"ifttt","permalink":"https://anjia0532.github.io/tags/ifttt/"}]},{"title":"云原生时代如何方便的进行本地调试","date":"2019-01-21T12:00:00.000Z","path":"2019/01/21/debug-cloud-native/","text":"云原生的四要素：持续交付、DevOps、微服务、容器，虽然极大的解放了生产力，但是不可避免的也带来了诸多问题，本文不做延伸，感兴趣的，可以自行百度。本文只为解决微服务(本文以 Spring Cloud 为例)+Kubernetes 开发调试低效问题。 telepresence如果团队内成员都有 k8s 基础，并且都用 win10 或者 linux,macos，那建议直接用 telepresence,简单直接。详见 Fast development workflow with Docker and Kubernetes，A development workflow for Kubernetes services Service 映射如果团队内 k8s 基础弱，或者硬件条件不满足，可以使用 Service 映射方案，在 k8s 集群里创建一个 Service 和 Endpoint，然后进行绑定。但是适用于单向的，比如，k8s 访问外部 mysql，如果要逆向访问，不好意思，不支持。 静态路由https://github.com/jkwong888/k8s-add-static-routes TDD如果团队对于单院测试和 Mock 掌握的比较好，可以直接开启 TDD 模式，省事省心 远程调试k8s 集群暴露远程调试接口。Remote debugging Spring Boot on Kubernetes 开发机纳入集群应用发到本地 pod 里，省的走 cicd 那么费劲了 热部署开发机纳入集群后，把 target\\class 挂载到本地卷，并且配置上 rebel.xml，idea build 后生成 class，然后 pod 里触发 jrebel 的热部署。 参考 https://www.telepresence.io/tutorials/java#hot-code-replace","tags":[{"name":"devops","slug":"devops","permalink":"https://anjia0532.github.io/tags/devops/"},{"name":"k8s","slug":"k8s","permalink":"https://anjia0532.github.io/tags/k8s/"},{"name":"微服务","slug":"微服务","permalink":"https://anjia0532.github.io/tags/微服务/"},{"name":"容器","slug":"容器","permalink":"https://anjia0532.github.io/tags/容器/"},{"name":"云原生","slug":"云原生","permalink":"https://anjia0532.github.io/tags/云原生/"},{"name":"jrebel","slug":"jrebel","permalink":"https://anjia0532.github.io/tags/jrebel/"},{"name":"telepresence","slug":"telepresence","permalink":"https://anjia0532.github.io/tags/telepresence/"}]},{"title":"使用github搭建自己的maven库","date":"2018-10-11T10:24:40.000Z","path":"2018/10/11/git-maven-howto/","text":"建议使用maven中央仓库进行发布，不过我嫌步骤太繁琐了，还需要审核，所以才用github来做。发布中央仓库的可以参考Maven 发布自己的项目到 Maven 中央仓库 使用github分两种，一种是mvn install 或者deploy到本地路径，然后git add &amp;&amp; commit &amp;&amp; push ，一种是maven-plugins 两种方案都需要在github创建相应的repo，具体创建步骤不多说，自行百度。 1. maven-plugins参考 https://stackoverflow.com/a/14013645 1.修改 ~/.m2/settings.xml &lt;!-- NOTE: MAKE SURE THAT settings.xml IS NOT WORLD READABLE! --&gt;&lt;settings&gt; &lt;servers&gt; &lt;server&gt; &lt;id&gt;github&lt;/id&gt; &lt;username&gt;YOUR-USERNAME&lt;/username&gt; &lt;password&gt;YOUR-PASSWORD&lt;/password&gt; &lt;/server&gt; &lt;/servers&gt;&lt;/settings&gt; 2.修改pom.xml &lt;properties&gt; &lt;!-- github server corresponds to entry in ~/.m2/settings.xml --&gt; &lt;github.global.server&gt;github&lt;/github.global.server&gt;&lt;/properties&gt;&lt;distributionManagement&gt; &lt;repository&gt; &lt;id&gt;internal.repo&lt;/id&gt; &lt;name&gt;Temporary Staging Repository&lt;/name&gt; &lt;url&gt;file://$&#123;project.build.directory&#125;/mvn-repo&lt;/url&gt; &lt;/repository&gt;&lt;/distributionManagement&gt; &lt;build&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt; &lt;artifactId&gt;maven-deploy-plugin&lt;/artifactId&gt; &lt;version&gt;2.8.2&lt;/version&gt; &lt;configuration&gt; &lt;altDeploymentRepository&gt;internal.repo::default::file://$&#123;project.build.directory&#125;/mvn-repo&lt;/altDeploymentRepository&gt; &lt;/configuration&gt; &lt;/plugin&gt; &lt;/plugins&gt; &lt;/build&gt; 3.修改pom.xml，配置maven-plugins &lt;build&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;groupId&gt;com.github.github&lt;/groupId&gt; &lt;artifactId&gt;site-maven-plugin&lt;/artifactId&gt; &lt;version&gt;0.12&lt;/version&gt; &lt;configuration&gt; &lt;message&gt;Maven artifacts for $&#123;project.version&#125;&lt;/message&gt; &lt;!-- git commit message --&gt; &lt;noJekyll&gt;true&lt;/noJekyll&gt; &lt;!-- disable webpage processing --&gt; &lt;outputDirectory&gt;$&#123;project.build.directory&#125;/mvn-repo&lt;/outputDirectory&gt; &lt;!-- matches distribution management repository url above --&gt; &lt;branch&gt;refs/heads/master&lt;/branch&gt; &lt;!-- remote branch name --&gt; &lt;includes&gt;&lt;include&gt;**/*&lt;/include&gt;&lt;/includes&gt; &lt;repositoryName&gt;YOUR-REPOSITORY-NAME&lt;/repositoryName&gt; &lt;!-- github repo name --&gt; &lt;repositoryOwner&gt;YOUR-GITHUB-USERNAME&lt;/repositoryOwner&gt; &lt;!-- github username --&gt; &lt;force&gt;false&lt;/force&gt; &lt;!-- force commit or no --&gt; &lt;merge&gt;true&lt;/merge&gt; &lt;!-- merge or no --&gt; &lt;/configuration&gt; &lt;executions&gt; &lt;!-- run site-maven-plugin's 'site' target as part of the build's normal 'deploy' phase --&gt; &lt;execution&gt; &lt;goals&gt; &lt;goal&gt;site&lt;/goal&gt; &lt;/goals&gt; &lt;phase&gt;deploy&lt;/phase&gt; &lt;/execution&gt; &lt;/executions&gt; &lt;/plugin&gt; &lt;/plugins&gt;&lt;/build&gt; 4.提交到github mvn clean deploy 2. mvn deploy &amp;&amp; git add &amp;&amp; commit &amp;&amp; push参考 https://blog.csdn.net/u010442302/article/details/74639357 1.clone github repo git clone https://github.com/YOUR-USERNAME/YOUR-PROJECT-NAME /home/my/code/maven-repo/ 2.命令行执行mvn deploy mvn deploy -DaltDeploymentRepository=my-mvn-repo::default::file:/home/my/code/maven-repo/ 3.push到github cd /home/my/code/maven-repo/git add .git commit -m 'Maven artifacts for 0.0.1'git push -u origin master 3. 在项目中使用github repo&lt;repositories&gt; &lt;repository&gt; &lt;id&gt;YOUR-PROJECT-NAME-mvn-repo&lt;/id&gt; &lt;url&gt;https://raw.githubusercontent.com/YOUR-USERNAME/YOUR-PROJECT-NAME/master/&lt;/url&gt; &lt;snapshots&gt; &lt;enabled&gt;true&lt;/enabled&gt; &lt;updatePolicy&gt;always&lt;/updatePolicy&gt; &lt;/snapshots&gt; &lt;/repository&gt;&lt;/repositories&gt; 总结如果可以修改pom建议用maven-plugins，如果不能修改pom，则使用命令行mvn deploy&amp;&amp;git add&amp;&amp;commit&amp;&amp;push","tags":[{"name":"github","slug":"github","permalink":"https://anjia0532.github.io/tags/github/"},{"name":"maven","slug":"maven","permalink":"https://anjia0532.github.io/tags/maven/"},{"name":"central","slug":"central","permalink":"https://anjia0532.github.io/tags/central/"},{"name":"mvn-deploy","slug":"mvn-deploy","permalink":"https://anjia0532.github.io/tags/mvn-deploy/"}]},{"title":"让 @HystrixCommand 支持Spring EL实现动态commandKey,groupKey,threadPoolKey,fallbackMethod","date":"2018-09-26T11:59:40.000Z","path":"2018/09/26/hystrixcommand-dynamic-key/","text":"hystrix-javanica 极大的简化了hystrix的开发工作，不用显式的new一堆HystrixCommand对象，代价就是，@HystrixCommand 一旦添加到方法后就固定了，没法根据入参动态修改注解内容(如果运行时，全局修改注解，请参见 Changing Annotation Parameters At Runtime) 在官方有两个个issuesNetflix/Hystrix/issues#1421 和Netflix/Hystrix/issues#350 也在讨论这个问题，但是官方建议针对此场景，用传统的new HystrixCommand()解决 1. 添加必要依赖&lt;dependency&gt; &lt;groupId&gt;com.netflix.hystrix&lt;/groupId&gt; &lt;artifactId&gt;hystrix-core&lt;/artifactId&gt; &lt;version&gt;1.5.12&lt;/version&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;com.netflix.hystrix&lt;/groupId&gt; &lt;artifactId&gt;hystrix-javanica&lt;/artifactId&gt; &lt;version&gt;1.5.12&lt;/version&gt;&lt;/dependency&gt; 2. 新增 HystrixCommandEL 类import com.netflix.hystrix.contrib.javanica.annotation.HystrixCommand;import com.netflix.hystrix.contrib.javanica.annotation.HystrixException;import com.netflix.hystrix.contrib.javanica.annotation.HystrixProperty;import com.netflix.hystrix.contrib.javanica.annotation.ObservableExecutionMode;import org.apache.commons.lang3.StringUtils;import org.springframework.expression.ExpressionParser;import org.springframework.expression.spel.standard.SpelExpressionParser;import org.springframework.expression.spel.support.StandardEvaluationContext;import java.lang.annotation.Annotation;import java.util.Objects;public class HystrixCommandEL implements HystrixCommand &#123; private String[] names; private Object[] args; ExpressionParser parser = new SpelExpressionParser(); StandardEvaluationContext context = new StandardEvaluationContext(); private HystrixCommand hystrixCommand; public HystrixCommandEL(HystrixCommand hystrixCommand, String[] names, Object[] args) &#123; this.hystrixCommand = hystrixCommand; this.args = args; this.names = names; &#125; @Override public String groupKey() &#123; return parseEL(hystrixCommand.groupKey()); &#125; @Override public String commandKey() &#123; return parseEL(hystrixCommand.commandKey()); &#125; @Override public String threadPoolKey() &#123; return parseEL(hystrixCommand.threadPoolKey()); &#125; @Override public String fallbackMethod() &#123; return parseEL(hystrixCommand.fallbackMethod()); &#125; @Override public HystrixProperty[] commandProperties() &#123; return hystrixCommand.commandProperties(); &#125; @Override public HystrixProperty[] threadPoolProperties() &#123; return hystrixCommand.threadPoolProperties(); &#125; @Override public Class&lt;? extends Throwable&gt;[] ignoreExceptions() &#123; return hystrixCommand.ignoreExceptions(); &#125; @Override public ObservableExecutionMode observableExecutionMode() &#123; return hystrixCommand.observableExecutionMode(); &#125; @Override public HystrixException[] raiseHystrixExceptions() &#123; return hystrixCommand.raiseHystrixExceptions(); &#125; @Override public String defaultFallback() &#123; return parseEL(hystrixCommand.defaultFallback()); &#125; @Override public Class&lt;? extends Annotation&gt; annotationType() &#123; return hystrixCommand.annotationType(); &#125; private String parseEL(String key) &#123; // 为了效率和安全考虑目前只允许包含#的属性调用，如果想支持全部SpEl,将这个if全部去掉就行(比如，如果无参数，只是做计算，判断names,args就不合适了) if (!StringUtils.contains(key, \"#\") || isEmpty(args) || isEmpty(names)) &#123; return key; &#125; for (int i = 0; i &lt; names.length; i++) &#123; context.setVariable(names[i], args[i]); &#125; return parser.parseExpression(key).getValue(context, String.class); &#125; private boolean isEmpty(Object [] objs)&#123; return Objects.isNull(objs) || objs.length==0; &#125;&#125; 3. 新增 HystrixCommandAspect 类import com.google.common.base.Optional;import com.google.common.collect.ImmutableMap;import com.netflix.hystrix.HystrixInvokable;import com.netflix.hystrix.contrib.javanica.annotation.DefaultProperties;import com.netflix.hystrix.contrib.javanica.annotation.HystrixCollapser;import com.netflix.hystrix.contrib.javanica.annotation.HystrixCommand;import com.netflix.hystrix.contrib.javanica.annotation.HystrixException;import com.netflix.hystrix.contrib.javanica.command.CommandExecutor;import com.netflix.hystrix.contrib.javanica.command.ExecutionType;import com.netflix.hystrix.contrib.javanica.command.HystrixCommandFactory;import com.netflix.hystrix.contrib.javanica.command.MetaHolder;import com.netflix.hystrix.contrib.javanica.exception.CommandActionExecutionException;import com.netflix.hystrix.contrib.javanica.exception.FallbackInvocationException;import com.netflix.hystrix.contrib.javanica.utils.AopUtils;import com.netflix.hystrix.contrib.javanica.utils.FallbackMethod;import com.netflix.hystrix.contrib.javanica.utils.MethodProvider;import com.netflix.hystrix.exception.HystrixBadRequestException;import com.netflix.hystrix.exception.HystrixRuntimeException;import org.apache.commons.lang3.StringUtils;import org.apache.commons.lang3.Validate;import org.aspectj.lang.JoinPoint;import org.aspectj.lang.ProceedingJoinPoint;import org.aspectj.lang.annotation.Around;import org.aspectj.lang.annotation.Aspect;import org.aspectj.lang.annotation.Pointcut;import org.aspectj.lang.reflect.MethodSignature;import org.springframework.context.annotation.Configuration;import org.springframework.core.LocalVariableTableParameterNameDiscoverer;import rx.Completable;import rx.Observable;import rx.Single;import rx.functions.Func1;import java.lang.reflect.Method;import java.lang.reflect.ParameterizedType;import java.lang.reflect.Type;import java.util.List;import java.util.Map;import java.util.concurrent.Future;import static com.netflix.hystrix.contrib.javanica.utils.AopUtils.*;import static com.netflix.hystrix.contrib.javanica.utils.EnvUtils.isCompileWeaving;import static com.netflix.hystrix.contrib.javanica.utils.ajc.AjcUtils.getAjcMethodAroundAdvice;@Aspectpublic class HystrixCommandAspect &#123; private static final Map&lt;HystrixPointcutType, MetaHolderFactory&gt; META_HOLDER_FACTORY_MAP; // 新增 private static LocalVariableTableParameterNameDiscoverer u = new LocalVariableTableParameterNameDiscoverer(); static &#123; META_HOLDER_FACTORY_MAP = ImmutableMap.&lt;HystrixPointcutType, MetaHolderFactory&gt;builder() .put(HystrixPointcutType.COMMAND, new CommandMetaHolderFactory()) .put(HystrixPointcutType.COLLAPSER, new CollapserMetaHolderFactory()) .build(); &#125; @Pointcut(\"@annotation(com.netflix.hystrix.contrib.javanica.annotation.HystrixCommand)\") public void hystrixCommandAnnotationPointcut() &#123; &#125; @Pointcut(\"@annotation(com.netflix.hystrix.contrib.javanica.annotation.HystrixCollapser)\") public void hystrixCollapserAnnotationPointcut() &#123; &#125; @Around(\"hystrixCommandAnnotationPointcut() || hystrixCollapserAnnotationPointcut()\") public Object methodsAnnotatedWithHystrixCommand(final ProceedingJoinPoint joinPoint) throws Throwable &#123; Method method = getMethodFromTarget(joinPoint); Validate.notNull(method, \"failed to get method from joinPoint: %s\", joinPoint); if (method.isAnnotationPresent(HystrixCommand.class) &amp;&amp; method.isAnnotationPresent(HystrixCollapser.class)) &#123; throw new IllegalStateException(\"method cannot be annotated with HystrixCommandEL and HystrixCollapser \" + \"annotations at the same time\"); &#125; MetaHolderFactory metaHolderFactory = META_HOLDER_FACTORY_MAP.get(HystrixPointcutType.of(method)); MetaHolder metaHolder = metaHolderFactory.create(joinPoint); HystrixInvokable invokable = HystrixCommandFactory.getInstance().create(metaHolder); ExecutionType executionType = metaHolder.isCollapserAnnotationPresent() ? metaHolder.getCollapserExecutionType() : metaHolder.getExecutionType(); Object result; try &#123; if (!metaHolder.isObservable()) &#123; result = CommandExecutor.execute(invokable, executionType, metaHolder); &#125; else &#123; result = executeObservable(invokable, executionType, metaHolder); &#125; &#125; catch (HystrixBadRequestException e) &#123; throw e.getCause() != null ? e.getCause() : e; &#125; catch (HystrixRuntimeException e) &#123; throw hystrixRuntimeExceptionToThrowable(metaHolder, e); &#125; return result; &#125; private Object executeObservable(HystrixInvokable invokable, ExecutionType executionType, final MetaHolder metaHolder) &#123; return mapObservable(((Observable) CommandExecutor.execute(invokable, executionType, metaHolder)) .onErrorResumeNext(new Func1&lt;Throwable, Observable&gt;() &#123; @Override public Observable call(Throwable throwable) &#123; if (throwable instanceof HystrixBadRequestException) &#123; return Observable.error(throwable.getCause()); &#125; else if (throwable instanceof HystrixRuntimeException) &#123; HystrixRuntimeException hystrixRuntimeException = (HystrixRuntimeException) throwable; return Observable.error(hystrixRuntimeExceptionToThrowable(metaHolder, hystrixRuntimeException)); &#125; return Observable.error(throwable); &#125; &#125;), metaHolder); &#125; private Object mapObservable(Observable observable, final MetaHolder metaHolder) &#123; if (Completable.class.isAssignableFrom(metaHolder.getMethod().getReturnType())) &#123; return observable.toCompletable(); &#125; else if (Single.class.isAssignableFrom(metaHolder.getMethod().getReturnType())) &#123; return observable.toSingle(); &#125; return observable; &#125; private Throwable hystrixRuntimeExceptionToThrowable(MetaHolder metaHolder, HystrixRuntimeException e) &#123; if (metaHolder.raiseHystrixExceptionsContains(HystrixException.RUNTIME_EXCEPTION)) &#123; return e; &#125; return getCause(e); &#125; private Throwable getCause(HystrixRuntimeException e) &#123; if (e.getFailureType() != HystrixRuntimeException.FailureType.COMMAND_EXCEPTION) &#123; return e; &#125; Throwable cause = e.getCause(); // latest exception in flow should be propagated to end user if (e.getFallbackException() instanceof FallbackInvocationException) &#123; cause = e.getFallbackException().getCause(); if (cause instanceof HystrixRuntimeException) &#123; cause = getCause((HystrixRuntimeException) cause); &#125; &#125; else if (cause instanceof CommandActionExecutionException) &#123; // this situation is possible only if a callee throws an exception which type extends Throwable directly CommandActionExecutionException commandActionExecutionException = (CommandActionExecutionException) cause; cause = commandActionExecutionException.getCause(); &#125; return Optional.fromNullable(cause).or(e); &#125; /** * A factory to create MetaHolder depending on &#123;@link HystrixPointcutType&#125;. */ private static abstract class MetaHolderFactory &#123; public MetaHolder create(final ProceedingJoinPoint joinPoint) &#123; Method method = getMethodFromTarget(joinPoint); Object obj = joinPoint.getTarget(); Object[] args = joinPoint.getArgs(); Object proxy = joinPoint.getThis(); return create(proxy, method, obj, args, joinPoint); &#125; public abstract MetaHolder create(Object proxy, Method method, Object obj, Object[] args, final ProceedingJoinPoint joinPoint); MetaHolder.Builder metaHolderBuilder(Object proxy, Method method, Object obj, Object[] args, final ProceedingJoinPoint joinPoint) &#123; MetaHolder.Builder builder = MetaHolder.builder() .args(args).method(method).obj(obj).proxyObj(proxy) .joinPoint(joinPoint); setFallbackMethod(builder, obj.getClass(), method); builder = setDefaultProperties(builder, obj.getClass(), joinPoint); return builder; &#125; &#125; private static class CollapserMetaHolderFactory extends MetaHolderFactory &#123; @Override public MetaHolder create(Object proxy, Method collapserMethod, Object obj, Object[] args, final ProceedingJoinPoint joinPoint) &#123; HystrixCollapser hystrixCollapser = collapserMethod.getAnnotation(HystrixCollapser.class); if (collapserMethod.getParameterTypes().length &gt; 1 || collapserMethod.getParameterTypes().length == 0) &#123; throw new IllegalStateException(\"Collapser method must have one argument: \" + collapserMethod); &#125; Method batchCommandMethod = getDeclaredMethod(obj.getClass(), hystrixCollapser.batchMethod(), List.class); if (batchCommandMethod == null) throw new IllegalStateException(\"batch method is absent: \" + hystrixCollapser.batchMethod()); Class&lt;?&gt; batchReturnType = batchCommandMethod.getReturnType(); Class&lt;?&gt; collapserReturnType = collapserMethod.getReturnType(); boolean observable = collapserReturnType.equals(Observable.class); if (!collapserMethod.getParameterTypes()[0] .equals(getFirstGenericParameter(batchCommandMethod.getGenericParameterTypes()[0]))) &#123; throw new IllegalStateException(\"required batch method for collapser is absent, wrong generic type: expected \" + obj.getClass().getCanonicalName() + \".\" + hystrixCollapser.batchMethod() + \"(java.util.List&lt;\" + collapserMethod.getParameterTypes()[0] + \"&gt;), but it's \" + getFirstGenericParameter(batchCommandMethod.getGenericParameterTypes()[0])); &#125; final Class&lt;?&gt; collapserMethodReturnType = getFirstGenericParameter( collapserMethod.getGenericReturnType(), Future.class.isAssignableFrom(collapserReturnType) || Observable.class.isAssignableFrom(collapserReturnType) ? 1 : 0); Class&lt;?&gt; batchCommandActualReturnType = getFirstGenericParameter(batchCommandMethod.getGenericReturnType()); if (!collapserMethodReturnType .equals(batchCommandActualReturnType)) &#123; throw new IllegalStateException(\"Return type of batch method must be java.util.List parametrized with corresponding type: expected \" + \"(java.util.List&lt;\" + collapserMethodReturnType + \"&gt;)\" + obj.getClass().getCanonicalName() + \".\" + hystrixCollapser.batchMethod() + \"(java.util.List&lt;\" + collapserMethod.getParameterTypes()[0] + \"&gt;), but it's \" + batchCommandActualReturnType); &#125; HystrixCommand hystrixCommand = batchCommandMethod.getAnnotation(HystrixCommand.class); if (hystrixCommand == null) &#123; throw new IllegalStateException(\"batch method must be annotated with HystrixCommandEL annotation\"); &#125; // method of batch hystrix command must be passed to metaholder because basically collapser doesn't have any actions // that should be invoked upon intercepted method, it's required only for underlying batch command MetaHolder.Builder builder = metaHolderBuilder(proxy, batchCommandMethod, obj, args, joinPoint); if (isCompileWeaving()) &#123; builder.ajcMethod(getAjcMethodAroundAdvice(obj.getClass(), batchCommandMethod.getName(), List.class)); &#125; builder.hystrixCollapser(hystrixCollapser); builder.defaultCollapserKey(collapserMethod.getName()); builder.collapserExecutionType(ExecutionType.getExecutionType(collapserReturnType)); builder.defaultCommandKey(batchCommandMethod.getName()); builder.hystrixCommand(hystrixCommand); builder.executionType(ExecutionType.getExecutionType(batchReturnType)); builder.observable(observable); FallbackMethod fallbackMethod = MethodProvider.getInstance().getFallbackMethod(obj.getClass(), batchCommandMethod); if (fallbackMethod.isPresent()) &#123; fallbackMethod.validateReturnType(batchCommandMethod); builder .fallbackMethod(fallbackMethod.getMethod()) .fallbackExecutionType(ExecutionType.getExecutionType(fallbackMethod.getMethod().getReturnType())); &#125; return builder.build(); &#125; &#125; private static class CommandMetaHolderFactory extends MetaHolderFactory &#123; @Override public MetaHolder create(Object proxy, Method method, Object obj, Object[] args, final ProceedingJoinPoint joinPoint) &#123; HystrixCommand hystrixCommand = method.getAnnotation(HystrixCommand.class); // 新增 hystrixCommand = new HystrixCommandEL(hystrixCommand,u.getParameterNames(method),args); ExecutionType executionType = ExecutionType.getExecutionType(method.getReturnType()); MetaHolder.Builder builder = metaHolderBuilder(proxy, method, obj, args, joinPoint); if (isCompileWeaving()) &#123; builder.ajcMethod(getAjcMethodFromTarget(joinPoint)); &#125; return builder.defaultCommandKey(method.getName()) .hystrixCommand(hystrixCommand) .observableExecutionMode(hystrixCommand.observableExecutionMode()) .executionType(executionType) .observable(ExecutionType.OBSERVABLE == executionType) .build(); &#125; &#125; private enum HystrixPointcutType &#123; COMMAND, COLLAPSER; static HystrixPointcutType of(Method method) &#123; if (method.isAnnotationPresent(HystrixCommand.class)) &#123; return COMMAND; &#125; else if (method.isAnnotationPresent(HystrixCollapser.class)) &#123; return COLLAPSER; &#125; else &#123; String methodInfo = getMethodInfo(method); throw new IllegalStateException(\"'https://github.com/Netflix/Hystrix/issues/1458' - no valid annotation found for: \\n\" + methodInfo); &#125; &#125; &#125; private static Method getAjcMethodFromTarget(JoinPoint joinPoint) &#123; return getAjcMethodAroundAdvice(joinPoint.getTarget().getClass(), (MethodSignature) joinPoint.getSignature()); &#125; private static Class&lt;?&gt; getFirstGenericParameter(Type type) &#123; return getFirstGenericParameter(type, 1); &#125; private static Class&lt;?&gt; getFirstGenericParameter(final Type type, final int nestedDepth) &#123; int cDepth = 0; Type tType = type; for (int cDept = 0; cDept &lt; nestedDepth; cDept++) &#123; if (!(tType instanceof ParameterizedType)) throw new IllegalStateException(String.format(\"Sub type at nesting level %d of %s is expected to be generic\", cDepth, type)); tType = ((ParameterizedType) tType).getActualTypeArguments()[cDept]; &#125; if (tType instanceof ParameterizedType) return (Class&lt;?&gt;) ((ParameterizedType) tType).getRawType(); else if (tType instanceof Class) return (Class&lt;?&gt;) tType; throw new UnsupportedOperationException(\"Unsupported type \" + tType); &#125; private static MetaHolder.Builder setDefaultProperties(MetaHolder.Builder builder, Class&lt;?&gt; declaringClass, final ProceedingJoinPoint joinPoint) &#123; Optional&lt;DefaultProperties&gt; defaultPropertiesOpt = AopUtils.getAnnotation(joinPoint, DefaultProperties.class); builder.defaultGroupKey(declaringClass.getSimpleName()); if (defaultPropertiesOpt.isPresent()) &#123; DefaultProperties defaultProperties = defaultPropertiesOpt.get(); builder.defaultProperties(defaultProperties); if (StringUtils.isNotBlank(defaultProperties.groupKey())) &#123; builder.defaultGroupKey(defaultProperties.groupKey()); &#125; if (StringUtils.isNotBlank(defaultProperties.threadPoolKey())) &#123; builder.defaultThreadPoolKey(defaultProperties.threadPoolKey()); &#125; &#125; return builder; &#125; private static MetaHolder.Builder setFallbackMethod(MetaHolder.Builder builder, Class&lt;?&gt; declaringClass, Method commandMethod) &#123; FallbackMethod fallbackMethod = MethodProvider.getInstance().getFallbackMethod(declaringClass, commandMethod); if (fallbackMethod.isPresent()) &#123; fallbackMethod.validateReturnType(commandMethod); builder .fallbackMethod(fallbackMethod.getMethod()) .fallbackExecutionType(ExecutionType.getExecutionType(fallbackMethod.getMethod().getReturnType())); &#125; return builder; &#125;&#125; 此类99%都是copy自 com.netflix.hystrix.contrib.javanica.aop.aspectj.HystrixCommandAspect 仅仅新增了两行，分别都注明了//新增 使用要么在HystrixCommandAspect 增加@Configuration注解，要么在某个带有@Configuration的类内（建议用此方式） @Beanpublic HystrixCommandAspect hystrixCommandAspect()&#123; return new HystrixCommandAspect();&#125; @Componentpublic class Demo &#123; @HystrixCommand(commandKey = \"#key\",groupKey = \"#key\",fallbackMethod = \"fail\") public String exec(String key)&#123; if (RandomUtils.nextBoolean()) &#123; System.out.println(1 / 0); &#125; return key; &#125; public String fail(String key)&#123; System.out.println(\"fail:\"+key); return key; &#125;&#125;@RunWith(SpringRunner.class)@SpringBootTestpublic class DemoApplicationTests &#123; @Autowired private Demo demo; @Test public void testHystrixCommandDynamic()&#123; int i=0; while (i++&lt;5)&#123; e.exec(\"this is cmd key\"); Thread.sleep(1000); HystrixCommandMetrics.getInstances().forEach(m-&gt; System.out.println(\"cmd:\"+m.getCommandKey())); &#125; &#125;&#125; cmd:this is cmd keyfail:this is cmd keycmd:this is cmd keyfalsekey: this is cmd key Requests: 2 Errors: 1 (50%) Avg: 0 75th: 0 99th: 0 99.5th: 0 99.9th: 0 cmd:this is cmd keycmd:this is cmd keycmd:this is cmd key 放在后边的话本文只适用于@HystrixCommand修饰的，对于@HystrixCollapser合并的暂时无效（主要是懒得改），如果有需要自行修改HystrixCommandAspect 中的CollapserMetaHolderFactory中的HystrixCollapser和HystrixCommand相关部分 另外目前只适用于@HystrixCommand 中类型是String的字段(groupKey,commandKey,threadPoolKey,fallbackMethod,defaultFallback),如果要支持commandProperties 和threadPoolProperties 也动态，自己尝试修改一下就行了。很简单的 后续有时间，可能会写一下，基于redis的hystrix集群共享metrics的方案 博客 https://anjia0532.github.io/2018/09/26/hystrixcommand-dynamic-key/ 掘金 https://juejin.im/post/5bab20fc5188255c980bdc9d","tags":[{"name":"微服务","slug":"微服务","permalink":"https://anjia0532.github.io/tags/微服务/"},{"name":"hystrix","slug":"hystrix","permalink":"https://anjia0532.github.io/tags/hystrix/"},{"name":"hystrixcommand","slug":"hystrixcommand","permalink":"https://anjia0532.github.io/tags/hystrixcommand/"},{"name":"hystrix-command","slug":"hystrix-command","permalink":"https://anjia0532.github.io/tags/hystrix-command/"},{"name":"hystrix-command-dynamic","slug":"hystrix-command-dynamic","permalink":"https://anjia0532.github.io/tags/hystrix-command-dynamic/"}]},{"title":"让 @HystrixCommand 支持Spring EL实现动态commandKey,groupKey,threadPoolKey,fallbackMethod","date":"2018-09-26T11:59:40.000Z","path":"2018/09/26/hystrixcommand_dynamic_key/","text":"hystrix-javanica 极大的简化了hystrix的开发工作，不用显式的new一堆HystrixCommand对象，代价就是，@HystrixCommand 一旦添加到方法后就固定了，没法根据入参动态修改注解内容(如果运行时，全局修改注解，请参见 Changing Annotation Parameters At Runtime) 在官方有两个个issuesNetflix/Hystrix/issues#1421 和Netflix/Hystrix/issues#350 也在讨论这个问题，但是官方建议针对此场景，用传统的new HystrixCommand()解决 1. 添加必要依赖&lt;dependency&gt; &lt;groupId&gt;com.netflix.hystrix&lt;/groupId&gt; &lt;artifactId&gt;hystrix-core&lt;/artifactId&gt; &lt;version&gt;1.5.12&lt;/version&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;com.netflix.hystrix&lt;/groupId&gt; &lt;artifactId&gt;hystrix-javanica&lt;/artifactId&gt; &lt;version&gt;1.5.12&lt;/version&gt;&lt;/dependency&gt; 2. 新增 HystrixCommandEL 类import com.netflix.hystrix.contrib.javanica.annotation.HystrixCommand;import com.netflix.hystrix.contrib.javanica.annotation.HystrixException;import com.netflix.hystrix.contrib.javanica.annotation.HystrixProperty;import com.netflix.hystrix.contrib.javanica.annotation.ObservableExecutionMode;import org.apache.commons.lang3.StringUtils;import org.springframework.expression.ExpressionParser;import org.springframework.expression.spel.standard.SpelExpressionParser;import org.springframework.expression.spel.support.StandardEvaluationContext;import java.lang.annotation.Annotation;import java.util.Objects;public class HystrixCommandEL implements HystrixCommand &#123; private String[] names; private Object[] args; ExpressionParser parser = new SpelExpressionParser(); StandardEvaluationContext context = new StandardEvaluationContext(); private HystrixCommand hystrixCommand; public HystrixCommandEL(HystrixCommand hystrixCommand, String[] names, Object[] args) &#123; this.hystrixCommand = hystrixCommand; this.args = args; this.names = names; &#125; @Override public String groupKey() &#123; return parseEL(hystrixCommand.groupKey()); &#125; @Override public String commandKey() &#123; return parseEL(hystrixCommand.commandKey()); &#125; @Override public String threadPoolKey() &#123; return parseEL(hystrixCommand.threadPoolKey()); &#125; @Override public String fallbackMethod() &#123; return parseEL(hystrixCommand.fallbackMethod()); &#125; @Override public HystrixProperty[] commandProperties() &#123; return hystrixCommand.commandProperties(); &#125; @Override public HystrixProperty[] threadPoolProperties() &#123; return hystrixCommand.threadPoolProperties(); &#125; @Override public Class&lt;? extends Throwable&gt;[] ignoreExceptions() &#123; return hystrixCommand.ignoreExceptions(); &#125; @Override public ObservableExecutionMode observableExecutionMode() &#123; return hystrixCommand.observableExecutionMode(); &#125; @Override public HystrixException[] raiseHystrixExceptions() &#123; return hystrixCommand.raiseHystrixExceptions(); &#125; @Override public String defaultFallback() &#123; return parseEL(hystrixCommand.defaultFallback()); &#125; @Override public Class&lt;? extends Annotation&gt; annotationType() &#123; return hystrixCommand.annotationType(); &#125; private String parseEL(String key) &#123; // 为了效率和安全考虑目前只允许包含#的属性调用，如果想支持全部SpEl,将这个if全部去掉就行(比如，如果无参数，只是做计算，判断names,args就不合适了) if (!StringUtils.contains(key, \"#\") || isEmpty(args) || isEmpty(names)) &#123; return key; &#125; for (int i = 0; i &lt; names.length; i++) &#123; context.setVariable(names[i], args[i]); &#125; return parser.parseExpression(key).getValue(context, String.class); &#125; private boolean isEmpty(Object [] objs)&#123; return Objects.isNull(objs) || objs.length==0; &#125;&#125; 3. 新增 HystrixCommandAspect 类import com.google.common.base.Optional;import com.google.common.collect.ImmutableMap;import com.netflix.hystrix.HystrixInvokable;import com.netflix.hystrix.contrib.javanica.annotation.DefaultProperties;import com.netflix.hystrix.contrib.javanica.annotation.HystrixCollapser;import com.netflix.hystrix.contrib.javanica.annotation.HystrixCommand;import com.netflix.hystrix.contrib.javanica.annotation.HystrixException;import com.netflix.hystrix.contrib.javanica.command.CommandExecutor;import com.netflix.hystrix.contrib.javanica.command.ExecutionType;import com.netflix.hystrix.contrib.javanica.command.HystrixCommandFactory;import com.netflix.hystrix.contrib.javanica.command.MetaHolder;import com.netflix.hystrix.contrib.javanica.exception.CommandActionExecutionException;import com.netflix.hystrix.contrib.javanica.exception.FallbackInvocationException;import com.netflix.hystrix.contrib.javanica.utils.AopUtils;import com.netflix.hystrix.contrib.javanica.utils.FallbackMethod;import com.netflix.hystrix.contrib.javanica.utils.MethodProvider;import com.netflix.hystrix.exception.HystrixBadRequestException;import com.netflix.hystrix.exception.HystrixRuntimeException;import org.apache.commons.lang3.StringUtils;import org.apache.commons.lang3.Validate;import org.aspectj.lang.JoinPoint;import org.aspectj.lang.ProceedingJoinPoint;import org.aspectj.lang.annotation.Around;import org.aspectj.lang.annotation.Aspect;import org.aspectj.lang.annotation.Pointcut;import org.aspectj.lang.reflect.MethodSignature;import org.springframework.context.annotation.Configuration;import org.springframework.core.LocalVariableTableParameterNameDiscoverer;import rx.Completable;import rx.Observable;import rx.Single;import rx.functions.Func1;import java.lang.reflect.Method;import java.lang.reflect.ParameterizedType;import java.lang.reflect.Type;import java.util.List;import java.util.Map;import java.util.concurrent.Future;import static com.netflix.hystrix.contrib.javanica.utils.AopUtils.*;import static com.netflix.hystrix.contrib.javanica.utils.EnvUtils.isCompileWeaving;import static com.netflix.hystrix.contrib.javanica.utils.ajc.AjcUtils.getAjcMethodAroundAdvice;@Aspectpublic class HystrixCommandAspect &#123; private static final Map&lt;HystrixPointcutType, MetaHolderFactory&gt; META_HOLDER_FACTORY_MAP; // 新增 private static LocalVariableTableParameterNameDiscoverer u = new LocalVariableTableParameterNameDiscoverer(); static &#123; META_HOLDER_FACTORY_MAP = ImmutableMap.&lt;HystrixPointcutType, MetaHolderFactory&gt;builder() .put(HystrixPointcutType.COMMAND, new CommandMetaHolderFactory()) .put(HystrixPointcutType.COLLAPSER, new CollapserMetaHolderFactory()) .build(); &#125; @Pointcut(\"@annotation(com.netflix.hystrix.contrib.javanica.annotation.HystrixCommand)\") public void hystrixCommandAnnotationPointcut() &#123; &#125; @Pointcut(\"@annotation(com.netflix.hystrix.contrib.javanica.annotation.HystrixCollapser)\") public void hystrixCollapserAnnotationPointcut() &#123; &#125; @Around(\"hystrixCommandAnnotationPointcut() || hystrixCollapserAnnotationPointcut()\") public Object methodsAnnotatedWithHystrixCommand(final ProceedingJoinPoint joinPoint) throws Throwable &#123; Method method = getMethodFromTarget(joinPoint); Validate.notNull(method, \"failed to get method from joinPoint: %s\", joinPoint); if (method.isAnnotationPresent(HystrixCommand.class) &amp;&amp; method.isAnnotationPresent(HystrixCollapser.class)) &#123; throw new IllegalStateException(\"method cannot be annotated with HystrixCommandEL and HystrixCollapser \" + \"annotations at the same time\"); &#125; MetaHolderFactory metaHolderFactory = META_HOLDER_FACTORY_MAP.get(HystrixPointcutType.of(method)); MetaHolder metaHolder = metaHolderFactory.create(joinPoint); HystrixInvokable invokable = HystrixCommandFactory.getInstance().create(metaHolder); ExecutionType executionType = metaHolder.isCollapserAnnotationPresent() ? metaHolder.getCollapserExecutionType() : metaHolder.getExecutionType(); Object result; try &#123; if (!metaHolder.isObservable()) &#123; result = CommandExecutor.execute(invokable, executionType, metaHolder); &#125; else &#123; result = executeObservable(invokable, executionType, metaHolder); &#125; &#125; catch (HystrixBadRequestException e) &#123; throw e.getCause() != null ? e.getCause() : e; &#125; catch (HystrixRuntimeException e) &#123; throw hystrixRuntimeExceptionToThrowable(metaHolder, e); &#125; return result; &#125; private Object executeObservable(HystrixInvokable invokable, ExecutionType executionType, final MetaHolder metaHolder) &#123; return mapObservable(((Observable) CommandExecutor.execute(invokable, executionType, metaHolder)) .onErrorResumeNext(new Func1&lt;Throwable, Observable&gt;() &#123; @Override public Observable call(Throwable throwable) &#123; if (throwable instanceof HystrixBadRequestException) &#123; return Observable.error(throwable.getCause()); &#125; else if (throwable instanceof HystrixRuntimeException) &#123; HystrixRuntimeException hystrixRuntimeException = (HystrixRuntimeException) throwable; return Observable.error(hystrixRuntimeExceptionToThrowable(metaHolder, hystrixRuntimeException)); &#125; return Observable.error(throwable); &#125; &#125;), metaHolder); &#125; private Object mapObservable(Observable observable, final MetaHolder metaHolder) &#123; if (Completable.class.isAssignableFrom(metaHolder.getMethod().getReturnType())) &#123; return observable.toCompletable(); &#125; else if (Single.class.isAssignableFrom(metaHolder.getMethod().getReturnType())) &#123; return observable.toSingle(); &#125; return observable; &#125; private Throwable hystrixRuntimeExceptionToThrowable(MetaHolder metaHolder, HystrixRuntimeException e) &#123; if (metaHolder.raiseHystrixExceptionsContains(HystrixException.RUNTIME_EXCEPTION)) &#123; return e; &#125; return getCause(e); &#125; private Throwable getCause(HystrixRuntimeException e) &#123; if (e.getFailureType() != HystrixRuntimeException.FailureType.COMMAND_EXCEPTION) &#123; return e; &#125; Throwable cause = e.getCause(); // latest exception in flow should be propagated to end user if (e.getFallbackException() instanceof FallbackInvocationException) &#123; cause = e.getFallbackException().getCause(); if (cause instanceof HystrixRuntimeException) &#123; cause = getCause((HystrixRuntimeException) cause); &#125; &#125; else if (cause instanceof CommandActionExecutionException) &#123; // this situation is possible only if a callee throws an exception which type extends Throwable directly CommandActionExecutionException commandActionExecutionException = (CommandActionExecutionException) cause; cause = commandActionExecutionException.getCause(); &#125; return Optional.fromNullable(cause).or(e); &#125; /** * A factory to create MetaHolder depending on &#123;@link HystrixPointcutType&#125;. */ private static abstract class MetaHolderFactory &#123; public MetaHolder create(final ProceedingJoinPoint joinPoint) &#123; Method method = getMethodFromTarget(joinPoint); Object obj = joinPoint.getTarget(); Object[] args = joinPoint.getArgs(); Object proxy = joinPoint.getThis(); return create(proxy, method, obj, args, joinPoint); &#125; public abstract MetaHolder create(Object proxy, Method method, Object obj, Object[] args, final ProceedingJoinPoint joinPoint); MetaHolder.Builder metaHolderBuilder(Object proxy, Method method, Object obj, Object[] args, final ProceedingJoinPoint joinPoint) &#123; MetaHolder.Builder builder = MetaHolder.builder() .args(args).method(method).obj(obj).proxyObj(proxy) .joinPoint(joinPoint); setFallbackMethod(builder, obj.getClass(), method); builder = setDefaultProperties(builder, obj.getClass(), joinPoint); return builder; &#125; &#125; private static class CollapserMetaHolderFactory extends MetaHolderFactory &#123; @Override public MetaHolder create(Object proxy, Method collapserMethod, Object obj, Object[] args, final ProceedingJoinPoint joinPoint) &#123; HystrixCollapser hystrixCollapser = collapserMethod.getAnnotation(HystrixCollapser.class); if (collapserMethod.getParameterTypes().length &gt; 1 || collapserMethod.getParameterTypes().length == 0) &#123; throw new IllegalStateException(\"Collapser method must have one argument: \" + collapserMethod); &#125; Method batchCommandMethod = getDeclaredMethod(obj.getClass(), hystrixCollapser.batchMethod(), List.class); if (batchCommandMethod == null) throw new IllegalStateException(\"batch method is absent: \" + hystrixCollapser.batchMethod()); Class&lt;?&gt; batchReturnType = batchCommandMethod.getReturnType(); Class&lt;?&gt; collapserReturnType = collapserMethod.getReturnType(); boolean observable = collapserReturnType.equals(Observable.class); if (!collapserMethod.getParameterTypes()[0] .equals(getFirstGenericParameter(batchCommandMethod.getGenericParameterTypes()[0]))) &#123; throw new IllegalStateException(\"required batch method for collapser is absent, wrong generic type: expected \" + obj.getClass().getCanonicalName() + \".\" + hystrixCollapser.batchMethod() + \"(java.util.List&lt;\" + collapserMethod.getParameterTypes()[0] + \"&gt;), but it's \" + getFirstGenericParameter(batchCommandMethod.getGenericParameterTypes()[0])); &#125; final Class&lt;?&gt; collapserMethodReturnType = getFirstGenericParameter( collapserMethod.getGenericReturnType(), Future.class.isAssignableFrom(collapserReturnType) || Observable.class.isAssignableFrom(collapserReturnType) ? 1 : 0); Class&lt;?&gt; batchCommandActualReturnType = getFirstGenericParameter(batchCommandMethod.getGenericReturnType()); if (!collapserMethodReturnType .equals(batchCommandActualReturnType)) &#123; throw new IllegalStateException(\"Return type of batch method must be java.util.List parametrized with corresponding type: expected \" + \"(java.util.List&lt;\" + collapserMethodReturnType + \"&gt;)\" + obj.getClass().getCanonicalName() + \".\" + hystrixCollapser.batchMethod() + \"(java.util.List&lt;\" + collapserMethod.getParameterTypes()[0] + \"&gt;), but it's \" + batchCommandActualReturnType); &#125; HystrixCommand hystrixCommand = batchCommandMethod.getAnnotation(HystrixCommand.class); if (hystrixCommand == null) &#123; throw new IllegalStateException(\"batch method must be annotated with HystrixCommandEL annotation\"); &#125; // method of batch hystrix command must be passed to metaholder because basically collapser doesn't have any actions // that should be invoked upon intercepted method, it's required only for underlying batch command MetaHolder.Builder builder = metaHolderBuilder(proxy, batchCommandMethod, obj, args, joinPoint); if (isCompileWeaving()) &#123; builder.ajcMethod(getAjcMethodAroundAdvice(obj.getClass(), batchCommandMethod.getName(), List.class)); &#125; builder.hystrixCollapser(hystrixCollapser); builder.defaultCollapserKey(collapserMethod.getName()); builder.collapserExecutionType(ExecutionType.getExecutionType(collapserReturnType)); builder.defaultCommandKey(batchCommandMethod.getName()); builder.hystrixCommand(hystrixCommand); builder.executionType(ExecutionType.getExecutionType(batchReturnType)); builder.observable(observable); FallbackMethod fallbackMethod = MethodProvider.getInstance().getFallbackMethod(obj.getClass(), batchCommandMethod); if (fallbackMethod.isPresent()) &#123; fallbackMethod.validateReturnType(batchCommandMethod); builder .fallbackMethod(fallbackMethod.getMethod()) .fallbackExecutionType(ExecutionType.getExecutionType(fallbackMethod.getMethod().getReturnType())); &#125; return builder.build(); &#125; &#125; private static class CommandMetaHolderFactory extends MetaHolderFactory &#123; @Override public MetaHolder create(Object proxy, Method method, Object obj, Object[] args, final ProceedingJoinPoint joinPoint) &#123; HystrixCommand hystrixCommand = method.getAnnotation(HystrixCommand.class); // 新增 hystrixCommand = new HystrixCommandEL(hystrixCommand,u.getParameterNames(method),args); ExecutionType executionType = ExecutionType.getExecutionType(method.getReturnType()); MetaHolder.Builder builder = metaHolderBuilder(proxy, method, obj, args, joinPoint); if (isCompileWeaving()) &#123; builder.ajcMethod(getAjcMethodFromTarget(joinPoint)); &#125; return builder.defaultCommandKey(method.getName()) .hystrixCommand(hystrixCommand) .observableExecutionMode(hystrixCommand.observableExecutionMode()) .executionType(executionType) .observable(ExecutionType.OBSERVABLE == executionType) .build(); &#125; &#125; private enum HystrixPointcutType &#123; COMMAND, COLLAPSER; static HystrixPointcutType of(Method method) &#123; if (method.isAnnotationPresent(HystrixCommand.class)) &#123; return COMMAND; &#125; else if (method.isAnnotationPresent(HystrixCollapser.class)) &#123; return COLLAPSER; &#125; else &#123; String methodInfo = getMethodInfo(method); throw new IllegalStateException(\"'https://github.com/Netflix/Hystrix/issues/1458' - no valid annotation found for: \\n\" + methodInfo); &#125; &#125; &#125; private static Method getAjcMethodFromTarget(JoinPoint joinPoint) &#123; return getAjcMethodAroundAdvice(joinPoint.getTarget().getClass(), (MethodSignature) joinPoint.getSignature()); &#125; private static Class&lt;?&gt; getFirstGenericParameter(Type type) &#123; return getFirstGenericParameter(type, 1); &#125; private static Class&lt;?&gt; getFirstGenericParameter(final Type type, final int nestedDepth) &#123; int cDepth = 0; Type tType = type; for (int cDept = 0; cDept &lt; nestedDepth; cDept++) &#123; if (!(tType instanceof ParameterizedType)) throw new IllegalStateException(String.format(\"Sub type at nesting level %d of %s is expected to be generic\", cDepth, type)); tType = ((ParameterizedType) tType).getActualTypeArguments()[cDept]; &#125; if (tType instanceof ParameterizedType) return (Class&lt;?&gt;) ((ParameterizedType) tType).getRawType(); else if (tType instanceof Class) return (Class&lt;?&gt;) tType; throw new UnsupportedOperationException(\"Unsupported type \" + tType); &#125; private static MetaHolder.Builder setDefaultProperties(MetaHolder.Builder builder, Class&lt;?&gt; declaringClass, final ProceedingJoinPoint joinPoint) &#123; Optional&lt;DefaultProperties&gt; defaultPropertiesOpt = AopUtils.getAnnotation(joinPoint, DefaultProperties.class); builder.defaultGroupKey(declaringClass.getSimpleName()); if (defaultPropertiesOpt.isPresent()) &#123; DefaultProperties defaultProperties = defaultPropertiesOpt.get(); builder.defaultProperties(defaultProperties); if (StringUtils.isNotBlank(defaultProperties.groupKey())) &#123; builder.defaultGroupKey(defaultProperties.groupKey()); &#125; if (StringUtils.isNotBlank(defaultProperties.threadPoolKey())) &#123; builder.defaultThreadPoolKey(defaultProperties.threadPoolKey()); &#125; &#125; return builder; &#125; private static MetaHolder.Builder setFallbackMethod(MetaHolder.Builder builder, Class&lt;?&gt; declaringClass, Method commandMethod) &#123; FallbackMethod fallbackMethod = MethodProvider.getInstance().getFallbackMethod(declaringClass, commandMethod); if (fallbackMethod.isPresent()) &#123; fallbackMethod.validateReturnType(commandMethod); builder .fallbackMethod(fallbackMethod.getMethod()) .fallbackExecutionType(ExecutionType.getExecutionType(fallbackMethod.getMethod().getReturnType())); &#125; return builder; &#125;&#125; 此类99%都是copy自 com.netflix.hystrix.contrib.javanica.aop.aspectj.HystrixCommandAspect 仅仅新增了两行，分别都注明了//新增 使用要么在HystrixCommandAspect 增加@Configuration注解，要么在某个带有@Configuration的类内（建议用此方式） @Beanpublic HystrixCommandAspect hystrixCommandAspect()&#123; return new HystrixCommandAspect();&#125; @Componentpublic class Demo &#123; @HystrixCommand(commandKey = \"#key\",groupKey = \"#key\",fallbackMethod = \"fail\") public String exec(String key)&#123; if (RandomUtils.nextBoolean()) &#123; System.out.println(1 / 0); &#125; return key; &#125; public String fail(String key)&#123; System.out.println(\"fail:\"+key); return key; &#125;&#125;@RunWith(SpringRunner.class)@SpringBootTestpublic class DemoApplicationTests &#123; @Autowired private Demo demo; @Test public void testHystrixCommandDynamic()&#123; int i=0; while (i++&lt;5)&#123; e.exec(\"this is cmd key\"); Thread.sleep(1000); HystrixCommandMetrics.getInstances().forEach(m-&gt; System.out.println(\"cmd:\"+m.getCommandKey())); &#125; &#125;&#125; cmd:this is cmd keyfail:this is cmd keycmd:this is cmd keyfalsekey: this is cmd key Requests: 2 Errors: 1 (50%) Avg: 0 75th: 0 99th: 0 99.5th: 0 99.9th: 0 cmd:this is cmd keycmd:this is cmd keycmd:this is cmd key 放在后边的话本文只适用于@HystrixCommand修饰的，对于@HystrixCollapser合并的暂时无效（主要是懒得改），如果有需要自行修改HystrixCommandAspect 中的CollapserMetaHolderFactory中的HystrixCollapser和HystrixCommand相关部分 另外目前只适用于@HystrixCommand 中类型是String的字段(groupKey,commandKey,threadPoolKey,fallbackMethod,defaultFallback),如果要支持commandProperties 和threadPoolProperties 也动态，自己尝试修改一下就行了。很简单的 后续有时间，可能会写一下，基于redis的hystrix集群共享metrics的方案 博客 https://anjia0532.github.io/2018/09/26/hystrixcommand-dynamic-key/ 掘金 https://juejin.im/post/5bab20fc5188255c980bdc9d","tags":[{"name":"微服务","slug":"微服务","permalink":"https://anjia0532.github.io/tags/微服务/"},{"name":"hystrix","slug":"hystrix","permalink":"https://anjia0532.github.io/tags/hystrix/"},{"name":"hystrixcommand","slug":"hystrixcommand","permalink":"https://anjia0532.github.io/tags/hystrixcommand/"},{"name":"hystrix-command","slug":"hystrix-command","permalink":"https://anjia0532.github.io/tags/hystrix-command/"},{"name":"hystrix-command-dynamic","slug":"hystrix-command-dynamic","permalink":"https://anjia0532.github.io/tags/hystrix-command-dynamic/"}]},{"title":"(2018年12月可用)官网下载免费版xshell5","date":"2018-09-14T09:18:40.000Z","path":"2018/09/14/xshell5/","text":"xshell 是一个强大的终端模拟软件，类似的还有很多，比如 mobaxterm ,putty, Securecrt(本文不过多介绍，感兴趣自行百度) 回到xshell, 自从手贱升级到xshell6以后,发现只能支持4个tab页，尴尬症都犯了，想降回xshell5，发现官方已经关闭5的下载通道了，难道你敢从百度等下载站随便下载xshell么？反正我不敢，经过一通折腾，终于成功找到官方下载入口了。 根据 v2ex, 其中 chanssl 指出 Xshell: http://www.netsarang.com/download/down_live.html?productcode=2&amp;majorversion=5 Xftp: http://www.netsarang.com/download/down_live.html?productcode=3&amp;majorversion=5 的办法，发现下载的是评估版的，也就是30天可用。而且最蛋疼的是不能输入注册码，所以网上找的注册码都GG了。 途中又尝试了https://www.netsarang.com/download/down_form.html?code=622改成https://www.netsarang.com/download/down_form.html?code=522发现只能输入Product key ，Evaluation user / Home &amp; School user 压根就被删除了 难道只能下载免费的6或者换别的终端软件？ 不死心的又尝试了一下F12大法，打开 https://www.netsarang.com/download/down_form.html?code=622 在 Console执行 document.getElementById(&quot;code&quot;).value=522 然后打开邮箱，查看有没有收到下载链接 这属于程序漏洞，所以随着本文的传播，很可能被堵上。(截止2018-09-14本方法仍可用) 所以，一旦下载成功后，千万千万记得在云盘存一份。防止后期系统重装时，本方法不可用了，又信不过网上提供的下载链接，就抓瞎了。 此处贴一下Xshell-5.0.1339p.exe校验码 大小： 33, 012, 688 字节MD5： AB1A4AFB4894B71A3DC4DE84A84E7126SHA1： D2DA24229554139AEF8D21F737D6F78F7BEF7A7FCRC32：305847D5 至于为啥跟 https://www.netsarang.com/download/down_live.html?productcode=2&amp;majorversion=5 的校验码(MD5: 6a2aef6ac7a502f31607524a13659a81)不一致，因为 https://www.netsarang.com/download/down_live.html?productcode=2&amp;majorversion=5 是评估版，并且文件名是Xshell-5.0.1339.exe 另：出于对看客服务器的安全考虑，本文不会提供二进制下载。 博客 https://anjia0532.github.io/2018/09/14/xshell5/ 掘金 https://juejin.im/post/5b9b271be51d450e7e513d88","tags":[{"name":"linux","slug":"linux","permalink":"https://anjia0532.github.io/tags/linux/"},{"name":"xshell","slug":"xshell","permalink":"https://anjia0532.github.io/tags/xshell/"},{"name":"xshell5","slug":"xshell5","permalink":"https://anjia0532.github.io/tags/xshell5/"}]},{"title":"elasticsearch冷热数据分离并使用oss备份老数据","date":"2018-07-30T16:31:40.000Z","path":"2018/07/30/es-oss-hot-warm-backup/","text":"从某东看希捷2.5寸企业级硬盘10K转600G在1.6K左右，英特尔ssd 1T 在2-3K左右，（普通民用的便宜，普通硬盘8T 10T 12T 的也不超过2.5K） 怎么在保证扩容方便（不用走冗长的采购审批流程），保证数据安全（oss 持久性SLA是99.999999999% ），前提下，节省存储成本,经过一番研究，发现用oss来做虽然猥琐了点，但是成本最低（目前阿里云oss有活动1T三年99,10T三年999，到期后，就别续费了，新买资源包就行了，数据不用迁移）。 下面讲一下具体步骤，以及遇到的坑。 简要介绍 环境 vpc 内网 ，ecs，数据磁盘，oss，elk 热数据存在ecs数据磁盘，冷数据存在oss上，归档数据存在oss上 热数据(hot)：(根据情况1d-7d,一般日志场景超过1d就不会有高频访问了)，按需设置1-3副本 冷数据(warm)：(根据情况[2~7]-30天的)，副本0，分片1，应对偶尔的查询需求 快照(snapshot)：超过30天的，进行归档。 准备ossfs &gt; 快速安装 将oss挂载成warm节点的磁盘 $ mkdir /path/to/warm/dir$ ossfs &lt;bucketname&gt; /path/to/warm/dir -ourl=http://vpc100-oss-cn-&lt;节点名&gt;.aliyuncs.com -opasswd_file=/path/to/oss-passwds/file -o allow_other -omultireq_max=100 -omultipart_size=20 -oretries=4 -oconnect_timeout=600 -oreadwrite_timeout=600 -omax_stat_cache_size=5000 设置冷热节点详见 “Hot-Warm” Architecture in Elasticsearch 5.x 中文(像是机译) Elasticsearch 5.x 版本中的冷热节点架构 请别纠结为嘛hot-warm不叫成热-温，而是叫冷热，纯粹是叫着顺口，that’s all 修改elasticsearch.yml 在热数据节点的elasticsearch.yml中增加 node.attr.box_type: hot,path.data:/path/to/data 如果是多块磁盘建议写多个文件夹，加快写入速度，防止磁盘io阻塞 详见 path.data and path.logs 在冷数据节点的elasticsearch.yml中增加 node.attr.box_type: warm,path.data:/path/to/oss_data Note: 此处的hot和warm是可以随便写的 设置索引模板PUT _template/hot_warm_template&#123; &quot;order&quot;: 0, &quot;version&quot;: 60001, &quot;index_patterns&quot;: [ &quot;&lt;indexname&gt;*&quot; ], &quot;settings&quot; : &#123; &quot;index.routing.allocation.require.box_type&quot;: &quot;hot&quot; ...&#125; 以后新增的索引，都会发往hot节点， 需要将上面的template中的&lt;indexname&gt;替换成真正的indexname，如果要弄成全部，则可以粗暴的改成* 将老数据迁移到warm节点（oss）坑1 开始想着标准存储的dd测速，读100m/s 写40m/s速度足够了，然后热数据直接写入到oss，返回数据会有丢失情况（正常30G的数据，oss只有1-2G），原因不明，改用hot-warm后，因为不会有小文件(forcemerge成大文件了)，转存到oss上不会丢失数据 简单的，可以通过 PUT /indexname/_settings&#123; &quot;settings&quot;: &#123; &quot;index.routing.allocation.require.box_type&quot;: &quot;warm&quot; &#125; &#125; 但是不建议这么做，一个是累（每次都得写命令干?），再就是还得合并索引段(index segments),另外还得减少副本数。 所以，Curator 了解一下？详见Features 如果嫌弃安装麻烦，我封装了一个docker-curator镜像 action_file.ymlactions: 1: action: replicas description: &gt;- 超过3天的logstash-%Y.%m.%d副本数设置成0 options: count: 0 wait_for_completion: True disable_action: True filters: - filtertype: pattern kind: prefix value: logstash- - filtertype: age source: creation_date direction: older unit: days unit_count: 3 2: action: forcemerge description: &gt;- 强制合并超过3天的logstash-%Y.%m.%d为每片（每个shard不建议超过32G）2个segments(单个segments不建议超过5G)，自动跳过低于2个segments的，防止重复合并 options: max_num_segments: 2 delay: 120 timeout_override: continue_if_exception: False disable_action: True filters: - filtertype: pattern kind: prefix value: logstash- exclude: - filtertype: age source: creation_date direction: older unit: days unit_count: 3 exclude: - filtertype: forcemerged max_num_segments: 2 exclude: 3: action: allocation description: \"将超过3天的logstash-%Y.%m.%d移动到warm节点上\" options: key: box_type value: warm allocation_type: require wait_for_completion: true timeout_override: continue_if_exception: false disable_action: false filters: - filtertype: pattern kind: prefix value: logstash- - filtertype: age source: name direction: older timestring: '%Y.%m.%d' unit: days unit_count: 3 可以通过GET _cat/segments 查看segments count和所属节点 因为warm节点的data指定的是oss挂载的磁盘，所以数据此时已经迁移到oss上了 数据快照备份到oss如果你想说为啥warm已经放到oss了，还要整快照(备份) 可以不同集群恢复数据 减少es堆内存 关闭用不到的index等 如果是按量付费的oss，归档类型的比标准类型的便宜很多(0.033元/GB/月) 以上 设置共享文件存储我采用的还是挂载磁盘的方案，不过社区内有大牛基于aliyun-oss-sdk写了个es的存储插件，elasticsearch-repository-oss 但是这个是5.5.3的，如果其他版本，需要修改plguins/plugin-descriptor.properties中的elasticsearch.version和version,改为自己es集群的版本 也有别人改好的，参见 gist#aramalipoor/.env ，当然也可以fork后简单的改改，比如升级一下sdk版本，优化一下代码啥的，我也是这么干的，哈哈，详见 anjia0532/elasticsearch-repository-oss#6.3.1 没有改原有逻辑，只是升级了jar版本 此处主要讲 挂载磁盘当共享存储用的方案，参见 shared file system repository1.挂载oss磁盘为 /es-data/backup 2.修改所有master节点和data节点的elasticsearch.ymlpath.repo: [\"/es-data/backup\"] 3.创建共享文件库PUT /_snapshot/my_backup&#123; &quot;type&quot;: &quot;fs&quot;, &quot;settings&quot;: &#123; &quot;location&quot;: &quot;/es-data/backup&quot;, &quot;compress&quot;: true &#125;&#125; action_file.yml actions: 1: action: snapshot description: &gt;- 将超过15天的logstash-%Y.%m.%d 索引按照指定的名字(默认curator-%Y%m%d%H%M%S)备份快照。 等待快照完成，不跳过存储库文件系统检查，使用别的选项创建快照 options: repository: # 如果为空，则默认快照名为 'curator-%Y%m%d%H%M%S' name: ignore_unavailable: False include_global_state: True partial: False wait_for_completion: True skip_repo_fs_check: False disable_action: True filters: - filtertype: pattern kind: prefix value: logstash- - filtertype: age source: creation_date direction: older unit: days unit_count: 15 其余的，如何恢复和恢复时修改index settings详见 modules-snapshots.html#restore","tags":[{"name":"es","slug":"es","permalink":"https://anjia0532.github.io/tags/es/"},{"name":"elasticsearch","slug":"elasticsearch","permalink":"https://anjia0532.github.io/tags/elasticsearch/"},{"name":"curator","slug":"curator","permalink":"https://anjia0532.github.io/tags/curator/"},{"name":"hot-warm","slug":"hot-warm","permalink":"https://anjia0532.github.io/tags/hot-warm/"},{"name":"oss","slug":"oss","permalink":"https://anjia0532.github.io/tags/oss/"},{"name":"backup","slug":"backup","permalink":"https://anjia0532.github.io/tags/backup/"}]},{"title":"ansible","date":"2018-04-28T13:23:28.000Z","path":"2018/04/28/ansible/","text":"环境安装参考资料 官方Installation Guide 中文Installation $ sudo apt-get update$ sudo apt-get install software-properties-common$ sudo apt-add-repository ppa:ansible/ansible -y$ sudo apt-get update$ sudo apt-get install ansible 查看安装结果 $ ansible --versionansible 2.4.3.0 config file = /etc/ansible/ansible.cfg configured module search path = [u'/home/xxx/.ansible/plugins/modules', u'/usr/share/ansible/plugins/modules'] ansible python module location = /usr/local/lib/python2.7/dist-packages/ansible executable location = /usr/local/bin/ansible python version = 2.7.12 (default, Dec 4 2017, 14:50:18) [GCC 5.4.0 20160609] ## 参考 Linux轻量级自动运维工具-Ansible浅析","tags":[{"name":"python","slug":"python","permalink":"https://anjia0532.github.io/tags/python/"},{"name":"ansible","slug":"ansible","permalink":"https://anjia0532.github.io/tags/ansible/"},{"name":"运维","slug":"运维","permalink":"https://anjia0532.github.io/tags/运维/"},{"name":"linux","slug":"linux","permalink":"https://anjia0532.github.io/tags/linux/"}]},{"title":"rke安装k8s","date":"2018-01-05T16:56:28.000Z","path":"2018/01/05/rke/","text":"安装Kubernetes是公认的对运维和DevOps而言最棘手的问题之一。因为Kubernetes可以在各种平台和操作系统上运行，所以在安装过程中需要考虑很多因素。 在这篇文章中，我将介绍一种新的、用于在裸机、虚拟机、公私有云上安装Kubernetes的轻量级工具——Rancher Kubernetes Engine（RKE）。RKE是一个用Golang编写的Kubernetes安装程序，极为简单易用，用户不再需要做大量的准备工作，即可拥有闪电般快速的Kubernetes安装部署体验。 Rancher Kubernetes Engine (RKE) 旨在简化k8s的安装。但是根据官方blog和github文档，安装遇到很多问题，遂进行记录，以备查阅。 环境准备(node必须2个+，之前用一个node会报 certificate signed by unknown authority) 主机名 主机ip OS docker version k8s-server 172.60.20.12 ubuntu 17.04 4.9.0-12-generic x86_64 17.03.2-ce k8s-worker 172.60.20.13 ubuntu 17.04 4.9.0-12-generic x86_64 17.03.2-ce 下载RKE最新rke 0.0.9 但是我一直跑不起来，用0.0.8可以 wget -O rke https://github.com/rancher/rke/releases/download/v0.0.8-dev/rke_linux-amd64chmod +x ./rkewget https://raw.githubusercontent.com/rancher/rke/master/cluster.yml 开启ssh-key如果未开启ssh-key登陆，会报 client 端如果未安装 ssh-server，则通过 sudo apt-get install openssh-server -y安装 cd ~/.sshssh-keygen -t rsa -b 2048scp ~/.ssh/id_rsa.pub server_name@server_ip:/path/to/rsa/key/id_rsa.pub server 端mkdir ~/.ssh/cat /path/to/rsa/key/id_rsa.pub &gt;&gt; ~/.ssh/authorized_keyschmod 0600 ~/.ssh/*rm -rf /path/to/rsa/key/id_rsa.pubsudo service ssh restart 参考 SSH公钥(public key)验证 禁用swapFailed to deploy addon execute job: Failed to get job complete status: $ docker logs kubeletI1212 01:50:20.857798 19652 server.go:422] --cgroups-per-qos enabled, but --cgroup-root was not specified. defaulting to /error: failed to run Kubelet: Running with swap on is not supported, please disable swap! or set --fail-swap-on flag to false. /proc/swaps contained: [Filename Type Size Used Priority /dev/sda5 partition 1046524 2000 -1] sudo swapoff -a 参考 升级到Kubernetes1.8.4的配置细节差异以及k8s几个不常见的坑 运行cluster.yml ---auth: strategy: x509network: plugin: flannelssh_key_path: /home/root/.ssh/id_rsanodes: - address: 172.60.20.12 user: root role: [controlplane, etcd] - address: 172.60.20.13 user: root role: [worker]services: etcd: image: quay.io/coreos/etcd:latest kube-api: image: rancher/k8s:v1.8.3-rancher2 service_cluster_ip_range: 10.233.0.0/18 extra_args: v: 4 kube-controller: image: rancher/k8s:v1.8.3-rancher2 cluster_cidr: 10.233.64.0/18 service_cluster_ip_range: 10.233.0.0/18 scheduler: image: rancher/k8s:v1.8.3-rancher2 kubelet: image: rancher/k8s:v1.8.3-rancher2 cluster_domain: cluster.local cluster_dns_server: 10.233.0.3 infra_container_image: anjia0532/pause-amd64:3.0 kubeproxy: image: rancher/k8s:v1.8.3-rancher2system_images: alpine: alpine:latest nginx_proxy: rancher/rke-nginx-proxy:0.1.0 cert_downloader: rancher/rke-cert-deployer:0.1.0 kubedns_image: anjia0532/k8s-dns-kube-dns-amd64:1.14.5 dnsmasq_image: anjia0532/k8s-dns-dnsmasq-nanny-amd64:1.14.5 kubedns_sidecar_image: anjia0532/k8s-dns-sidecar-amd64:1.14.5 kubedns_autoscaler_image: anjia0532/cluster-proportional-autoscaler-amd64:1.0.0addons: |- --- apiVersion: v1 kind: Pod metadata: name: my-nginx namespace: default spec: containers: - name: my-nginx image: nginx ports: - containerPort: 80 ./rke up --config ./cluster.yml INFO[0041] [addons] Saving addon ConfigMap to Kubernetes INFO[0041] [addons] Successfully Saved addon to Kubernetes ConfigMap: rke-network-plugin INFO[0041] [addons] Executing deploy job.. INFO[0046] [addons] Setting up KubeDNS INFO[0046] [addons] Saving addon ConfigMap to Kubernetes INFO[0046] [addons] Successfully Saved addon to Kubernetes ConfigMap: rke-kubedns-addon INFO[0046] [addons] Executing deploy job.. INFO[0051] [addons] KubeDNS deployed successfully.. INFO[0051] [addons] Setting up user addons.. INFO[0051] [addons] Saving addon ConfigMap to Kubernetes INFO[0051] [addons] Successfully Saved addon to Kubernetes ConfigMap: rke-user-addon INFO[0051] [addons] Executing deploy job.. INFO[0056] [addons] User addon deployed successfully.. INFO[0056] Finished building Kubernetes cluster successfully $ docker psCONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES437cde03416b anjia0532/k8s-dns-sidecar-amd64@sha256:6f49768b598f9b74ee3774c19406a1512567e73f103544cf6bd3e04420ed669a \"/sidecar --v=2 --...\" 37 minutes ago Up 37 minutes k8s_sidecar_kube-dns-66fc7d58bf-lpps5_kube-system_c9c4615e-f288-11e7-8429-000c29218fe1_008db9a075ecd nginx@sha256:926b086e1234b6ae9a11589c4cece66b267890d24d1da388c96dd8795b2ffcfb \"nginx -g 'daemon ...\" 37 minutes ago Up 37 minutes k8s_my-nginx_my-nginx_default_ccc273f2-f288-11e7-8429-000c29218fe1_005e25488ec1a anjia0532/k8s-dns-dnsmasq-nanny-amd64@sha256:667c279741b1efe1e667dabc022f04f04ff0d1d35af934c0f2508bee903c6c23 \"/dnsmasq-nanny -v...\" 37 minutes ago Up 37 minutes k8s_dnsmasq_kube-dns-66fc7d58bf-lpps5_kube-system_c9c4615e-f288-11e7-8429-000c29218fe1_0e7064c9f4738 anjia0532/cluster-proportional-autoscaler-amd64@sha256:03795e1fbcc5ad4071ec969012c60dc53c8dce1b542c94701164b1224c53abaf \"/cluster-proporti...\" 37 minutes ago Up 37 minutes k8s_autoscaler_kube-dns-autoscaler-84476ff9c8-57sf9_kube-system_c9b608ef-f288-11e7-8429-000c29218fe1_04b845893a51f anjia0532/pause-amd64:3.0 \"/pause\" 38 minutes ago Up 38 minutes k8s_POD_my-nginx_default_ccc273f2-f288-11e7-8429-000c29218fe1_0c2ded5b27a95 anjia0532/k8s-dns-kube-dns-amd64@sha256:d965a1a9b53b254e2bedcbf86d0eba9378ea47084771e20f744cfbf7a1025ba6 \"/kube-dns --domai...\" 38 minutes ago Up 38 minutes k8s_kubedns_kube-dns-66fc7d58bf-lpps5_kube-system_c9c4615e-f288-11e7-8429-000c29218fe1_097736e09c32b anjia0532/pause-amd64:3.0 \"/pause\" 38 minutes ago Up 38 minutes k8s_POD_kube-dns-66fc7d58bf-lpps5_kube-system_c9c4615e-f288-11e7-8429-000c29218fe1_01f16ce846485 anjia0532/pause-amd64:3.0 \"/pause\" 38 minutes ago Up 38 minutes k8s_POD_kube-dns-autoscaler-84476ff9c8-57sf9_kube-system_c9b608ef-f288-11e7-8429-000c29218fe1_0df03a750637d quay.io/coreos/flannel-cni@sha256:77bf1017845afb65e2603d8573e9a2d649eb645a4f7fe4843f17e276b8126968 \"/install-cni.sh\" 38 minutes ago Up 38 minutes k8s_install-cni_kube-flannel-6kff4_kube-system_c78facb9-f288-11e7-8429-000c29218fe1_0e4d8b49b1f63 quay.io/coreos/flannel@sha256:60d77552f4ebb6ed4f0562876c6e2e0b0e0ab873cb01808f23f55c8adabd1f59 \"/opt/bin/flanneld...\" 38 minutes ago Up 38 minutes k8s_kube-flannel_kube-flannel-6kff4_kube-system_c78facb9-f288-11e7-8429-000c29218fe1_090b858291c7f anjia0532/pause-amd64:3.0 \"/pause\" 38 minutes ago Up 38 minutes k8s_POD_kube-flannel-6kff4_kube-system_c78facb9-f288-11e7-8429-000c29218fe1_0fd1fd7b1928c rancher/k8s:v1.8.3-rancher2 \"kube-proxy --v=2 ...\" 39 minutes ago Up 39 minutes kube-proxy1d1d03d6de8c rancher/k8s:v1.8.3-rancher2 \"kubelet --v=2 --a...\" 39 minutes ago Up 39 minutes kubeletc8f19935efd4 rancher/k8s:v1.8.3-rancher2 \"kube-scheduler --...\" 39 minutes ago Up 39 minutes scheduler1d234c5c8247 rancher/k8s:v1.8.3-rancher2 \"kube-controller-m...\" 39 minutes ago Up 39 minutes kube-controllerc3eb4391249f rancher/k8s:v1.8.3-rancher2 \"kube-apiserver --...\" 39 minutes ago Up 39 minutes kube-api8ff019fee9d8 quay.io/coreos/etcd:latest \"/usr/local/bin/et...\" 39 minutes ago Up 39 minutes 0.0.0.0:2379-2380-&gt;2379-2380/tcp etcd $ docker imagesREPOSITORY TAG IMAGE ID CREATED SIZEquay.io/coreos/etcd latest 30d9f8842f26 3 days ago 37.2 MBnginx latest 3f8a4339aadd 10 days ago 108 MBrancher/rke-service-sidekick 0.1.0 0f60235e607e 3 weeks ago 746 Balpine latest e21c333399e0 5 weeks ago 4.14 MBrancher/rke-cert-deployer 0.1.0 c8907e804cfe 5 weeks ago 9.09 MBrancher/k8s v1.8.3-rancher2 bbbe40353d71 7 weeks ago 1.54 GBquay.io/coreos/flannel v0.9.1 2b736d06ca4c 7 weeks ago 51.3 MBanjia0532/k8s-dns-sidecar-amd64 1.14.5 fed89e8b4248 3 months ago 41.8 MBanjia0532/k8s-dns-kube-dns-amd64 1.14.5 512cd7425a73 3 months ago 49.4 MBanjia0532/k8s-dns-dnsmasq-nanny-amd64 1.14.5 459944ce8cc4 3 months ago 41.4 MBquay.io/coreos/flannel-cni v0.2.0 7252edf978c0 4 months ago 49.8 MBanjia0532/cluster-proportional-autoscaler-amd64 1.0.0 e183460c484d 14 months ago 48.2 MBanjia0532/pause-amd64 3.0 99e59f495ffa 20 months ago 747 kB 参考 RKE快速上手指南：开源的轻量级K8S安装程序 rancher/rke#README.md An Introduction to Rancher Kubernetes Engine (RKE)","tags":[{"name":"k8s","slug":"k8s","permalink":"https://anjia0532.github.io/tags/k8s/"},{"name":"kubernetes","slug":"kubernetes","permalink":"https://anjia0532.github.io/tags/kubernetes/"},{"name":"rancher","slug":"rancher","permalink":"https://anjia0532.github.io/tags/rancher/"},{"name":"rke","slug":"rke","permalink":"https://anjia0532.github.io/tags/rke/"}]},{"title":"基于spring cloud的微服务实践","date":"2017-12-26T17:44:28.000Z","path":"2017/12/26/rancher-wechat-18-01-10/","text":"初创团队如何快速落地微服务–基于spring cloud/jhipster的微服务实践本次分享主要是针对，小公司及初创团队如何用较低成本落地微服务，拥抱变化，快速交付 微服务概述相关趋势图从百度指数搜索 微服务、spring boot、spring cloud、dubbo 相关关键词，得到如下趋势（微服务的概念源于2014年3月Martin Fowler所写的一篇文章Microservices ,所以选择从2014.03至今） 从图中可见，dubbo的搜索量增势放缓，而Spring Boot从16年中下旬开始发力，一路高涨。而学习了Spring boot 再学习Spring Cloud 几乎顺理成章。 spring boot旨在解决Spring越来越臃肿的全家桶方案的配置地狱（讽刺的是，Spring刚出道是扯着轻量化解决方案大旗一路冲杀，现在自己也开始慢慢胖起来了）,提供了很多简单易用的starter。特点是预定大于配置。 dubbo放缓是源于，阿里巴巴中间断更将近三年(dubbo-2.4.11 2014-10-30, dubbo-2.5.4 2017-09-07),很多依赖框架和技术都较为陈旧，也不接纳社区的PR(当然，从17年九月份开始恢复更新，后面会有说到)，导致当当另起炉灶，fork了一个dangdangdotcom/dubbox 当然，现在也已断更。而且dubbo仅相当于Spring cloud的一个子集，参考 微服务架构的基础框架选择：Spring Cloud还是Dubbo？ (此处说的是dubbo2.x,最新的3.x变化较大，后边会说到) k8s、kubernetes 、docker 的搜索趋势 微服务vs单体应用下面是我整理的一些关于单体服务和微服务的对比 单体应用好处 开发简单 容易测试 易于部署 事务回滚容易 无分布式管理，调用开销 重复功能/代码较少 单体应用缺点 迭代缓慢 维护困难 持续部署困难：微小改动，必须重启，不相干功能无法提供服务 牵一发而动全身：依赖项冲突，变更后，需要大量测试，防止影响其他功能 基础语言、框架升级缓慢 框架语言单一，无法灵活选用 微服务好处 敏捷性：按功能拆分，快速迭代 自主性：团队技术选型灵活(PHP,python,java,C#,nodejs,golang)，设计自主 可靠性：微服务故障只影响此服务消费者，而单体式应用会导致整个服务不可用 持续集成持续交付 可扩展性：热点功能容易扩展 微服务的缺点 性能降低：服务间通过网络调用 管理难度增大：增加了项目的复杂性 事务一致性 扩展阅读 Introduction to Microservices 框架选型下面讲一下，我司在落地微服务时的框架选型方面的一些经验。 公司主要使用java，所以决定使用spring 框架中的spring cloud作为微服务基础框架，但是原生 spring cloud 学习曲线比较陡峭，需要学习feign,zuul,eureka,hystrix,zipkin,ribbon… 所谓的Spring Cloud全家桶 综合考虑团队的技术水平和学习成本，最后采用了国外的开源框架 jhipster官网 jhipster github，登记在册的，使用jhipster的企业有224家(截止2018-01-11)，包括埃森哲，google，adobe等大厂。 jhipster 是由2013年由法国Java专家 Julien Dubois (朱利安 杜波尔斯)率先倡导，至今已有快5年了，积累了大量丰富经验。 采用Java 8(目前尚不支持java9,但是有开发计划)，特色是多用注解, 不用XML 配置的组态，配备了全方位的工作环境，从开发，测试，监控到制成，以及云部署。 国内用dubbo的较多，用jhipster的较少，起码很多群里交流的时候，很多表示没听过，或者是我加的假群？至于为啥不用dubbo，前面提到过，一个是中间断更，以及阿里说不更就不更的优良传统，还有dubbo从功能来说，只是Spring Cloud的一个子集(dubbo 2.x) 。 列举一下 jhipster 给的技术栈 ，参见 Technology stack 客户端技术栈 angular4,5 or angularv1.x Bootstrap HTML5 Boilerplate 兼容IE11+及现代浏览器 支持国际化 支持sass 支持spring websocket 支持yarn、bower管理js库 支持webpack、gulp.js构建，优化，应用 支持Karma, Headless Chrome 和 Protractor 进行前端单元测试测试 支持Thymeleaf 模板引擎，从服务端渲染页面 服务端技术栈 支持spring boot 简化spring配置 支持maven、gradle，构建、测试、运行程序 支持多配置文件(默认dev,prod) spring security spring mvc REST + jackson spring websocket spring data jpa + Bean Validation 使用liquibase管理数据库表结构变更版本 支持elasticsearch，进行应用内搜素 支持mongoDB 、Couchbase、Cassandra等NoSQL 支持h2db,pgsql,mysql,meriadb,sqlserver,oracle等关系型sql 支持kafka mq 使用 zuul或者traefik作为http理由 使用eureka或consul进行服务发现 支持ehcache,hazelcast,infinispan等缓存框架 支持基于hazelcast的httpsession集群 数据源使用HikariCP连接池 生成Dockerfile,docker-compose.yml 支持云服务商,AWS,Cloud Foundry,Heroku,Kubernetes,Openshift,Docker … 支持统一配置中心 其实真正用过就会发现，jhipster支持的不止列表中描述的这些。 如果不会用yarn或者不方便用命令行生成项目，可以使用jhipster online 如果想学习jhipster，可以参考我在公司推广jhipster时写的一本gitbook jhipster开发笔记 同时，值得一提的是，jhipster也支持通过 jhipster rancher-compose 命令来生成rancher-compose.yml和docker-compose.yml 参见 [BETA] Deploying to Rancher 对于小团队落地微服务，可以考虑使用jhipster来生成项目，能够极大的提高效率。基本上可以视作jhipster是一套基于spring boot的最佳实践(不仅支持微服务，也支持单体式应用)。 对于想学习spring boot或者spring cloud的也建议了解一下jhipster，好过独自摸索 jhipster依赖的技术框架版本基本都是最新稳定版，版本更新比较及时，基本上一月一个版本，对github上的issues和pr响应比较及时(一般在24小时内) 10分钟搭建微服务安装node,yarn注意 如果是windows nodejs 需要安装v7.x，因为注册中心和网关需要用到node-sass@4.5.0，但是github上的node-sass的rebuild只有v7.x(process 51) 版本的，而自己构建太反人类了。如果是linux，可以尝试高版本的。 安装完 node,yarn后，执行下面代码，使用npm的淘宝镜像，加速构建。 yarn config set sass_binary_site https://npm.taobao.org/mirrors/node-sass/yarn config set phantomjs_cdnurl https://npm.taobao.org/mirrors/phantomjs/yarn config set registry https://registry.npm.taobao.org 安装 jdk8,maven,maven加速，请自行百度。 安装jhipster下载注册中心下载并运行 注册中心-jhipster-registry 详细文档，参见 The JHipster Registry $ git clone https://github.com/jhipster/jhipster-registry.git$ cd jhipster-registry$ yarn install$ mvnw##....---------------------------------------------------------- Application 'jhipster-registry' is running! Access URLs: Local: http://localhost:8761 External: http://xx.xx.xx.xx:8761 Profile(s): [swagger, dev, native]---------------------------------------------------------- 浏览器访问 http://localhost:8761 初始用户名密码均为 admin spring config server,统一配置中心，可以统一管理不同环境的数据库地址，用户名，密码等敏感数据 jhipster registry 对应SC(Spring Cloud)的eurake+spring config server，想想自己用原生的SC自己搞的辛酸泪吧，再牛逼，刚学，也得10min+才能跑起来吧？ 创建网关创建api网关，参见 Creating an application 和The JHipster API Gateway $ yarn global add generator-jhipster$ mkdir gateway$ cd gateway$ yo jhipster ██╗ ██╗ ██╗ ████████╗ ███████╗ ██████╗ ████████╗ ████████╗ ███████╗ ██║ ██║ ██║ ╚══██╔══╝ ██╔═══██╗ ██╔════╝ ╚══██╔══╝ ██╔═════╝ ██╔═══██╗ ██║ ████████║ ██║ ███████╔╝ ╚█████╗ ██║ ██████╗ ███████╔╝ ██╗ ██║ ██╔═══██║ ██║ ██╔════╝ ╚═══██╗ ██║ ██╔═══╝ ██╔══██║ ╚██████╔╝ ██║ ██║ ████████╗ ██║ ██████╔╝ ██║ ████████╗ ██║ ╚██╗ ╚═════╝ ╚═╝ ╚═╝ ╚═══════╝ ╚═╝ ╚═════╝ ╚═╝ ╚═══════╝ ╚═╝ ╚═╝ http://www.jhipster.techWelcome to the JHipster Generator v4.13.2 _______________________________________________________________________________________________________________ If you find JHipster useful consider supporting our collective https://opencollective.com/generator-jhipster Documentation for creating an application: http://www.jhipster.tech/creating-an-app/ _______________________________________________________________________________________________________________Application files will be generated in folder: G:\\jh\\gateway? Which *type* of application would you like to create? Microservice gateway? What is the base name of your application? gateway? As you are running in a microservice architecture, on which port would like your server to run? It should be unique to avoid port conflicts. 8080? What is your default Java package name? com.anjia.gateway? Which service discovery server do you want to use? JHipster Registry (uses Eureka, provides Spring Cloud Config support and monitoring dashboards)? Which *type* of authentication would you like to use? JWT authentication (stateless, with a token)? Which *type* of database would you like to use? SQL (H2, MySQL, MariaDB, PostgreSQL, Oracle, MSSQL)? Which *production* database would you like to use? MySQL? Which *development* database would you like to use? H2 with disk-based persistence? Do you want to use Hibernate 2nd level cache? Yes? Would you like to use Maven or Gradle for building the backend? Maven? Which other technologies would you like to use?? Which *Framework* would you like to use for the client? Angular 5? Would you like to enable *SASS* support using the LibSass stylesheet preprocessor? No? Would you like to enable internationalization support? Yes? Please choose the native language of the application English? Please choose additional languages to install? Besides JUnit and Karma, which testing frameworks would you like to use?? Would you like to install other generators from the JHipster Marketplace? No$ mvnw---------------------------------------------------------- Application 'gateway' is running! Access URLs: Local: http://localhost:8080 External: http://xx.xx.xx.xx:8080 Profile(s): [swagger, dev]---------------------------------------------------------- 访问 http://localhost:8080/ 默认用户名密码均为 admin 创建服务创建服务 参考 Creating an application $ mkdir foo$ cd foo$ yo jhipster ██╗ ██╗ ██╗ ████████╗ ███████╗ ██████╗ ████████╗ ████████╗ ███████╗ ██║ ██║ ██║ ╚══██╔══╝ ██╔═══██╗ ██╔════╝ ╚══██╔══╝ ██╔═════╝ ██╔═══██╗ ██║ ████████║ ██║ ███████╔╝ ╚█████╗ ██║ ██████╗ ███████╔╝ ██╗ ██║ ██╔═══██║ ██║ ██╔════╝ ╚═══██╗ ██║ ██╔═══╝ ██╔══██║ ╚██████╔╝ ██║ ██║ ████████╗ ██║ ██████╔╝ ██║ ████████╗ ██║ ╚██╗ ╚═════╝ ╚═╝ ╚═╝ ╚═══════╝ ╚═╝ ╚═════╝ ╚═╝ ╚═══════╝ ╚═╝ ╚═╝ http://www.jhipster.techWelcome to the JHipster Generator v4.13.2 _______________________________________________________________________________________________________________ If you find JHipster useful consider supporting our collective https://opencollective.com/generator-jhipster Documentation for creating an application: http://www.jhipster.tech/creating-an-app/ _______________________________________________________________________________________________________________Application files will be generated in folder: G:\\jh\\foo? Which *type* of application would you like to create? Microservice application? What is the base name of your application? foo? As you are running in a microservice architecture, on which port would like your server to run? It should be unique to avoid port conflicts. 8081? What is your default Java package name? com.anjia.foo? Which service discovery server do you want to use? JHipster Registry (uses Eureka, provides Spring Cloud Config support and monitoring dashboards)? Which *type* of authentication would you like to use? JWT authentication (stateless, with a token)? Which *type* of database would you like to use? SQL (H2, MySQL, MariaDB, PostgreSQL, Oracle, MSSQL)? Which *production* database would you like to use? MySQL? Which *development* database would you like to use? H2 with disk-based persistence? Do you want to use the Spring cache abstraction? Yes, with the Hazelcast implementation (distributed cache, for multiple nodes)? Do you want to use Hibernate 2nd level cache? Yes? Would you like to use Maven or Gradle for building the backend? Maven? Which other technologies would you like to use?? Would you like to enable internationalization support? Yes? Please choose the native language of the application Chinese (Simplified)? Please choose additional languages to install? Besides JUnit and Karma, which testing frameworks would you like to use?? Would you like to install other generators from the JHipster Marketplace? No$ mvnw---------------------------------------------------------- Application 'foo' is running! Access URLs: Local: http://localhost:8081 External: http://xx.xx.xx.xx:8081 Profile(s): [swagger, dev]---------------------------------------------------------- 访问 http://localhost:8080/#/docs 默认用户名密码均为 admin ，使用swagger管理api文档，开发时，仅需要添加对应的注解，即可自动生成文档，解决了传统通过word，pdf等管理接口时，文档更新不及时等问题。并且可以通过try it可以直接调用接口，避免了接口调试时使用curl,postman等工具 至此，已经创建了一个简单微服务（jhipster-registry是注册中心，gateway是网关，foo是具体的功能模块）。 创建实体参考文档 Creating an entity jhipster支持通过命令行创建实体，也支持uml或jdl生成实体，为了省事，此处使用 官方jdl-studio 的默认jdl文件 https://start.jhipster.tech/jdl-studio/ $ yo jhipster:import-jdl /path/to/jdl-studio/jhipster-jdl.jhThe jdl is being parsed.Writing entity JSON files.Updated entities are: Region,Country,Location,Department,Task,Employee,Job,JobHistoryGenerating entities.Found the .jhipster/Region.json configuration file, entity can be automatically generated!The entity Region is being updated.Found the .jhipster/Country.json configuration file, entity can be automatically generated!The entity Country is being updated.Found the .jhipster/Location.json configuration file, entity can be automatically generated!The entity Location is being updated.Found the .jhipster/Department.json configuration file, entity can be automatically generated!The entity Department is being updated.Found the .jhipster/Task.json configuration file, entity can be automatically generated!The entity Task is being updated.Found the .jhipster/Employee.json configuration file, entity can be automatically generated!The entity Employee is being updated.Found the .jhipster/Job.json configuration file, entity can be automatically generated!The entity Job is being updated.Found the .jhipster/JobHistory.json configuration file, entity can be automatically generated!The entity JobHistory is being updated. create src\\main\\resources\\config\\liquibase\\changelog\\20180107064934_added_entity_Region.xml create src\\main\\java\\com\\anjia\\foo\\domain\\Region.java create src\\main\\java\\com\\anjia\\foo\\repository\\RegionRepository.java create src\\main\\java\\com\\anjia\\foo\\web\\rest\\RegionResource.java create src\\main\\java\\com\\anjia\\foo\\service\\RegionService.java create src\\main\\java\\com\\anjia\\foo\\service\\impl\\RegionServiceImpl.java create src\\main\\java\\com\\anjia\\foo\\service\\dto\\RegionDTO.java create src\\main\\java\\com\\anjia\\foo\\service\\mapper\\EntityMapper.java create src\\main\\java\\com\\anjia\\foo\\service\\mapper\\RegionMapper.java create src\\test\\java\\com\\anjia\\foo\\web\\rest\\RegionResourceIntTest.java conflict src\\main\\resources\\config\\liquibase\\master.xml? Overwrite src\\main\\resources\\config\\liquibase\\master.xml? overwrite force src\\main\\resources\\config\\liquibase\\master.xml create src\\main\\resources\\config\\liquibase\\changelog\\20180107064935_added_entity_Country.xml create src\\main\\resources\\config\\liquibase\\changelog\\20180107064935_added_entity_constraints_Country.xml create src\\main\\java\\com\\anjia\\foo\\domain\\Country.java create src\\main\\java\\com\\anjia\\foo\\repository\\CountryRepository.java create src\\main\\java\\com\\anjia\\foo\\web\\rest\\CountryResource.java create src\\main\\java\\com\\anjia\\foo\\service\\CountryService.java create src\\main\\java\\com\\anjia\\foo\\service\\impl\\CountryServiceImpl.java create src\\main\\java\\com\\anjia\\foo\\service\\dto\\CountryDTO.java create src\\main\\java\\com\\anjia\\foo\\service\\mapper\\CountryMapper.java create src\\test\\java\\com\\anjia\\foo\\web\\rest\\CountryResourceIntTest.java create src\\main\\resources\\config\\liquibase\\changelog\\20180107064936_added_entity_Location.xml create src\\main\\resources\\config\\liquibase\\changelog\\20180107064936_added_entity_constraints_Location.xml create src\\main\\java\\com\\anjia\\foo\\domain\\Location.java create src\\main\\java\\com\\anjia\\foo\\repository\\LocationRepository.java create src\\main\\java\\com\\anjia\\foo\\web\\rest\\LocationResource.java create src\\main\\java\\com\\anjia\\foo\\service\\LocationService.java create src\\main\\java\\com\\anjia\\foo\\service\\impl\\LocationServiceImpl.java create src\\main\\java\\com\\anjia\\foo\\service\\dto\\LocationDTO.java create src\\main\\java\\com\\anjia\\foo\\service\\mapper\\LocationMapper.java create src\\test\\java\\com\\anjia\\foo\\web\\rest\\LocationResourceIntTest.java create src\\main\\resources\\config\\liquibase\\changelog\\20180107064937_added_entity_Department.xml create src\\main\\resources\\config\\liquibase\\changelog\\20180107064937_added_entity_constraints_Department.xml create src\\main\\java\\com\\anjia\\foo\\domain\\Department.java create src\\main\\java\\com\\anjia\\foo\\repository\\DepartmentRepository.java create src\\main\\java\\com\\anjia\\foo\\web\\rest\\DepartmentResource.java create src\\main\\java\\com\\anjia\\foo\\service\\DepartmentService.java create src\\main\\java\\com\\anjia\\foo\\service\\impl\\DepartmentServiceImpl.java create src\\main\\java\\com\\anjia\\foo\\service\\dto\\DepartmentDTO.java create src\\main\\java\\com\\anjia\\foo\\service\\mapper\\DepartmentMapper.java create src\\test\\java\\com\\anjia\\foo\\web\\rest\\DepartmentResourceIntTest.java create src\\main\\resources\\config\\liquibase\\changelog\\20180107064938_added_entity_Task.xml create src\\main\\java\\com\\anjia\\foo\\domain\\Task.java create src\\main\\java\\com\\anjia\\foo\\repository\\TaskRepository.java create src\\main\\java\\com\\anjia\\foo\\web\\rest\\TaskResource.java create src\\main\\java\\com\\anjia\\foo\\service\\TaskService.java create src\\main\\java\\com\\anjia\\foo\\service\\impl\\TaskServiceImpl.java create src\\main\\java\\com\\anjia\\foo\\service\\dto\\TaskDTO.java create src\\main\\java\\com\\anjia\\foo\\service\\mapper\\TaskMapper.java create src\\test\\java\\com\\anjia\\foo\\web\\rest\\TaskResourceIntTest.java create src\\main\\resources\\config\\liquibase\\changelog\\20180107064939_added_entity_Employee.xml create src\\main\\resources\\config\\liquibase\\changelog\\20180107064939_added_entity_constraints_Employee.xml create src\\main\\java\\com\\anjia\\foo\\domain\\Employee.java create src\\main\\java\\com\\anjia\\foo\\repository\\EmployeeRepository.java create src\\main\\java\\com\\anjia\\foo\\web\\rest\\EmployeeResource.java create src\\main\\java\\com\\anjia\\foo\\service\\dto\\EmployeeDTO.java create src\\main\\java\\com\\anjia\\foo\\service\\mapper\\EmployeeMapper.java create src\\test\\java\\com\\anjia\\foo\\web\\rest\\EmployeeResourceIntTest.java create src\\main\\resources\\config\\liquibase\\changelog\\20180107064940_added_entity_Job.xml create src\\main\\resources\\config\\liquibase\\changelog\\20180107064940_added_entity_constraints_Job.xml create src\\main\\java\\com\\anjia\\foo\\domain\\Job.java create src\\main\\java\\com\\anjia\\foo\\repository\\JobRepository.java create src\\main\\java\\com\\anjia\\foo\\web\\rest\\JobResource.java create src\\main\\java\\com\\anjia\\foo\\service\\dto\\JobDTO.java create src\\main\\java\\com\\anjia\\foo\\service\\mapper\\JobMapper.java create src\\test\\java\\com\\anjia\\foo\\web\\rest\\JobResourceIntTest.java create src\\main\\resources\\config\\liquibase\\changelog\\20180107064941_added_entity_JobHistory.xml create src\\main\\resources\\config\\liquibase\\changelog\\20180107064941_added_entity_constraints_JobHistory.xml create src\\main\\java\\com\\anjia\\foo\\domain\\JobHistory.java create src\\main\\java\\com\\anjia\\foo\\repository\\JobHistoryRepository.java create src\\main\\java\\com\\anjia\\foo\\web\\rest\\JobHistoryResource.java create src\\main\\java\\com\\anjia\\foo\\service\\JobHistoryService.java create src\\main\\java\\com\\anjia\\foo\\service\\impl\\JobHistoryServiceImpl.java create src\\main\\java\\com\\anjia\\foo\\service\\dto\\JobHistoryDTO.java create src\\main\\java\\com\\anjia\\foo\\service\\mapper\\JobHistoryMapper.java create src\\test\\java\\com\\anjia\\foo\\web\\rest\\JobHistoryResourceIntTest.java create src\\main\\java\\com\\anjia\\foo\\domain\\enumeration\\Language.java 重启 foo服务,再次访问 http://localhost:8080/#/docs 发现多了很多接口 通过swagger ui，找到 region-resource 找到 POST /api/regions 创建一个名为test的regison 点 try it out! 然后浏览器打开 h2 数据库 http://localhost:8081/h2-console 查询 REGION表，数据已经插入成功。 至此，一个虽然简单，但是可用的微服务已经弄好。 将服务发布到rancher参见文档 [BETA] Deploying to Rancher ,jhipster支持发布到 Cloud Foundry ,Heroku,Kubernetes,Openshift,Rancher,AWS,Boxfuse 建议使用rancher，原因， Cloud Foundry ,Heroku,AWS,Boxfuse 都是云环境，k8s和openshift origin太复杂了，而rancher很容易上手，其联合创始人成为CNCF的理事会成员。 附上一张 CNCF天梯图 $ mkdir docker $ cd docker $ yo jhipster rancher-rancher ██╗ ██╗ ██╗ ████████╗ ███████╗ ██████╗ ████████╗ ████████╗ ███████╗ ██║ ██║ ██║ ╚══██╔══╝ ██╔═══██╗ ██╔════╝ ╚══██╔══╝ ██╔═════╝ ██╔═══██╗ ██║ ████████║ ██║ ███████╔╝ ╚█████╗ ██║ ██████╗ ███████╔╝ ██╗ ██║ ██╔═══██║ ██║ ██╔════╝ ╚═══██╗ ██║ ██╔═══╝ ██╔══██║ ╚██████╔╝ ██║ ██║ ████████╗ ██║ ██████╔╝ ██║ ████████╗ ██║ ╚██╗ ╚═════╝ ╚═╝ ╚═╝ ╚═══════╝ ╚═╝ ╚═════╝ ╚═╝ ╚═══════╝ ╚═╝ ╚═╝ http://www.jhipster.techWelcome to the JHipster Generator v4.13.2 _______________________________________________________________________________________________________________ If you find JHipster useful consider supporting our collective https://opencollective.com/generator-jhipster Documentation for creating an application: http://www.jhipster.tech/creating-an-app/ _______________________________________________________________________________________________________________Application files will be generated in folder: G:\\jh\\docker? What is the base name of your application? (docker)G:\\jh\\dockerλ jhipster rancher-composeUsing JHipster version installed globallyExecuting jhipster:rancher-composeOptions:🐮 [BETA] Welcome to the JHipster Rancher Compose Generator 🐮Files will be generated in folder: G:\\jh\\docker? Which *type* of application would you like to deploy? Microservice application? Enter the root directory where your gateway(s) and microservices are located ../2 applications found at G:\\jh\\? Which applications do you want to include in your configuration? foo, gateway? Do you want to setup monitoring for your applications ? Yes, for logs and metrics with the JHipster Console (based on ELK and Zipkin)JHipster registry detected as the service discovery and configuration provider used by your apps? Enter the admin password used to secure the JHipster Registry admin? Would you like to enable rancher load balancing support? Yes? What should we use for the base Docker repository name?? What command should we use for push Docker image to repository? docker pushChecking Docker images in applications' directories...ls: no such file or directory: G:/jh/foo/target/dockerls: no such file or directory: G:/jh/gateway/target/docker create rancher-compose.yml create docker-compose.yml create registry-config-sidekick\\Dockerfile create registry-config-sidekick\\application.ymlRancher Compose configuration generated with missing images!To generate the missing Docker image(s), please run: ./mvnw verify -Pprod dockerfile:build in G:\\jh\\foo ./mvnw verify -Pprod dockerfile:build in G:\\jh\\gatewayWARNING! You will need to push your image to a registry. If you have not done so, use the following commands to tag and push the images:docker push foodocker push gatewayCongratulations, JHipster execution is complete! rancher-compose.ymlversion: '2'services: lb: # load balancer container scale: 1 load_balancer_config: name: lb config health_check: port: 42 interval: 2000 unhealthy_threshold: 3 healthy_threshold: 2 response_timeout: 2000 foo-app: scale: 1 foo-mysql: scale: 1 gateway-app: scale: 1 gateway-mysql: scale: 1 jhipster-registry: scale: 1 jhipster-elasticsearch: scale: 1 jhipster-logstash: scale: 1 jhipster-console: scale: 1 # Uncomment this section to enable Zipkin #jhipster-zipkin: # scale: 1 docker-compose.ymlversion: '2'services: lb: image: rancher/load-balancer-service ports: # Listen on public port 80 and direct traffic to private port 8080 of the service - 80:8080 links: # Target services in the same stack will be listed as a link - gateway-app:gateway-app foo-app: image: foo environment: - SPRING_PROFILES_ACTIVE=prod,swagger - EUREKA_CLIENT_SERVICE_URL_DEFAULTZONE=http://admin:$$&#123;jhipster.registry.password&#125;@jhipster-registry:8761/eureka - SPRING_CLOUD_CONFIG_URI=http://admin:$$&#123;jhipster.registry.password&#125;@jhipster-registry:8761/config - SPRING_DATASOURCE_URL=jdbc:mysql://foo-mysql:3306/foo?useUnicode=true&amp;characterEncoding=utf8&amp;useSSL=false - JHIPSTER_SLEEP=30 - JHIPSTER_LOGGING_LOGSTASH_ENABLED=true - JHIPSTER_LOGGING_LOGSTASH_HOST=jhipster-logstash - JHIPSTER_METRICS_LOGS_ENABLED=true - JHIPSTER_METRICS_LOGS_REPORT_FREQUENCY=60 - JHIPSTER_REGISTRY_PASSWORD=admin foo-mysql: image: mysql:5.7.20 environment: - MYSQL_USER=root - MYSQL_ALLOW_EMPTY_PASSWORD=yes - MYSQL_DATABASE=foo command: &gt;- mysqld --lower_case_table_names=1 --skip-ssl --character_set_server=utf8 --explicit_defaults_for_timestamp gateway-app: image: gateway environment: - SPRING_PROFILES_ACTIVE=prod,swagger - EUREKA_CLIENT_SERVICE_URL_DEFAULTZONE=http://admin:$$&#123;jhipster.registry.password&#125;@jhipster-registry:8761/eureka - SPRING_CLOUD_CONFIG_URI=http://admin:$$&#123;jhipster.registry.password&#125;@jhipster-registry:8761/config - SPRING_DATASOURCE_URL=jdbc:mysql://gateway-mysql:3306/gateway?useUnicode=true&amp;characterEncoding=utf8&amp;useSSL=false - JHIPSTER_SLEEP=30 - JHIPSTER_LOGGING_LOGSTASH_ENABLED=true - JHIPSTER_LOGGING_LOGSTASH_HOST=jhipster-logstash - JHIPSTER_METRICS_LOGS_ENABLED=true - JHIPSTER_METRICS_LOGS_REPORT_FREQUENCY=60 - JHIPSTER_REGISTRY_PASSWORD=admin ports: - 8080:8080 gateway-mysql: image: mysql:5.7.20 environment: - MYSQL_USER=root - MYSQL_ALLOW_EMPTY_PASSWORD=yes - MYSQL_DATABASE=gateway command: &gt;- mysqld --lower_case_table_names=1 --skip-ssl --character_set_server=utf8 --explicit_defaults_for_timestamp jhipster-registry: image: jhipster/jhipster-registry:v3.2.4 #volumes: # - ./central-server-config:/central-config # By default the JHipster Registry runs with the \"dev\" and \"native\" # Spring profiles. # \"native\" profile means the filesystem is used to store data, see # http://cloud.spring.io/spring-cloud-config/spring-cloud-config.html environment: - SPRING_PROFILES_ACTIVE=dev,native - SECURITY_USER_PASSWORD=admin - JHIPSTER_LOGGING_LOGSTASH_ENABLED=true - JHIPSTER_LOGGING_LOGSTASH_HOST=jhipster-logstash - JHIPSTER_METRICS_LOGS_ENABLED=true - JHIPSTER_METRICS_LOGS_REPORTFREQUENCY=60 - SPRING_CLOUD_CONFIG_SERVER_NATIVE_SEARCH_LOCATIONS=file:./config/ # Uncomment to use a Git configuration source instead of the local filesystem # mounted from the registry-config-sidekick volume # - GIT_URI=https://github.com/jhipster/jhipster-registry/ # - GIT_SEARCH_PATHS=central-config ports: - 8761:8761 volumes: - /config volumes_from: - registry-config-sidekick labels: io.rancher.sidekicks: registry-config-sidekick registry-config-sidekick: # this docker image must be built with: # docker build -t registry-config-sidekick registry-config-sidekick image: registry-config-sidekick tty: true stdin_open: true command: - cat volumes: - config:/config jhipster-elasticsearch: image: jhipster/jhipster-elasticsearch:v2.2.1 ports: - 9200:9200 - 9300:9300 # Uncomment this section to have elasticsearch data persisted to a volume #volumes: # - ./log-data:/usr/share/elasticsearch/data jhipster-logstash: image: jhipster/jhipster-logstash:v2.2.1 command: logstash -f /conf/logstash.conf ports: - 5000:5000/udp # Uncomment this section to have logstash config loaded from a volume #volumes: # - ./log-conf/:/conf jhipster-console: image: jhipster/jhipster-console:v2.2.1 ports: - 5601:5601 # Uncomment this section to enable Zipkin #jhipster-zipkin: # image: jhipster/jhipster-zipkin:v2.2.1 # ports: # - 9411:9411 # environment: # - ES_HOSTS=http://jhipster-elasticsearch:9200 # - ZIPKIN_UI_LOGS_URL=http://localhost:5601/app/kibana#/dashboard/logs-dashboard?_g=(refreshInterval:(display:Off,pause:!f,value:0),time:(from:now-1h,mode:quick,to:now))&amp;_a=(filters:!(),options:(darkTheme:!f),panels:!((col:1,id:logs-levels,panelIndex:2,row:1,size_x:6,size_y:3,type:visualization),(col:7,columns:!(stack_trace),id:Stacktraces,panelIndex:7,row:1,size_x:4,size_y:3,sort:!('@timestamp',desc),type:search),(col:11,id:Log-forwarding-instructions,panelIndex:8,row:1,size_x:2,size_y:3,type:visualization),(col:1,columns:!(app_name,level,message),id:All-logs,panelIndex:9,row:4,size_x:12,size_y:7,sort:!('@timestamp',asc),type:search)),query:(query_string:(analyze_wildcard:!t,query:'&#123;traceId&#125;')),title:logs-dashboard,uiState:()) docker-compose.yml中给的jhipster-registry是本地模式的，可以根据注释部分内容，改成从git拉。好处是维护方便，坏处是，容易造成单点故障。使用git模式，就可以将 registry-config-sidekick 部分去掉。 jhipster使用liquibase 进行数据库版本管理，便于数据库版本变更记录管理和迁移。(rancher server 也用的liquibase) 把docker-compose.yml和rancher-compose.yml贴到rancher上，就能创建一个应用 stack了。 不过，好像漏了点啥，少了CICD，rancher和docker的compsoe.yml有了，但是，还没构建镜像呢，镜像还没push到registry呢，对吧 自建gitlab我司用gitlab管理源码，我在docker hub上发布了一个汉化的gitlab https://hub.docker.com/r/gitlab/gitlab-ce/tags/,如果要用官方镜像，参见 https://hub.docker.com/r/gitlab/gitlab-ce/tags/ version: '2'services: gitlab: mem_limit: 5368709120 #限制内存最大 5G = 5*1024*1024*1024 image: anjia0532/gitlab-ce-zh:10.3.3-ce.0 volumes: - /data/gitlab/config:/etc/gitlab - /data/gitlab/data:/var/opt/gitlab - /data/gitlab/log:/var/log/gitlab ports: - 80:80/tcp - 443:443/tcp gitlab ci参见文档 GitLab Continuous Integration (GitLab CI) 为啥不用jenkins？ 这个萝卜白菜各有所爱，我是出于压缩技术栈的考虑， gitlab-ci够简单，也够用， 根gitlab配套，不用多学习jenkins，毕竟多一套，就多一套的学习成本 搭建镜像伺服 老牌 sonatype nexus oss 可以管理 Bower,Docker,Git LFS,Maven,npm,NuGet,PyPI,Ruby Gems,Yum Proxy,功能丰富 GitLab Container Registry administration gitlab registry跟gitlab集成，不需要额外安装服务 harbor rancher应用商店就有，安装方便，号称企业级registry，功能强大。 还是那句话，看需求，我司有部署maven和npm的需要，所以用了nexus oss，顺便管理docker registry。 Service Mesh–下一代微服务我司是从16年八九月份开始拆分单体服务，彼时国内spring cloud，微服务等相关资料较少，国内流行dubbo(那会已经断更1年多了，虽然现在复更，但是对其前景不太看好) 从17年开始，圈内讨论spring cloud的渐渐多起来了，同时市面上也有了介绍spring cloud的书籍，比如周立的Spring Cloud与Docker微服务架构实战, 翟永超的Spring Cloud微服务实战 等 但是用了spring cloud后，感觉spring cloud太复杂了(如果用了jhipster情况会好点)，并没有实现微服务的初衷 跟语言，框架无关:局限于java 隐藏底层细节，需要学习zuul路由，eureka注册中心，configserver配置中心，需要熔断，降级，需要实现分布式跟踪… 在这种情况下，16年，国外buoyant公司提出Service Mesh概念，基于scala创建了linkerd项目。 service mesh 的设想就是，让开发人员专注于业务，不再分心于基础设施。 目前主流框架 istio 背靠google，ibm，后台硬，前景广阔 conduit 跟linkerd是一个公司的，使用Rust语言开发，proxy消耗不到10M内存，p99控制在毫秒内 linkerd 商用企业较多，国内我知道的有豆瓣 envoy 国内腾讯在用 其中istio和conduit都不太成熟，而linkerd和envoy都有商用案例，较为成熟。长远来看，更看好 istio和conduit 在此 分享一个dubbo的老用户的利好消息，据说 dubbo3 将兼容2，并且支持service mesh，并且支持反应式编程。参见 重大革新！Dubbo 3.0来了 扩展阅读资料 官方文档|ServiceMesh服务网格Istio面板组件&amp;设计目标 演讲实录 | Service Mesh 时代的选边与站队（附PPT下载） Service Mesh：下一代微服务 Service Mesh 在华为公有云的实践 明星分分合合的洪荒点击量，微博Mesh服务化改造如何支撑？（附PPT下载） 注意 需要根据公司、团队实际情况理性选择框架，目前service mesh还处于垦荒阶段，而spring cloud或者dubbo还没到彻底过时的程度，建议持续关注，不建议立刻上马，如果已经落地了相关的微服务技术，不要盲目跟风，在可接受学习成本和开发成本情况下，可以考虑研究一下service mesh。 如果使用的是spring框架的话，建议抛开spring cloud，直接spring boot+service mesh，更清爽一些","tags":[{"name":"k8s","slug":"k8s","permalink":"https://anjia0532.github.io/tags/k8s/"},{"name":"微服务","slug":"微服务","permalink":"https://anjia0532.github.io/tags/微服务/"},{"name":"kubernetes","slug":"kubernetes","permalink":"https://anjia0532.github.io/tags/kubernetes/"},{"name":"jhipster","slug":"jhipster","permalink":"https://anjia0532.github.io/tags/jhipster/"},{"name":"spring","slug":"spring","permalink":"https://anjia0532.github.io/tags/spring/"},{"name":"spring-boot","slug":"spring-boot","permalink":"https://anjia0532.github.io/tags/spring-boot/"},{"name":"spring-cloud","slug":"spring-cloud","permalink":"https://anjia0532.github.io/tags/spring-cloud/"},{"name":"microservices","slug":"microservices","permalink":"https://anjia0532.github.io/tags/microservices/"},{"name":"service-mesh","slug":"service-mesh","permalink":"https://anjia0532.github.io/tags/service-mesh/"}]},{"title":"微服务场景下性能问题排查神器之xrebel","date":"2017-11-21T14:57:14.000Z","path":"2017/11/21/xrebel-introducing-microservices-profiling/","text":"对于java应用性能跟踪其实有很多种手段，本文只是针对xrebel的使用做一些简单讲解（单体应用和微服务应用）。分布式跟踪有很多，比如zipkin等，详见 分布式跟踪系统（一）：Zipkin的背景和设计，但是太重了，不适合小规模团队，开发时期用。 而且以zipkin为例，仅仅是A服务调用B服务耗时多少，并不会显示详细的线程，堆栈信息。需要搭配其他手段进行排查。 示例： 下载xrebel目前最新版本 xrebel-3.4.1.zip xrebel 支持的框架及场景快速安装xrebel支持eclipse和idea,同时有eclipse插件，建议使用独立方式安装。 下载xrebel.zip 并解压到本地，e.g. D:\\xrebel 在tomcat也好，idea,eclipse也好，修改vm 参数，添加 -javaagent:[path/to/xrebel]/xrebel.jar 下面分别是idea,eclipse 默认是可以试用14天的，建议支持正版，毕竟大家都是吃这行饭的。而且 xrebel jrebel jrebel for android 给你省的时间，绝对值这个价。 jrebel有个免费的社区计划 https://my.jrebel.com/ web ui打开 web 服务页面，xrebel会直接注入到你的页面中，左下角会出现 xrebel的toolbar，(e.g. http://localhost:8080) 或者通过 访问服务/xrebel (e.g. http://localhost:8080/xrebel) 打开单独页面，适用于webservice,restful 等无页面场景 如果不想注入到页面中，只想通过服务/xrebel访问，则可以添加 -Dxrebel.injection=true|false ，默认为true 其余开关参数 参见 XRebel launch parameters xrebel 简单使用教程参考 Using XRebel 微服务参考 Microservices 和 XRebel 3.0: introducing microservices profiling 确保调用方，和被调用方，都开了xrebel， 效果如下 启用xrebel调试参考 Debugging with XRebel enabled 题外话 静态资源分离的必要性为嘛建议将静态文件分离？通过xrebel就可以清晰看出来 博客 https://anjia.ml/2017/11/21/xrebel-introducing-microservices-profiling/掘金 https://juejin.im/post/5a13e3db6fb9a045186a5bfc简书 http://www.jianshu.com/p/0029c32dde4e","tags":[{"name":"jrebel","slug":"jrebel","permalink":"https://anjia0532.github.io/tags/jrebel/"},{"name":"spring-cloud","slug":"spring-cloud","permalink":"https://anjia0532.github.io/tags/spring-cloud/"},{"name":"xrebel","slug":"xrebel","permalink":"https://anjia0532.github.io/tags/xrebel/"},{"name":"micro-service","slug":"micro-service","permalink":"https://anjia0532.github.io/tags/micro-service/"}]},{"title":"Google Container Registry(gcr.io) 中国可用镜像(长期维护)","date":"2017-11-15T12:04:14.000Z","path":"2017/11/15/gcr-io-image-mirror/","text":"google镜像库Google Container Registry(gcr.io) 被gfw墙了。花了点时间用github + travis ci + docker hub成功将gcr.io的全部镜像同步到docker hub了。配合 国内各种加速器 Docker 中国官方镜像加速 ,加速器 DaoCloud - 业界领先的容器云平台速度还是很快的 何时同步使用了 travis ci 的定时构建功能，每天同步一次，同步成功后，会将结果更新到 https://github.com/anjia0532/gcr.io_mirror , 注意，同步时间为 UTC 时间，换成北京时间+8小时即可 如何使用将 gcr.io/google-containers 替换为 anjia0532 即可. 缺少镜像如果本项目中缺少 gcr.io 的镜像,请提issues","tags":[{"name":"k8s","slug":"k8s","permalink":"https://anjia0532.github.io/tags/k8s/"},{"name":"kubernetes","slug":"kubernetes","permalink":"https://anjia0532.github.io/tags/kubernetes/"},{"name":"rancher","slug":"rancher","permalink":"https://anjia0532.github.io/tags/rancher/"},{"name":"gcr.io","slug":"gcr-io","permalink":"https://anjia0532.github.io/tags/gcr-io/"}]},{"title":"rancher中国区加速安装Kubernetes","date":"2017-11-13T12:04:14.000Z","path":"2017/11/13/rancher-k8s-china/","text":"上篇 《rancher安装Kubernetes》 最后的步骤是错误的，即使每次手动改了k8s的镜像，但是依然服务pull，而且每次重启docker或者k8s，又会重置回默认的gcr.io的镜像。 本文是在群内@天阑-李小威 @洪晓露 @logan 等大神指导下,并根据 《原生加速中国区Kubernetes安装》，最终搞定的方案 环境准备 主机名 主机ip OS docker version ranhcer version anjia-ubuntu 192.168.31.83 ubuntu 17.04 4.9.0-12-generic x86_64 Docker version 1.12.6 v1.6.11 安装 docker按照 Getting Started with Hosts#SUPPORTED DOCKER VERSIONS 安装受支持的docker version (如果国内安装较慢，可以考虑使用中科大docker镜像 ,或者其他阿里云镜像，腾讯云镜像，清华镜像等) 一定注意版本号，在群里处理过好几个因为docker版本不对导致的k8s无法打开dashboard 如果之前装有其他版本的，需要删除所有镜像和容器，并卸载docker重装,rancher k8s 目前只支持 docker 1.12.3+ 的版本 curl https://releases.rancher.com/install-docker/1.12.sh | sh 安装rancher按照 Installing Rancher Server 根据实际情况，安装rancher ,建议使用 加速器 DaoCloud - 业界领先的容器云平台 或者 阿里云docker加速器 如果rancher/server是v1.6.10版本(低于v1.6.10版本未试过)，需要你修改私有registry，且将gcr.io的插件push到私有registry，且namespace必须为google_containers,建议v1.6.11+ sudo docker run -d --restart=unless-stopped --name=rancher-server -p 8080:8080 rancher/server:v1.6.11 &amp;&amp; sudo docker logs -f rancher-server 注册 docker hub安装k8s如果之前安装过docker和k8s，需要运行docker rm -f -v $(docker ps -aq) docker volume rm $(docker volume ls)sudo rm -rf /var/etcd/ 创建环境模板 修改k8s模板鉴于gfw屏蔽gcr.io的情况，花了点时间，将所有的gcr.io镜像(423个镜像，7547个版本)都同步到我的docker hub账号下 https://hub.docker.com/r/anjia0532/ 并且每天定时更新，详情参见另外一篇文章 Google Container Registry(gcr.io) 中国可用镜像(长期维护) Private Registry for Add-Ons and Pod Infra Container Image index.docker.io Image namespace for Add-Ons and Pod Infra Container Image anjia0532 Image namespace for kubernetes-helm Image anjia0532 Pod Infra Container Image anjia0532 创建k8s环境 选择k8s环境并添加主机 查看k8s基础服务状态当基础服务都是绿色后，即可使用 查看k8s 仪表板 dashboard 异常排查如果打开dashboard 报 503 ServiceUnavailable , 非常感谢群内@天阑-李小威 耐心解答，同时 参考 Kubernetes 部署失败的 10 个最普遍原因（Part 1） 解决了好几个问题 打开Cli &gt; kubectl --namespace=kube-system get podsNAME READY STATUS RESTARTS AGEheapster-79684d56d6-8pjrd 1/1 Running 0 13mkube-dns-7f59fd996-nkvv5 3/3 Running 0 13mkubernetes-dashboard-86d9cc5b4-7lxj5 0/1 ImagePullBackOff 0 13mmonitoring-grafana-6dc7576774-8x79x 1/1 Running 0 13mmonitoring-influxdb-d78f84c6c-29wcp 1/1 Running 0 13mtiller-deploy-c4598db7d-8wxpp 1/1 Running 0 13m# 复&gt; kubectl --namespace=kube-system describe pod kubernetes-dashboard-86d9cc5b4-7lxj5# 我这是正常Running的日志,ImagePullBackOff的没截下来 Events: Type Reason Age From Message ---- ------ ---- ---- ------- Normal Scheduled 16m default-scheduler Successfully assigned kubernetes-dashboard-86d9cc5b4-7lxj5 to k8s Normal SuccessfulMountVolume 16m kubelet, k8s MountVolume.SetUp succeeded for volume \"io-rancher-system-token-lb68r\" Normal Pulled 16m kubelet, k8s Container image \"index.docker.io/anjia0532/kubernetes-dashboard-amd64:v1.7.1\" already present on machine Normal Created 16m kubelet, k8s Created container Normal Started 16m kubelet, k8s Started container# 也可以根据 events 来辅助排查问题&gt; kubectl --namespace=kube-system get events 博客 https://anjia.ml/2017/11/13/rancher-k8s-china/掘金 https://juejin.im/post/5a097599f265da430d578385简书 http://www.jianshu.com/p/2f906a7f4bfa","tags":[{"name":"k8s","slug":"k8s","permalink":"https://anjia0532.github.io/tags/k8s/"},{"name":"kubernetes","slug":"kubernetes","permalink":"https://anjia0532.github.io/tags/kubernetes/"},{"name":"rancher","slug":"rancher","permalink":"https://anjia0532.github.io/tags/rancher/"},{"name":"gcr.io","slug":"gcr-io","permalink":"https://anjia0532.github.io/tags/gcr-io/"}]},{"title":"rancher安装Kubernetes","date":"2017-11-10T10:57:14.000Z","path":"2017/11/10/rancher-k8s/","text":"目前docker官方默认的编排容器改成k8s，已经让k8s成为事实标准，但是受限于天朝的gfw，导致下载gcr.io registry的镜像基本没戏。 而rancher中国的两篇博文 Rancher-k8s加速安装文档 和 原生加速中国区Kubernetes安装 我是死活没成功。 本文主要介绍，如何在国内，使用rancher加速k8s的安装，部分内容也适用于直接原生k8s加速 以下部分看看即可，最新方案，参考《rancher中国区加速安装Kubernetes》 环境准备 主机名 主机ip OS docker version ranhcer version anjia-ubuntu 192.168.31.83 ubuntu 17.04 4.9.0-12-generic x86_64 17.06.2-ce v1.6.10 安装 docker按照 Getting Started with Hosts#SUPPORTED DOCKER VERSIONS 安装受支持的docker-ce version (如果国内安装较慢，可以考虑使用中科大docker镜像 ,或者其他阿里云镜像，腾讯云镜像，清华镜像等) 安装rancher按照 Installing Rancher Server 根据实际情况，安装rancher ,建议使用 加速器 DaoCloud - 业界领先的容器云平台 或者 阿里云docker加速器 注册 docker hub安装k8s 复制出这串命令，在从机上运行，注册一个主机到k8s环境。稍等大约10分钟左右，基础设施全是绿色。此时kubernetes-dashboard是打不开的，提示 Service unavailable 按照 群内 @天阑-李小威 给的命令，在cli执行 kubectl --namespace=kube-system get pods 发现容器一直卡住. 打开CLI 运行k8s=( heapster kube-dns kubernetes-dashboard monitoring-grafana monitoring-influxdb tiller-deploy)for imageName in $&#123;k8s[@]&#125; ; do for t in $(kubectl --namespace=kube-system describe deployment $imageName | grep gcr | awk '&#123;print $2&#125;') ; do echo $t donedone 输出类似gcr.io/google_containers/heapster-amd64:v1.3.0-beta.1gcr.io/google_containers/k8s-dns-kube-dns-amd64:1.14.5gcr.io/google_containers/k8s-dns-dnsmasq-nanny-amd64:1.14.5gcr.io/google_containers/k8s-dns-sidecar-amd64:1.14.5gcr.io/google_containers/kubernetes-dashboard-amd64:v1.6.1gcr.io/google_containers/heapster-grafana-amd64:v4.0.2gcr.io/google_containers/heapster-influxdb-amd64:v1.3.3gcr.io/kubernetes-helm/tiller:v2.3.0 找一台能翻墙的vps,docker login 登陆docker hub的账号,如果没有翻墙vps，稍微麻烦点，在github上创建repo，然后创建Dockerfile，里面很简单 FROM gcr.io/google_containers/..... 就行，用docker-hub 添加自动构建库，并在github上给dockerhub分配读权限 #!/usr/bin/env bashhubName=anjia0532images=( gcr.io/google_containers/heapster-amd64:v1.3.0-beta.1 gcr.io/google_containers/k8s-dns-kube-dns-amd64:1.14.5 gcr.io/google_containers/k8s-dns-dnsmasq-nanny-amd64:1.14.5 gcr.io/google_containers/k8s-dns-sidecar-amd64:1.14.5 gcr.io/google_containers/kubernetes-dashboard-amd64:v1.6.1 gcr.io/google_containers/heapster-grafana-amd64:v4.0.2 gcr.io/google_containers/heapster-influxdb-amd64:v1.3.3 gcr.io/kubernetes-helm/tiller:v2.3.0)for imageName in $&#123;images[@]&#125; ; do imgName=$(echo $&#123;imageName&#125; | cut -d\"/\" -f3) docker pull $imageName docker tag $imageName $hubName/$imgName docker push $hubName/$imgNamedone 将k8s-cli中输出的版本，替换到images中，并修改hubName为自己实际的docker hub 账号,运行。 输出类似$ docker imagesanjia0532/k8s-dns-sidecar-amd64 1.14.5 fed89e8b4248 6 weeks ago 41.8MBanjia0532/k8s-dns-kube-dns-amd64 1.14.5 512cd7425a73 6 weeks ago 49.4MBanjia0532/k8s-dns-dnsmasq-nanny-amd64 1.14.5 459944ce8cc4 6 weeks ago 41.4MBanjia0532/heapster-influxdb-amd64 v1.3.3 577260d221db 2 months ago 12.5MBanjia0532/kubernetes-dashboard-amd64 v1.6.1 71dfe833ce74 5 months ago 134MBanjia0532/tiller v2.3.0 24d2d8f25332 7 months ago 56MBanjia0532/heapster-grafana-amd64 v4.0.2 a1956d2a1a16 9 months ago 131MBanjia0532/heapster-amd64 v1.3.0-beta.1 4ff6ad0ca64c 9 months ago 101MB 修改kube-system的镜像地址,打开cli运行,注意将anjia0532替换成docker hub账号 kubectl --namespace=kube-system edit deployment heapsterkubectl --namespace=kube-system edit deployment kube-dnskubectl --namespace=kube-system edit deployment kubernetes-dashboardkubectl --namespace=kube-system edit deployment monitoring-grafanakubectl --namespace=kube-system edit deployment monitoring-influxdb#替换:%s#gcr.io/google_containers#anjia0532#g#保存:wq!kubectl --namespace=kube-system edit deployment tiller-deploy#替换:%s#gcr.io/kubernetes-helm#anjia0532#g#保存:wq! 运行$ kubectl --namespace=kube-system get podsNAME READY STATUS RESTARTS AGEheapster-2407085140-hgddj 0/1 ContainerCreating 0 48mkube-dns-570853077-hcqzg 0/3 Pending 0 1hkube-dns-638003847-8vps9 0/3 ContainerCreating 0 2hkubernetes-dashboard-3888044391-wm3s3 0/1 ContainerCreating 0 14mmonitoring-grafana-3847008717-06988 0/1 ContainerCreating 0 14mmonitoring-influxdb-3527312529-n3xxw 0/1 ContainerCreating 0 14mtiller-deploy-402017509-jkw7n 0/1 ContainerCreating 0 13m 查看状态，我这边一直Pending 手动囧一个,找到原因,后续补充.","tags":[{"name":"k8s","slug":"k8s","permalink":"https://anjia0532.github.io/tags/k8s/"},{"name":"kubernetes","slug":"kubernetes","permalink":"https://anjia0532.github.io/tags/kubernetes/"},{"name":"rancher","slug":"rancher","permalink":"https://anjia0532.github.io/tags/rancher/"}]},{"title":"gitlab迁移到docker并升级大版本到10.1.1和汉化","date":"2017-11-07T10:38:37.000Z","path":"2017/11/07/gitlab-upgrade/","text":"本文主要讲 gitlab切换为docker版本，并且升级大版本(9.x-10.x)的较为快捷的方式 gitlab备份查看现有版本sudo gitlab-rake gitlab:env:info...GitLab informationVersion: 9.2.5... 备份在原服务器运行sudo gitlab-rake gitlab:backup:create RAILS_ENV=productionsudo sh -c &apos;umask 0077; tar -cf /var/opt/gitlab/backups/$(date &quot;+etc-gitlab-%s_%Y_%m_%d.tar&quot;) -C / etc/gitlab&apos; 通过sudo ls -lah /var/opt/gitlab/backups | grep $(date &quot;+%Y_%m_%d&quot; ) 查看 -rw------- 1 git git 172M 11月 7 11:07 1510024070_2017_11_07_x.x.x_gitlab_backup.tar-rw------- 1 root root 150K 11月 7 11:28 etc-gitlab-1510025309_2017_11_07.tar 移动到目标服务器使用scp将备份文件复制到目标主机 username是用户名ip是来源主机ip 登陆目标主机， sudo mkdir -p /data/gitlab/data/backupsscp username@ip:/var/opt/gitlab/backups/1510024070_2017_11_07_x.x.x_gitlab_backup.tar /data/gitlab/data/backups/1510024070_gitlab_backup.tarscp username@ip:/var/opt/gitlab/backups/etc-gitlab-1510025309_2017_11_07.tar /data/gitlab/data/backups/# 需要注意ssh的权限问题，如果无权限，要么改配置，要么就用winscp,ftp等进行上传 gitlab恢复docker-composeversion: '2'services: gitlab: image: 'gitlab/gitlab-ce:x.x.x-ce.0' # 将x.x.x-ce.0改成之前gitlab版本,否则无法恢复备份 restart: unless-stopped ports: - '80:80' - '443:443' - '22:22' volumes: - config:/etc/gitlab - data:/var/opt/gitlab - logs:/var/log/gitlabvolumes: config:/data/gitlab/config data:/data/gitlab/data logs:/data/gitlab/log docker-compose up -d 恢复数据docker exec -it gitlab_gitlab_1 /bin/bashgitlab-rake gitlab:backup:restore RAILS_ENV=production BACKUP=1510024070 # 1510024070_gitlab_backup.tar 的前段tar -xf /var/opt/gitlab/backups/etc-gitlab-1510025309_2017_11_07.tar -C / 访问以下http://ip/如果正常，则执行`docker-compose down` gitlab升级和汉化version: '2'services: gitlab: image: 'anjia0532/gitlab-ce-zh:10.1.1-ce.0' # 汉化的10.1.1版本 restart: unless-stopped ports: - '80:80' - '443:443' - '22:22' volumes: - config:/etc/gitlab - data:/var/opt/gitlab - logs:/var/log/gitlabvolumes: config:/data/gitlab/config data:/data/gitlab/data logs:/data/gitlab/log 参考连接: gitlab服务器迁移–深山鬼怪 Gitlab CE 8.9 升级/迁移到GitLab CE 9.3.4 – baowei Backups – gitlab-ce-doc 博客 https://anjia.ml/2017/11/07/gitlab-upgrade/掘金 https://juejin.im/post/5a0170a9f265da430702aea5简书 http://www.jianshu.com/p/3ac4bd8372e0","tags":[{"name":"docker","slug":"docker","permalink":"https://anjia0532.github.io/tags/docker/"},{"name":"gitlab","slug":"gitlab","permalink":"https://anjia0532.github.io/tags/gitlab/"},{"name":"docker-compose","slug":"docker-compose","permalink":"https://anjia0532.github.io/tags/docker-compose/"}]},{"title":"openresty使用火焰图排查性能问题","date":"2017-09-12T16:31:40.000Z","path":"2017/09/12/stap/","text":"本文主要是讲解如何在ubuntu安装最新Systemtap.以及绘制火焰图 安装调试镜像# 导入 GPG keysudo apt-key adv --keyserver keyserver.ubuntu.com --recv-keys 428D7C01 C8CAB6595FDFF622echo \"deb http://ddebs.ubuntu.com $(lsb_release -cs) main restricted universe multiversedeb http://ddebs.ubuntu.com $(lsb_release -cs)-updates main restricted universe multiversedeb http://ddebs.ubuntu.com $(lsb_release -cs)-proposed main restricted universe multiverse\" | \\sudo tee -a /etc/apt/sources.list.d/ddebs.list# 更新sudo apt-get update# 安装调试镜像sudo apt-get install -y linux-image-$(uname -r)-dbgsym 安装最新版 systemtap$ sudo apt-get install -y build-essential zlib1g-dev elfutils libdw-dev gettext# https://sourceware.org/elfutils/ftp/?C=M;O=D$ wget https://sourceware.org/elfutils/ftp/0.170/elfutils-0.170.tar.bz2$ tar xf elfutils-0.170.tar.bz2# https://sourceware.org/systemtap/ftp/releases/?C=M;O=D$ wget https://sourceware.org/systemtap/ftp/releases/systemtap-3.1.tar.gz$ tar zxf systemtap-3.1.tar.gz$ cd systemtap-3.1$ ./configure --prefix=/opt/stap --disable-docs \\ --disable-publican --disable-refdocs CFLAGS=&quot;-g -O2&quot; \\ --with-elfutils=../elfutils-0.170$ make -j$(getconf _NPROCESSORS_ONLN) &amp;&amp; sudo make install# export STAP_HOME=/opt/stap/# export PATH=$STAP_HOME:$PATH# stap -VSystemtap translator/driver (version 3.1/0.170, non-git sources)Copyright (C) 2005-2017 Red Hat, Inc. and othersThis is free software; see the source for copying conditions.tested kernel versions: 2.6.18 ... 4.10-rc8enabled features: PYTHON2 PYTHON3 LIBXML2 NLS READLINE 测试是否生效# stap -v -e &apos;probe vfs.read &#123;printf(&quot;read performed\\n&quot;); exit()&#125;&apos;Pass 1: parsed user script and 465 library scripts using 77388virt/46648res/5256shr/41840data kb, in 80usr/30sys/333real ms.Pass 2: analyzed script: 1 probe, 1 function, 7 embeds, 0 globals using 260440virt/231204res/6736shr/224892data kb, in 1680usr/350sys/7050real ms.Pass 3: translated to C into &quot;/tmp/stap8Lyxq5/stap_e1c4934460a3e749f6deefe95dd50015_2729_src.c&quot; using 260440virt/231404res/6936shr/224892data kb, in 10usr/0sys/5real ms.Pass 4: compiled C into &quot;stap_e1c4934460a3e749f6deefe95dd50015_2729.ko&quot; in 5260usr/420sys/7185real ms.Pass 5: starting run.read performedPass 5: run completed in 0usr/20sys/486real ms. 绘制火焰图下载各工具包# git clone https://github.com/openresty/stapxx.git --depth=1 /opt/stapxx# export STAP_PLUS_HOME=/opt/stapxx# export PATH=$STAP_PLUS_HOME:$STAP_PLUS_HOME/samples:$PATH# stap++ -e &apos;probe begin &#123; println(&quot;hello&quot;) exit() &#125;&apos;hello# git clone https://github.com/openresty/openresty-systemtap-toolkit.git --depth=1 /opt/openresty-systemtap-toolkit# git clone https://github.com/brendangregg/FlameGraph.git --depth=1 /opt/FlameGraph 绘制火焰图# /opt/stapxx/samples/lj-lua-stacks.sxx --arg time=120 --skip-badvars -x `ps --no-headers -fC nginx|awk &apos;/worker/ &#123;print$2&#125;&apos;| shuf | head -n 1` &gt; /tmp/tmp.bt （-x 是要抓的进程的 pid， 探测结果输出到 tmp.bt）# /opt/openresty-systemtap-toolkit/fix-lua-bt tmp.bt &gt; /tmp/flame.bt (处理 lj-lua-stacks.sxx 的输出，使其可读性更佳)# /opt/FlameGraph/stackcollapse-stap.pl /tmp/flame.bt &gt; /tmp/flame.cbt# /opt/FlameGraph/flamegraph.pl /tmp/flame.cbt &gt; /tmp/flame.svg 为了突出效果，建议在运行stap++的时候，使用压测工具，以便采集足够的样本 # ab -n 10000 -c 100 -k http://localhost/ 用浏览器打开 /tmp/flame.svg 尽量用 chrome firefox别用国产乱七八糟浏览器. openresty/stapxx## 使用 stap++ --args xx.sxx查看具体参数# stap++ --args /opt/stapxx/samples/lj-lua-stacks.sxx --arg depth=VALUE (default: 30) --arg detailed=VALUE (default: 0) --arg limit=VALUE (default: 1000) --arg min=VALUE (default: 2) --arg nointerp=VALUE (default: ) --arg nojit=VALUE (default: ) --arg probe=VALUE (default: timer.profile) --arg time=VALUE (default: ) 具体脚本用法，参见 openresty/stapxx#samples openresty/openresty-systemtap-toolkit这一系列脚本很有用，比如可以用来看共享内存大小，使用情况，内存泄露情况，哪里泄露的，不过部分脚本需要在编译的时候，开启调试或者增加依赖。具体参见readme. 如果要使用ngx-leaked-pools需要用到dtrace$ apt install systemtap-sdt-dev -y$ ./configure --prefix=/etc/openresty \\ --with-dtrace-probes 如果要用到ngx-pcrejit需要在编译openresty时增加--with-pcre-opt=-g 重新编译并make &amp;&amp; make install 后会将原有的二进制文件重命名为${openresty_home}/nginx/sbin/nginx.old，并创建一个${openresty_home}/nginx/sbin/nginx(新版) $ kill -USR2 `cat /var/run/nginx.pid` 通过ps -fC nginx或者ps -fC openresty查看新版本是否成功启动 如果成功启动，此时新旧版本同时接受请求 通过$ kill -QUIT `cat /var/run/nginx.pid.oldbin` 平滑杀掉旧版 更多资料请自行谷歌、百度。或者参阅 下面的参考连接 参考连接 白话火焰图-火丁笔记 Build Systemtap-openresty官方文档 火焰图-openresty最佳实践 Systemtap - ubuntu wiki [Debug Symbol Packages][Debug-Symbol-Packages] openresty/stapxx openresty/openresty-systemtap-toolkit brendangregg/FlameGraph 虢兆坤- Nginx 的启动、停止、平滑重启、信号控制和平滑升级 博客 https://anjia.ml/2017/09/12/stap/掘金 https://juejin.im/post/59ce27fef265da065b66d54b简书 http://www.jianshu.com/p/008fde8837f5 Debug-Symbol-Packages","tags":[{"name":"openresty","slug":"openresty","permalink":"https://anjia0532.github.io/tags/openresty/"},{"name":"stap","slug":"stap","permalink":"https://anjia0532.github.io/tags/stap/"},{"name":"systemtap","slug":"systemtap","permalink":"https://anjia0532.github.io/tags/systemtap/"},{"name":"flame-graph","slug":"flame-graph","permalink":"https://anjia0532.github.io/tags/flame-graph/"}]},{"title":"xshell 使用 Oh My ZSH home键 end键 小键盘区无效解决办法","date":"2017-09-10T16:38:41.000Z","path":"2017/09/10/zsh-home-end-keypad-not-work/","text":"zsh是一款超赞的shell工具，但是配置复杂，有个闲着没事的程序员，弄了一个开源项目 robbyrussell/oh-my-zsh 截止目前，58.8k+ star就知道有多火了。比如 Spring boot在github才 15.7K+ spring framework 也16.1k+,最近火到炸天的tensorflow 69.4k 同样很优秀的有 fisherman/fisherman 此文不讲如何安装，如何配置 。有此需求的同学，出门左转，找度娘解决。 此文主要解决，xshell 远程连接时，host将zsh设置成默认shell时，Home,End,小键盘区诸键无效问题 参考连接 Cannot using home/end key after install oh-my-zsh 第一种方法也是最简单的办法是，修改xshell连接此host的终端类型，改成linux 但是注意 @linlinlinlin 所说，改用linux可能会导致shell的颜色比较奇怪。 linux xterm 结合 @candrew34 和 @linlinlinlin 的回复，得出第二种方案 第二种方法，稍微复杂点 cat &lt;&lt;ENDOF &gt;&gt; ~/.zshrc# Homebindkey '\\e[1~' beginning-of-line# Endbindkey '\\e[4~' end-of-line# Keypad# 0 . Enterbindkey -s \"^[Op\" \"0\"bindkey -s \"^[Ol\" \".\"bindkey -s \"^[OM\" \"^M\"# 1 2 3bindkey -s \"^[Oq\" \"1\"bindkey -s \"^[Or\" \"2\"bindkey -s \"^[Os\" \"3\"# 4 5 6bindkey -s \"^[Ot\" \"4\"bindkey -s \"^[Ou\" \"5\"bindkey -s \"^[Ov\" \"6\"# 7 8 9bindkey -s \"^[Ow\" \"7\"bindkey -s \"^[Ox\" \"8\"bindkey -s \"^[Oy\" \"9\"# + - * /bindkey -s \"^[Ok\" \"+\"bindkey -s \"^[Om\" \"-\"bindkey -s \"^[Oj\" \"*\"bindkey -s \"^[Oo\" \"/\"ENDOFsource ~/.zshrc 另附 客户端putty, xshell连接linux中vim的小键盘问题","tags":[{"name":"xshell","slug":"xshell","permalink":"https://anjia0532.github.io/tags/xshell/"},{"name":"zsh","slug":"zsh","permalink":"https://anjia0532.github.io/tags/zsh/"},{"name":"oh-my-zsh","slug":"oh-my-zsh","permalink":"https://anjia0532.github.io/tags/oh-my-zsh/"}]},{"title":"彻底解决docker build时安装软件失败问题","date":"2017-09-01T11:35:31.000Z","path":"2017/09/01/docker-dns/","text":"最近遇到一个问题，构建Dockerfile镜像时，如果安装软件，有一定概率失败(2%-10%)。以alpine为例 失败日志如下 Step 4/6 : RUN echo -e \"https://mirrors.ustc.edu.cn/alpine/latest-stable/main\\nhttps://mirrors.ustc.edu.cn/alpine/latest-stable/community\" &gt; /etc/apk/repositories &amp;&amp; apk update &amp;&amp; apk add tzdata &amp;&amp; cp /usr/share/zoneinfo/Asia/Shanghai /etc/localtime &amp;&amp; echo \"Asia/Shanghai\" &gt; /etc/timezone &amp;&amp; rm -rf /var/cache/apk/* ---&gt; Running in bd5d1dfd3ff4fetch https://mirrors.ustc.edu.cn/alpine/latest-stable/main/x86_64/APKINDEX.tar.gzfetch https://mirrors.ustc.edu.cn/alpine/latest-stable/community/x86_64/APKINDEX.tar.gzv3.6.2-83-g1079181bed [https://mirrors.ustc.edu.cn/alpine/latest-stable/main]v3.6.2-84-g6ee501e465 [https://mirrors.ustc.edu.cn/alpine/latest-stable/community]OK: 8440 distinct packages available(1/1) Installing tzdata (2017a-r0)ERROR: tzdata-2017a-r0: temporary error (try again later) 为了重现该问题，简单的构建一个Docker 镜像，基于alpine，安装tzdata，并设置北京时区 为了加速构建，替换为中科大的镜像地址 Dockerfile FROM alpineRUN echo -e \"https://mirrors.ustc.edu.cn/alpine/latest-stable/main\\nhttps://mirrors.ustc.edu.cn/alpine/latest-stable/community\" &gt; /etc/apk/repositories &amp;&amp; \\ apk update &amp;&amp;\\ apk --no-cache add tzdata &amp;&amp; \\ cp /usr/share/zoneinfo/Asia/Shanghai /etc/localtime &amp;&amp; \\ echo \"Asia/Shanghai\" &gt; /etc/timezone 其实一开始没有用国内源，用的官方，但是经常失败，以为是墙的问题，辗转换过阿里云镜像，清华镜像，中科大镜像，甚至后来自建镜像 github repo anjia0532/alpine-package-mirror , 三种方法解决docker构建失败(alpine),但是都是时好时坏，严重影响效率。 后来在观察nginx访问日志的时候，报错的时候nginx没有产生访问日志，遂怀疑是构建镜像时没有发出网络请求，祭出神器 tcpdump 进行进一步排查 note 为了减少干扰，实验机器中，没有其他docker服务在跑(否则tcp请求太多) sudo tcpdump -i docker0....10:47:43.038404 IP6 :: &gt; ff02::16: HBH ICMP6, multicast listener report v2, 1 group record(s), length 2810:47:43.114734 ARP, Request who-has 172.17.0.1 tell 172.17.0.2, length 2810:47:43.114746 ARP, Reply 172.17.0.1 is-at 02:42:30:19:53:45 (oui Unknown), length 2810:47:43.114750 IP 172.17.0.2.48223 &gt; google-public-dns-a.google.com.domain: 18503+ A? alpine.xxx.com. (39)10:47:43.114775 IP 172.17.0.2.48223 &gt; google-public-dns-b.google.com.domain: 18503+ A? alpine.xxx.com. (39)10:47:43.114827 IP 172.17.0.2.48223 &gt; google-public-dns-a.google.com.domain: 18687+ AAAA? alpine.xxx.com. (39)10:47:43.114833 IP 172.17.0.2.48223 &gt; google-public-dns-b.google.com.domain: 18687+ AAAA? alpine.xxx.com. (39)10:47:43.209679 IP google-public-dns-a.google.com.domain &gt; 172.17.0.2.48223: 18503 1/0/0 A 172.60.20.6 (55)10:47:43.229261 IP google-public-dns-a.google.com.domain &gt; 172.17.0.2.48223: 18687 0/1/0 (106).... 发现在构建的时候，是走的google的dns进行解析的，因为众多不可描述的问题，google在国内基本是瘫痪状态（google翻译例外） Filtering is necessary because all localhost addresses on the host are unreachable from the container’s network. After this filtering, if there are no more nameserver entries left in the container’s /etc/resolv.conf file, the daemon adds public Google DNS nameservers (8.8.8.8 and 8.8.4.4) to the container’s DNS configuration. If IPv6 is enabled on the daemon, the public IPv6 Google DNS nameservers will also be added (2001:4860:4860::8888 and 2001:4860:4860::8844). 原文见官方文档 Embedded DNS server in user-defined networks 两种方案， 修改宿主机的hosts文件，写死ip 修改Docker的daemon.json文件 推荐用第二种，参考一下官方文档 DAEMON CONFIGURATION FILE#On Linux 更合理的方案是修改docker的daemon.json sudo vi /etc/docker/daemon.json 比如改成dnspod dns 增加 &quot;dns&quot;: [&quot;119.29.29.29&quot;] 然后sudo systemctl daemon-reload 11:14:17.586559 ARP, Request who-has 172.17.0.1 tell 172.17.0.2, length 2811:14:17.586577 ARP, Reply 172.17.0.1 is-at 02:42:30:19:53:45 (oui Unknown), length 2811:14:17.586581 IP 172.17.0.2.43273 &gt; pdns.dnspod.cn.domain: 53616+ A? alpine.xxx.com. (39)11:14:17.586604 IP 172.17.0.2.43273 &gt; pdns.dnspod.cn.domain: 53868+ AAAA? alpine.xxx.com. (39)11:14:17.777921 IP pdns.dnspod.cn.domain &gt; 172.17.0.2.43273: 53868 0/1/0 (106)11:14:17.843875 IP pdns.dnspod.cn.domain &gt; 172.17.0.2.43273: 53616 1/0/0 A 172.60.20.6 (55)11:14:17.844028 IP 172.17.0.2.36810 &gt; 172.60.20.6.http: Flags [S], seq 4032628285, win 42340, options [mss 1460,sackOK,TS val 1959807306 ecr 0,nop,wscale 11], length 0 整个过程可参见我在中科大 github的issues alpine 镜像频繁异常 博客 https://anjia.ml/2017/09/01/docker-dns/掘金 https://juejin.im/post/59a8f9e0f265da24797b7da0简书 http://www.jianshu.com/p/1f4e62dff251","tags":[{"name":"docker","slug":"docker","permalink":"https://anjia0532.github.io/tags/docker/"}]},{"title":"alpine-mirror-server","date":"2017-08-23T08:49:53.000Z","path":"2017/08/23/alpine-mirror-server/","text":"alpine linux是一个最小化linux系统，常用作docker基础镜像。可以有效减小镜像体积 但是天朝网络很。。。。所以经常容易安装软件失败(apk update &amp;&amp; apk --no-cache add ...) 利用国内镜像源清华镜像 中科大镜像 阿里云镜像 三个都用过，但是都会出现安装软件失败的情况(需要多次重新构建)，严重影响效率。 境外服务器做反代如果有幸有台境外(东京，香港等)服务器，又不想镜像站(全部镜像下载)，可以考虑使用nginx反代国外镜像(找一个近源高质量镜像，别三天两头老崩溃的那种) 自建镜像站截止 20170510 官方给出的全部镜像的磁盘使用量 edge v2.4 v2.5 v2.6 v2.7 v3.0 v3.1 v3.2 v3.3 v3.4 v3.5 v3.6 Total 53.1G 18.8G 10.4G 13.0G 16.5G 16.5G 17.5G 14.5G 19.0G 23.2G 32.5G 34.4G 269.5G 一般自用的话，只会用有限几个版本，比如v3.6 的x86_64 ?那么其余的完全可以忽略，这么一来会小很多，大约11G左右。 核心命令是 rsync.sh src=rsync://rsync.alpinelinux.org/alpine/ dest=/usr/share/nginx/html/usr/bin/rsync -prua \\ --exclude-from /etc/rsync/exclude.txt \\ --delete \\ --timeout=600 \\ --delay-updates \\ --delete-after \\ \"$src\" \"$dest\" /etc/rsync/exclude.txtedge/v2.*/v3.0/v3.1/v3.2/v3.3/v3.4/v3.5/aarch64/armhf/ppc64le/s390x/x86/ 解释一下,edge+v. 是版本号，其余的是不同cpu架构的不同版本。x86是intel 的32位 lscpu | grep Architecture 根据实际情况，自行加减 详细情况，详见项目 anjia0532/alpine-package-mirror 博客 https://anjia.ml/2017/08/23/alpine-mirror-server/掘金 https://juejin.im/post/599b1b2a51882511264e7097简书 http://www.jianshu.com/p/36396a20ea4c","tags":[{"name":"docker","slug":"docker","permalink":"https://anjia0532.github.io/tags/docker/"},{"name":"alpine","slug":"alpine","permalink":"https://anjia0532.github.io/tags/alpine/"},{"name":"alpine-mirror","slug":"alpine-mirror","permalink":"https://anjia0532.github.io/tags/alpine-mirror/"}]},{"title":"openresty(nginx) redis 通用工具类","date":"2017-08-16T14:47:41.000Z","path":"2017/08/16/openresty-redis-common-utils/","text":"openresty/lua-resty-redis 是章亦春开发的openresty中的操作redis的库。 截取官方部分代码，进行说明 local redis = require \"resty.redis\"local red = redis:new()red:set_timeout(1000) -- 1 sec --设置超时时间local ok, err = red:connect(\"127.0.0.1\", 6379) --设置redis的host和portif not ok then --判断生成连接是否失败 ngx.say(\"failed to connect: \", err) returnendok, err = red:set(\"dog\", \"an animal\") --插入键值(类似 mysql insert)if not ok then --判断操作是否成功 ngx.say(\"failed to set dog: \", err) returnendngx.say(\"set result: \", ok) -- 页面输出结果-- put it into the connection pool of size 100,-- with 10 seconds max idle timelocal ok, err = red:set_keepalive(10000, 100) --将连接放入连接池,100个连接，最长10秒的闲置时间if not ok then --判断放池结果 ngx.say(\"failed to set keepalive: \", err) returnend-- 如果不放池，用完就关闭的话，用下面的写法-- or just close the connection right away:-- local ok, err = red:close()-- if not ok then-- ngx.say(\"failed to close: \", err)-- return-- end 如果用过java，c#等面向对象的语言，就会觉得这么写太。。。。了，必须重构啊，暴露太多无关细节了，导致代码中有大量重复代码了。 同样的内容，使用我封装后的代码。 -- 依赖库local redis = require \"resty.redis-util\"-- 初始化local red = redis:new();-- 插入键值local ok,err = red:set(\"dog\",\"an animal\")-- 判断结果if not ok then ngx.say(\"failed to set dog:\",err) returnend-- 页面打印结果ngx.say(\"set result: \", ok) -- 页面输出结果 详细使用方法，参见我的项目 anjia0532/lua-resty-redis-util 博客 https://anjia.ml/2017/08/16/openresty-redis-common-utils/掘金 https://juejin.im/post/5993fea8518825242d5f72fb简书 http://www.jianshu.com/p/54cca5f33d48","tags":[{"name":"openresty","slug":"openresty","permalink":"https://anjia0532.github.io/tags/openresty/"},{"name":"nginx","slug":"nginx","permalink":"https://anjia0532.github.io/tags/nginx/"},{"name":"redis","slug":"redis","permalink":"https://anjia0532.github.io/tags/redis/"},{"name":"lua","slug":"lua","permalink":"https://anjia0532.github.io/tags/lua/"},{"name":"lua-resty-redis","slug":"lua-resty-redis","permalink":"https://anjia0532.github.io/tags/lua-resty-redis/"}]},{"title":"OpenResty编译安装以及安全加固(WAF)","date":"2017-07-19T16:04:57.000Z","path":"2017/07/19/openresty/","text":"Nginx 还是TengineTengine是阿里巴巴的深度定制的nginx，目前最新版本Tengine-2.2.0.tar.gz , 继承了nginx 1.8.1的所有特性，并且兼容nginx的配置，但是最后一次更新是2016-12-02截止到目前，已经半年多没更新了。https://github.com/alibaba/tengine 上已经有137条未关闭的issus和39条pull request 下面是官网自述 Tengine是由淘宝网发起的Web服务器项目。它在Nginx的基础上，针对大访问量网站的需求，添加了很多高级功能和特性。Tengine的性能和稳定性已经在大型的网站如淘宝网，天猫商城等得到了很好的检验。它的最终目标是打造一个高效、稳定、安全、易用的Web平台。 但是鉴于阿里有很多看似不错的项目最后都人走政息的传统(KPI驱动的项目),比如 微服务框架dubbo 长期不维护，后来被坑的几家(当当，韩都衣舍)为了自身需要，又在他基础上搞了dubbox, 淘宝家的玉伯的seajs 补充 alibaba/tengine/issues/921#Tengine future 一个老外在tengine上发的讨论帖，以及国人的回复，挺热闹。看样子最近有重新启动的迹象，但是，很难说。 而且Tengine还不支持Windows,网上文档比nginx少很多，所以如无特殊必要，还是建议用nginx。 nginx 最新主线版本1.13.3，稳定版本1.12.1，基本保持1月一更甚至3更的频率，响应很快，堪称版本帝，可以参考 [changes][] 和security来考虑是否有必要升级 如果不差钱，可以考虑一下 nginx plus ,价格很感人，Pricing - Application Delivery for the Modern Web | NGINX 如果不差钱，其实可以考虑用 openresty edge (openresty的商业版) ,按照实例数收费，一般1-2个微小企业，一次交买3年，平均每月1000左右人民币。 nginx本文主要讲解openresty编译安装以及加固，对于nginx只做简单描述。 nginx本身提供编译好的二进制文件，linux的参见 prebuilt ，windows的从 download 下载nginx/Windows-VERSION相关zip包，建议生产环境使用 stable(稳定版本) 如果是想从源码编译的话，从download 下载nginx-VERSION 的tar.gz包，一般格式为http://nginx.org/download/nginx-VERSION.tar.gz 注意将VERSION替换成实际版本号，e.g. 1.12.1 nginx编译参数ubuntu nginx 默认编译参数如下(为了便于阅读，将一行的编译参数展开成多行),nginx -V是查看构建参数，nginx -v是查看版本号/usr/sbin/nginx -Vnginx version: nginx/1.13.0built by gcc 5.4.0 20160609 (Ubuntu 5.4.0-6ubuntu1~16.04.2) built with OpenSSL 1.0.2g-fips 1 Mar 2016 (running with OpenSSL 1.0.2g 1 Mar 2016)TLS SNI support enabledconfigure arguments: --prefix=/etc/nginx \\--sbin-path=/usr/sbin/nginx \\--modules-path=/usr/lib/nginx/modules \\--conf-path=/etc/nginx/nginx.conf \\--error-log-path=/var/log/nginx/error.log \\--http-log-path=/var/log/nginx/access.log \\--pid-path=/var/run/nginx.pid \\--lock-path=/var/run/nginx.lock \\--http-client-body-temp-path=/var/cache/nginx/client_temp \\--http-proxy-temp-path=/var/cache/nginx/proxy_temp \\--http-fastcgi-temp-path=/var/cache/nginx/fastcgi_temp \\--http-uwsgi-temp-path=/var/cache/nginx/uwsgi_temp \\--http-scgi-temp-path=/var/cache/nginx/scgi_temp \\--user=nginx \\--group=nginx \\--with-compat \\--with-file-aio \\--with-threads \\--with-http_addition_module \\--with-http_auth_request_module \\--with-http_dav_module \\--with-http_flv_module \\--with-http_gunzip_module \\--with-http_gzip_static_module \\--with-http_mp4_module \\--with-http_random_index_module \\--with-http_realip_module \\--with-http_secure_link_module \\--with-http_slice_module \\--with-http_ssl_module \\--with-http_stub_status_module \\--with-http_sub_module \\--with-http_v2_module \\--with-mail \\--with-mail_ssl_module \\--with-stream \\--with-stream_realip_module \\--with-stream_ssl_module \\--with-stream_ssl_preread_module \\--with-cc-opt='-g -O2 -fstack-protector-strong -Wformat -Werror=format-security -Wp,-D_FORTIFY_SOURCE=2 -fPIC' \\--with-ld-opt='-Wl,-Bsymbolic-functions -Wl,-z,relro -Wl,-z,now -Wl,--as-needed -pie' 具体参数含义可 参考官网 Building nginx from Sources 和 梦想远航#nginx安装及编译参数详解, 如果要构建nginx for windows参见 Building nginx on the Win32 platform with Visual C 编译nginx参考 官方文档 INSTALLING NGINX OPEN SOURCE # pcre 正则库 $ wget ftp://ftp.csx.cam.ac.uk/pub/software/programming/pcre/pcre-8.41.tar.gz$ tar -zxf pcre-*.tar.gz$ cd pcre-*$ ./configure$ make &amp;&amp; sudo make install# zlib gzip 库$ wget http://zlib.net/zlib-1.2.11.tar.gz$ tar -zxf zlib-1.2.11.tar.gz$ cd zlib-1.2.11$ ./configure$ make &amp;&amp; sudo make install# openssl https库 注意官网代码是mac编译，建议如果失败，搜索一下openssl 编译 $ wget https://www.openssl.org/source/openssl-1.0.2l.tar.gz$ tar -zxf openssl-*.tar.gz$ cd openssl-*$ ./config --prefix=/usr/local/openssl/$ make &amp;&amp; sudo make install#主线和稳定二选一# 主线版本$ wget http://nginx.org/download/nginx-1.13.3.tar.gz#稳定版本$ wget http://nginx.org/download/nginx-1.12.1.tar.gz$ tar zxf nginx-*.tar.gz$ cd nginx-*$ ./configure --prefix=/etc/nginx \\--sbin-path=/usr/sbin/nginx \\--modules-path=/usr/lib/nginx/modules \\--conf-path=/etc/nginx/nginx.conf \\--error-log-path=/var/log/nginx/error.log \\--http-log-path=/var/log/nginx/access.log \\--pid-path=/var/run/nginx.pid \\--lock-path=/var/run/nginx.lock \\--with-http_gunzip_module \\--with-http_gzip_static_module \\--with-http_addition_module \\--with-http_auth_request_module \\--with-http_realip_module \\--with-http_slice_module \\--with-http_stub_status_module \\--with-http_sub_module \\--with-compat \\--with-file-aio \\--with-threads \\--with-stream \\--with-stream_realip_module \\--with-stream_ssl_module \\--with-stream_ssl_preread_module \\--with-http_v2_module \\--with-http_ssl_module \\--with-pcre=../pcre-8.41 \\--with-zlib=../zlib-1.2.11 \\--without-http_autoindex_module \\--without-http_fastcgi_module \\--without-http_uwsgi_module \\--without-http_scgi_module \\--without-http_memcached_module \\--without-http_empty_gif_module$ make &amp;&amp; sudo make install# 从官方标准参数中去除不用的模块，并新增了pcre和zlib模块# 临时文件相关#--http-fastcgi-temp-path=/var/cache/nginx/fastcgi_temp \\#--http-uwsgi-temp-path=/var/cache/nginx/uwsgi_temp \\#--http-scgi-temp-path=/var/cache/nginx/scgi_temp \\#--http-client-body-temp-path=/var/cache/nginx/client_temp \\#--http-proxy-temp-path=/var/cache/nginx/proxy_temp \\# dav，媒体相关#--with-http_dav_module \\#--with-http_flv_module \\#--with-http_mp4_module \\#随机首页，安全连接相关#--with-http_random_index_module \\#--with-http_secure_link_module \\#email相关#--with-mail \\#--with-mail_ssl_module \\#gcc相关#--with-cc-opt='-g -O2 -fstack-protector-strong -Wformat -Werror=format-security -Wp,-D_FORTIFY_SOURCE=2 -fPIC' \\#--with-ld-opt='-Wl,-Bsymbolic-functions -Wl,-z,relro -Wl,-z,now -Wl,--as-needed -pie'#组，用户相关#--user=nginx #--group=nginx #如果指定user和group 则通过此命令创建用户#$ sudo adduser --system --no-create-home --shell /bin/false --group --disabled-login nginx#如果用不到https，可以把ssl和http2模块也禁掉#禁用未用模块，减少安全风险#--without-http_autoindex_module \\#--without-http_fastcgi_module \\#--without-http_uwsgi_module \\#--without-http_scgi_module \\#--without-http_memcached_module \\#--without-http_empty_gif_module$ nginx -t &amp;&amp; nginxnginx: the configuration file /etc/nginx/nginx.conf syntax is oknginx: configuration file /etc/nginx/nginx.conf test is successful 至此nginx编译完成。可以通过curl localhost或者浏览器打开localhost 查看nginx默认页面 nginx init.d 脚本详见 anjia0532/nginx openresty学习资料 官网 openresty ，开涛博客 使用Nginx+Lua(OpenResty)开发高性能Web应用 ，温铭的gitbook OpenResty 最佳实践 温铭的stuq视频教程OpenResty 系列课程 安装预编译包详见官方文档 OpenResty® Linux 包 openresty编译参数ubuntu openresty 默认编译参数如下(为了便于阅读，将一行的编译参数展开成多行),resty -V是查看构建参数，resty -v是查看版本号 openresty官方组件 ,nginx 模块 nginx version: openresty/1.11.2.4built with OpenSSL 1.0.2k 26 Jan 2017TLS SNI support enabledconfigure arguments: --prefix=/usr/local/openresty/nginx \\--with-cc-opt='-O2 -I/usr/local/openresty/zlib/include -I/usr/local/openresty/pcre/include -I/usr/local/openresty/openssl/include' \\--add-module=../ngx_devel_kit-0.3.0 \\--add-module=../echo-nginx-module-0.60 \\--add-module=../xss-nginx-module-0.05 \\--add-module=../ngx_coolkit-0.2rc3 \\--add-module=../set-misc-nginx-module-0.31 \\--add-module=../form-input-nginx-module-0.12 \\--add-module=../encrypted-session-nginx-module-0.06 \\--add-module=../srcache-nginx-module-0.31 \\--add-module=../ngx_lua-0.10.8 \\--add-module=../ngx_lua_upstream-0.06 \\--add-module=../headers-more-nginx-module-0.32 \\--add-module=../array-var-nginx-module-0.05 \\--add-module=../memc-nginx-module-0.18 \\--add-module=../redis2-nginx-module-0.14 \\--add-module=../redis-nginx-module-0.3.7 \\--with-ld-opt='-Wl,-rpath,/usr/local/openresty/luajit/lib -L/usr/local/openresty/zlib/lib -L/usr/local/openresty/pcre/lib -L/usr/local/openresty/openssl/lib -Wl,-rpath,/usr/local/openresty/zlib/lib:/usr/local/openresty/pcre/lib:/usr/local/openresty/openssl/lib' \\--with-pcre-jit \\--with-ipv6 \\--with-stream \\--with-stream_ssl_module \\--with-http_v2_module \\--without-mail_pop3_module \\--without-mail_imap_module \\--without-mail_smtp_module \\--with-http_stub_status_module \\--with-http_realip_module \\--with-http_addition_module \\--with-http_auth_request_module \\--with-http_secure_link_module \\--with-http_random_index_module \\--with-http_gzip_static_module \\--with-http_sub_module \\--with-http_dav_module \\--with-http_flv_module \\--with-http_mp4_module \\--with-http_gunzip_module \\--with-threads \\--with-file-aio \\--with-dtrace-probes \\--with-http_ssl_module 构建openresty参见 构建openresty $ sudo apt-get install -y libreadline-dev libncurses5-dev libpcre3-dev libssl-dev perl make build-essential dos2unix mercurial$ wget https://openresty.org/download/openresty-1.11.2.4.tar.gz$ tar zxf openresty-1.11.2.4.tar.gz# 或者直接从github clone 一份自行编译# git clone https://github.com/openresty/openresty # cd openresty # make -j4$ cd openresty-*# 查看所有编译参数$ ./configure --help #进行编译./configure --prefix=/etc/openresty \\--user=nginx \\--group=nginx \\--with-cc-opt='-O2 -I/usr/local/openresty/zlib/include -I/usr/local/openresty/pcre/include -I/usr/local/openresty/openssl/include' \\--with-ld-opt='-Wl,-rpath,/usr/local/openresty/luajit/lib -L/usr/local/openresty/zlib/lib -L/usr/local/openresty/pcre/lib -L/usr/local/openresty/openssl/lib -Wl,-rpath,/usr/local/openresty/zlib/lib:/usr/local/openresty/pcre/lib:/usr/local/openresty/openssl/lib' \\--with-pcre-jit \\--with-dtrace-probes \\--with-pcre-opt=-g \\--with-stream \\--with-stream_ssl_module \\--with-http_v2_module \\--with-http_stub_status_module \\--with-http_realip_module \\--with-http_gzip_static_module \\--with-http_sub_module \\--with-http_gunzip_module \\--with-threads \\--with-file-aio \\--with-http_ssl_module \\--with-http_auth_request_module \\--without-mail_pop3_module \\--without-mail_imap_module \\--without-mail_smtp_module \\--without-http_fastcgi_module \\--without-http_uwsgi_module \\--without-http_scgi_module \\--without-http_autoindex_module \\--without-http_memcached_module \\--without-http_empty_gif_module \\--without-http_ssi_module \\--without-http_userid_module \\--without-http_browser_module \\--without-http_rds_json_module \\--without-http_rds_csv_module \\--without-http_memc_module \\--without-http_redis2_module \\--without-lua_resty_memcached \\--without-lua_resty_mysql \\-j4#禁用memcached模块#--without-http_memc_module \\#禁用redis模块(保留redis2模块)#--without-http_redis_module \\#禁用email相关模块#--without-mail_pop3_module \\#--without-mail_imap_module \\#--without-mail_smtp_module \\#禁用rds模块#--without-http_rds_json_module \\#--without-http_rds_csv_module \\#禁用cgi #--without-http_fastcgi_module \\#--without-http_uwsgi_module \\#--without-http_scgi_module \\#--without-http_autoindex_module \\#--without-http_memcached_module \\#--without-http_empty_gif_module \\$ make -j4 &amp;&amp; sudo make install#确保80端口没被占用$ lsof -i:80$ /opt/openresty/nginx/nginx/sbin/nginx -t &amp;&amp; /opt/openresty/nginx/nginx/sbin/nginx$ curl localhost openresty init.d 脚本详见 anjia0532/openresty $ chmod +x /etc/init.d/openresty#$ systemctl mask openresty#$ systemctl unmask openresty 一般来说，只需要修改 OPENRESTY_WORKSPACE=${OPENRESTY_HOME}/nginx 为实际的应用目录即可(需要确保该有的目录都存在)nginx/├── client_body_temp├── conf├── html├── logs└── proxy_temp 可以使用 mkdir -p ${OPENRESTY_WORKSPACE}/{client_body_temp,conf,html,logs,proxy_temp} 进行批量创建 waf 部分暂时先搁置 WAF 基于ModSecurity参考资料 Ubuntu 15.04 $ git clone -b v3/master --single-branch https://github.com/SpiderLabs/ModSecurity.git --depth=1$ cd ModSecurity/$ git checkout -b v3/master origin/v3/master$ sh build.sh$ git submodule init$ git submodule update #[for bindings/python, others/libinjection, test/test-cases/secrules-language-tests]$ ./configure$ make$ sudo make install#使用 ModSecurity-nginx 而不是网上流传的独立版 详见 https://github.com/SpiderLabs/ModSecurity-nginx$ export MODSECURITY_INC=\"/home/anjia/openresty/ModSecurity/headers\"$ export MODSECURITY_LIB=\"/home/anjia/openresty/ModSecurity/src/.libs\"$ git clone https://github.com/SpiderLabs/ModSecurity-nginx --depth=1$ git clone https://github.com/SpiderLabs/owasp-modsecurity-crs.git --depth=1$ sudo cp -R owasp-modsecurity-crs/rules /opt/openresty/nginx/nginx/conf $ cp owasp-modsecurity-crs/crs-setup.conf.example /opt/openresty/nginx/nginx/conf/crs-setup.conf$ sudo wget -P /opt/openresty/nginx/nginx/conf https://raw.githubusercontent.com/SpiderLabs/ModSecurity/master/modsecurity.conf-recommended https://raw.githubusercontent.com/SpiderLabs/ModSecurity/master/unicode.mapping$ sudo mv /opt/openresty/nginx/nginx/conf/modsecurity.conf-recommended /opt/openresty/nginx/nginx/conf/modsecurity.conf$ sudo mkdir /opt/openresty/nginx/nginx/conf/sites-enabled#使用www-data用户$ sudo sed -i '1s/^/user www-data;\\n/' /opt/openresty/nginx/nginx/conf/nginx.conf$ sudo vim /opt/openresty/nginx/nginx/conf/nginx.conf#删除36-116行，即server&#123;&#125;段，可以在英文输入法状态按 :36,166d 然后 :wq#如果确认行数没问题，也可以用sudo sed '35,116d' -i /opt/openresty/nginx/nginx/conf/nginx.conf$ sudo sed '$i include /opt/openresty/nginx/nginx/conf/sites-enabled/*; ' -i /opt/openresty/nginx/nginx/conf/nginx.conf#嫌费事，也可以直接用下面的配置文件user www-data;worker_processes 1;events &#123; worker_connections 1024;&#125;http &#123; include mime.types; default_type application/octet-stream; sendfile on; keepalive_timeout 65; include /opt/openresty/nginx/nginx/conf/sites-enabled/*;&#125;$ vi /opt/openresty/nginx/nginx/conf/modsecurity.conf#Load OWASP Config Include crs-setup.conf #Load all other Rules Include rules/*.conf #Disable rule by ID from error message #SecRuleRemoveById 920350$ sudo sed s/\"SecRuleEngine DetectionOnly\"/\"SecRuleEngine On\"/g -i /opt/openresty/nginx/nginx/conf/modsecurity.conf$ sudo /opt/openresty/nginx/nginx/sbin/nginx -t &amp;&amp; sudo /opt/openresty/nginx/nginx/sbin/nginx -s reload$ curl \"http://localhost/wp-admin/admin.php?where1=%3Cscript%3Ealert(String.fromCharCode(88,+83,+83))%3C/script%3E&amp;searchsubmit=Buscar&amp;page=nsp_search\"# 返回403 Forbidden","tags":[{"name":"openresty","slug":"openresty","permalink":"https://anjia0532.github.io/tags/openresty/"},{"name":"nginx","slug":"nginx","permalink":"https://anjia0532.github.io/tags/nginx/"},{"name":"waf","slug":"waf","permalink":"https://anjia0532.github.io/tags/waf/"},{"name":"firewall","slug":"firewall","permalink":"https://anjia0532.github.io/tags/firewall/"}]},{"title":"使用jupyter(IPython)开发opencv","date":"2017-07-16T17:09:12.000Z","path":"2017/07/16/opencv-on-jupyter/","text":"opencv 的默认使用highgui显示图片，用命令行运行，可以正常显示cv.namedWindow(&quot;Image&quot;)cv.imshow(&quot;Image&quot;,img) 用jupyter则有无反应 本文环境import sysimport cv2print(\"python版本:%s\"% sys.version)print(\"opencv版本:%s\"% cv2.__version__) 输出python版本:3.5.3 |Continuum Analytics, Inc.| (default, May 15 2017, 10:43:23) [MSC v.1900 64 bit (AMD64)]opencv版本:3.2.0 安装opencv如果使用Anaconda,则打开 Anaconda Prompt,activate python35切换到相应的python环境 pip install --upgrade setuptoolspip install numpy Matplotlibpip install opencv-python 参考 Python环境搭建之OpenCV,但是在jupyter中，运行该博文下一段demo代码，无反应 经过一番google，已解决，现整理如下 jupyter显示opencv图片以lenna 图为例 import cv2from matplotlib import pyplot as pltimg = cv2.imread('lenna1.png') show_img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB) plt.imshow(show_img)plt.show() 参考自 Quickie: Mix up OpenCV and Jupyter (iPython Notebook) 和官方 Using Matplotlib opencv读取网络图片%matplotlib inlineimport numpy as npimport cv2from matplotlib import pyplot as pltimport urllib.request as uldata = Nonetry: data = ul.urlopen('http://www.mupin.it/wp-content/uploads/2012/06/lenna1.png').read() except Exception as e: print(\"Could not download the image: %s \" %( e.message)) else: data = np.fromstring(data, np.uint8) img_data = cv2.imdecode(data, cv2.IMREAD_COLOR ) img_data = cv2.cvtColor(img_data, cv2.COLOR_BGR2RGB) plt.imshow(img_data) plt.show() 本示例用的环境是python:3.5.3 和 opencv:3.2.0，在opencv3.x中已经不存在cv2.CV_LOAD_IMAGE_COLOR,根据 Python OpenCV load image from byte string ，改成cv2.IMREAD_COLOR 大部分代码 参考自 Quickie: Grab an image from the web with urllib2 and OpenCV OpenCV入门教程博客 https://anjia.ml/2017/07/16/opencv-on-jupyter/掘金 https://juejin.im/post/596b3e50f265da6c2211b609简书 http://www.jianshu.com/p/69af8b1dce6d","tags":[{"name":"jupyter","slug":"jupyter","permalink":"https://anjia0532.github.io/tags/jupyter/"},{"name":"ipython","slug":"ipython","permalink":"https://anjia0532.github.io/tags/ipython/"},{"name":"opencv","slug":"opencv","permalink":"https://anjia0532.github.io/tags/opencv/"}]},{"title":"windows 10 64bit下安装Tensorflow+Keras","date":"2017-07-03T16:40:58.000Z","path":"2017/07/03/windows-install-tensorflow-keras/","text":"windows 10 下 pip,conda 换国内源，安装Tensorflow,Keras 修改pip源 参考 Python pip 国内镜像大全及使用办法官方文档 Config file windows 全部用户需要在%APPDATA%\\pip\\pip.ini,当前用户在%HOME%\\pip\\pip.ini [global]index-url=http://mirrors.aliyun.com/pypi/simple/[install]trusted-host=mirrors.aliyun.com 安装Tensorflow参考 Installing TensorFlow on Windows # 切换到 python3.5 参考 详见另外一篇博文 https://anjia.ml/2017/07/02/anaconda-install-and-configurating-jupyter/#切换python版本#打开Anaconda Prompt(python35) C:\\Users\\xx&gt; activate python35#因为电脑无独显，所以安装`CPU-only`版本(python35) C:\\Users\\xx&gt; pip install --ignore-installed --upgrade https://storage.googleapis.com/tensorflow/windows/cpu/tensorflow-1.2.1-cp35-cp35m-win_amd64.whl (python35) C:\\Users\\xx&gt;python &gt;&gt;&gt; import tensorflow as tf&gt;&gt;&gt; hello = tf.constant('Hello, TensorFlow')&gt;&gt;&gt; sess = tf.Session()2017-07-03 16:44:16.082952: W c:\\tf_jenkins\\home\\workspace\\release-win\\m\\windows\\py\\35\\tensorflow\\core\\platform\\cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE instructions, but these are available on your machine and could speed up CPU computations.2017-07-03 16:44:16.085175: W c:\\tf_jenkins\\home\\workspace\\release-win\\m\\windows\\py\\35\\tensorflow\\core\\platform\\cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE2 instructions, but these are available on your machine and could speed up CPU computations.2017-07-03 16:44:16.085590: W c:\\tf_jenkins\\home\\workspace\\release-win\\m\\windows\\py\\35\\tensorflow\\core\\platform\\cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE3 instructions, but these are available on your machine and could speed up CPU computations.2017-07-03 16:44:16.085952: W c:\\tf_jenkins\\home\\workspace\\release-win\\m\\windows\\py\\35\\tensorflow\\core\\platform\\cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.1 instructions, but these are available on your machine and could speed up CPU computations.2017-07-03 16:44:16.086312: W c:\\tf_jenkins\\home\\workspace\\release-win\\m\\windows\\py\\35\\tensorflow\\core\\platform\\cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.2 instructions, but these are available on your machine and could speed up CPU computations.2017-07-03 16:44:16.086634: W c:\\tf_jenkins\\home\\workspace\\release-win\\m\\windows\\py\\35\\tensorflow\\core\\platform\\cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX instructions, but these are available on your machine and could speed up CPU computations.2017-07-03 16:44:16.087014: W c:\\tf_jenkins\\home\\workspace\\release-win\\m\\windows\\py\\35\\tensorflow\\core\\platform\\cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX2 instructions, but these are available on your machine and could speed up CPU computations.2017-07-03 16:44:16.087363: W c:\\tf_jenkins\\home\\workspace\\release-win\\m\\windows\\py\\35\\tensorflow\\core\\platform\\cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use FMA instructions, but these are available on your machine and could speed up CPU computations.&gt;&gt;&gt; print(sess.run(hello))b'Hello, TensorFlow' 如果要去掉4-12的警告信息，需要自己编译。详见 “The TensorFlow library wasn’t compiled to use SSE instructions, but these are available on your machine and could speed up CPU computations” in “Hello, TensorFlow!” program #7778 安装Keras参考 官方文档 Installation 中文文档 Keras安装和配置指南(Windows) (python35) C:\\Users\\xx&gt;pip install keras -U --pre 但是我安装一直报错，Running setup.py bdist_wheel for scipy ... error Complete output from command &#123;Anaconda3_home&#125;\\envs\\python35\\python.exe -u -c \"import setuptools, tokenize;__file__='&#123;AppData&#125;\\\\Local\\\\Temp\\\\pip-build-mgdjtt1d\\\\scipy\\\\setup.py';f=getattr(tokenize, 'open', open)(__file__);code=f.read().replace('\\r\\n', '\\n');f.close();exec(compile(code, __file__, 'exec'))\" bdist_wheel -d &#123;AppData&#125;\\Local\\Temp\\tmpb_od_dlvpip-wheel- --python-tag cp35: lapack_opt_info: lapack_mkl_info: libraries mkl_rt not found in ['&#123;Anaconda3_home&#125;\\\\envs\\\\python35\\\\lib', 'C:\\\\', '&#123;Anaconda3_home&#125;\\\\envs\\\\python35\\\\libs'] NOT AVAILABLE## ...Command \"&#123;Anaconda3_home&#125;\\envs\\python35\\python.exe -u -c \"import setuptools, tokenize;__file__='&#123;AppData&#125;\\\\Local\\\\Temp\\\\pip-build-mgdjtt1d\\\\scipy\\\\setup.py';f=getattr(tokenize, 'open', open)(__file__);code=f.read().replace('\\r\\n', '\\n');f.close();exec(compile(code, __file__, 'exec'))\" install --record &#123;AppData&#125;\\Local\\Temp\\pip-htcraop7-record\\install-record.txt --single-version-externally-managed --compile\" failed with error code 1 in &#123;AppData&#125;\\Local\\Temp\\pip-build-mgdjtt1d\\scipy\\ 网上有建议通过 pip install git+git://github.com/Theano/Theano.git 从github直接下最新代码安装的，但是也是安装失败 我成功的方式 (python35) C:\\Users\\xx&gt;conda install mingw libpython theano -y(python35) C:\\Users\\xx&gt;pip install keras 天朝网络不稳定，挺慢的，可以参考 另外一篇博文切换清华源 https://anjia.ml/2017/07/02/anaconda-install-and-configurating-jupyter/#设置清华镜像源(python35) C:\\Users\\xx&gt;pythonPython 3.5.3 |Continuum Analytics, Inc.| (default, May 15 2017, 10:43:23) [MSC v.1900 64 bit (AMD64)] on win32Type &quot;help&quot;, &quot;copyright&quot;, &quot;credits&quot; or &quot;license&quot; for more information.&gt;&gt;&gt; import kerasUsing TensorFlow backend. 安装成功，默认后端是TensorFlow 博客 https://anjia.ml/2017/07/03/windows-install-tensorflow-keras/掘金 https://juejin.im/post/595a24b15188250d8d14237a简书 http://www.jianshu.com/p/e0d9fa795116","tags":[{"name":"python","slug":"python","permalink":"https://anjia0532.github.io/tags/python/"},{"name":"anaconda","slug":"anaconda","permalink":"https://anjia0532.github.io/tags/anaconda/"},{"name":"AI","slug":"AI","permalink":"https://anjia0532.github.io/tags/AI/"},{"name":"Tensorflow","slug":"Tensorflow","permalink":"https://anjia0532.github.io/tags/Tensorflow/"},{"name":"Keras","slug":"Keras","permalink":"https://anjia0532.github.io/tags/Keras/"}]},{"title":"安装anaconda并且配置jupyter notebook支持python2.x和3.x共存","date":"2017-07-02T10:59:18.000Z","path":"2017/07/02/anaconda-install-and-configurating-jupyter/","text":"业余时间，偶尔接触了python，感觉python很优雅，遂研究一下。基于elk报警器elastalert的微信企业号插件 之前一直用的sublime text 3 , 但是对于控制台输入(2.x raw_input,3.x input)支持不太好，虽然可以通过sublimeREPL-&gt;python-&gt;execfile(filepath)实现，但是无疑更繁琐(可以使用sublime 的key bindings，定义快捷键来触发，但是还是觉得繁琐)，而且使用sublime+python切换python版本也不方便(网上很多资料是基于python2.x)，但是python3的文章资料也越来越多，学习时经常需要切换很不方便 经过一番搜索，最后决定使用Anaconda Anaconda是Python众多发行版中非常适用于科学计算的版本，里面已经集成了很多优秀的科学计算Python库,开源且免费，全平台支持:linux,mac,windows;支持python 2.x，3.x,Anaconda集成了jupyter notebook ，可以使用 try it in your browser 进行体验。 安装anaconda官方安装包 https://www.continuum.io/downloads ,但是国内比较慢，可以使用清华镜像 ,从 https://mirrors.tuna.tsinghua.edu.cn/anaconda/archive/ 下载安装包。目前(2017-07-02)最新的是 Anaconda3-4.4.0-* 我下载的是windows 64位版Anaconda3-4.4.0-Windows-x86_64.exe（如果用于机器学习(e.g. Tensorflow) 建议使用Linux系统，具体参见 Keras安装和配置指南(Windows)）。 同时推荐 李金的 《中文 Python 笔记》 ,github 打开.ipynb 较慢，推荐使用NbViewer 查看 设置清华镜像源更多可参阅 conda 使用清华大学开源软件镜像 或者 清华镜像conda config --add channels https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/free/conda config --set show_channel_urls yes 修改windows下jupyter默认路径参考 stackoverflow 上 how to change jupyter start folder? 的回答 打开 C:\\ProgramData\\Microsoft\\Windows\\Start Menu\\Programs\\Anaconda3 (64-bit) 运行 Anaconda Prompt 运行jupyter notebook --generate-config 会生成一个默认配置文件，C:\\Users\\{用户名}\\.jupyter\\jupyter_notebook_config.py 修改#c.NotebookApp.notebook_dir = &#39;&#39; 为 c.NotebookApp.notebook_dir = &#39;你的默认路径&#39; 打开C:\\Users\\{用户名}\\Anaconda3\\Scripts 右键单击jupyter-notebook.exe并发送到桌面快捷方式 在桌面上找到该快捷方式，右键-&gt;属性-&gt;更改图标(C)...-&gt;{Anaconda3_home}\\Menu\\jupyter.ico 双击运行，会自动打开默认浏览器。 输入 print('hello jupyter') 按 Ctrl+Enter 运行，结果如下 具体快捷键，参见 Help -&gt; Keyboard Shortcuts 切换python版本参考 Managing Python 或者 Anaconda多环境多版本python配置指导 打开 C:\\ProgramData\\Microsoft\\Windows\\Start Menu\\Programs\\Anaconda3 (64-bit) 运行 Anaconda Prompt 创建python2.7环境conda create -n python27 python=2.7 -yactivate python27 设置jupyter 2.7,3.6共存参考 Anaconda3 Python 3 和 2 in Jupyter Notebook共存方法conda install ipykernel -y 复制${Anaconda3_home}\\share\\jupyter\\kernels\\python3 并重命名为${Anaconda3_home}\\share\\jupyter\\kernels\\python27，编辑${Anaconda3_home}\\share\\jupyter\\kernels\\python27\\kernel.json&#123; &quot;argv&quot;: [ &quot;$&#123;Anaconda3_home&#125;\\\\envs\\\\python27\\\\python.exe&quot;, &quot;-m&quot;, &quot;ipykernel_launcher&quot;, &quot;-f&quot;, &quot;&#123;connection_file&#125;&quot; ], &quot;display_name&quot;: &quot;Python 27&quot;, &quot;language&quot;: &quot;python&quot;&#125; 注意，修改display_name为自定义名称，argv第一行中路径用\\\\替代\\ 在cell中输入import sys sys.version 切换不同python版本 按Ctrl+Enter运行 查看版本，e.g. 上图中的3.6.1,因为 Tensorflow官方文档说windows只支持 3.5.x ，故而又装了一个3.5.3的环境 jupyter作为公开服务使用(云IDE)参考 Running a notebook server ，使用nssm将jupyter设置为开机自启动服务 打开 C:\\ProgramData\\Microsoft\\Windows\\Start Menu\\Programs\\Anaconda3 (64-bit) 运行 Anaconda Prompt 切换回anaconda默认环境activate root 创建密码 jupyter notebook password Preparing a hashed password 修改C:\\Users\\{用户名}\\.jupyter\\jupyter_notebook_config.py中c.NotebookApp.ip = &#39;*&#39;,c.NotebookApp.open_browser = False 重启 jupyter ,打开 http://{ip}:8888, 提示输入密码，输入密码即可登录 注册为服务 下载nssm 注意，如果之前用过nssm，建议升级到 nssm 2.24-101-g897c7ad 版本，详见 Windows 10 Creators Update {nssm_home}\\win64\\nssm.exe install jupyter {Anaconda3_home}\\Scripts\\jupyter-notebook.exe --config=C:\\Users\\{用户名}\\.jupyter\\jupyter_notebook_config.py `{nssm_home}\\win64\\nssm.exe start jupyter’ 浏览器打开 http://ip:8888 输入密码登录 注意，nssm默认使用LOCALSYSTEM账号操作，而jupyter默认读取~\\.jupyter(~\\是当前登录用户文件夹)，可以使用nssm set &lt;servicename&gt; ObjectName &lt;username&gt; &lt;password&gt; 使用指定用户，这样就不需要--config=C:\\Users\\{用户名}\\.jupyter\\jupyter_notebook_config.py 参数了，具体详见 Usage 和 Managing services from the command line nginx反向代理upstream jupyter &#123; server http://ip:8888; server http://ip2:8888;&#125;server &#123; listen 80; server_name jupyter.example.com; location / &#123; proxy_set_header X-Real-IP $remote_addr; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; proxy_set_header X-Nginx-Proxy true; proxy_set_header Host $host; # kernels使用websocket通讯，需要增加Upgrade和Connection [WebSocket proxying](http://nginx.org/en/docs/http/websocket.html) proxy_http_version 1.1; proxy_set_header Upgrade $http_upgrade; proxy_set_header Connection $connection_upgrade; #如果是单服务，无负载，则不需要用upsstream #proxy_pass http://ip:8888; proxy_pass http://jupyter; &#125;&#125; 博客 https://anjia.ml/2017/07/02/anaconda-install-and-configurating-jupyter/掘金 https://juejin.im/post/595897c36fb9a06bca0b91eb简书 http://www.jianshu.com/p/e981c9d28555","tags":[{"name":"python","slug":"python","permalink":"https://anjia0532.github.io/tags/python/"},{"name":"anaconda","slug":"anaconda","permalink":"https://anjia0532.github.io/tags/anaconda/"},{"name":"jupyter","slug":"jupyter","permalink":"https://anjia0532.github.io/tags/jupyter/"},{"name":"ipython","slug":"ipython","permalink":"https://anjia0532.github.io/tags/ipython/"}]},{"title":"nginx正则表达式快捷测试方法","date":"2017-06-29T16:03:19.000Z","path":"2017/06/29/nginx-regex-test-way/","text":"之前在配置时都是本地起一个nginx服务，修改location规则,然后nginx -s reload 或则 service nginx reload不断尝试来判断是否符合预期。显而易见，效率极低。使用一些在线正则表达式测试(e.g. 在线工具)又因为使用的库不同，多少存在差异。 正则表达式有不同的规则引擎，具体参见 wikipedia的 Comparison of regular expression engines nginx使用的是PCRE 截取nginx官方文档 Building nginx from Sources –with-pcre=path — sets the path to the sources of the PCRE library. The library distribution (version 4.4 — 8.40) needs to be downloaded from the PCRE site and extracted. The rest is done by nginx’s ./configure and make. The library is required for regular expressions support in the location directive and for the ngx_http_rewrite_module module. 建议使用linux下的 grep 工具 windows可以使用cygwin 或者git for windows中的git-bash.exe $ grep --help# ...Regexp selection and interpretation: -E, --extended-regexp PATTERN is an extended regular expression (ERE) -F, --fixed-strings PATTERN is a set of newline-separated strings -G, --basic-regexp PATTERN is a basic regular expression (BRE) -P, --perl-regexp PATTERN is a Perl regular expression -e, --regexp=PATTERN use PATTERN for matching -f, --file=FILE obtain PATTERN from FILE -i, --ignore-case ignore case distinctions -w, --word-regexp force PATTERN to match only whole words -x, --line-regexp force PATTERN to match only whole lines -z, --null-data a data line ends in 0 byte, not newline# ... 使用 grep -P命令即可 $ echo 'a.gif' | grep -P '\\.(jp?g|gif|bmp|png)'#输出a.gif 如果只想输出匹配部分，则加上-o参数 $ echo 'a.gif' | grep -P -o '\\.(jp?g|gif|bmp|png)'#输出.gif 具体 perl 正则表达式语法，可参考 Perl regular expressions man page 汤姆的猫-Perl入门（四）Perl的正则表达式 博客 https://anjia.ml/2017/06/29/nginx-regex-test-way/简书 http://www.jianshu.com/p/17eb0ba22ff6掘金 https://juejin.im/post/5954ad1b5188250d8f602bca","tags":[{"name":"nginx","slug":"nginx","permalink":"https://anjia0532.github.io/tags/nginx/"}]},{"title":"nginx日志中$request_body 十六进制字符(\\x22\\x9B\\x5C\\x09\\x08...)完美解决方案","date":"2017-06-21T10:11:46.000Z","path":"2017/06/21/nginx-logging-request-body-as-hexidecimal/","text":"在使用nginx记录访问日志时，发现在含有request_body的 PUT,POST 请求时，日志中会含有 \\x22 \\x9B \\x5C \\x09 \\x08 字符，不利于阅读和处理。 具体 支持request_body的http method参见 http1.1定义 9 Method Definitions 和 Payloads of HTTP Request Methods nginx.conf 默认access_log 配置log_format main &apos;$remote_addr - $remote_user [$time_local] &quot;$request&quot; &apos; &apos;$status $body_bytes_sent &quot;$http_referer&quot; &apos; &apos;&quot;$http_user_agent&quot; &quot;$http_x_forwarded_for&quot;&apos; &apos;$http_host $upstream_status $upstream_addr $request_time $upstream_response_time&apos;; 改成log_format json_log escape=json &apos;&#123;&quot;realip&quot;:&quot;$remote_addr&quot;,&quot;@timestamp&quot;:&quot;$time_iso8601&quot;,&quot;host&quot;:&quot;$http_host&quot;,&quot;request&quot;:&quot;$request&quot;,&quot;req_body&quot;:&quot;$request_body&quot;,&quot;status&quot;:&quot;$status&quot;,&quot;size&quot;:$body_bytes_sent,&quot;ua&quot;:&quot;$http_user_agent&quot;,&quot;cookie&quot;:&quot;$http_cookie&quot;,&quot;req_time&quot;:&quot;$request_time&quot;,&quot;uri&quot;:&quot;$uri&quot;,&quot;referer&quot;:&quot;$http_referer&quot;,&quot;xff&quot;:&quot;$http_x_forwarded_for&quot;,&quot;ups_status&quot;:&quot;$upstream_status&quot;,&quot;ups_addr&quot;:&quot;$upstream_addr&quot;,&quot;ups_time&quot;:&quot;$upstream_response_time&quot;&#125;&apos;; 参考 How to generate a JSON log from nginx? 官方文档ngx_http_log_module.html#log_format 注意，escape是从1.11.8后新增的参数。 如果是老版本的，linux可以考虑使用shell命令替换，logstash可以考虑使用ruby处理 ，参考 Optionally support handling of \\x escape codes 博客 https://anjia.ml/2017/06/21/nginx-logging-request-body-as-hexidecimal/简书 http://www.jianshu.com/p/8409f28f32e9掘金 https://juejin.im/post/5949e0f7128fe1006a627cc0","tags":[{"name":"nginx","slug":"nginx","permalink":"https://anjia0532.github.io/tags/nginx/"},{"name":"elk","slug":"elk","permalink":"https://anjia0532.github.io/tags/elk/"},{"name":"elkstack","slug":"elkstack","permalink":"https://anjia0532.github.io/tags/elkstack/"},{"name":"logstash","slug":"logstash","permalink":"https://anjia0532.github.io/tags/logstash/"}]},{"title":"jdk绿色免安装","date":"2017-05-17T12:39:16.000Z","path":"2017/05/17/jdk-zip/","text":"windows 免安装java自从被oracle收购后，windows下新的版本只有安装版。没有zip免安装。 windows安装版有一下坏处 会写注册表 会将java.exe,javaw.exe 等解压到C:\\Windows\\System32或者C:\\Windows\\SysWOW64 会将定期更新程序设置开机自启动，发现新版本弹窗提示 会在PATH中写一个oracle的javapath,还会加上jre\\bin 好处就是安装方便 今天给同事处理问题时，就因为他电脑装了jdk7和jdk8两个安装版，并且path配置的%JAVA_HOME%\\bin;又配了一个%JAVA_HOME%\\jre\\bin;导致出了一个很诡异的错误。 下面说一下，如何免安装 从 http://www.oracle.com/technetwork/java/javase/downloads/index.html 下载最新的jdk windows安装版e.g.jdk-8u131-windows-x64.exe 用解压缩软件解压到E:\\jdk-8u131-windows-x64\\ Win+R-&gt;cmd打开命令行 cd /d E:\\jdk-8u131-windows-x64\\.rsrc\\1033\\JAVA_CAB10extrac32.exe 111:: 此时解压出 tools.zip 文件:: 打开当前文件夹explorer.exe .:: 将tools.zip 用解压软件解压到当前文件夹,e.g. `E:\\jdk-8u131-windows-x64\\.rsrc\\1033\\JAVA_CAB10\\tools`:: 将 .pack文件改成.jar文件cd toolsfor /r %x in (*.pack) do .\\bin\\unpack200 -r &quot;%x&quot; &quot;%~dx%~px%~nx.jar&quot;:: 解压 src.zip 如果不需要源码 src.zip 可忽略此步cd ..\\..\\JAVA_CAB9extrac32 110:: 将src.zip移动到tools文件夹move src.zip ..\\JAVA_CAB10\\tools\\:: 将tools文件夹里的内容复制到指定目录，e.g. D:\\jdkxcopy /s /e /i /y E:\\jdk-8u131-windows-x64\\.rsrc\\1033\\JAVA_CAB10\\tools d:\\jdk:: 删除 E:\\jdk-8u131-windows-x64 文件夹cd / &amp;&amp; rd /s /q E:\\jdk-8u131-windows-x64 设置环境变量增加 JAVA_HOME d:\\jdk 修改PATH 追加 ;%JAVA_HOME%\\bin; 增加 CLASSPATH .;%JAVA_HOME%\\lib\\dt.jar;%JAVA_HOME%\\lib\\tools.jar; 设置环境变量后，需要重新打开cmd java -version &amp;&amp; javac -versionjava version &quot;1.8.0_131&quot;Java(TM) SE Runtime Environment (build 1.8.0_131-b15)Java HotSpot(TM) 64-Bit Server VM (build 25.131-b15, mixed mode)javac 1.8.0_131 linux 免安装# 下载文件$ wget -P ~/downloads --no-check-certificate --no-cookies --header \"Cookie: oraclelicense=accept-securebackup-cookie\" http://download.oracle.com/otn-pub/java/jdk/8u121-b13/e9e7ea248e2c4826b92b3f075a80e441/jdk-8u121-linux-x64.tar.gz# 解压$ sudo tar zxf ~/downloads/jdk-*.tar.gz -C /usr/local/#创建软连接$ sudo ln -sf /usr/local/jdk1.8.0_121 /usr/local/jdk$ sudo vi /etc/profile#设置java环境export JAVA_HOME=/usr/local/jdkexport CLASSPATH=.:$JAVA_HOME/lib/dt.jar;:$JAVA_HOME/lib/tools.jar:$CLASSPATHexport PATH=$JAVA_HOME/bin:$PATH#保存并退出#使配置生效$ source /etc/profile 本人原创 博客 https://anjia.ml/2017/05/17/jdk-zip/简书 http://www.jianshu.com/p/5dc20d5d4f5c掘金 https://juejin.im/post/591bdb222f301e006bcde36b","tags":[{"name":"java","slug":"java","permalink":"https://anjia0532.github.io/tags/java/"}]},{"title":"elasticsearch按照日期定时删除索引","date":"2017-04-06T14:10:47.000Z","path":"2017/04/06/elasticsearch-delete-indices-by-date/","text":"使用elkstack作为日志分析工具，采集nginx访问日志，项目log日志，心跳检测日志，服务器度量日志等，每天产生大量索引(Index)，占用磁盘空间。对于过期数据需要进行删除来释放磁盘空间。 使用官网_delete_by_query进行删除官网文档–Delete By Query API curl -u 用户名:密码 -H'Content-Type:application/json' -d'&#123; \"query\": &#123; \"range\": &#123; \"@timestamp\": &#123; \"lt\": \"now-7d\", \"format\": \"epoch_millis\" &#125; &#125; &#125;&#125;' -XPOST \"http://127.0.0.1:9200/*-*/_delete_by_query?pretty\" 解释 -u是格式为userName:password，使用Basic Auth进行登录。如果elasticsearch没有使用类似x-pack进行安全登录，则不需要加-u参数 -H是指定文档类型是json格式 -XPOST是指定用POST方式请求 -d是指定body内容 &#123; \"query\": &#123; \"range\": &#123; //范围 \"@timestamp\": &#123;//时间字段 \"lt\": \"now-7d\",//lt是小于(&lt;)，lte是小于等于(&lt;=),gt是大于(&gt;),gte是大于等于(&gt;=),now-7d是当前时间减7天 \"format\": \"epoch_millis\" &#125; &#125; &#125;&#125; 定时删除$ crontab -e* 0 * * * /usr/bin/curl -u username:password -H'Content-Type:application/json' -d'&#123;\"query\":&#123;\"range\":&#123;\"@timestamp\":&#123;\"lt\":\"now-7d\",\"format\":\"epoch_millis\"&#125;&#125;&#125;&#125;' -XPOST \"http://127.0.0.1:9200/*-*/_delete_by_query?pretty\" &gt; /tmp/elk_clean.txt 每天0点删除超过7天的无效索引 优点： 不依赖第三方插件或者代码 简单易理解 不需要指定索引名称可用*通配符删除 缺点： 效率低 使用sh脚本删除在stackoverflow看到一个帖子 Removing old indices in elasticsearch#answer-39746705#!/bin/bashsearchIndex=logstash-monitorelastic_url=logging.core.k94.kvk.nlelastic_port=9200date2stamp () &#123; date --utc --date \"$1\" +%s&#125;dateDiff ()&#123; case $1 in -s) sec=1; shift;; -m) sec=60; shift;; -h) sec=3600; shift;; -d) sec=86400; shift;; *) sec=86400;; esac dte1=$(date2stamp $1) dte2=$(date2stamp $2) diffSec=$((dte2-dte1)) if ((diffSec &lt; 0)); then abs=-1; else abs=1; fi echo $((diffSec/sec*abs))&#125;for index in $(curl -s \"$&#123;elastic_url&#125;:$&#123;elastic_port&#125;/_cat/indices?v\" | grep -E \" $&#123;searchIndex&#125;-20[0-9][0-9]\\.[0-1][0-9]\\.[0-3][0-9]\" | awk '&#123; print $3 &#125;'); do date=$(echo $&#123;index: -10&#125; | sed 's/\\./-/g') cond=$(date +%Y-%m-%d) diff=$(dateDiff -d $date $cond) echo -n \"$&#123;index&#125; ($&#123;diff&#125;)\" if [ $diff -gt 1 ]; then echo \" / DELETE\" # curl -XDELETE \"$&#123;elastic_url&#125;:$&#123;elastic_port&#125;/$&#123;index&#125;?pretty\" else echo \"\" fidone 使用了 _cat/indicesapi。 使用 curator支持windowszip,msi,和linuxapt,yum Curator Reference github-curator 安装安装 配置参考 http://stackoverflow.com/questions/33430055/removing-old-indices-in-elasticsearch#answer-42268400 1.config文件 ---# Remember, leave a key empty if there is no value. None will be a string,# not a Python \"NoneType\"client: hosts: * 127.0.0.1 port: 9200 url_prefix: use_ssl: False certificate: client_cert: client_key: ssl_no_validate: False http_auth: username:password timeout: master_only: Truelogging: loglevel: INFO logfile: logformat: default #blacklist: ['elasticsearch', 'urllib3'] 2.action文件 ---actions: 1: action: delete_indices description: &gt;- Delete indices older than 7 days (based on index name), for logstash- prefixed indices. Ignore the error if the filter does not result in an actionable list of indices (ignore_empty_list) and exit cleanly. options: ignore_empty_list: True timeout_override: continue_if_exception: False disable_action: False filters: * filtertype: pattern kind: prefix value: logstash- exclude: * filtertype: age source: name direction: older timestring: '%Y.%m.%d' unit: days unit_count: 7 exclude: 这里是用index-&#39;%Y.%m.%d&#39;进行匹配，如果是按照索引创建日期来删除，source: creation_date 参见 https://www.elastic.co/guide/en/elasticsearch/client/curator/current/fe_source.html#_creation_date 3.运行 curator --config /path/config_file.yml /path/action_file.yml 别忘了加定时任务crontab -e","tags":[{"name":"elk","slug":"elk","permalink":"https://anjia0532.github.io/tags/elk/"},{"name":"elkstasck","slug":"elkstasck","permalink":"https://anjia0532.github.io/tags/elkstasck/"},{"name":"curator","slug":"curator","permalink":"https://anjia0532.github.io/tags/curator/"}]},{"title":"自建私有云Owncloud+Nginx（支持16G大文件上传）","date":"2017-04-05T12:21:25.000Z","path":"2017/04/05/owncloud/","text":"Owncloud官网桌面版支持Windows,Mac,Linux 移动版本支持，android,ios,blackberry 环境 Ubuntu-16.04_64 Owncloud9.14-2.1 SQLite3 PHP7 Nginx 1.10.0 最简单安装根据linux版本选择相应版本owncloud-9.1 安装以Ubuntu-16.04 安装owncloud-9.14-2.1为例 用root权限添加owncloud密钥su rootwget -nv https://download.owncloud.org/download/repositories/9.1/Ubuntu_16.04/Release.key -O Release.keyapt-key add - &lt; Release.key 用root权限添加owncloud软件源sh -c \"echo 'deb http://download.owncloud.org/download/repositories/9.1/Ubuntu_16.04/ /' &gt; /etc/apt/sources.list.d/owncloud.list\"apt update -y &amp;&amp; apt install owncloud -y 源码安装安装PHP7sudo apt-get install -y php7.0-common php7.0-gd php7.0-json php7.0-mysql php7.0-curl php7.0-intl php7.0-mcrypt php-imagick php7.0-zip php7.0-xml php7.0-mbstring 安装数据库#mariadbsudo apt-get install -y mariadb-server php7.0-mysql#sqlite3sudo apt-get install -y sqlite3 php7.0-sqlite3 安装web容器#apache2sudo apt-get install -y apache2 libapache2-mod-php7.0#nginxsudo apt-get install -y nginx php7.0-fpm 修改fpm配置文件(nginx)$ vi /etc/php/7.0/fpm/pool.d/www.conf 修改listen = /run/php/php7.0-fpm.sock为listen=127.0.0.1:9000(大约36行) 放开env的注释(大约384-388行)env[HOSTNAME] = $HOSTNAMEenv[PATH] = /usr/local/bin:/usr/bin:/binenv[TMP] = /tmpenv[TMPDIR] = /tmpenv[TEMP] = /tmp 下载最新源码$ wget -P /tmp https://download.owncloud.org/download/community/owncloud-latest.zip &amp;&amp; sudo unzip /tmp/owncloud-latest.zip -d /var/www/ &amp;&amp; rm -rf /tmp/owncloud-latest.zip 给www-data授权sudo chown -R www-data:www-data /var/www/owncloud/ 参考资料官方nginx+https配置 支持大文件上传(16G) 我的nginx配置nginx$ vi /etc/nginx/sites-enabled/owncloud.confupstream php-handler &#123; server 127.0.0.1:9000; #server unix:/var/run/php5-fpm.sock;&#125;server &#123; listen 10010; server_name 127.0.0.1; # Add headers to serve security related headers # Before enabling Strict-Transport-Security headers please read into this topic first. #add_header Strict-Transport-Security \"max-age=15552000; includeSubDomains\"; add_header X-Content-Type-Options nosniff; add_header X-Frame-Options \"SAMEORIGIN\"; add_header X-XSS-Protection \"1; mode=block\"; add_header X-Robots-Tag none; add_header X-Download-Options noopen; add_header X-Permitted-Cross-Domain-Policies none; # Path to the root of your installation root /var/www/owncloud/; location = /robots.txt &#123; allow all; log_not_found off; access_log off; &#125; # The following 2 rules are only needed for the user_webfinger app. # Uncomment it if you're planning to use this app. #rewrite ^/.well-known/host-meta /public.php?service=host-meta last; #rewrite ^/.well-known/host-meta.json /public.php?service=host-meta-json last; location = /.well-known/carddav &#123; return 301 $scheme://$host/remote.php/dav; &#125; location = /.well-known/caldav &#123; return 301 $scheme://$host/remote.php/dav; &#125; location /.well-known/acme-challenge &#123; &#125; # set max upload size client_max_body_size 16400M; fastcgi_buffers 64 4K; fastcgi_read_timeout 600; client_body_buffer_size 1048576k; client_body_temp_path /tmp/owncloud; # Disable gzip to avoid the removal of the ETag header gzip off; # Uncomment if your server is build with the ngx_pagespeed module # This module is currently not supported. #pagespeed off; error_page 403 /core/templates/403.php; error_page 404 /core/templates/404.php; location / &#123; rewrite ^ /index.php$uri; &#125; location ~ ^/(?:build|tests|config|lib|3rdparty|templates|data)/ &#123; return 404; &#125; location ~ ^/(?:\\.|autotest|occ|issue|indie|db_|console) &#123; return 404; &#125; location ~ ^/(?:index|remote|public|cron|core/ajax/update|status|ocs/v[12]|updater/.+|ocs-provider/.+|core/templates/40[34])\\.php(?:$|/) &#123; fastcgi_split_path_info ^(.+\\.php)(/.*)$; include fastcgi_params; fastcgi_param SCRIPT_FILENAME $document_root$fastcgi_script_name; fastcgi_param PATH_INFO $fastcgi_path_info; #fastcgi_param HTTPS on; fastcgi_param modHeadersAvailable true; #Avoid sending the security headers twice fastcgi_param front_controller_active true; fastcgi_pass php-handler; fastcgi_intercept_errors on; fastcgi_request_buffering off; #Available since nginx 1.7.11 &#125; location ~ ^/(?:updater|ocs-provider)(?:$|/) &#123; try_files $uri $uri/ =404; index index.php; &#125; # Adding the cache control header for js and css files # Make sure it is BELOW the PHP block location ~* \\.(?:css|js)$ &#123; try_files $uri /index.php$uri$is_args$args; add_header Cache-Control \"public, max-age=7200\"; # Add headers to serve security related headers (It is intended to have those duplicated to the ones above) # Before enabling Strict-Transport-Security headers please read into this topic first. #add_header Strict-Transport-Security \"max-age=15552000; includeSubDomains\"; add_header X-Content-Type-Options nosniff; add_header X-Frame-Options \"SAMEORIGIN\"; add_header X-XSS-Protection \"1; mode=block\"; add_header X-Robots-Tag none; add_header X-Download-Options noopen; add_header X-Permitted-Cross-Domain-Policies none; # Optional: Don't log access to assets access_log off; &#125; location ~* \\.(?:svg|gif|png|html|ttf|woff|ico|jpg|jpeg)$ &#123; try_files $uri /index.php$uri$is_args$args; # Optional: Don't log access to other assets access_log off; &#125;&#125; php.ini$ sudo vi /etc/php/7.0/fpm/php.ini##修改以下几个配置参数; should be bit bigger than upload_max_filesize 16400M = 16G + 16M = 16 * 1025 MBpost_max_size = 16400M; cannot be bigger than post_max_sizeupload_max_filesize = 16G; on online servers this could require bigger values (my server is at home)max_input_time = 3600; from ownCloud documentation - not sure if is requiredoutput_buffering = Off; not sure if it is required [3] but it seems like ownCloud needs time to move the file to it's; final place after upload and that can take quite some time for big filesmax_execution_time = 1800; you may also want to point this to a folder having enough space for big files being uploadedupload_tmp_dir = /tmp/owncloud 启动服务$ sudo service php7.0-fpm restart$ sudo service nginx restart 配置浏览器打开http://127.0.0.1:10010,MariaDB是Mysql的开源分支(mysql被oracle收购了)，适合大规模使用，对并发和性能要求比较高的场景。SQLite3适合小规模使用。此处使用SQLite3。详见 https://doc.owncloud.org/server/latest/admin_manual/configuration_database/db_conversion.html 和https://doc.owncloud.org/server/latest/admin_manual/configuration_database/linux_database_configuration.html 配置域名详见 https://doc.owncloud.org/server/latest/admin_manual/configuration_server/config_sample_php_parameters.htmlsudo vi /var/www/owncloud/config/config.php 修改&apos;trusted_domains&apos; =&gt; array ( 0 =&gt; &apos;127.0.0.1:10010&apos;, 1 =&gt; &apos;域名&apos;, ), 修改&apos;overwrite.cli.url&apos; =&gt; &apos;http://域名&apos;, 创建用户浏览器访问http://127.0.0.1:10010/settings/users,用管理员用户名密码登陆 下载客户端参见 https://owncloud.org/install/#install-clients","tags":[{"name":"owncloud","slug":"owncloud","permalink":"https://anjia0532.github.io/tags/owncloud/"}]},{"title":"ElkStack之Heartbeat(心跳检测)","date":"2017-03-03T01:20:16.000Z","path":"2017/03/03/heartbeat/","text":"Heartbeat是一个轻量级守护程序，安装在远程服务器上以定期检查服务的状态，检查服务是否可用。与Metricbeat不同，Metricbeat只告诉你服务器是启动还是停止，Heartbeat可以告诉你，服务是否可以正常访问 Heartbeat可以帮你验证服务是否可以正常访问，如果你需要验证内部服务时，他还可以用于其它方案，例如，安全用例 你可以配置Heartbeat来Ping指定主机名的所有DNS可解析的IP地址。从而检查所有的负载均衡服务，是否可用 配置Heartbeat时，可以指定用于监控的hosts 。 每个监控器按照你设置的监控计划运行。例如，你可以将一个监控器配置为每10分钟运行一次，并且配置不同的监控器在9:00~17:00运行 Heartbeat目前支持通过以下方式检查hosts ICMP(IPV4/IPV6)回显请求。当你只是想检查服务是否可用时，可以使用icmp。这个监控器需要管理员权限 TCP。 tcp监控器是通过TCP协议来连接。可以选择配置tcp监控器，通过发送或接受自定义有效内容(payload)来验证端点(endpoint)是否可用 HTTP。使用http监控器是通过http协议进行连接。可以选择配置http监控器来验证服务是否返回预期的响应，例如，特定的状态码，响应头或者内容 tcp和http都支持SSL/TLS和代理设置 安装HeartbeatHeartbeat检测服务心跳，一般安装在较为稳定的独立服务器上（类似云服务，不断电，不断网）。尽量不要跟被监控的服务放在一个篮子里 从下载页面根据系统下载相应的安装包 deb(Debian/Ubuntu)curl -L -O https://artifacts.elastic.co/downloads/beats/heartbeat/heartbeat-5.2.2-amd64.debsudo dpkg -i heartbeat-5.2.2-amd64.deb rpm(Redhat / Centos / Fedora)curl -L O https://artifacts.elastic.co/downloads/beats/heartbeat/heartbeat-5.2.2-x86_64.rpmsudo rpm -vi heartbeat-5.2.2-x86_64.rpm maccurl -L -O https://artifacts.elastic.co/downloads/beats/heartbeat/heartbeat-5.2.2-darwin-x86_64.tar.gztar xzvf heartbeat-5.2.2-darwin-x86_64.tar.gz windows 根据具体系统下载 32位系统 https://artifacts.elastic.co/downloads/beats/heartbeat/heartbeat-{version}-windows-x86.zip或者 64位系统https://artifacts.elastic.co/downloads/beats/heartbeat/heartbeat-{version}-windows-x86_64.zip 注意将{version}替换成具体版本,格式类似于5.2.1 将下载的zip解压到指定文件夹，例如 D:\\Heartbeat 以管理员身份打开PowerShell(右键单击PowerShell图标，选择以管理员身份运行)。注意，如果是xp，需要单独安装powershell 运行以下命令安装为Windows服务 PS &gt; cd 'D:\\Heartbeat'PS D:\\Heartbeat&gt; .\\install-service-heartbeat.ps1 !&gt; 如果脚本被禁用，或者安装不成功，或者是xp系统，其实可以考虑使用nssm,具体用法，百度之。具体参数为-c D:\\Heartbeat\\heartbeat.yml -path.home D:\\Heartbeat\\ -path.data D:\\Heartbeat\\ 测试阶段可以使用 heartbeat.exe -e -f heartbeat.yml 如果已经安装服务，可以使用net start heartbeat(使用管理员权限的cmd或者powershell或者从服务(Win+R输入services.msc，找到heartbeat服务手动开启) 配置Heartbeat可以通过编辑heartbeat.yml来配置heartbeat。heartbeat.full.yml里面有所有可用的选项，可以作为参考 Heartbeat提供在指定的间隔时间检测主机心跳状态的监控，可以单独配置每个监控。Heartbeat目前提供ICMP,TCP 和HTTP 的监控（更多有关监控的信息，参见 简介） 要启用的监控列表，使用(-) 开头(yaml中的数组),以下表示的用Heartbeat监控ICMP和TCPheartbeat.monitors:- type: icmp schedule: '*/5 * * * * * *' #1 hosts: [\"myhost\"]- type: tcp schedule: '@every 5s' #2 hosts: [\"myhost:7\"] # default TCP Echo Protocol mode: any #3 check.send: \"Check\" check.receive: \"Check\"- type: http schedule: '@every 5s' urls: [\"http://localhost:80/service/status\"] check.response.status: 200heartbeat.scheduler: limit: 10 这个ICMP监控，每五秒钟运行一次(e.g. 10:00:00,10:00:05 …) schedule选项是类cron语法。具体参见this cronexpr implementation 这个TCP监控也是每5秒运行一次。Heartbeat添加了@every关键词添加到了conexpr包里 mode指定是否用来ping一个ip（any）或全解析IPS(all) 。 原版配置 监控选项type icmp(IPV4/IPV6)回显请求。当你只是想检查服务是否可用时，可以使用icmp。这个监控器需要管理员权限 tcp。 tcp监控器是通过TCP协议来连接。可以选择配置tcp监控器，通过发送或接受自定义有效内容(payload)来验证端点(endpoint)是否可用 http。使用http监控器是通过http协议进行连接。可以选择配置http监控器来验证服务是否返回预期的响应，例如，特定的状态码，响应头或者内容 tcp和http都支持SSL/TLS和代理设置 name监控器名字 enabledBoolean值，指定监控模块是否启用，默认为true schedule类cron表达式 ipv4Boolean值，如果指定了host，是否使用ipv4协议进行pin，默认为true ipv6Boolean值，如果指定了host，是否使用ipv4协议进行pin，默认为true modeany或者all,默认为any。如果是any，监控器对指定的主机名只ping一个ip地址。如果是all，则ping所有dns能解析出来的ip地址。对于负载均衡监控很有用 watch.poll_file此为实验功能。未来可能更改或删除 这是JSON格式的监控器配置文件。可以包含多个需要监控的对象。Heartbeat定期检查此文件。Heartbeat会合并heartbeat.yml和json中的配置，有新增的则新增监控实例。josn文件中删除实例后，heartbeat会停止监控该实例。 每个监控器用协议，主机，端口等参数作为唯一id。如果存在相同的，则使用合并后的最后一个json定义的设置。(以json中定义的为准)。所以为了不重启heartbeat，建议使用watch.poll_file进行配置，但是需要注意，这个是实验室功能，后期可能会修改或者变更 heartbeat.monitors:- type: tcp schedule: '*/5 * * * * * *' hosts: [\"myhost\"] watch.poll_file: path: &#123;path.config&#125;/monitors/dynamic.json interval: 5s path 指定的JSON文件地址 interval 指定间隔时间 JSON文件内容如下&#123;\"hosts\": [\"myhost:1234\"], \"schedule\": \"*/15 * * * * * *\"&#125; #1&#123;\"hosts\": [\"tls://otherhost:479\"], \"ssl.certificate_authorities\": [\"path/to/ca/file.pem\"]&#125; #2 检查到文件变更后，heartbeat会重启该监控器，并改为每15秒钟运行一次 heartbeat新增一个监控，使用带有ca证书的基于TLS的连接 ICMP选项type设置为icmp时，该项生效。Heartbeat使用ICMP(v4和v6)回显请求来检查配置的主机 hosts需要ping的主机列表 wait等待时间，默认1s TCP 选项type设置为tcp时，该项生效。通过tcp协议发送或接受自定义内容来验证端点是否可用。 hosts需要ping的主机列表。 简单的主机名，例如localhost 或者ip地址。如果你指定了这个选项，你必须在指定ports选项。如果监控器配置了使用ssl，heartbeat使用基于ssl、tls的连接。否则的话，使用普通的tcp连接 主机名+端口，例如localhost:8080。heartbeat根据主机名和端口号进行连接。如果监控器配置了使用ssl，heartbeat使用基于ssl、tls的连接。否则的话，使用普通的tcp连接 完整的URL，语法为 scheme://&lt;host&gt;:[port] scheme 为 tcp,plain,ssl或者tls。如果指定的是tcp或者plain，heartbeat使用tcp连接即使监控器配置为使用ssl，如果指定了tls或者ssl,heartbeat建立ssl连接。但是如果监控器没用ssl，则使用系统默认值(暂不支持windows) host是主机名。 port是端口号。 ports如果hosts中没指定端口，则在此需要配置需要ping的端口列表。例如检查 80,9200,5044端口- type: tcp schedule: '@every 5s' hosts: [\"myhost\"] ports: [80, 9200, 5044] check验证发送到主机的有效内容(payload)和预期的响应。如果未指定有效内容(payload)，一旦连接成功，则视为可用。如果只指定了发送，未指定接收。接收到任何响应都视为成功。如果只指定接收内容，未指定发送内容。不发送payload，但是在连接中，客户端希望接收到的内容为hello message或者banner(原文: If receive is specified without send, no payload is sent, but the client expects to receive a payload in the form of a “hello message” or “banner” on connect.)- type: tcp schedule: '@every 5s' hosts: [\"myhost\"] ports: [7] check.send: 'Hello World' check.receive: 'Hello World' proxy_url只可以用socks5代理。proxy_url: socks5://user:password@socks5-proxy:2233 使用代理时，主机名实在代理服务器上解析，而不是在客户端解析。可以通过设置 proxy_use_local_resolver来修改 proxy_use_local_resolverBoolean值，用于确定主机名是否本地解析还是在代理服务器解析。默认值为false，即在代理服务器解析。 sslTLS/SSL连接设置。如果check未配置，则监控器将仅检查是否可以建立SSL/TLS连接。此检查可能在TCP级别或在证书验证期间失败 - type: tcp schedule: '@every 5s' hosts: [\"myhost\"] ports: [80, 9200, 5044] ssl: certificate_authorities: ['/etc/ca.crt'] supported_protocols: [\"TLSv1.0\", \"TLSv1.1\", \"TLSv1.2\"] HTTP选项type设置为http时，该项生效。通过http协议验证host是否返回预期响应。 urls用于连接的URLs列表 - type: http schedule: '@every 5s' urls: [\"http://myhost:80\"] proxy_urlhttp代理url。选填项。如果不设置，默认使用系统环境中的HTTP_PROXY username选填项。用来请求身份验证的服务。如果验证身份的服务不指定，很可能返回403 password选填项。同username ssl 同tcp sslcheck(咳咳，划重点)选填项。发送request到远程服务，并接受期望响应response - type: http schedule: '@every 5s' urls: [\"http://myhost:80\"] check.request.method: HEAD check.response.status: 200 check.request 选项 method - HTTP方法。支持HEAD,GET和POST headers - 设置请求头 body - 选填请求体(用于POST方法) check.response 选项 status - 期望的响应码。未设置或者设置的是0，除404以外状态码均可 headers - 必须响应的header头信息 body - 必须的响应体 - type: http schedule: '@every 5s' urls: [\"https://myhost:80\"]check.request: method: GET headers: 'X-API-Key': '12345-mykey-67890'check.response: status: 200 body: '&#123;\"status\": \"ok\"&#125;' Scheduler 选项heartbeat.scheduler: limit: 10 location: 'UTC-08:00' 示例中设置limit为10，确保只有10个IO任务处于活动状态。IO任务可以是通过DNS实际检查或者解析地址 limit允许Heartbeat执行的并发IO任务数。如果为0，则没有限制。默认值为0。大多数操作系统文件，将文件描述符限制设置为1024。为了Heartbeat正确运行并且不意外组织输出。应该将limit的值设置低于ulimit location设置时区。默认使用本地实际 localtime 发送到Elasticsearchoutput.elasticsearch: hosts: [\"192.168.1.42:9200\"] template.name: \"heartbeat\" #1 template.path: \"heartbeat.template.json\" #2 1,2处是自动在Elasticsearch中加载索引模板，详细信息参见官网文档 如果是要输出到Logstash，参见配置Heartbeat使用Logstash 如果要测试配置，在heartbeat可执行目录下，运行./heartbeat -configtest -e 运行Heartbeatdeb :sudo /etc/init.d/ start rpm :sudo /etc/init.d/heartbeat start mac :sudo ./heartbeat -e -c heartbeat.yml -d \"publish\" win : 管理员权限net start heartbeat Windows默认将log输出在${Heartbeat_home}\\Logs文件夹 目前为止，Heartbeat已经开始检查你的服务状态并且发送相应的数据到你定义的输出点了(logstash/elasticsearch) 命令行选项命令行运行./heartbeat -h查看完整的选项列表 -E &lt;setting&gt;=&lt;value&gt; 覆盖配置文件中的某个配置例如 `./heartbeat -c heartbeat.yml -E name=mybeat` -N 禁止发送数据到指定的输出。这个选项在测试Beat时很有用 -c &lt;file&gt; 指定heartbeat配置文件 configtest 测试配置文件是否可用，然后退出。在排除配置文件错误时很有用 -cpuprofile &lt;output file&gt; 将cpu配置信息输出到指定文件。在排除故障的时候很有用 -d &lt;selectors&gt; 使用指定的选择器进行调试。参数用逗号隔开，或者使用 `-d &quot;*&quot;`调试所有的组件。例如`-d &quot;publish&quot;`显示所有`&quot;publish&quot;`相关的信息 -e 禁用syslog/file输出，只记录到stderr -httpprof [&lt;host&gt;]:&lt;port&gt; 启动http服务器进行性能分析 -memprofile &lt;output file&gt; 将内存配置信息写入到指定文件。 -path.config 设置配置文件的路径 -path.data 设置data文件路径 -path.home 设置可执行文件所在路径 -path.logs 设置日志文件的路径 -v 启用详细输出，以显示INFO级别日志 -version 显示beat版本并退出 本文只是针对官网文档进行了部分翻译。其他像是输出到logstash,redis等配置信息以及Processors部分Exported Fields部分,Securing Heartbeat暂不翻译 Heartbeat+ElastAlert 心跳报警ElastAlert如何使用， 参见另外一篇文章 。 监控服务(主机能否ping通，端口是否开放，http响应是否合法)。使用Heartbeat如果up=true则说明验证通过。服务可用。common fields#_up 。 使用ElastAlert的change rule。具体示例参见 example_rules/example_change.yaml文件。为啥用change rule，是因为一般服务就两种状态，up/down 我们只需要在状态切换(可用-&gt;不可用/不可用-&gt;可用)时获取到通知即可 我的配置如下 # Alert when some field changes between documents# This rule would alert on documents similar to the following:# &#123;'username': 'bob', 'country_name': 'USA', '@timestamp': '2014-10-15T00:00:00'&#125;# &#123;'username': 'bob', 'country_name': 'Russia', '@timestamp': '2014-10-15T05:00:00'&#125;# Because the user (query_key) bob logged in from different countries (compare_key) in the same day (timeframe)# (Optional)# Elasticsearch host# es_host: elasticsearch.example.com# (Optional)# Elasticsearch port# es_port: 14900# (Optional) Connect with SSL to Elasticsearch#use_ssl: True# (Optional) basic-auth username and password for elasticsearch#es_username: someusername#es_password: somepassword# (Required)# Rule name, must be uniquename: heartbeat-monitor# (Required)# Type of alert.# the change rule will alert when a certain field changes in two documents within a timeframetype: change# (Required)# Index to search, wildcard supportedindex: heartbeat-*# (Required, change specific)# The field to look for changes incompare_key: up# (Required, change specific)# Ignore documents without the compare_key (country_name) fieldignore_null: true# (Required, change specific)# The change must occur in two documents with the same query_keyquery_key: monitor# (Required, change specific)# The value of compare_key must change in two events that are less than timeframe apart to trigger an alertnum_events: 1timeframe: minutes: 1# (Required)# The alert is use when a match is foundalert:#- \"email\"#- \"debug\"- \"elastalert_modules.wechat_qiye_alert.WeChatAlerter\"#后台登陆后【设置】-&gt;【权限管理】-&gt;【普通管理组】-&gt;【创建并设置通讯录和应用权限】-&gt;【CorpID，Secret】#设置微信企业号的appidcorp_id: xxx#设置微信企业号的Secretsecret: xxx#后台登陆后【应用中心】-&gt;【选择应用】-&gt;【应用id】#设置微信企业号应用idagent_id: xxx#如果标签下无用户，则推送到部门#party_id: xxx#如果标签下无用户，则推送到用户#user_id: xxxtag_id: xxx 不过elastalert有个代码逻辑错误。我已提交Pull request#926和Issue#925 。 如果官方不采纳的话，可以手动修改elastalert\\ruletypes.py#L135将 not val改成 val is None具体原因参见Issue#925 如果正常的话，先将Heartbeat监听的服务启动，输出到Elasticsearch后，再停用。再次写入到Elasticsearch后。Elastalert控制台也会提示xx hits/xx hits并发送微信。","tags":[{"name":"elk","slug":"elk","permalink":"https://anjia0532.github.io/tags/elk/"},{"name":"elkstasck","slug":"elkstasck","permalink":"https://anjia0532.github.io/tags/elkstasck/"},{"name":"Heartbeat","slug":"Heartbeat","permalink":"https://anjia0532.github.io/tags/Heartbeat/"}]},{"title":"ELK Stack之Beats简介","date":"2017-03-02T18:55:39.000Z","path":"2017/03/02/elk-stack-beats/","text":"Beats 是ELK Stack技术栈中负责单一用途数据采集并推送给Logstash或Elasticsearch的轻量级产品。 FilebeatFilebeat是一个轻量级日志收集工具。官网介绍说，当有几十，几百甚至上千台服务器、容器、虚拟机生成日志时，Filebeat提供一种轻量级简单的方式转发和收集日志。 健壮性filebeat异常中断重启后会继续上次停止的位置。（通过${filebeat_home}\\data\\registry文件来记录日志的偏移量） 智能调节传输速度，防止logstash、elasticsearch过载Filebeat使用压力敏感协议(backpressure-sensitive)来传输数据，在logstash忙的时候，Filebeat会减慢读取-传输速度，一旦logsta恢复，则Filebeat恢复原来的速度。 MetricbeatMetricbeat是一个轻量级的系统级性能指标监控工具。收集CPU，内存，磁盘等系统指标和Redis，nginx等各种服务的指标 简化系统监控通过在Linux，Windows，Mac上部署Metricbeat，可以收集cpu，内存，文件系统，磁盘IO，网络IO等统计信息 多模块监控支持支持采集Apache, NGINX, MongoDB, MySQL, PostgreSQL, Redis, and ZooKeeper等服务的指标。零依赖，只需要在配置文件中启用即可 监控容器如果你使用Docker管理你的服务。可以在该主机上单独起一个Metricbeat容器，他通过从proc文件系统中直接读取cgroups信息来收集有关Docker主机上每个容器的统计信息。不需要特殊权限访问Docker API 无缝接入ELKMetricbeats是ELK Stack全家桶中的一员，可以和ELK无缝协同工作。例如使用Logstash二次处理数据，用Elasticsearch分析，或者用Kibana创建和共享仪表盘。 PacketbeatPacketbeat是一个轻量级的网络数据包分析工具。如果你用过wireshark，fiddler会很好理解数据包分析的概念，如果没用过，那你可以参考Chrome的dev tools的Network的功能。Packetbeat可以通过抓包分析应用程序的网络交互。并且将抓到的数据发送到Logstash或者Elasticsearch。 实时监控你的服务和应用程序Packetbeat 轻松的实时监控并解析像HTTP这样的网络协议。以了解流量是如何经过你的网络。Packetbeat是被动的，不增加延迟开销，无代码侵入。不干涉其他基础设施 支持多种应用层协议Packetbeat是一个库，支持多种应用程序层协议，如下所示 可以搜索和分析网络流量Packetbeat可以让你实时在目标服务器上进行抓包-解码-获取请求和响应-展开字段-将json格式的结果发送到Elasticsearch 无缝接入ELKPacketbeat是ELK Stack全家桶中的一员，可以和ELK无缝协同工作。例如使用Logstash二次处理数据，用Elasticsearch分析，或者用Kibana创建和共享仪表盘。 WinlogbeatWinlogbeat是一个轻量级的Windows事件日志收集工具。将Windows事件发送到Elasticsearch或者Logstash 从任何Windows事件日志通道(Channel)读取如果你有Windows服务器的话，其实可以从Windows事件日志中看到很多东西。例如，登陆(4624),登陆失败(4625),插入USB便携设备(4663)或者新装软件(11707)。WinlogBeat可以配置从任何事件日志通道读取并且结构化提供原始事件数据。使得通过Elasticsearch过滤和聚合结果变得很容易。 无缝接入ELKWinlogbeat是ELK Stack全家桶中的一员，可以和ELK无缝协同工作。例如使用Logstash二次处理数据，用Elasticsearch分析，或者用Kibana创建和共享仪表盘。 HeartbeatHeartbeat 是一个心跳检测工具，主要监控服务的可用性。监控给定的地址是否可用(官网原话：对于给定的URL列表，Heartbeat就问一句，还活着没？活着吱一声。。。) 可以结合ELK Stack其他产品做进一步的分析 容易上手，配置简单不管你是测试同主机服务还是其他网络服务，Heartbeat都可以很轻松的生成正常运行时间和响应时间数据。而且修改配置不需要重启Heartbeat Ping你想Ping的任何东西Heartbeat通过ICMP,TCP,和HTTP进行ping，也支持TLS，身份验证（authentication ），和代理(proxies)。由于简单的DNS解析，你可以监控所有负载均衡的服务(原文:You can monitor all the hosts behind a load-balanced server thanks to simple DNS resolution) 动态添加和删除目标现如今基础设施，服务和主机经常动态调整。Heartbeat可以修改配置文件后自动加载(原文:Heartbeat makes it easy to automate the process of adding and removing monitoring targets via a simple, file-based interface.) 无缝接入ELKHeartbeat是ELK Stack全家桶中的一员，可以和ELK无缝协同工作。例如使用Logstash二次处理数据，用Elasticsearch分析，或者用Kibana创建和共享仪表盘。","tags":[{"name":"beats","slug":"beats","permalink":"https://anjia0532.github.io/tags/beats/"},{"name":"elk","slug":"elk","permalink":"https://anjia0532.github.io/tags/elk/"},{"name":"elkstack","slug":"elkstack","permalink":"https://anjia0532.github.io/tags/elkstack/"}]},{"title":"Spring3.0 Log4j转logback","date":"2017-02-28T14:54:44.000Z","path":"2017/02/28/springmvc-log4j-to-logback/","text":"公司项目用的还是Spring3.0.5,而目前Spring5.0 M3已发布。。。 为啥选择 logback 而不是log4j2 原因 log4j2 不支持动态改变logger的级别(生产环境不利于定位问题) log4j2 的JSONLayout 内置字段较少，且不支持自定义。 而且log4j2引以为傲的领先logback 10倍的吞吐量的情况在最新版本中(1.2.0+)已经不存在了。具体参见(需翻墙) FileAppender throughput 本文主要讲解，如何将spring3.0.5(非maven)由log4j迁移到slf4j+logback1.2.1 Mavenpom.xml中关键部分代码 &lt;properties&gt; &lt;!-- log相关 --&gt; &lt;slf4j.version&gt;1.7.24&lt;/slf4j.version&gt; &lt;logback.version&gt;1.2.1&lt;/logback.version&gt; &lt;!-- Spring监听 --&gt; &lt;logback-ext-spring.version&gt;0.1.4&lt;/logback-ext-spring.version&gt; &lt;!-- logback的logstash插件 --&gt; &lt;logstash-logback-encoder.version&gt;4.8&lt;/logstash-logback-encoder.version&gt; &lt;!-- 可以略去jackson的依赖， logstash-logback-encoder自带的版本较低，所以手动指定jackson版本--&gt; &lt;jackson.version&gt;2.8.6&lt;/jackson.version&gt; &lt;!-- 项目使用UTF-8字符集 --&gt; &lt;project.build.sourceEncoding&gt;UTF-8&lt;/project.build.sourceEncoding&gt; &lt;project.reporting.outputEncoding&gt;UTF-8&lt;/project.reporting.outputEncoding&gt; &lt;maven.compiler.encoding&gt;UTF-8&lt;/maven.compiler.encoding&gt;&lt;/properties&gt;&lt;dependencies&gt; &lt;!-- slf4j统一log接口 --&gt; &lt;dependency&gt; &lt;groupId&gt;org.slf4j&lt;/groupId&gt; &lt;artifactId&gt;slf4j-api&lt;/artifactId&gt; &lt;version&gt;$&#123;slf4j.version&#125;&lt;/version&gt; &lt;/dependency&gt; &lt;!-- slf4j接管 Apache Commons Logging --&gt; &lt;dependency&gt; &lt;groupId&gt;org.slf4j&lt;/groupId&gt; &lt;artifactId&gt;jcl-over-slf4j&lt;/artifactId&gt; &lt;version&gt;$&#123;slf4j.version&#125;&lt;/version&gt; &lt;/dependency&gt; &lt;!-- slf4j接管log4j --&gt; &lt;dependency&gt; &lt;groupId&gt;org.slf4j&lt;/groupId&gt; &lt;artifactId&gt;log4j-over-slf4j&lt;/artifactId&gt; &lt;version&gt;$&#123;slf4j.version&#125;&lt;/version&gt; &lt;/dependency&gt; &lt;!-- logback的Spring监听 --&gt; &lt;dependency&gt; &lt;groupId&gt;org.logback-extensions&lt;/groupId&gt; &lt;artifactId&gt;logback-ext-spring&lt;/artifactId&gt; &lt;version&gt;$&#123;logback-ext-spring.version&#125;&lt;/version&gt; &lt;/dependency&gt; &lt;!-- slf4j日志接口，logback具体实现 --&gt; &lt;dependency&gt; &lt;groupId&gt;ch.qos.logback&lt;/groupId&gt; &lt;artifactId&gt;logback-core&lt;/artifactId&gt; &lt;version&gt;$&#123;logback.version&#125;&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;ch.qos.logback&lt;/groupId&gt; &lt;artifactId&gt;logback-classic&lt;/artifactId&gt; &lt;version&gt;$&#123;logback.version&#125;&lt;/version&gt; &lt;/dependency&gt; &lt;!-- logback 日志输出到logstash的插件 --&gt; &lt;dependency&gt; &lt;groupId&gt;net.logstash.logback&lt;/groupId&gt; &lt;artifactId&gt;logstash-logback-encoder&lt;/artifactId&gt; &lt;version&gt;$&#123;logstash-logback-encoder.version&#125;&lt;/version&gt; &lt;/dependency&gt; &lt;!-- logstash-logback-encoder依赖的jackson版本较旧 --&gt; &lt;dependency&gt; &lt;groupId&gt;com.fasterxml.jackson.core&lt;/groupId&gt; &lt;artifactId&gt;jackson-core&lt;/artifactId&gt; &lt;version&gt;$&#123;jackson.version&#125;&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;com.fasterxml.jackson.core&lt;/groupId&gt; &lt;artifactId&gt;jackson-databind&lt;/artifactId&gt; &lt;version&gt;$&#123;jackson.version&#125;&lt;/version&gt; &lt;/dependency&gt;&lt;/dependencies&gt; 非Maven项目(有个小技巧，本地配有maven环境的情况下，将上面的关键代码贴到pom.xml保存成文件,cmd进入到pom.xml同目录，运行 mvn dependency:copy-dependencies -DoutputDirectory=lib 会自动将依赖包，复制到当前lib目录下)从中央仓库下载下列jar 到Spring MVC 项目的lib目录jackson-annotations-2.8.0.jarjackson-core-2.8.6.jarjackson-databind-2.8.6.jarjcl-over-slf4j-1.7.24.jarlog4j-over-slf4j-1.7.24.jarlogback-classic-1.2.1.jarlogback-core-1.2.1.jarlogback-ext-spring-0.1.4.jarlogstash-logback-encoder-4.8.jarslf4j-api-1.7.24.jar 解决jar冲突不管是maven还是非maven项目都需要删除类似log4j.jar,slf4j-log4j12-xxx.jar,旧版本的slf4j-api-xxx.jar和commons-logging.jar 确保不会有jar冲突 解决问题代码删除项目自定义的一些log工具类，e.g. StdoutListener,MyDailyRollingFileAppender 修改web.xml删除log4j相关配置删除以下代码 &lt;context-param&gt; &lt;param-name&gt;log4jConfigLocation&lt;/param-name&gt; &lt;param-value&gt;/WEB-INF/properties/log4j.xml&lt;/param-value&gt;&lt;/context-param&gt;&lt;listener&gt; &lt;listener-class&gt;org.springframework.web.util.Log4jConfigListener&lt;/listener-class&gt;&lt;/listener&gt; 删除相关的log4j.xml文件 添加logback相关配置&lt;context-param&gt; &lt;param-name&gt;logbackConfigLocation&lt;/param-name&gt; &lt;param-value&gt;WEB-INF/config/logback.xml&lt;/param-value&gt;&lt;/context-param&gt;&lt;listener&gt; &lt;listener-class&gt;ch.qos.logback.ext.spring.web.LogbackConfigListener&lt;/listener-class&gt;&lt;/listener&gt; logback.xml配置将下面的配置文件保存到 WEB-INF/config/logback.xml,注意修改项目名，logstash等相关配置 &lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt;&lt;configuration scan=\"false\" scanPeriod=\"60 seconds\" debug=\"false\"&gt; &lt;!-- log输出目录 --&gt; &lt;property name=\"LOG_HOME\" value=\"D:/logtest\" /&gt; &lt;!-- 项目名称 --&gt; &lt;property name=\"APP_NAME\" value=\"logtest\" /&gt; &lt;!-- 项目端口号 --&gt; &lt;property name=\"APP_PORT\" value=\"8080\" /&gt; &lt;!-- 控制台和文件的日志格式 --&gt; &lt;!-- %method和%line性能较低，如果不太介意打印的方法和行号，强烈建议取消 --&gt; &lt;property name=\"CONSOLE_LOG_PATTERN\" value=\"%date&#123;HH:mm:ss.SSS&#125;[%-5level]%logger.%method#%line - %msg%n\" /&gt; &lt;property name=\"FILE_LOG_PATTERN\" value=\"%date&#123;HH:mm:ss.SSS&#125;[%-5level]%logger.%method#%line - %msg%n\" /&gt; &lt;!-- Logstash 服务器地址和端口 --&gt; &lt;property name=\"LOGSTASH_SERVER\" value=\"\" /&gt; &lt;property name=\"LOGSTASH_PORT\" value=\"\" /&gt; &lt;logger name=\"org.springframework\" level=\"WARN\" /&gt; &lt;logger name=\"org.springframework.web\" level=\"WARN\" /&gt; &lt;logger name=\"org.springframework.security\" level=\"WARN\" /&gt; &lt;logger name=\"org.springframework.cache\" level=\"WARN\" /&gt; &lt;logger name=\"org.springframework.beans\" level=\"WARN\" /&gt; &lt;logger name=\"com.shunneng.logtest\" level=\"DEBUG\" /&gt; &lt;!-- 输出日志到控制台 --&gt; &lt;appender name=\"CONSOLE\" class=\"ch.qos.logback.core.ConsoleAppender\"&gt; &lt;!-- 控制台输出性能较低。只打印ERRROR,其他信息从日志或者elasticsearch查询 --&gt; &lt;filter class=\"ch.qos.logback.classic.filter.LevelFilter\"&gt; &lt;level&gt;ERROR&lt;/level&gt; &lt;onMatch&gt;ACCEPT&lt;/onMatch&gt; &lt;onMismatch&gt;DENY&lt;/onMismatch&gt; &lt;/filter&gt; &lt;encoder&gt; &lt;pattern&gt;$&#123;CONSOLE_LOG_PATTERN&#125;&lt;/pattern&gt; &lt;charset&gt;utf8&lt;/charset&gt; &lt;/encoder&gt; &lt;/appender&gt; &lt;!-- 输出日志到文件 --&gt; &lt;appender name=\"FILE\" class=\"ch.qos.logback.core.rolling.RollingFileAppender\"&gt; &lt;!-- 文件名称 --&gt; &lt;file&gt;$&#123;LOG_HOME&#125;/$&#123;APP_NAME&#125;.log&lt;/file&gt; &lt;!-- 编码字符集和日志格式 --&gt; &lt;encoder&gt; &lt;charset&gt;utf-8&lt;/charset&gt; &lt;pattern&gt;$&#123;FILE_LOG_PATTERN&#125;&lt;/pattern&gt; &lt;/encoder&gt; &lt;!-- 日志过大后，滚动输出日志 --&gt; &lt;rollingPolicy class=\"ch.qos.logback.core.rolling.FixedWindowRollingPolicy\"&gt; &lt;fileNamePattern&gt;$&#123;LOG_HOME&#125;/$&#123;APP_NAME&#125;.%i.log&lt;/fileNamePattern&gt; &lt;/rollingPolicy&gt; &lt;!-- 限定单日志大小 --&gt; &lt;triggeringPolicy class=\"ch.qos.logback.core.rolling.SizeBasedTriggeringPolicy\"&gt; &lt;MaxFileSize&gt;100MB&lt;/MaxFileSize&gt; &lt;/triggeringPolicy&gt; &lt;/appender&gt; &lt;!-- 日志输出到日志搜集框架 --&gt; &lt;appender name=\"LOGSTASH\" class=\"net.logstash.logback.appender.LogstashSocketAppender\"&gt; &lt;!-- logstash 服务地址 --&gt; &lt;host&gt;$&#123;LOGSTASH_SERVER&#125;&lt;/host&gt; &lt;!-- logstash 端口 --&gt; &lt;port&gt;$&#123;LOGSTASH_PORT&#125;&lt;/port&gt; &lt;!-- 自定义字段，增加项目名称和端口 --&gt; &lt;customFields&gt;&#123;\"app_name\":\"$&#123;APP_NAME&#125;\",\"app_port\":\"$&#123;APP_PORT&#125;\"&#125;&lt;/customFields&gt; &lt;/appender&gt; &lt;!-- 异步批量(512)打印日志，在异常关闭时，有可能会有部分日志丢失 --&gt; &lt;appender name=\"ASYNC\" class=\"ch.qos.logback.classic.AsyncAppender\"&gt; &lt;queueSize&gt;512&lt;/queueSize&gt; &lt;appender-ref ref=\"FILE\" /&gt; &lt;/appender&gt; &lt;!-- 允许动态修改日志级别 --&gt; &lt;contextListener class=\"ch.qos.logback.classic.jul.LevelChangePropagator\"&gt; &lt;resetJUL&gt;true&lt;/resetJUL&gt; &lt;/contextListener&gt; &lt;!-- 默认输出INFO级别日志 --&gt; &lt;root level=\"INFO\"&gt; &lt;appender-ref ref=\"CONSOLE\" /&gt; &lt;appender-ref ref=\"ASYNC\" /&gt; &lt;appender-ref ref=\"LOGSTASH\" /&gt; &lt;/root&gt;&lt;/configuration&gt; Java改造使用了jcl-over-slf4j和log4j-over-slf4j后原有方法不需要变更。但是建议在允许的情况下。改成slf4j的方法 ...import org.slf4j.Logger;import org.slf4j.LoggerFactory;...private final Logger logger = LoggerFactory.getLogger(Demo.class);log.info(\"这是一个&#123;&#125;信息\",\"info\"); //输出:这是一个info信息... 不建议使用logger.info(“这是一个”+”info”+”信息”); 原因在于，假设该logger设置的是error级别，程序走到这会先将输出信息toString后并拼接，但是因为不是error级别的，所以不输出。导致性能上的浪费。需要改成 if (logger.isInfoEnabled())&#123; logger.info(\"这是一个\"+\"info\"+\"信息\");&#125; 当然如果是常量字符串拼接，在编译时会自动优化成 这是一个info信息但是对于变量拼接，字符串拼接的缺点就体现出来了。（感兴趣的可以自行百度 string stringbuilder stringbuffer区别） 所以，建议使用 {}进行占位输出。如果是变量很多，使用Object[] 规范强烈建议阅读此文 写给开发者：记录日志的10个建议 英语原文(需翻墙)The 10 Commandments of Logging 以及 简书上的LOG使用规范（整理） 摘录其中部分内容 2. 你应在适当级别上进行logTRACE level: 如果使用在生产环境中，这是一个代码异味(code smell)。它可以用于开发过程中追踪bug，但不要提交到你的版本控制系统 DEBUG level: 把一切东西都记录在这里。这在debug过程中最常用到。我主张在进入生产阶段前减少debug语句的数量，只留下最有意义的部分，在调试(troubleshooting)的时候激活。 INFO level: 把用户行为(user-driven)和系统的特定行为(例如计划任务…) NOTICE level: 这是生产环境中使用的级别。把一切不认为是错误的，可以记录的事件都log起来 WARN level: 记录在这个级别的事件都有可能成为一个error。例如，一次调用数据库使用的时间超过了预设时间，或者内存缓存即将到达容量上限。这可以让你适当地发出警报，或者在调试时更好地理解系统在failure之前做了些什么 ERROR level: 把每一个错误条件都记录在这。例如API调用返回了错误，或是内部错误条件 FATAL level: 末日来了。它极少被用到，在实际程序中也不应该出现多少。在这个级别上进行log意味着程序要结束了。例如一个网络守护进程无法bind到socket上，那么它唯一能做的就只有log到这里，然后退出运行。 4. 你应该写有意义的log6. 你应该给log带上上下文7. 你应该用机器可解析的格式来打日志 对于需要打印的对象，一定注意重载对象的toString方法，或者使用commons-lang3包下的 ReflectionToStringBuilder.toString()和new ToStringBuilder() 其中 ReflectionToStringBuilder.toString() 打印的类似 lang.Foo@c2a132[name=foo,age=88,bar=lang.Bar@e102dc[name=bar]] 而 new ToStringBuilder()可以只打印部分属性new ToStringBuilder(this, ToStringStyle.MULTI_LINE_STYLE) .append(\"name\", name) .append(\"age\", age) .append(\"bar\", bar) .toString()","tags":[{"name":"springmvc","slug":"springmvc","permalink":"https://anjia0532.github.io/tags/springmvc/"},{"name":"logback","slug":"logback","permalink":"https://anjia0532.github.io/tags/logback/"},{"name":"log4j","slug":"log4j","permalink":"https://anjia0532.github.io/tags/log4j/"},{"name":"log","slug":"log","permalink":"https://anjia0532.github.io/tags/log/"}]},{"title":"elastalert微信报警","date":"2017-02-16T16:27:53.000Z","path":"2017/02/16/elastalert-wechat-plugin/","text":"针对国人微信使用率较高的情况，开发了三个ElastAlert微信插件(shell,python,java) 简介ElastAlert支持以下方式报警 Command Email JIRA OpsGenie SNS HipChat Slack Telegram Debug Stomp Email 优点是免费，可追溯(不手动删除情况下),配置方便。缺点是查看不及时(QQ邮箱除外，弹窗提示，我服)，阅读不方便，大部分人都是使用PC阅读邮件 使用Command调用短信接口推送短信，成本高，信息少且单一，不及时（停机时，丢失信息） 详细分析 参见 为何使用微信企业号团队号 ElastAlert Python 插件准备工作 Elasticsearch 5.2.0 ElastAlert 0.1.8 步骤具体ElastAlert安装以及使用Email报警，参见我写的另外一篇文章 ElastAlert 基于Elasticsearch的监控告警 $ cd ~/$ git clone https://github.com/Yelp/elastalert.git$ cd elastalert$ wget -P ~/elastalert/elastalert_modules/ wget https://raw.githubusercontent.com/anjia0532/elastalert-wechat-plugin/master/elastalert_modules/wechat_qiye_alert.py$ touch ~/elastalert/elastalert_modules/__init__.py$ cp config.yaml.example config.yaml$ vi example_rules/example_frequency.yaml # From example_rules/example_frequency.yaml#es_host: elasticsearch.example.com#es_port: 14900name: Example ruletype: frequencyindex: logstash-*num_events: 1timeframe: minutes: 1filter:- term: _type: \"test\"# (Required)# The alert is use when a match is foundalert:- \"elastalert_modules.wechat_qiye_alert.WeChatAlerter\"#后台登陆后【设置】-&gt;【权限管理】-&gt;【普通管理组】-&gt;【创建并设置通讯录和应用权限】-&gt;【CorpID，Secret】#设置微信企业号的appidcorp_id: xx#设置微信企业号的Secretsecret: xx#后台登陆后【应用中心】-&gt;【选择应用】-&gt;【应用id】#设置微信企业号应用idagent_id: xx#部门idparty_id: xx#用户微信号user_id: xx# 标签idtag_id: xx $ python -m elastalert.elastalert --verbose --rule example_rules/example_frequency.yaml$ curl -X POST 'http://127.0.0.1:9200/logstash-'$(date +%Y.%m.%d)'/test' -d '&#123;\"@timestamp\": \"'$(date +%Y-%m-%d'T'%T%z)'\",\"field\": \"value\"&#125;'INFO:elastalert:Starting upINFO:elastalert:Queried rule Example rule from 2017-02-16 17:16 CST to 2017-02-16 17:25 CST: 1 / 1 hits&#123;u'errcode': 0, u'errmsg': u'ok'&#125;INFO:elastalert:发送消息给 xxxINFO:elastalert:Ran Example rule from 2017-02-16 16:31 CST to 2017-02-16 17:25 CST: 1 query hits, 1 matches, 2 alerts sentINFO:elastalert:Sleeping for 57 seconds 部分代码参考 python与shell通过微信企业号发送消息 ElastAlert Command之java版准备工作 申请企业号 具体自行百度 安装Git Java 1.8+ Maven 步骤参见我的项目 anjia0532/weixin-qiye-alert","tags":[{"name":"elk","slug":"elk","permalink":"https://anjia0532.github.io/tags/elk/"},{"name":"elkstasck","slug":"elkstasck","permalink":"https://anjia0532.github.io/tags/elkstasck/"},{"name":"ElastAlert","slug":"ElastAlert","permalink":"https://anjia0532.github.io/tags/ElastAlert/"}]},{"title":"ElastAlert 基于Elasticsearch的监控告警","date":"2017-02-14T08:27:47.000Z","path":"2017/02/14/elasticsearch-elastalert/","text":"Elastalert是Yelp公司用python2写的一个报警框架(目前支持python2.6和2.7，不支持3.x),github地址为 https://github.com/Yelp/elastalert 环境Ubuntu 16.10(内核 4.8.0-37-generic) elasticsearch 5.2.0 logstash 5.2.0 kibana 5.2.0 依赖参见 http://elastalert.readthedocs.io/en/latest/running_elastalert.html#requirements Elasticsearch ISO8601 or Unix timestamped data Python 2.6 or 2.7 pip, see requirements.txt 安装Elastalert安装之前先运行 python --version查看python的版本 $ python --versionPython 2.7.12+#如果2.6或者2.7则正常，如果是3.x则需要改成python2.x#假设本机装了python 2和3 可以将/usr/bin/python的软连接指向 python2 下载最新elastalert并安装模块 $ git clone https://github.com/Yelp/elastalert.git$ sudo python setup.py install$ sudo pip install -r requirements.txt 安装完后，会在 /usr/local/bin/ 下生成4个elastalert命令$ ll /usr/local/bin/elastalert*-rwxr-xr-x 1 root root 396 2月 14 10:03 /usr/local/bin/elastalert-rwxr-xr-x 1 root root 422 2月 14 10:03 /usr/local/bin/elastalert-create-index-rwxr-xr-x 1 root root 430 2月 14 10:03 /usr/local/bin/elastalert-rule-from-kibana-rwxr-xr-x 1 root root 416 2月 14 10:03 /usr/local/bin/elastalert-test-rule 设置elasticsearch索引参见 setting-up-elasticsearch elastalert-create-index 这个命令会在elasticsearch创建索引，这不是必须的步骤，但是强烈建议创建。因为对于，审计，测试很有用，并且重启elastalert不影响计数和发送alert,默认情况下，创建的索引叫 elastalert_status $ elastalert-create-indexNew index name (Default elastalert_status)Name of existing index to copy (Default None)New index elastalert_status createdDone! 具体生成的数据，请参见 ElastAlert Metadata Index 设置配置文件和规则Rule$ cp ~/elastalert/config.yaml.example ~/elastalert/config.yaml$ vi ~/elastalert/config.yaml # This is the folder that contains the rule yaml files# Any .yaml file will be loaded as a rulerules_folder: example_rules# How often ElastAlert will query Elasticsearch# The unit can be anything from weeks to secondsrun_every: minutes: 1# ElastAlert will buffer results from the most recent# period of time, in case some log sources are not in real timebuffer_time: minutes: 15# The Elasticsearch hostname for metadata writeback# Note that every rule can have its own Elasticsearch hostes_host: 127.0.0.1# The Elasticsearch portes_port: 9200# Optional URL prefix for Elasticsearch#es_url_prefix: elasticsearch# Connect with TLS to Elasticsearch#use_ssl: True# Verify TLS certificates#verify_certs: True# GET request with body is the default option for Elasticsearch.# If it fails for some reason, you can pass 'GET', 'POST' or 'source'.# See http://elasticsearch-py.readthedocs.io/en/master/connection.html?highlight=send_get_body_as#transport# for details#es_send_get_body_as: GET# Option basic-auth username and password for Elasticsearch#es_username: someusername#es_password: somepassword# The index on es_host which is used for metadata storage# This can be a unmapped index, but it is recommended that you run# elastalert-create-index to set a mappingwriteback_index: elastalert_status# If an alert fails for some reason, ElastAlert will retry# sending the alert until this time period has elapsedalert_time_limit: days: 1 #注意将$&#123;userName&#125;替换成具体用户名vi /home/$&#123;userName&#125;/elastalert/example_rules/smtp_auth_file.yaml #发送邮件的邮箱user: xxx@163.com#不是邮箱密码，是设置的POP3密码password: xxx vi ~/elastalert/example_rules/example_frequency.yaml 参见 creating-a-rule# From example_rules/example_frequency.yaml#es_host: elasticsearch.example.com#es_port: 14900name: Example ruletype: frequencyindex: logstash-*#限定时间内，发生事件次数num_events: 1#限定时间刻度timeframe: #1分钟 minutes: 1filter:- query: query_string: query: \"field: value\"#SMTP协议的邮件服务器相关配置#smtp.163.com是网易163邮箱的smtp服务器#登陆163邮箱后，找到 【设置】&gt;【POP3/SMTP/IMAP】&gt;开启，然后设置【客户端授权密码】smtp_host: smtp.163.comsmtp_port: 25#用户认证文件，需要user和password两个属性#注意将$&#123;userName&#125;替换成具体用户名smtp_auth_file: /home/$&#123;userName&#125;/elastalert/example_rules/smtp_auth_file.yaml#回复给那个邮箱email_reply_to: xxx@163.com#从哪个邮箱发送from_addr: xxx@163.com# (Required)# The alert is use when a match is foundalert:- \"email\"# (required, email specific)# a list of email addresses to send alerts toemail:#接收报警邮件的邮箱- \"xxxx@qq.com\" 测试规则参见 Testing Your Rule elastalert-test-rule ~/elastalert/example_rules/example_frequency.yaml 具体配置，参见 commonconfig 运行$ cd ~/elastalert$ python -m elastalert.elastalert --verbose --rule example_frequency.yamlINFO:elastalert:Starting upINFO:elastalert:Queried rule Example rule from 2017-02-14 11:08 CST to 2017-02-14 11:09 CST: 0 / 0 hitsINFO:elastalert:Ran Example rule from 2017-02-14 11:08 CST to 2017-02-14 11:09 CST: 0 query hits, 0 matches, 0 alerts sentINFO:elastalert:Sleeping for 59 seconds $ curl -X POST \"http://127.0.0.1:9200/logstash-2017.02.14/test\" -d '&#123;\"@timestamp\": \"2017-02-14T03:10:46.000Z\",\"field\": \"value\"&#125;'# 返回 &#123;\"_index\":\"logstash-2017.02.14\",\"_type\":\"test\",\"_id\":\"AVo6oVCnFreCcJPhQqgX\",\"_version\":1,\"result\":\"created\",\"shards\":&#123;\"total\":2,\"successful\":1,\"failed\":0&#125;,\"created\":true&#125; @timestamp的时间是UTC时间，换算方式北京时间（东八区）减8小时，例如2017-02-14 11:21:50的UTC时间是 2017-02-14 03:21:50#如果正常，会输出如下信息INFO:elastalert:Queried rule Example rule from 2017-02-14 11:08 CST to 2017-02-14 11:19 CST: 2 / 2 hitsINFO:elastalert:Alert for Example rule at 2017-02-14T03:10:46Z:INFO:elastalert:Example ruleAt least 1 events occurred between 2017-02-14 11:09 CST and 2017-02-14 11:10 CST@timestamp: 2017-02-14T03:10:46Z_id: AVo6oVCnFreCcJPhQqgX_index: logstash-2017.02.14_type: testfield: valuenum_hits: 2num_matches: 1INFO:elastalert:Sent email to ['xxx@qq.com']INFO:elastalert:Ran Example rule from 2017-02-14 11:08 CST to 2017-02-14 11:19 CST: 2 query hits, 1 matches, 2 alerts sentINFO:elastalert:Sleeping for 59 seconds Alert","tags":[{"name":"elk","slug":"elk","permalink":"https://anjia0532.github.io/tags/elk/"},{"name":"elkstasck","slug":"elkstasck","permalink":"https://anjia0532.github.io/tags/elkstasck/"},{"name":"ElastAlert","slug":"ElastAlert","permalink":"https://anjia0532.github.io/tags/ElastAlert/"}]},{"title":"synergy 一套键鼠多台设备共享","date":"2017-02-08T17:44:28.000Z","path":"2017/02/08/share-mouse-and-keyboard-with-your-windows-linux-machines-md/","text":"Synergy 可以在多台电脑之间共享鼠标、键盘、剪贴板。开源，跨 Win、Linux、Mac。 Synergy 需要注意不是远控软件，类似双屏或者KVM切换器，只是共享鼠标和键盘. 具体关于synergy的介绍可以看 Synergy 一套键鼠同时控制多台电脑的神器！超级方便！开源免费，支持(Win/Mac/Linux) Synergy – 教你在局域网中用一套键盘/鼠标控制多台电脑 想必很多人都拥有多台电脑，譬如台式机+笔记本，很多时候我们都会同时打开它们工作。可是你有没发现，如果桌子上摆放着多台电脑多套键盘鼠标，不停来回切换使用是否很累呢？如果说现在可以只用一套键鼠，就能同时控制你全部的电脑，你会否兴奋？ Synergy 正是为此而生的好工具！它可以让你的多台电脑共享一套键鼠，甚至还可以共享剪贴板，而你只需动动鼠标，指针就可以轻松地在各台电脑屏幕之间来回穿梭，就像一台电脑使用多个显示器一样。而且 Synergy 完全免费开源，并跨平台支持 Win/Mac/Linux，相当给力！ 使用之后，工作效率提高，腿不酸腰不疼，桌面也干净了，绝对是绝世神器啊！ 但是该文章中的版本较旧，本着折腾的态度，终于搞定2台PC（Ubuntu Zesty Zapus + Windows10 1607版），安装最新版并且免费使用。 下载最新稳定版本最新稳定版本按照需要下载指定版本 比如我下载的 synergy-v1.8.8-stable-Windows-x64.msi 和 synergy-v1.8.8-stable-Linux-x86_64.deb 获取序列号Synergy and Serial Number Activation Key for SSL security - Reverse Engineering the source code (easy) 安装windows版本千万注意安装和运行时，退出360，否则会卡死，妈的，被坑的很惨 安装步骤 有个地方选择语言，因为已经安装过了，无法截图，可参见 http://www.veryhuo.com/down/html/90189.html 设置服务器 安装Ubuntu# synergy 依赖 libavahi-compat-libdnssd1# 但是从sudo apt install -y libavahi-compat-libdnssd1 会提示找不到已废弃# 所以手动下载# 从https://www.ubuntuupdates.org/package_metas?utf8=%E2%9C%93&amp;q=libavahi-compat-libdnssd1 找最新的下载wget http://security.ubuntu.com/ubuntu/pool/main/a/avahi/libavahi-compat-libdnssd1_0.6.32-1ubuntu1_amd64.deb #ubuntu 16.10 版本wget https://github.com/brahma-dev/synergy-stable-builds/releases/download/v1.8.8-stable/synergy-v1.8.8-stable-Linux-x86_64.debsudo dpkg -i libavahi-compat-libdnssd1_0.6.32-1ubuntu1_amd64.deb# 此时如果提示依赖项未安装，则执行# sudo apt-get update # 更新# sudo apt-get -f install # 解决依赖关系# sudo dpkg -i xxx.deb # 重新安装sudo dpkg -i synergy-v1.8.8-stable-Linux-x86_64.debnohup synergy &amp; synergy启动后取消自动配置，手动填写server ip 注意如果在server端未设置client，client会一直报错 client和server需要在一个局域网里，否则无法连接。如果网速慢的话，server控制client会出现卡顿现象 如果在一个局域网但是不是一个网段，无法直接ping通可以通过端口映射e.g. Ngrok等软件进行端口映射","tags":[{"name":"synergy","slug":"synergy","permalink":"https://anjia0532.github.io/tags/synergy/"}]},{"title":"hexo搭建博客","date":"2017-02-03T16:07:16.000Z","path":"2017/02/03/hexo-github-pages-blog/","text":"本文主要讲解如何通过github pages功能从零开始搭建一个炫酷的个人技术博客 配置环境Nodejs安装Nodejs 默认安装在c盘,具体的默认参数可以通过 npm config ls -l 进行查看,输出类似下面的信息, 注意 ; ... 开头的都是注释内容,不生效 ; cli configslong = truescope = \"\"user-agent = \"npm/4.0.5 node/v7.4.0 win32 x64\"; builtin config undefined; prefix = \"C:\\\\Users\\\\&#123;userName&#125;\\\\AppData\\\\Roaming\\\\npm\" (overridden); cache = \"C:\\\\Users\\\\&#123;userName&#125;\\\\AppData\\\\Roaming\\\\npm-cache\" (overridden)cache-lock-retries = 10cache-lock-stale = 60000cache-lock-wait = 10000cache-max = null 修改默认库路径 npm config set cache \"$&#123;NodejsHome&#125;\\node_cache\" # 将$&#123;NodejsHome&#125;换成实际安装路径npm config set prefix \"$&#123;NodejsHome&#125;\" npm config set prefix 设置成安装路径的好处是 npm install -g xxx 安装的库在执行时不会报命令找不到(否则还需要改系统的Path环境变量) 天朝网络环境比较差,需要使用 淘宝npm镜像 npm install -g cnpm --registry=https://registry.npm.taobao.org 安装成功后,以后使用npm install的统统可以改成cnpm install Git下载地址: http://git-scm.com/download/ Hexocd d:\\blog # 创建目录cnpm install hexo-cli -g # 全局安装hexohexo init # 初始化当前目录(hexo init blog 创建blog并初始化)cnpm install # 使用淘宝npm镜像加载依赖hexo g # 生成静态代码hexo s # 启动服务,在http://localhost:4000/查看 打开 http://localhost:4000/ 已经可以看到默认的一篇blog了 # 命令缩写hexo n == hexo newhexo g == hexo generatehexo s == hexo serverhexo d == hexo deploy# 命令组合hexo d -g # 生成并部署hexo s -g # 生成并本地预览 如果是windows打开git-bash.exe GitHub 配置生成rsa文件ssh-keygen# 输入编译代码Enter file in which to save the key (/c/Users/&#123;userName&#125;/.ssh/id_rsa): # rsakey文件名,假设使用默认的id_rsaEnter passphrase (empty for no passphrase): # 密码Enter same passphrase again: #确认密码 文本编辑器打开 ~/.ssh/id_rsa.pub 并复制内容ssh-rsaxxxx 具体的key xxxxxx userName@email github 设置ssh key左上角 用户-&gt;settings-&gt;Personal settings-&gt;SSH and GPG keys-&gt;New SSH key-&gt;Title 随意-&gt;Key 贴上一步的ssh-rsa开头的一串文本 -&gt;Add SSH key 创建仓库左上角 用户旁边 + 号-&gt;New repository-&gt;Repository name 填${userName}.github.io ${userName}为账号名-&gt;Create repository 提交github并自动发布提交代码到githubgit init # 初始化本地仓库git add . # 添加文件git commit -m '初始化' # 提交到本地仓库并指定messagegit checkout -b blog-source # 创建分支,为了使用 travis-ci 自动构建git remote add origin git@github.com:$&#123;userName&#125;/$&#123;userName&#125;.github.io.git # 添加远程仓库地址 将 $&#123;userName&#125; 替换成实际账户名git push origin blog-source:blog-source # 推送到github远程仓库分支 创建 .travis.yml 文件language: node_jsnode_js: stable# S: Build Lifecycleinstall: - npm installbefore_script: - npm install hexo-helper-qrcode --save - npm install hexo-generator-feed --savescript: - hexo gafter_script: - cd ./public # 如果设置自定义域名,则自动生成CNAME文件 - if [ $MY_DOMAIN ]; then echo $&#123;MY_DOMAIN&#125; &gt; CNAME; fi - git init - git config user.name \"$&#123;userName&#125;\" - git config user.email \"$&#123;email&#125;\" - git add . - git commit -m \"Update docs\" - git push --force --quiet \"https://$&#123;GH_TOKEN&#125;@$&#123;GH_REF&#125;\" master:masterbranches: only: - blog-sourceenv: global: - GH_REF: github.com/$&#123;userName&#125;/$&#123;userName&#125;.github.io.git # 自定义域名 - MY_DOMAIN: anjia.ml 将${userName}和${email}替换成实际值 参考 简书-手把手教你使用Travis CI自动部署你的Hexo博客到Github上 通过travis自动构建并发布 使用https 自定义域名开启 Github Pages 自定义域名 HTTPS 和 HTTP/2 支持​","tags":[{"name":"blog","slug":"blog","permalink":"https://anjia0532.github.io/tags/blog/"},{"name":"hexo","slug":"hexo","permalink":"https://anjia0532.github.io/tags/hexo/"}]},{"title":"博客模板","date":"2010-08-01T11:35:21.000Z","path":"2010/08/01/rbfk67/","text":"这是坚持技术写作计划（含翻译）的第 70 篇，定个小目标 999，每周最少 2 篇。 本文 招聘小广告山东济南的小伙伴欢迎投简历啊 加入我们 , 一起搞事情。长期招聘，Java 程序员，大数据工程师，运维工程师，前端工程师。 参考资料 我的博客 我的掘金","tags":[]}]